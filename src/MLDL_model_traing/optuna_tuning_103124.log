2024-10-31 01:22:45,417 - INFO - Trial 0: Train MSE=1.128563744681222, Train R²=0.8122617942946297
2024-10-31 01:22:45,418 - INFO - Trial 0: Test MSE=2.391941726207733, Test R²=0.6078067719936371
2024-10-31 01:22:45,418 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:23:23,384 - INFO - Trial 1: Train MSE=1.1519915504114968, Train R²=0.8083500989845821
2024-10-31 01:23:23,384 - INFO - Trial 1: Test MSE=2.56627242905753, Test R²=0.5828624197414943
2024-10-31 01:23:23,384 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:23:56,513 - INFO - Trial 2: Train MSE=3.2384531838553294, Train R²=0.46057269615786417
2024-10-31 01:23:56,514 - INFO - Trial 2: Test MSE=2.270256314958845, Test R²=0.6305238434246608
2024-10-31 01:23:56,514 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:24:28,730 - INFO - Trial 3: Train MSE=1.7826328788484846, Train R²=0.7035035490989685
2024-10-31 01:24:28,730 - INFO - Trial 3: Test MSE=2.723130702972412, Test R²=0.5534303337335587
2024-10-31 01:24:28,730 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:25:16,219 - INFO - Trial 4: Train MSE=1.125473482268197, Train R²=0.8129804730415344
2024-10-31 01:25:16,219 - INFO - Trial 4: Test MSE=2.3747497967311313, Test R²=0.6132715174130031
2024-10-31 01:25:16,219 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:25:47,787 - INFO - Trial 5: Train MSE=5.445538180215018, Train R²=0.09495720267295837
2024-10-31 01:25:47,787 - INFO - Trial 5: Test MSE=2.6025391817092896, Test R²=0.5735529810190201
2024-10-31 01:25:47,787 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:26:58,929 - INFO - Trial 6: Train MSE=2.1659977084824016, Train R²=0.6330098610903535
2024-10-31 01:26:58,929 - INFO - Trial 6: Test MSE=2.4310970093522752, Test R²=0.5986739099025726
2024-10-31 01:26:58,929 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:27:22,733 - INFO - Trial 7: Train MSE=0.7619488494736808, Train R²=0.873390964099339
2024-10-31 01:27:22,733 - INFO - Trial 7: Test MSE=2.4607259035110474, Test R²=0.596337616443634
2024-10-31 01:27:22,733 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:28:25,053 - INFO - Trial 8: Train MSE=0.632004229085786, Train R²=0.8945958720786231
2024-10-31 01:28:25,053 - INFO - Trial 8: Test MSE=2.498436450958252, Test R²=0.5914708248206547
2024-10-31 01:28:25,053 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:30:07,977 - INFO - Trial 9: Train MSE=2.0716224536299706, Train R²=0.6495871022343636
2024-10-31 01:30:07,978 - INFO - Trial 9: Test MSE=2.398819931915828, Test R²=0.6031741521188191
2024-10-31 01:30:07,978 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:30:43,090 - INFO - Trial 10: Train MSE=5.528779591832842, Train R²=0.07845442635672432
2024-10-31 01:30:43,090 - INFO - Trial 10: Test MSE=3.406125443322318, Test R²=0.4458014794758388
2024-10-31 01:30:43,090 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:31:15,380 - INFO - Trial 11: Train MSE=3.3492619821003506, Train R²=0.4428133943251201
2024-10-31 01:31:15,380 - INFO - Trial 11: Test MSE=2.289835844721113, Test R²=0.6272320577076503
2024-10-31 01:31:15,380 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:31:59,674 - INFO - Trial 12: Train MSE=4.322522018636976, Train R²=0.2808937728404999
2024-10-31 01:31:59,674 - INFO - Trial 12: Test MSE=2.5005147457122803, Test R²=0.5932815670967102
2024-10-31 01:31:59,674 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:32:39,989 - INFO - Trial 13: Train MSE=3.4964915088244846, Train R²=0.41754648089408875
2024-10-31 01:32:39,989 - INFO - Trial 13: Test MSE=2.458282845360892, Test R²=0.5999941059521267
2024-10-31 01:32:39,989 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:33:42,836 - INFO - Trial 14: Train MSE=2.6206121615001132, Train R²=0.5621277455772672
2024-10-31 01:33:42,836 - INFO - Trial 14: Test MSE=2.399476110935211, Test R²=0.6072004778044564
2024-10-31 01:33:42,836 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:34:31,537 - INFO - Trial 15: Train MSE=4.203698635101318, Train R²=0.29666987487248014
2024-10-31 01:34:31,537 - INFO - Trial 15: Test MSE=2.6586126599993025, Test R²=0.5674605199268886
2024-10-31 01:34:31,537 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:35:11,994 - INFO - Trial 16: Train MSE=1.4020128548145294, Train R²=0.7662551764930997
2024-10-31 01:35:11,994 - INFO - Trial 16: Test MSE=2.316169261932373, Test R²=0.6231117844581604
2024-10-31 01:35:11,994 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:35:45,805 - INFO - Trial 17: Train MSE=3.5603099380220686, Train R²=0.40663241914340426
2024-10-31 01:35:45,805 - INFO - Trial 17: Test MSE=2.3746373994009837, Test R²=0.6135355234146118
2024-10-31 01:35:45,806 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:36:49,193 - INFO - Trial 18: Train MSE=1.8720420130661555, Train R²=0.6871169922607285
2024-10-31 01:36:49,194 - INFO - Trial 18: Test MSE=2.27155647959028, Test R²=0.6285218894481659
2024-10-31 01:36:49,194 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:37:50,530 - INFO - Trial 19: Train MSE=1.575766914657184, Train R²=0.7359251784426826
2024-10-31 01:37:50,530 - INFO - Trial 19: Test MSE=2.3305357694625854, Test R²=0.6185608931950161
2024-10-31 01:37:50,530 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:38:47,655 - INFO - Trial 20: Train MSE=1.210996504340853, Train R²=0.7975036331585476
2024-10-31 01:38:47,655 - INFO - Trial 20: Test MSE=2.386968799999782, Test R²=0.6087923858846936
2024-10-31 01:38:47,655 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:39:56,829 - INFO - Trial 21: Train MSE=2.2818829395941327, Train R²=0.6176804889525686
2024-10-31 01:39:56,830 - INFO - Trial 21: Test MSE=2.248301727431161, Test R²=0.6324667206832341
2024-10-31 01:39:56,830 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:41:05,064 - INFO - Trial 22: Train MSE=1.729771375656128, Train R²=0.7112118612442698
2024-10-31 01:41:05,064 - INFO - Trial 22: Test MSE=2.299329629966191, Test R²=0.6239436098507473
2024-10-31 01:41:05,064 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:41:53,515 - INFO - Trial 23: Train MSE=3.3600485708032335, Train R²=0.43997128840003696
2024-10-31 01:41:53,515 - INFO - Trial 23: Test MSE=2.7493180547441756, Test R²=0.5497096606663295
2024-10-31 01:41:53,515 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:43:01,798 - INFO - Trial 24: Train MSE=1.4155744633504324, Train R²=0.7627920902201107
2024-10-31 01:43:01,798 - INFO - Trial 24: Test MSE=2.359564925943102, Test R²=0.6135531067848206
2024-10-31 01:43:01,798 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:44:10,428 - INFO - Trial 25: Train MSE=1.395412483385631, Train R²=0.7656509120549474
2024-10-31 01:44:10,429 - INFO - Trial 25: Test MSE=2.351610149656023, Test R²=0.6150705303464618
2024-10-31 01:44:10,429 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:45:29,451 - INFO - Trial 26: Train MSE=3.404320478439331, Train R²=0.42536938935518265
2024-10-31 01:45:29,451 - INFO - Trial 26: Test MSE=2.816460362502507, Test R²=0.5313123379434858
2024-10-31 01:45:29,451 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:46:21,178 - INFO - Trial 27: Train MSE=2.334052813904626, Train R²=0.6099834793380329
2024-10-31 01:46:21,178 - INFO - Trial 27: Test MSE=2.3553877898624966, Test R²=0.6137036468301501
2024-10-31 01:46:21,178 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:47:19,097 - INFO - Trial 28: Train MSE=2.1527571380138397, Train R²=0.6403378280145782
2024-10-31 01:47:19,097 - INFO - Trial 28: Test MSE=2.259375172001975, Test R²=0.6299865118094853
2024-10-31 01:47:19,097 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:49:04,284 - INFO - Trial 29: Train MSE=2.4999643713235855, Train R²=0.580767325524773
2024-10-31 01:49:04,284 - INFO - Trial 29: Test MSE=2.340231720890318, Test R²=0.6122805944510868
2024-10-31 01:49:04,284 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:49:35,387 - INFO - Trial 30: Train MSE=2.8357251031058177, Train R²=0.5284637468201774
2024-10-31 01:49:35,387 - INFO - Trial 30: Test MSE=2.2753772139549255, Test R²=0.6271035373210907
2024-10-31 01:49:35,387 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:50:32,781 - INFO - Trial 31: Train MSE=2.3133131052766527, Train R²=0.6121717542409897
2024-10-31 01:50:32,782 - INFO - Trial 31: Test MSE=2.271859245640891, Test R²=0.6283329895564488
2024-10-31 01:50:32,782 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:51:30,670 - INFO - Trial 32: Train MSE=0.8889525703021458, Train R²=0.8509025520512036
2024-10-31 01:51:30,670 - INFO - Trial 32: Test MSE=2.3915902631623402, Test R²=0.6082943890775953
2024-10-31 01:51:30,670 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:52:27,973 - INFO - Trial 33: Train MSE=3.352971021618162, Train R²=0.43844858024801525
2024-10-31 01:52:27,974 - INFO - Trial 33: Test MSE=2.3886057138442993, Test R²=0.6092025084154946
2024-10-31 01:52:27,974 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:53:29,433 - INFO - Trial 34: Train MSE=1.6996651270559855, Train R²=0.7128949803965432
2024-10-31 01:53:29,433 - INFO - Trial 34: Test MSE=2.3220215950693404, Test R²=0.6202952265739441
2024-10-31 01:53:29,433 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:54:25,399 - INFO - Trial 35: Train MSE=1.341678717306682, Train R²=0.774086132645607
2024-10-31 01:54:25,399 - INFO - Trial 35: Test MSE=2.320348697049277, Test R²=0.6202573435647147
2024-10-31 01:54:25,399 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:54:56,896 - INFO - Trial 36: Train MSE=4.783174276351929, Train R²=0.2059158342225211
2024-10-31 01:54:56,896 - INFO - Trial 36: Test MSE=2.508412003517151, Test R²=0.5889697968959808
2024-10-31 01:54:56,896 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:55:44,455 - INFO - Trial 37: Train MSE=1.0833924753325326, Train R²=0.8183823951653072
2024-10-31 01:55:44,456 - INFO - Trial 37: Test MSE=2.364799806049892, Test R²=0.6126667516572135
2024-10-31 01:55:44,456 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:56:17,341 - INFO - Trial 38: Train MSE=1.7070986713681902, Train R²=0.7165100617068154
2024-10-31 01:56:17,341 - INFO - Trial 38: Test MSE=2.3316659331321716, Test R²=0.6176570504903793
2024-10-31 01:56:17,341 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:57:39,015 - INFO - Trial 39: Train MSE=1.984926130090441, Train R²=0.6647857762873173
2024-10-31 01:57:39,015 - INFO - Trial 39: Test MSE=2.318788468837738, Test R²=0.61554397216865
2024-10-31 01:57:39,015 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:58:27,703 - INFO - Trial 40: Train MSE=1.4751238312040056, Train R²=0.7527332039816039
2024-10-31 01:58:27,703 - INFO - Trial 40: Test MSE=2.4314091375895908, Test R²=0.6012930997780391
2024-10-31 01:58:27,703 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 01:59:12,300 - INFO - Trial 41: Train MSE=2.3984881596905843, Train R²=0.5978001302906445
2024-10-31 01:59:12,300 - INFO - Trial 41: Test MSE=2.294474354812077, Test R²=0.6246659329959324
2024-10-31 01:59:12,300 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:00:09,932 - INFO - Trial 42: Train MSE=2.548386995281492, Train R²=0.5727153814264706
2024-10-31 02:00:09,932 - INFO - Trial 42: Test MSE=2.272706185068403, Test R²=0.6284971535205841
2024-10-31 02:00:09,932 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:01:07,846 - INFO - Trial 43: Train MSE=3.650419648204531, Train R²=0.3901769093104771
2024-10-31 02:01:07,846 - INFO - Trial 43: Test MSE=2.467123508453369, Test R²=0.5960734273706164
2024-10-31 02:01:07,846 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:01:43,883 - INFO - Trial 44: Train MSE=3.100181426320757, Train R²=0.4834801490817751
2024-10-31 02:01:43,884 - INFO - Trial 44: Test MSE=2.4399505342756, Test R²=0.6028520890644619
2024-10-31 02:01:43,884 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:02:41,577 - INFO - Trial 45: Train MSE=3.264743072646005, Train R²=0.4547884187528065
2024-10-31 02:02:41,577 - INFO - Trial 45: Test MSE=2.5127576930182323, Test R²=0.5887618703501565
2024-10-31 02:02:41,577 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:03:20,876 - INFO - Trial 46: Train MSE=3.5571913548878262, Train R²=0.4090622067451477
2024-10-31 02:03:20,876 - INFO - Trial 46: Test MSE=2.4834568159920827, Test R²=0.5959113240242004
2024-10-31 02:03:20,876 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:04:08,286 - INFO - Trial 47: Train MSE=2.695779114961624, Train R²=0.5474478283098766
2024-10-31 02:04:08,286 - INFO - Trial 47: Test MSE=2.3158636263438632, Test R²=0.6216752656868526
2024-10-31 02:04:08,286 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:04:43,687 - INFO - Trial 48: Train MSE=3.1736506649426053, Train R²=0.4726032742432186
2024-10-31 02:04:43,688 - INFO - Trial 48: Test MSE=2.3376396042960033, Test R²=0.6195387073925563
2024-10-31 02:04:43,688 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:05:17,764 - INFO - Trial 49: Train MSE=3.1071605341775075, Train R²=0.4835059174469539
2024-10-31 02:05:17,764 - INFO - Trial 49: Test MSE=2.3108327388763428, Test R²=0.6210252493619919
2024-10-31 02:05:17,764 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:06:54,386 - INFO - Trial 50: Train MSE=2.096485153904983, Train R²=0.644795400755746
2024-10-31 02:06:54,386 - INFO - Trial 50: Test MSE=2.3324232612337386, Test R²=0.6134972551039287
2024-10-31 02:06:54,386 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:07:52,159 - INFO - Trial 51: Train MSE=1.9965053009135383, Train R²=0.666813245841435
2024-10-31 02:07:52,159 - INFO - Trial 51: Test MSE=2.2437293274062022, Test R²=0.6328664762633187
2024-10-31 02:07:52,159 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:08:49,789 - INFO - Trial 52: Train MSE=2.5244524564061845, Train R²=0.5786238067916462
2024-10-31 02:08:49,789 - INFO - Trial 52: Test MSE=2.262037294251578, Test R²=0.6300787925720215
2024-10-31 02:08:49,789 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:09:47,120 - INFO - Trial 53: Train MSE=2.6699017584323883, Train R²=0.554228598518031
2024-10-31 02:09:47,120 - INFO - Trial 53: Test MSE=2.251893843923296, Test R²=0.6320069985730308
2024-10-31 02:09:47,120 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:10:44,498 - INFO - Trial 54: Train MSE=2.27207966361727, Train R²=0.6196334425892148
2024-10-31 02:10:44,498 - INFO - Trial 54: Test MSE=2.272906448159899, Test R²=0.6281318621976035
2024-10-31 02:10:44,498 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:11:41,867 - INFO - Trial 55: Train MSE=2.7164218383175984, Train R²=0.5453735589981079
2024-10-31 02:11:41,867 - INFO - Trial 55: Test MSE=2.27403062582016, Test R²=0.6284265177590507
2024-10-31 02:11:41,867 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:12:21,574 - INFO - Trial 56: Train MSE=2.2382694610527585, Train R²=0.6284157782793045
2024-10-31 02:12:21,574 - INFO - Trial 56: Test MSE=2.2361366408211842, Test R²=0.6360931651932853
2024-10-31 02:12:21,574 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:13:00,264 - INFO - Trial 57: Train MSE=2.4552136063575745, Train R²=0.5912625981228692
2024-10-31 02:13:00,264 - INFO - Trial 57: Test MSE=2.2338777439934865, Test R²=0.6363414781434196
2024-10-31 02:13:00,264 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:13:38,928 - INFO - Trial 58: Train MSE=2.3881033829280307, Train R²=0.603177221758025
2024-10-31 02:13:38,928 - INFO - Trial 58: Test MSE=2.211223670414516, Test R²=0.6399579473904201
2024-10-31 02:13:38,928 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:14:18,002 - INFO - Trial 59: Train MSE=2.336299342768533, Train R²=0.6108036296708244
2024-10-31 02:14:18,003 - INFO - Trial 59: Test MSE=2.266122817993164, Test R²=0.6311135462352208
2024-10-31 02:14:18,003 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:14:56,543 - INFO - Trial 60: Train MSE=2.4784236890929088, Train R²=0.5866487600973674
2024-10-31 02:14:56,543 - INFO - Trial 60: Test MSE=2.3007127216884067, Test R²=0.6256360752241952
2024-10-31 02:14:56,543 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:15:35,606 - INFO - Trial 61: Train MSE=2.4100633774484908, Train R²=0.5987739477838788
2024-10-31 02:15:35,606 - INFO - Trial 61: Test MSE=2.2323156084333147, Test R²=0.6366435033934457
2024-10-31 02:15:35,606 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:16:14,595 - INFO - Trial 62: Train MSE=2.321806298834937, Train R²=0.6142081107412066
2024-10-31 02:16:14,595 - INFO - Trial 62: Test MSE=2.241260085787092, Test R²=0.6351815462112427
2024-10-31 02:16:14,595 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:16:53,316 - INFO - Trial 63: Train MSE=2.455451105322157, Train R²=0.5914952733686992
2024-10-31 02:16:53,316 - INFO - Trial 63: Test MSE=2.2485337938581194, Test R²=0.6338940943990435
2024-10-31 02:16:53,317 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:17:32,533 - INFO - Trial 64: Train MSE=2.193182783467429, Train R²=0.6356634497642517
2024-10-31 02:17:32,533 - INFO - Trial 64: Test MSE=2.3236614976610457, Test R²=0.621689532484327
2024-10-31 02:17:32,534 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:18:11,527 - INFO - Trial 65: Train MSE=2.0123577458517894, Train R²=0.6646268027169364
2024-10-31 02:18:11,527 - INFO - Trial 65: Test MSE=2.3005965437207903, Test R²=0.6257107342992511
2024-10-31 02:18:11,527 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:18:49,839 - INFO - Trial 66: Train MSE=2.3684308103152683, Train R²=0.6056825603757586
2024-10-31 02:18:49,839 - INFO - Trial 66: Test MSE=2.3118227890559604, Test R²=0.623715375150953
2024-10-31 02:18:49,839 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:19:29,465 - INFO - Trial 67: Train MSE=2.331183740070888, Train R²=0.6121228550161634
2024-10-31 02:19:29,465 - INFO - Trial 67: Test MSE=2.276402643748692, Test R²=0.6295090658324105
2024-10-31 02:19:29,465 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:20:06,900 - INFO - Trial 68: Train MSE=2.557538083621434, Train R²=0.5748018388237272
2024-10-31 02:20:06,900 - INFO - Trial 68: Test MSE=2.226038251604353, Test R²=0.6377358181135995
2024-10-31 02:20:06,900 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:20:44,393 - INFO - Trial 69: Train MSE=2.653952181339264, Train R²=0.5581707209348679
2024-10-31 02:20:44,393 - INFO - Trial 69: Test MSE=2.2876434666769847, Test R²=0.627758971282414
2024-10-31 02:20:44,393 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:21:20,493 - INFO - Trial 70: Train MSE=2.155094087123871, Train R²=0.6415853308779853
2024-10-31 02:21:20,493 - INFO - Trial 70: Test MSE=2.2430717093603953, Test R²=0.634864900793348
2024-10-31 02:21:20,493 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:21:58,297 - INFO - Trial 71: Train MSE=2.275043338537216, Train R²=0.6214501815182822
2024-10-31 02:21:58,297 - INFO - Trial 71: Test MSE=2.251728211130415, Test R²=0.6333696927343097
2024-10-31 02:21:58,297 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:22:33,574 - INFO - Trial 72: Train MSE=2.286746178354536, Train R²=0.619265656386103
2024-10-31 02:22:33,574 - INFO - Trial 72: Test MSE=2.259668861116682, Test R²=0.632248750754765
2024-10-31 02:22:33,574 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:23:12,218 - INFO - Trial 73: Train MSE=2.557670167514256, Train R²=0.5750191531011036
2024-10-31 02:23:12,218 - INFO - Trial 73: Test MSE=2.325176170894078, Test R²=0.6215426751545498
2024-10-31 02:23:12,218 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:23:50,733 - INFO - Trial 74: Train MSE=2.120700861726488, Train R²=0.6466382890939713
2024-10-31 02:23:50,733 - INFO - Trial 74: Test MSE=2.2994132041931152, Test R²=0.6258128796304975
2024-10-31 02:23:50,733 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:24:26,563 - INFO - Trial 75: Train MSE=2.100413032940456, Train R²=0.6503283253737858
2024-10-31 02:24:26,563 - INFO - Trial 75: Test MSE=2.2617399181638445, Test R²=0.6318418639046806
2024-10-31 02:24:26,563 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:25:04,080 - INFO - Trial 76: Train MSE=2.118045151233673, Train R²=0.6472190192767552
2024-10-31 02:25:04,080 - INFO - Trial 76: Test MSE=2.2639308316367015, Test R²=0.6312495129449027
2024-10-31 02:25:04,080 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:25:41,711 - INFO - Trial 77: Train MSE=1.9840547144412994, Train R²=0.669612609914371
2024-10-31 02:25:41,711 - INFO - Trial 77: Test MSE=2.27919670513698, Test R²=0.6290198223931449
2024-10-31 02:25:41,711 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:26:19,494 - INFO - Trial 78: Train MSE=1.451209898505892, Train R²=0.7584727555513382
2024-10-31 02:26:19,494 - INFO - Trial 78: Test MSE=2.3556625502450124, Test R²=0.6164384484291077
2024-10-31 02:26:19,494 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:26:56,404 - INFO - Trial 79: Train MSE=2.556186088493892, Train R²=0.5742037807192121
2024-10-31 02:26:56,404 - INFO - Trial 79: Test MSE=2.288882085255214, Test R²=0.627333436693464
2024-10-31 02:26:56,404 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:27:32,438 - INFO - Trial 80: Train MSE=2.1380206559385573, Train R²=0.6443884266274316
2024-10-31 02:27:32,438 - INFO - Trial 80: Test MSE=2.2475411551339284, Test R²=0.6343206678118024
2024-10-31 02:27:32,438 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:28:08,634 - INFO - Trial 81: Train MSE=2.1614560527460918, Train R²=0.6396668936525073
2024-10-31 02:28:08,634 - INFO - Trial 81: Test MSE=2.2333390031542097, Test R²=0.6364934359277997
2024-10-31 02:28:08,634 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:28:44,453 - INFO - Trial 82: Train MSE=2.1987612673214505, Train R²=0.6348192798239845
2024-10-31 02:28:44,453 - INFO - Trial 82: Test MSE=2.2442496844700406, Test R²=0.6346062677247184
2024-10-31 02:28:44,453 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:29:20,508 - INFO - Trial 83: Train MSE=2.133667839424951, Train R²=0.6445505895784923
2024-10-31 02:29:20,508 - INFO - Trial 83: Test MSE=2.271603618349348, Test R²=0.6300519364220756
2024-10-31 02:29:20,508 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:29:56,239 - INFO - Trial 84: Train MSE=2.1226685558046614, Train R²=0.6470712146588734
2024-10-31 02:29:56,240 - INFO - Trial 84: Test MSE=2.252210889543806, Test R²=0.6336235744612557
2024-10-31 02:29:56,240 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:30:32,335 - INFO - Trial 85: Train MSE=2.3827842388834273, Train R²=0.6039238891431263
2024-10-31 02:30:32,335 - INFO - Trial 85: Test MSE=2.2870565141950334, Test R²=0.6276954157011849
2024-10-31 02:30:32,335 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:31:11,432 - INFO - Trial 86: Train MSE=2.690844646521977, Train R²=0.5513216789279666
2024-10-31 02:31:11,432 - INFO - Trial 86: Test MSE=2.2668967247009277, Test R²=0.6310561129025051
2024-10-31 02:31:11,432 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:31:48,862 - INFO - Trial 87: Train MSE=2.158047710146223, Train R²=0.6411143775497165
2024-10-31 02:31:48,862 - INFO - Trial 87: Test MSE=2.2740223748343333, Test R²=0.6296024152210781
2024-10-31 02:31:48,862 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:33:22,046 - INFO - Trial 88: Train MSE=2.409822159579822, Train R²=0.5891835620360715
2024-10-31 02:33:22,046 - INFO - Trial 88: Test MSE=2.2695456785815105, Test R²=0.6237198242119381
2024-10-31 02:33:22,046 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:34:00,353 - INFO - Trial 89: Train MSE=2.2324229521410808, Train R²=0.6286208842481885
2024-10-31 02:34:00,353 - INFO - Trial 89: Test MSE=2.2909046581813266, Test R²=0.6270900198391506
2024-10-31 02:34:00,354 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:34:40,385 - INFO - Trial 90: Train MSE=2.441926990236555, Train R²=0.5940833049161094
2024-10-31 02:34:40,386 - INFO - Trial 90: Test MSE=2.3255199193954468, Test R²=0.6188334822654724
2024-10-31 02:34:40,386 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:35:16,350 - INFO - Trial 91: Train MSE=2.131681446518217, Train R²=0.6452199029070991
2024-10-31 02:35:16,350 - INFO - Trial 91: Test MSE=2.3062972000667026, Test R²=0.6247650299753461
2024-10-31 02:35:16,350 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:35:52,464 - INFO - Trial 92: Train MSE=2.241920918226242, Train R²=0.627009921840259
2024-10-31 02:35:52,465 - INFO - Trial 92: Test MSE=2.2299047197614397, Test R²=0.6370148403303963
2024-10-31 02:35:52,465 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:36:27,856 - INFO - Trial 93: Train MSE=2.1888146698474884, Train R²=0.6356294921466282
2024-10-31 02:36:27,856 - INFO - Trial 93: Test MSE=2.258341142109462, Test R²=0.6323715363230024
2024-10-31 02:36:27,856 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:37:03,769 - INFO - Trial 94: Train MSE=2.252505660057068, Train R²=0.6245882851736886
2024-10-31 02:37:03,769 - INFO - Trial 94: Test MSE=2.295179469244821, Test R²=0.6265685217721122
2024-10-31 02:37:03,769 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:37:38,340 - INFO - Trial 95: Train MSE=2.339550563267299, Train R²=0.6103770967040744
2024-10-31 02:37:38,340 - INFO - Trial 95: Test MSE=2.368248326437814, Test R²=0.6144933359963554
2024-10-31 02:37:38,340 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:38:17,912 - INFO - Trial 96: Train MSE=1.7945368843419212, Train R²=0.7019357766423907
2024-10-31 02:38:17,912 - INFO - Trial 96: Test MSE=2.3121653624943326, Test R²=0.6234612124306815
2024-10-31 02:38:17,912 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:38:56,847 - INFO - Trial 97: Train MSE=2.6135906406811307, Train R²=0.5652166924306324
2024-10-31 02:38:56,847 - INFO - Trial 97: Test MSE=2.263920170920236, Test R²=0.6315977317946297
2024-10-31 02:38:56,847 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:39:35,160 - INFO - Trial 98: Train MSE=3.0858926517622813, Train R²=0.486364626458713
2024-10-31 02:39:35,160 - INFO - Trial 98: Test MSE=2.3675711836133684, Test R²=0.6146481122289386
2024-10-31 02:39:35,160 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:40:12,319 - INFO - Trial 99: Train MSE=2.6357121552739824, Train R²=0.5604667791298458
2024-10-31 02:40:12,319 - INFO - Trial 99: Test MSE=2.282351153237479, Test R²=0.6284147500991821
2024-10-31 02:40:12,319 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:40:52,186 - INFO - Trial 100: Train MSE=1.155393775020327, Train R²=0.807394374694143
2024-10-31 02:40:52,186 - INFO - Trial 100: Test MSE=2.4551096643720354, Test R²=0.600206732749939
2024-10-31 02:40:52,186 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:41:28,097 - INFO - Trial 101: Train MSE=2.228972609554018, Train R²=0.6291008527789798
2024-10-31 02:41:28,097 - INFO - Trial 101: Test MSE=2.254006930759975, Test R²=0.6330573047910418
2024-10-31 02:41:28,097 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:42:06,952 - INFO - Trial 102: Train MSE=1.9491380112511771, Train R²=0.6751577619995389
2024-10-31 02:42:06,952 - INFO - Trial 102: Test MSE=2.330939599445888, Test R²=0.6204674925122943
2024-10-31 02:42:06,952 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:42:42,788 - INFO - Trial 103: Train MSE=2.37857894386564, Train R²=0.6036161035299301
2024-10-31 02:42:42,788 - INFO - Trial 103: Test MSE=2.226710421698434, Test R²=0.6376425112996783
2024-10-31 02:42:42,788 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:44:05,332 - INFO - Trial 104: Train MSE=2.3166660709040507, Train R²=0.6092362808329719
2024-10-31 02:44:05,332 - INFO - Trial 104: Test MSE=2.2396686502865384, Test R²=0.6286455116101674
2024-10-31 02:44:05,332 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:45:25,684 - INFO - Trial 105: Train MSE=2.378478185406753, Train R²=0.6008846254221031
2024-10-31 02:45:25,684 - INFO - Trial 105: Test MSE=2.264280374561037, Test R²=0.6243437592472348
2024-10-31 02:45:25,684 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:46:47,873 - INFO - Trial 106: Train MSE=2.2530562207102776, Train R²=0.618937190089907
2024-10-31 02:46:47,873 - INFO - Trial 106: Test MSE=2.2829493411949704, Test R²=0.6215513114418302
2024-10-31 02:46:47,873 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:48:08,048 - INFO - Trial 107: Train MSE=2.265266528087003, Train R²=0.6190685486154897
2024-10-31 02:48:08,048 - INFO - Trial 107: Test MSE=2.24600641642298, Test R²=0.628027217728751
2024-10-31 02:48:08,048 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:49:28,243 - INFO - Trial 108: Train MSE=2.293802480612482, Train R²=0.6114618895309312
2024-10-31 02:49:28,243 - INFO - Trial 108: Test MSE=2.2691933938435147, Test R²=0.624202487724168
2024-10-31 02:49:28,243 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:50:03,537 - INFO - Trial 109: Train MSE=2.1251943026270186, Train R²=0.6463909021445683
2024-10-31 02:50:03,537 - INFO - Trial 109: Test MSE=2.2574078355516707, Test R²=0.6325064812387738
2024-10-31 02:50:03,537 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:50:43,033 - INFO - Trial 110: Train MSE=2.499391657965524, Train R²=0.5845014240060534
2024-10-31 02:50:43,033 - INFO - Trial 110: Test MSE=2.297145962715149, Test R²=0.6234763115644455
2024-10-31 02:50:43,033 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:51:22,123 - INFO - Trial 111: Train MSE=2.2793442053454265, Train R²=0.6208471847432
2024-10-31 02:51:22,123 - INFO - Trial 111: Test MSE=2.225250141961234, Test R²=0.6378700903483799
2024-10-31 02:51:22,123 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:52:00,912 - INFO - Trial 112: Train MSE=2.285982148987906, Train R²=0.6195075299058642
2024-10-31 02:52:00,912 - INFO - Trial 112: Test MSE=2.25659510067531, Test R²=0.632523238658905
2024-10-31 02:52:00,912 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:52:35,946 - INFO - Trial 113: Train MSE=2.08532668863024, Train R²=0.6516592268432889
2024-10-31 02:52:35,946 - INFO - Trial 113: Test MSE=2.290325607572283, Test R²=0.6270185794149127
2024-10-31 02:52:35,946 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:53:15,746 - INFO - Trial 114: Train MSE=2.4928855214800154, Train R²=0.5855526221649987
2024-10-31 02:53:15,747 - INFO - Trial 114: Test MSE=2.2346107278551375, Test R²=0.6362727965627398
2024-10-31 02:53:15,747 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:53:55,563 - INFO - Trial 115: Train MSE=2.54709792137146, Train R²=0.5765644950526101
2024-10-31 02:53:55,563 - INFO - Trial 115: Test MSE=2.2637941326413835, Test R²=0.631549528666905
2024-10-31 02:53:55,563 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:54:34,595 - INFO - Trial 116: Train MSE=2.5036729489054, Train R²=0.5830696565764291
2024-10-31 02:54:34,596 - INFO - Trial 116: Test MSE=2.296468939099993, Test R²=0.6262297970908028
2024-10-31 02:54:34,596 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:55:15,186 - INFO - Trial 117: Train MSE=1.0007311127015523, Train R²=0.8333496238504138
2024-10-31 02:55:15,187 - INFO - Trial 117: Test MSE=2.353651523590088, Test R²=0.6168569837297712
2024-10-31 02:55:15,187 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:56:44,414 - INFO - Trial 118: Train MSE=1.9796522738678115, Train R²=0.666834721075637
2024-10-31 02:56:44,414 - INFO - Trial 118: Test MSE=2.356510886124202, Test R²=0.6097587496042252
2024-10-31 02:56:44,415 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:57:23,762 - INFO - Trial 119: Train MSE=0.9108393639326096, Train R²=0.8479114707027163
2024-10-31 02:57:23,762 - INFO - Trial 119: Test MSE=2.426994494029454, Test R²=0.604888379573822
2024-10-31 02:57:23,762 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:58:02,650 - INFO - Trial 120: Train MSE=2.0075653408254897, Train R²=0.6658907362392971
2024-10-31 02:58:02,650 - INFO - Trial 120: Test MSE=2.230929340635027, Test R²=0.637004017829895
2024-10-31 02:58:02,650 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:58:41,366 - INFO - Trial 121: Train MSE=2.063543898718698, Train R²=0.6568335528884616
2024-10-31 02:58:41,366 - INFO - Trial 121: Test MSE=2.2476955481937955, Test R²=0.6342616251536778
2024-10-31 02:58:41,366 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:59:19,870 - INFO - Trial 122: Train MSE=2.1933484375476837, Train R²=0.6354821622371674
2024-10-31 02:59:19,871 - INFO - Trial 122: Test MSE=2.2463240964072093, Test R²=0.6343610797609601
2024-10-31 02:59:19,871 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 02:59:58,271 - INFO - Trial 123: Train MSE=2.576613562447684, Train R²=0.5709048168999808
2024-10-31 02:59:58,272 - INFO - Trial 123: Test MSE=2.2431559562683105, Test R²=0.6349897810391018
2024-10-31 02:59:58,272 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:00:37,346 - INFO - Trial 124: Train MSE=1.0284888233457292, Train R²=0.8284351187092918
2024-10-31 03:00:37,346 - INFO - Trial 124: Test MSE=2.427952357700893, Test R²=0.6049702422959464
2024-10-31 03:00:37,346 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:01:17,212 - INFO - Trial 125: Train MSE=2.4415608814784457, Train R²=0.594337882740157
2024-10-31 03:01:17,212 - INFO - Trial 125: Test MSE=2.3266089303152904, Test R²=0.6213199240820748
2024-10-31 03:01:17,212 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:01:54,793 - INFO - Trial 126: Train MSE=0.9057867931468147, Train R²=0.8492249697446823
2024-10-31 03:01:54,793 - INFO - Trial 126: Test MSE=2.407477242606027, Test R²=0.6079149501664298
2024-10-31 03:01:54,793 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:02:33,521 - INFO - Trial 127: Train MSE=2.4373031301157817, Train R²=0.595256256205695
2024-10-31 03:02:33,521 - INFO - Trial 127: Test MSE=2.22488796710968, Test R²=0.6377497400556292
2024-10-31 03:02:33,521 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:03:13,139 - INFO - Trial 128: Train MSE=2.4926901629992892, Train R²=0.5859406760760716
2024-10-31 03:03:13,139 - INFO - Trial 128: Test MSE=2.252018996647426, Test R²=0.6335895657539368
2024-10-31 03:03:13,139 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:03:51,888 - INFO - Trial 129: Train MSE=2.2782290237290517, Train R²=0.6208170077630452
2024-10-31 03:03:51,888 - INFO - Trial 129: Test MSE=2.316322462899344, Test R²=0.6227898342268807
2024-10-31 03:03:51,888 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:04:24,497 - INFO - Trial 130: Train MSE=3.243446401187352, Train R²=0.4617196364062173
2024-10-31 03:04:24,497 - INFO - Trial 130: Test MSE=2.34364253282547, Test R²=0.6160479187965393
2024-10-31 03:04:24,497 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:05:03,665 - INFO - Trial 131: Train MSE=2.394947213785989, Train R²=0.6025004876511437
2024-10-31 03:05:03,665 - INFO - Trial 131: Test MSE=2.2381355421883717, Test R²=0.635503854070391
2024-10-31 03:05:03,665 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:05:42,466 - INFO - Trial 132: Train MSE=2.5067475523267473, Train R²=0.5837413455758776
2024-10-31 03:05:42,467 - INFO - Trial 132: Test MSE=2.3028083188193187, Test R²=0.6250889556748527
2024-10-31 03:05:42,467 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:06:21,450 - INFO - Trial 133: Train MSE=2.022088344608034, Train R²=0.6642148473433086
2024-10-31 03:06:21,450 - INFO - Trial 133: Test MSE=2.287370579583304, Test R²=0.6275664397648403
2024-10-31 03:06:21,451 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:07:00,589 - INFO - Trial 134: Train MSE=2.407516394342695, Train R²=0.5991074975047793
2024-10-31 03:07:00,590 - INFO - Trial 134: Test MSE=2.273123128073556, Test R²=0.6298605118479047
2024-10-31 03:07:00,590 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:07:39,524 - INFO - Trial 135: Train MSE=2.1627377441951205, Train R²=0.6398822984525135
2024-10-31 03:07:39,524 - INFO - Trial 135: Test MSE=2.2695042065211704, Test R²=0.6306742259434291
2024-10-31 03:07:39,524 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:08:18,715 - INFO - Trial 136: Train MSE=2.248907651220049, Train R²=0.6256661244801113
2024-10-31 03:08:18,715 - INFO - Trial 136: Test MSE=2.2357351779937744, Test R²=0.6358927318028041
2024-10-31 03:08:18,715 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:08:58,262 - INFO - Trial 137: Train MSE=2.2019423076084683, Train R²=0.6339141790355954
2024-10-31 03:08:58,262 - INFO - Trial 137: Test MSE=2.2774947030203685, Test R²=0.629261485167912
2024-10-31 03:08:58,262 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:09:36,930 - INFO - Trial 138: Train MSE=1.8214927656309945, Train R²=0.6971658979143415
2024-10-31 03:09:36,930 - INFO - Trial 138: Test MSE=2.25263660294669, Test R²=0.6330829773630414
2024-10-31 03:09:36,930 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:10:11,810 - INFO - Trial 139: Train MSE=2.4622194596699307, Train R²=0.590242549777031
2024-10-31 03:10:11,810 - INFO - Trial 139: Test MSE=2.2738822528294156, Test R²=0.6298287681170872
2024-10-31 03:10:11,810 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:10:50,798 - INFO - Trial 140: Train MSE=2.3585876396724155, Train R²=0.6065201056855065
2024-10-31 03:10:50,798 - INFO - Trial 140: Test MSE=2.271951471056257, Test R²=0.6301847100257874
2024-10-31 03:10:50,798 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:11:29,521 - INFO - Trial 141: Train MSE=2.7242908818381175, Train R²=0.5467997299773353
2024-10-31 03:11:29,521 - INFO - Trial 141: Test MSE=2.2826846667698453, Test R²=0.6285051958901542
2024-10-31 03:11:29,521 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:13:02,922 - INFO - Trial 142: Train MSE=2.5112324080296924, Train R²=0.5720594551946435
2024-10-31 03:13:02,922 - INFO - Trial 142: Test MSE=2.2654247752257755, Test R²=0.6250169660363879
2024-10-31 03:13:02,922 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:13:41,936 - INFO - Trial 143: Train MSE=2.5079742074012756, Train R²=0.5830097092049462
2024-10-31 03:13:41,936 - INFO - Trial 143: Test MSE=2.2586144549506053, Test R²=0.6322564227240426
2024-10-31 03:13:41,936 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:14:21,105 - INFO - Trial 144: Train MSE=2.555259568350656, Train R²=0.5743198288338525
2024-10-31 03:14:21,105 - INFO - Trial 144: Test MSE=2.255021299634661, Test R²=0.6329228111675808
2024-10-31 03:14:21,105 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:14:58,663 - INFO - Trial 145: Train MSE=2.1052308636052266, Train R²=0.6495554340737206
2024-10-31 03:14:58,664 - INFO - Trial 145: Test MSE=2.258094310760498, Test R²=0.6322041920253209
2024-10-31 03:14:58,664 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:15:35,927 - INFO - Trial 146: Train MSE=2.8261796491486684, Train R²=0.5300089355025973
2024-10-31 03:15:35,927 - INFO - Trial 146: Test MSE=2.309182269232614, Test R²=0.6241157054901123
2024-10-31 03:15:35,927 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:16:15,139 - INFO - Trial 147: Train MSE=2.611742837088449, Train R²=0.5658236231122699
2024-10-31 03:16:15,139 - INFO - Trial 147: Test MSE=2.2632631233760288, Test R²=0.6315512401717049
2024-10-31 03:16:15,139 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:16:51,281 - INFO - Trial 148: Train MSE=1.8451558904988425, Train R²=0.6923570611647197
2024-10-31 03:16:51,282 - INFO - Trial 148: Test MSE=2.274535894393921, Test R²=0.6297919409615653
2024-10-31 03:16:51,282 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:18:17,886 - INFO - Trial 149: Train MSE=2.2879936578018323, Train R²=0.6143508196941444
2024-10-31 03:18:17,886 - INFO - Trial 149: Test MSE=2.263413135494505, Test R²=0.625432048525129
2024-10-31 03:18:17,886 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:18:55,110 - INFO - Trial 150: Train MSE=3.027750406946455, Train R²=0.4969478760446821
2024-10-31 03:18:55,110 - INFO - Trial 150: Test MSE=2.4576214722224643, Test R²=0.6000967706952777
2024-10-31 03:18:55,110 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:19:33,642 - INFO - Trial 151: Train MSE=2.438882044383458, Train R²=0.5939533369881767
2024-10-31 03:19:33,642 - INFO - Trial 151: Test MSE=2.2922698089054654, Test R²=0.6267799990517753
2024-10-31 03:19:33,642 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:20:12,706 - INFO - Trial 152: Train MSE=2.261054698910032, Train R²=0.6238288964544024
2024-10-31 03:20:12,706 - INFO - Trial 152: Test MSE=2.2582788126809255, Test R²=0.6323313287326268
2024-10-31 03:20:12,706 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:20:51,913 - INFO - Trial 153: Train MSE=2.3643118057932173, Train R²=0.6059048771858215
2024-10-31 03:20:51,913 - INFO - Trial 153: Test MSE=2.2651775905064175, Test R²=0.6313298259462629
2024-10-31 03:20:51,913 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:21:31,205 - INFO - Trial 154: Train MSE=2.1970163754054477, Train R²=0.6343255702938352
2024-10-31 03:21:31,205 - INFO - Trial 154: Test MSE=2.2815089566367015, Test R²=0.6285594276019505
2024-10-31 03:21:31,205 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:22:10,304 - INFO - Trial 155: Train MSE=2.59427547454834, Train R²=0.5680448774780545
2024-10-31 03:22:10,304 - INFO - Trial 155: Test MSE=2.307371514184134, Test R²=0.6244569080216544
2024-10-31 03:22:10,304 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:22:49,941 - INFO - Trial 156: Train MSE=1.4928615093231201, Train R²=0.7513183568205152
2024-10-31 03:22:49,941 - INFO - Trial 156: Test MSE=2.321162394114903, Test R²=0.6220218964985439
2024-10-31 03:22:49,941 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:23:29,034 - INFO - Trial 157: Train MSE=2.5655597107751027, Train R²=0.5728210615260261
2024-10-31 03:23:29,034 - INFO - Trial 157: Test MSE=2.3021437440599715, Test R²=0.6252905130386353
2024-10-31 03:23:29,034 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:24:07,834 - INFO - Trial 158: Train MSE=2.0500869197504863, Train R²=0.6585269868373871
2024-10-31 03:24:07,834 - INFO - Trial 158: Test MSE=2.30363883290972, Test R²=0.6250122104372297
2024-10-31 03:24:07,834 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:24:38,117 - INFO - Trial 159: Train MSE=2.024124196597508, Train R²=0.6638651405061994
2024-10-31 03:24:38,117 - INFO - Trial 159: Test MSE=2.2469561100006104, Test R²=0.631635308265686
2024-10-31 03:24:38,117 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:25:17,110 - INFO - Trial 160: Train MSE=2.3166834797177995, Train R²=0.6144841185637883
2024-10-31 03:25:17,110 - INFO - Trial 160: Test MSE=2.247954947607858, Test R²=0.6340962137494769
2024-10-31 03:25:17,110 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:25:53,698 - INFO - Trial 161: Train MSE=2.167955083506448, Train R²=0.6400465794972011
2024-10-31 03:25:53,698 - INFO - Trial 161: Test MSE=2.198427472795759, Test R²=0.6421435901096889
2024-10-31 03:25:53,698 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:26:29,109 - INFO - Trial 162: Train MSE=2.1567562307630266, Train R²=0.6414158982889993
2024-10-31 03:26:29,109 - INFO - Trial 162: Test MSE=2.2567793301173618, Test R²=0.6326158727918353
2024-10-31 03:26:29,109 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:27:04,624 - INFO - Trial 163: Train MSE=2.288137721163886, Train R²=0.6187133193016052
2024-10-31 03:27:04,624 - INFO - Trial 163: Test MSE=2.2316546951021468, Test R²=0.6366400718688965
2024-10-31 03:27:04,624 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:27:40,282 - INFO - Trial 164: Train MSE=2.468650145190103, Train R²=0.5881312808820179
2024-10-31 03:27:40,283 - INFO - Trial 164: Test MSE=2.230605431965419, Test R²=0.6368014557021004
2024-10-31 03:27:40,283 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:28:16,136 - INFO - Trial 165: Train MSE=2.3187461410249983, Train R²=0.6144403730119977
2024-10-31 03:28:16,136 - INFO - Trial 165: Test MSE=2.2622983115059987, Test R²=0.6317256689071655
2024-10-31 03:28:16,136 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:28:51,866 - INFO - Trial 166: Train MSE=2.2208218702248166, Train R²=0.6306224167346954
2024-10-31 03:28:51,866 - INFO - Trial 166: Test MSE=2.2157733270100186, Test R²=0.6393250567572457
2024-10-31 03:28:51,866 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:29:28,171 - INFO - Trial 167: Train MSE=2.372446141072682, Train R²=0.6042740366288594
2024-10-31 03:29:28,171 - INFO - Trial 167: Test MSE=2.242828369140625, Test R²=0.6348088298525129
2024-10-31 03:29:28,171 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:30:15,044 - INFO - Trial 168: Train MSE=2.392995400088174, Train R²=0.601842577968325
2024-10-31 03:30:15,044 - INFO - Trial 168: Test MSE=2.3444768020084927, Test R²=0.618339044707162
2024-10-31 03:30:15,044 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:30:50,432 - INFO - Trial 169: Train MSE=2.205185898712703, Train R²=0.632847262280328
2024-10-31 03:30:50,432 - INFO - Trial 169: Test MSE=2.243398530142648, Test R²=0.6348429322242737
2024-10-31 03:30:50,432 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:31:30,733 - INFO - Trial 170: Train MSE=2.5253489443234036, Train R²=0.5792060111250196
2024-10-31 03:31:30,734 - INFO - Trial 170: Test MSE=2.3061653545924594, Test R²=0.6246149625097003
2024-10-31 03:31:30,734 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:32:06,177 - INFO - Trial 171: Train MSE=2.0606933321271623, Train R²=0.6567899286746979
2024-10-31 03:32:06,177 - INFO - Trial 171: Test MSE=2.2782653399876187, Test R²=0.6291203413690839
2024-10-31 03:32:06,177 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:32:42,098 - INFO - Trial 172: Train MSE=2.1561368703842163, Train R²=0.6414257436990738
2024-10-31 03:32:42,099 - INFO - Trial 172: Test MSE=2.2751857893807546, Test R²=0.62952949319567
2024-10-31 03:32:42,099 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:33:17,399 - INFO - Trial 173: Train MSE=2.046572204147066, Train R²=0.659289328115327
2024-10-31 03:33:17,399 - INFO - Trial 173: Test MSE=2.2459553820746287, Test R²=0.6343136770384652
2024-10-31 03:33:17,399 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:33:52,835 - INFO - Trial 174: Train MSE=2.1330296652657643, Train R²=0.6452876904181072
2024-10-31 03:33:52,835 - INFO - Trial 174: Test MSE=2.2456158229282925, Test R²=0.6344524196216038
2024-10-31 03:33:52,835 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:34:28,336 - INFO - Trial 175: Train MSE=2.278046497276851, Train R²=0.6214391440153122
2024-10-31 03:34:28,337 - INFO - Trial 175: Test MSE=2.2217088597161427, Test R²=0.6381145715713501
2024-10-31 03:34:28,337 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:35:03,698 - INFO - Trial 176: Train MSE=2.345495585884367, Train R²=0.6097187186990466
2024-10-31 03:35:03,698 - INFO - Trial 176: Test MSE=2.2476232733045305, Test R²=0.6341405851500375
2024-10-31 03:35:03,698 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:35:39,850 - INFO - Trial 177: Train MSE=2.182697743177414, Train R²=0.6362444630690983
2024-10-31 03:35:39,850 - INFO - Trial 177: Test MSE=2.2475145203726634, Test R²=0.6342735205377851
2024-10-31 03:35:39,850 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:36:14,563 - INFO - Trial 178: Train MSE=2.9025422079222545, Train R²=0.51654671558312
2024-10-31 03:36:14,563 - INFO - Trial 178: Test MSE=2.2310175555092946, Test R²=0.636979239327567
2024-10-31 03:36:14,563 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:36:54,967 - INFO - Trial 179: Train MSE=2.940003182206835, Train R²=0.5103674509695598
2024-10-31 03:36:54,968 - INFO - Trial 179: Test MSE=2.2974076781954085, Test R²=0.6261814066341945
2024-10-31 03:36:54,968 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:37:39,625 - INFO - Trial 180: Train MSE=2.94819222177778, Train R²=0.5090988576412201
2024-10-31 03:37:39,626 - INFO - Trial 180: Test MSE=2.2600038392203197, Test R²=0.6322443059512547
2024-10-31 03:37:39,626 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:38:18,078 - INFO - Trial 181: Train MSE=2.226368955203465, Train R²=0.6296490664993014
2024-10-31 03:38:18,078 - INFO - Trial 181: Test MSE=2.2777183055877686, Test R²=0.6290579438209534
2024-10-31 03:38:18,078 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:38:55,841 - INFO - Trial 182: Train MSE=2.819929156984602, Train R²=0.5306580662727356
2024-10-31 03:38:55,842 - INFO - Trial 182: Test MSE=2.209205780710493, Test R²=0.6403809019497463
2024-10-31 03:38:55,842 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:39:40,217 - INFO - Trial 183: Train MSE=2.7150540011269704, Train R²=0.5482405232531684
2024-10-31 03:39:40,217 - INFO - Trial 183: Test MSE=2.2313569443566457, Test R²=0.6368854982512338
2024-10-31 03:39:40,217 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:40:24,046 - INFO - Trial 184: Train MSE=2.6763036591666087, Train R²=0.5548916352646691
2024-10-31 03:40:24,046 - INFO - Trial 184: Test MSE=2.2049577917371477, Test R²=0.6412179384912763
2024-10-31 03:40:24,046 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:41:08,700 - INFO - Trial 185: Train MSE=2.6893408639090404, Train R²=0.5522719706807818
2024-10-31 03:41:08,700 - INFO - Trial 185: Test MSE=2.2352159363882884, Test R²=0.6362581338201251
2024-10-31 03:41:08,700 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:41:50,429 - INFO - Trial 186: Train MSE=2.6242182084492276, Train R²=0.5635112736906324
2024-10-31 03:41:50,429 - INFO - Trial 186: Test MSE=2.2578461510794505, Test R²=0.6324172786303929
2024-10-31 03:41:50,429 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:42:24,384 - INFO - Trial 187: Train MSE=2.7087219527789523, Train R²=0.5485225128276008
2024-10-31 03:42:24,384 - INFO - Trial 187: Test MSE=2.2790378161839078, Test R²=0.6290217638015747
2024-10-31 03:42:24,384 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:43:04,574 - INFO - Trial 188: Train MSE=2.715790961469923, Train R²=0.5488634620394025
2024-10-31 03:43:04,574 - INFO - Trial 188: Test MSE=2.2225220033100674, Test R²=0.6382928235190255
2024-10-31 03:43:04,574 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:43:38,838 - INFO - Trial 189: Train MSE=2.7913911512919833, Train R²=0.5353758696998868
2024-10-31 03:43:38,838 - INFO - Trial 189: Test MSE=2.251757417406355, Test R²=0.6333723493984768
2024-10-31 03:43:38,838 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:44:16,609 - INFO - Trial 190: Train MSE=2.605632628713335, Train R²=0.5664999570165362
2024-10-31 03:44:16,609 - INFO - Trial 190: Test MSE=2.2331111431121826, Test R²=0.6365282535552979
2024-10-31 03:44:16,609 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:44:52,553 - INFO - Trial 191: Train MSE=2.50521320104599, Train R²=0.5822174506528037
2024-10-31 03:44:52,553 - INFO - Trial 191: Test MSE=2.267210006713867, Test R²=0.6310286777360099
2024-10-31 03:44:52,553 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:45:27,361 - INFO - Trial 192: Train MSE=2.651656891618456, Train R²=0.557793242590768
2024-10-31 03:45:27,361 - INFO - Trial 192: Test MSE=2.3624045167650496, Test R²=0.61542809009552
2024-10-31 03:45:27,361 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:46:12,336 - INFO - Trial 193: Train MSE=2.5462280341557095, Train R²=0.5759541456188474
2024-10-31 03:46:12,336 - INFO - Trial 193: Test MSE=2.2483162539345876, Test R²=0.633962597165789
2024-10-31 03:46:12,336 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:46:52,952 - INFO - Trial 194: Train MSE=2.599708846637181, Train R²=0.5676683783531189
2024-10-31 03:46:52,952 - INFO - Trial 194: Test MSE=2.2900326592581615, Test R²=0.6273199660437447
2024-10-31 03:46:52,952 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:47:27,049 - INFO - Trial 195: Train MSE=2.716680118015834, Train R²=0.5479906222649983
2024-10-31 03:47:27,049 - INFO - Trial 195: Test MSE=2.2348020928246632, Test R²=0.636363548891885
2024-10-31 03:47:27,049 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:48:03,850 - INFO - Trial 196: Train MSE=2.7082812786102295, Train R²=0.5498629638126918
2024-10-31 03:48:03,850 - INFO - Trial 196: Test MSE=2.247710176876613, Test R²=0.634105520589011
2024-10-31 03:48:03,850 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:48:41,473 - INFO - Trial 197: Train MSE=2.6351917130606517, Train R²=0.5608003309794835
2024-10-31 03:48:41,474 - INFO - Trial 197: Test MSE=2.294039385659354, Test R²=0.6265471237046378
2024-10-31 03:48:41,474 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:49:21,412 - INFO - Trial 198: Train MSE=2.6253225718225752, Train R²=0.5634380195822034
2024-10-31 03:49:21,412 - INFO - Trial 198: Test MSE=2.2256880828312466, Test R²=0.6377738799367633
2024-10-31 03:49:21,412 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:49:59,151 - INFO - Trial 199: Train MSE=2.921339920588902, Train R²=0.5152568221092224
2024-10-31 03:49:59,151 - INFO - Trial 199: Test MSE=2.25302654504776, Test R²=0.6307287365198135
2024-10-31 03:49:59,151 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:50:43,185 - INFO - Trial 200: Train MSE=2.7078143613679067, Train R²=0.5495018448148455
2024-10-31 03:50:43,185 - INFO - Trial 200: Test MSE=2.2432365247181485, Test R²=0.6348744886262077
2024-10-31 03:50:43,185 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:51:23,863 - INFO - Trial 201: Train MSE=2.516542545386723, Train R²=0.5805653589112418
2024-10-31 03:51:23,863 - INFO - Trial 201: Test MSE=2.245516436440604, Test R²=0.6344920737402779
2024-10-31 03:51:23,863 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:52:01,306 - INFO - Trial 202: Train MSE=2.6297580003738403, Train R²=0.5620030441454479
2024-10-31 03:52:01,306 - INFO - Trial 202: Test MSE=2.261138779776437, Test R²=0.6320480363709586
2024-10-31 03:52:01,306 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:52:35,924 - INFO - Trial 203: Train MSE=1.6257603892258234, Train R²=0.7287984426532473
2024-10-31 03:52:35,924 - INFO - Trial 203: Test MSE=2.331072909491403, Test R²=0.6204739809036255
2024-10-31 03:52:35,924 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:53:20,162 - INFO - Trial 204: Train MSE=2.552172669342586, Train R²=0.5753196158579418
2024-10-31 03:53:20,162 - INFO - Trial 204: Test MSE=2.2769630466188704, Test R²=0.6294847130775452
2024-10-31 03:53:20,162 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:54:04,723 - INFO - Trial 205: Train MSE=2.8228058644703458, Train R²=0.5302881151437759
2024-10-31 03:54:04,723 - INFO - Trial 205: Test MSE=2.242436374936785, Test R²=0.6350654874529157
2024-10-31 03:54:04,723 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:54:39,201 - INFO - Trial 206: Train MSE=0.8088228745119912, Train R²=0.8653668825115476
2024-10-31 03:54:39,201 - INFO - Trial 206: Test MSE=2.4920150552477156, Test R²=0.5944947344916207
2024-10-31 03:54:39,201 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:55:17,876 - INFO - Trial 207: Train MSE=2.6073009627205983, Train R²=0.5649598709174565
2024-10-31 03:55:17,876 - INFO - Trial 207: Test MSE=2.2562829085758755, Test R²=0.6326814123562404
2024-10-31 03:55:17,876 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:56:02,389 - INFO - Trial 208: Train MSE=2.530579686164856, Train R²=0.5786695224898202
2024-10-31 03:56:02,389 - INFO - Trial 208: Test MSE=2.2564049788883755, Test R²=0.6326313955443246
2024-10-31 03:56:02,389 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:56:46,331 - INFO - Trial 209: Train MSE=2.58834240266255, Train R²=0.5688596580709729
2024-10-31 03:56:46,331 - INFO - Trial 209: Test MSE=2.2520673956189836, Test R²=0.6334923846381051
2024-10-31 03:56:46,331 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:57:23,683 - INFO - Trial 210: Train MSE=2.7943223885127475, Train R²=0.5354535430669785
2024-10-31 03:57:23,683 - INFO - Trial 210: Test MSE=2.2744605200631276, Test R²=0.6298625043460301
2024-10-31 03:57:23,683 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:58:06,042 - INFO - Trial 211: Train MSE=2.5894420572689603, Train R²=0.5686349783624921
2024-10-31 03:58:06,042 - INFO - Trial 211: Test MSE=2.238662770816258, Test R²=0.635657719203404
2024-10-31 03:58:06,042 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:58:48,989 - INFO - Trial 212: Train MSE=2.7358587043625966, Train R²=0.5448489253010068
2024-10-31 03:58:48,989 - INFO - Trial 212: Test MSE=2.280766078404018, Test R²=0.628859281539917
2024-10-31 03:58:48,989 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 03:59:33,550 - INFO - Trial 213: Train MSE=2.6897483553205217, Train R²=0.5524508740220752
2024-10-31 03:59:33,550 - INFO - Trial 213: Test MSE=2.3064840180533275, Test R²=0.6246004530361721
2024-10-31 03:59:33,550 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:00:17,565 - INFO - Trial 214: Train MSE=2.9153789366994585, Train R²=0.5137201781783786
2024-10-31 04:00:17,565 - INFO - Trial 214: Test MSE=2.2443984236036028, Test R²=0.6345976080213275
2024-10-31 04:00:17,565 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:01:02,232 - INFO - Trial 215: Train MSE=2.6966978907585144, Train R²=0.5514225768191474
2024-10-31 04:01:02,232 - INFO - Trial 215: Test MSE=2.238926274435861, Test R²=0.6356302755219596
2024-10-31 04:01:02,232 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:01:51,527 - INFO - Trial 216: Train MSE=1.8800232665879386, Train R²=0.6869248215641294
2024-10-31 04:01:51,527 - INFO - Trial 216: Test MSE=2.2556991236550465, Test R²=0.6327561736106873
2024-10-31 04:01:51,527 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:02:30,670 - INFO - Trial 217: Train MSE=1.8700469519410814, Train R²=0.6891549868243081
2024-10-31 04:02:30,670 - INFO - Trial 217: Test MSE=2.287963254111154, Test R²=0.6275293741907392
2024-10-31 04:02:30,670 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:03:13,204 - INFO - Trial 218: Train MSE=2.596475456442152, Train R²=0.5674687709127154
2024-10-31 04:03:13,205 - INFO - Trial 218: Test MSE=2.289273296083723, Test R²=0.6275472470692226
2024-10-31 04:03:13,205 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:03:50,244 - INFO - Trial 219: Train MSE=2.2029077453272685, Train R²=0.6328591001885278
2024-10-31 04:03:50,245 - INFO - Trial 219: Test MSE=2.2679689611707414, Test R²=0.6309662801878793
2024-10-31 04:03:50,245 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:04:25,832 - INFO - Trial 220: Train MSE=2.3120502829551697, Train R²=0.6154577710798809
2024-10-31 04:04:25,832 - INFO - Trial 220: Test MSE=2.2526584352765764, Test R²=0.6333860754966736
2024-10-31 04:04:25,832 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:05:03,323 - INFO - Trial 221: Train MSE=2.462998492377145, Train R²=0.5895429296152932
2024-10-31 04:05:03,323 - INFO - Trial 221: Test MSE=2.231169138635908, Test R²=0.6368156501225063
2024-10-31 04:05:03,323 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:05:40,939 - INFO - Trial 222: Train MSE=2.4406541160174777, Train R²=0.5944524960858482
2024-10-31 04:05:40,939 - INFO - Trial 222: Test MSE=2.277961713927133, Test R²=0.6293587940079826
2024-10-31 04:05:40,939 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:06:18,399 - INFO - Trial 223: Train MSE=2.5199099268232072, Train R²=0.5809653252363205
2024-10-31 04:06:18,399 - INFO - Trial 223: Test MSE=2.258845703942435, Test R²=0.6323737076350621
2024-10-31 04:06:18,399 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:06:55,544 - INFO - Trial 224: Train MSE=1.3015834093093872, Train R²=0.7834903853280204
2024-10-31 04:06:55,544 - INFO - Trial 224: Test MSE=2.376932110105242, Test R²=0.6128957356725421
2024-10-31 04:06:55,544 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:07:31,440 - INFO - Trial 225: Train MSE=2.2314687882150923, Train R²=0.629527000444276
2024-10-31 04:07:31,440 - INFO - Trial 225: Test MSE=2.2742133821759904, Test R²=0.6296512229101998
2024-10-31 04:07:31,440 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:07:58,384 - INFO - Trial 226: Train MSE=2.448564120701381, Train R²=0.5932295684303556
2024-10-31 04:07:58,384 - INFO - Trial 226: Test MSE=2.2383520943777904, Test R²=0.635722952229636
2024-10-31 04:07:58,384 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:08:38,640 - INFO - Trial 227: Train MSE=1.4275351507323129, Train R²=0.7621399824108396
2024-10-31 04:08:38,640 - INFO - Trial 227: Test MSE=2.427828550338745, Test R²=0.6049621020044599
2024-10-31 04:08:38,640 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:09:15,601 - INFO - Trial 228: Train MSE=2.221963895218713, Train R²=0.6295468594346728
2024-10-31 04:09:15,601 - INFO - Trial 228: Test MSE=2.2731820174625943, Test R²=0.6300144451005119
2024-10-31 04:09:15,601 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:09:52,304 - INFO - Trial 229: Train MSE=2.390371927193233, Train R²=0.601418456860951
2024-10-31 04:09:52,304 - INFO - Trial 229: Test MSE=2.2326696600232805, Test R²=0.6364580733435494
2024-10-31 04:09:52,305 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:10:31,140 - INFO - Trial 230: Train MSE=2.0920872603143965, Train R²=0.6515603108065469
2024-10-31 04:10:31,140 - INFO - Trial 230: Test MSE=2.247785074370248, Test R²=0.6340993983404977
2024-10-31 04:10:31,140 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:11:06,724 - INFO - Trial 231: Train MSE=2.3882541401045665, Train R²=0.6028089459453311
2024-10-31 04:11:06,724 - INFO - Trial 231: Test MSE=2.226602418082101, Test R²=0.637488169329507
2024-10-31 04:11:06,724 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:11:43,210 - INFO - Trial 232: Train MSE=2.32653272151947, Train R²=0.6116625389882496
2024-10-31 04:11:43,210 - INFO - Trial 232: Test MSE=2.2671439988272533, Test R²=0.6309426086289542
2024-10-31 04:11:43,211 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:12:20,000 - INFO - Trial 233: Train MSE=2.397961573941367, Train R²=0.6007879035813468
2024-10-31 04:12:20,000 - INFO - Trial 233: Test MSE=2.2090440137045726, Test R²=0.6404390675680978
2024-10-31 04:12:20,000 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:12:56,534 - INFO - Trial 234: Train MSE=2.4162558828081404, Train R²=0.5979630414928708
2024-10-31 04:12:56,534 - INFO - Trial 234: Test MSE=2.202567764690944, Test R²=0.6414898463657924
2024-10-31 04:12:56,534 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:13:31,511 - INFO - Trial 235: Train MSE=2.42165812424251, Train R²=0.5963614689452308
2024-10-31 04:13:31,511 - INFO - Trial 235: Test MSE=2.277977296284267, Test R²=0.6291473763329642
2024-10-31 04:13:31,511 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:14:07,121 - INFO - Trial 236: Train MSE=2.456760457583836, Train R²=0.5910831647259849
2024-10-31 04:14:07,121 - INFO - Trial 236: Test MSE=2.2481500250952586, Test R²=0.6341417687279838
2024-10-31 04:14:07,121 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:14:44,580 - INFO - Trial 237: Train MSE=2.405427949769156, Train R²=0.5989468608583722
2024-10-31 04:14:44,580 - INFO - Trial 237: Test MSE=2.2484399591173445, Test R²=0.6340817127908979
2024-10-31 04:14:44,580 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:15:20,545 - INFO - Trial 238: Train MSE=2.4577343804495677, Train R²=0.591005978839738
2024-10-31 04:15:20,545 - INFO - Trial 238: Test MSE=2.2120547464915683, Test R²=0.6399171096937997
2024-10-31 04:15:20,545 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:15:50,628 - INFO - Trial 239: Train MSE=2.674750328063965, Train R²=0.5564142891338894
2024-10-31 04:15:50,628 - INFO - Trial 239: Test MSE=2.276591658592224, Test R²=0.6268444210290909
2024-10-31 04:15:50,628 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:16:27,063 - INFO - Trial 240: Train MSE=2.2704035810061862, Train R²=0.6210941480738776
2024-10-31 04:16:27,064 - INFO - Trial 240: Test MSE=2.2636002131870816, Test R²=0.6314892854009356
2024-10-31 04:16:27,064 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:17:04,583 - INFO - Trial 241: Train MSE=2.465151454721178, Train R²=0.5898997762373516
2024-10-31 04:17:04,583 - INFO - Trial 241: Test MSE=2.264649340084621, Test R²=0.63145341191973
2024-10-31 04:17:04,583 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:17:42,645 - INFO - Trial 242: Train MSE=2.4102008768490384, Train R²=0.5984536068780082
2024-10-31 04:17:42,646 - INFO - Trial 242: Test MSE=2.23353259904044, Test R²=0.6364326817648751
2024-10-31 04:17:42,646 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:18:21,084 - INFO - Trial 243: Train MSE=2.380822624479021, Train R²=0.6032464333942958
2024-10-31 04:18:21,084 - INFO - Trial 243: Test MSE=2.2024815593447005, Test R²=0.6416076251438686
2024-10-31 04:18:21,084 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:18:56,346 - INFO - Trial 244: Train MSE=2.3270505411284312, Train R²=0.6119869564260755
2024-10-31 04:18:56,347 - INFO - Trial 244: Test MSE=2.2368943180356706, Test R²=0.6358378784997123
2024-10-31 04:18:56,347 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:19:32,531 - INFO - Trial 245: Train MSE=2.4604643412998746, Train R²=0.591482590351786
2024-10-31 04:19:32,532 - INFO - Trial 245: Test MSE=2.2702788625444685, Test R²=0.6305366584232875
2024-10-31 04:19:32,532 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:20:08,169 - INFO - Trial 246: Train MSE=2.2623837930815562, Train R²=0.6232190366302218
2024-10-31 04:20:08,169 - INFO - Trial 246: Test MSE=2.2319052049091885, Test R²=0.6368067264556885
2024-10-31 04:20:08,169 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:20:43,940 - INFO - Trial 247: Train MSE=2.2299932965210507, Train R²=0.6296371434416089
2024-10-31 04:20:43,941 - INFO - Trial 247: Test MSE=2.2198339700698853, Test R²=0.6386635218347821
2024-10-31 04:20:43,941 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:21:20,300 - INFO - Trial 248: Train MSE=2.3019100768225536, Train R²=0.6176974688257489
2024-10-31 04:21:20,300 - INFO - Trial 248: Test MSE=2.2319961275373186, Test R²=0.6365947893687657
2024-10-31 04:21:20,300 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:21:55,825 - INFO - Trial 249: Train MSE=2.3800651175635203, Train R²=0.6025692820549011
2024-10-31 04:21:55,825 - INFO - Trial 249: Test MSE=2.222208091190883, Test R²=0.6381715110370091
2024-10-31 04:21:55,826 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:22:31,544 - INFO - Trial 250: Train MSE=2.370296290942601, Train R²=0.6063843624932426
2024-10-31 04:22:31,544 - INFO - Trial 250: Test MSE=2.247784359114511, Test R²=0.6341228655406407
2024-10-31 04:22:31,544 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:23:07,317 - INFO - Trial 251: Train MSE=2.3174287336213246, Train R²=0.6148534906761987
2024-10-31 04:23:07,317 - INFO - Trial 251: Test MSE=2.267061267580305, Test R²=0.6311474101884025
2024-10-31 04:23:07,317 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:23:42,810 - INFO - Trial 252: Train MSE=2.5300425716808865, Train R²=0.579144652400698
2024-10-31 04:23:42,810 - INFO - Trial 252: Test MSE=2.2515370505196706, Test R²=0.6334836142403739
2024-10-31 04:23:42,810 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:24:17,928 - INFO - Trial 253: Train MSE=2.365989463669913, Train R²=0.6056343466043472
2024-10-31 04:24:17,928 - INFO - Trial 253: Test MSE=2.2347159726279124, Test R²=0.6361637881823948
2024-10-31 04:24:17,928 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:24:53,924 - INFO - Trial 254: Train MSE=2.2542525870459422, Train R²=0.6246818325349263
2024-10-31 04:24:53,924 - INFO - Trial 254: Test MSE=2.245039531162807, Test R²=0.6345193130629403
2024-10-31 04:24:53,924 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:25:43,026 - INFO - Trial 255: Train MSE=2.005948407309396, Train R²=0.6656144665820258
2024-10-31 04:25:43,026 - INFO - Trial 255: Test MSE=2.2633651324680875, Test R²=0.6315730384417942
2024-10-31 04:25:43,026 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:26:20,016 - INFO - Trial 256: Train MSE=2.2383531587464467, Train R²=0.6266396194696426
2024-10-31 04:26:20,016 - INFO - Trial 256: Test MSE=2.2986182144709995, Test R²=0.6256585546902248
2024-10-31 04:26:20,016 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:26:57,847 - INFO - Trial 257: Train MSE=2.5594939589500427, Train R²=0.5748624759060996
2024-10-31 04:26:57,848 - INFO - Trial 257: Test MSE=2.205709866115025, Test R²=0.6409646187509809
2024-10-31 04:26:57,848 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:27:35,657 - INFO - Trial 258: Train MSE=2.7688004033906117, Train R²=0.5379288153988975
2024-10-31 04:27:35,658 - INFO - Trial 258: Test MSE=2.253636360168457, Test R²=0.6333184157099042
2024-10-31 04:27:35,658 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:28:13,518 - INFO - Trial 259: Train MSE=1.1166019631283624, Train R²=0.8140753954648972
2024-10-31 04:28:13,518 - INFO - Trial 259: Test MSE=2.4554282256535123, Test R²=0.6001279098646981
2024-10-31 04:28:13,519 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:28:51,429 - INFO - Trial 260: Train MSE=2.3380471978868758, Train R²=0.610777456845556
2024-10-31 04:28:51,429 - INFO - Trial 260: Test MSE=2.2484794684818814, Test R²=0.6339528220040458
2024-10-31 04:28:51,429 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:29:29,170 - INFO - Trial 261: Train MSE=2.5389468244143893, Train R²=0.5772672316857747
2024-10-31 04:29:29,170 - INFO - Trial 261: Test MSE=2.2144709655216763, Test R²=0.6394700493131366
2024-10-31 04:29:29,170 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:30:25,374 - INFO - Trial 262: Train MSE=2.3950019968407497, Train R²=0.5998415340270314
2024-10-31 04:30:25,374 - INFO - Trial 262: Test MSE=2.2335782051086426, Test R²=0.6349100427968162
2024-10-31 04:30:25,374 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:31:11,533 - INFO - Trial 263: Train MSE=2.452687348638262, Train R²=0.5915068238973618
2024-10-31 04:31:11,533 - INFO - Trial 263: Test MSE=2.22574520111084, Test R²=0.6376652717590332
2024-10-31 04:31:11,533 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:31:48,903 - INFO - Trial 264: Train MSE=2.425370122705187, Train R²=0.5966447059597287
2024-10-31 04:31:48,904 - INFO - Trial 264: Test MSE=2.2611037492752075, Test R²=0.6319243737629482
2024-10-31 04:31:48,904 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:32:26,457 - INFO - Trial 265: Train MSE=2.4914355788912093, Train R²=0.5848632752895355
2024-10-31 04:32:26,457 - INFO - Trial 265: Test MSE=2.279481887817383, Test R²=0.6290535160473415
2024-10-31 04:32:26,457 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:33:04,076 - INFO - Trial 266: Train MSE=2.3632177114486694, Train R²=0.6066449603864125
2024-10-31 04:33:04,076 - INFO - Trial 266: Test MSE=2.2780421461377824, Test R²=0.6292922581945147
2024-10-31 04:33:04,076 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:33:35,643 - INFO - Trial 267: Train MSE=2.7221736226763045, Train R²=0.5481831346239362
2024-10-31 04:33:35,644 - INFO - Trial 267: Test MSE=2.2517759203910828, Test R²=0.6309264749288559
2024-10-31 04:33:35,644 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:34:13,068 - INFO - Trial 268: Train MSE=2.306761690548488, Train R²=0.6152714363166264
2024-10-31 04:34:13,068 - INFO - Trial 268: Test MSE=2.2652672018323625, Test R²=0.6310158712523324
2024-10-31 04:34:13,068 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:34:50,574 - INFO - Trial 269: Train MSE=2.418507848467146, Train R²=0.5976606373276029
2024-10-31 04:34:50,574 - INFO - Trial 269: Test MSE=2.2581896441323415, Test R²=0.6324991754123143
2024-10-31 04:34:50,574 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:35:31,313 - INFO - Trial 270: Train MSE=2.7274035130228316, Train R²=0.5471711648362023
2024-10-31 04:35:31,313 - INFO - Trial 270: Test MSE=2.2861169406345914, Test R²=0.6280534693173
2024-10-31 04:35:31,313 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:36:08,911 - INFO - Trial 271: Train MSE=2.5761796150888716, Train R²=0.5707434394529888
2024-10-31 04:36:08,911 - INFO - Trial 271: Test MSE=2.228778600692749, Test R²=0.6372085298810687
2024-10-31 04:36:08,911 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:36:46,454 - INFO - Trial 272: Train MSE=2.3892293742724826, Train R²=0.6030355308737073
2024-10-31 04:36:46,455 - INFO - Trial 272: Test MSE=2.2729789529527937, Test R²=0.6300341486930847
2024-10-31 04:36:46,455 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:37:22,855 - INFO - Trial 273: Train MSE=2.433716595172882, Train R²=0.595027323280062
2024-10-31 04:37:22,855 - INFO - Trial 273: Test MSE=2.237341982977731, Test R²=0.6358270474842617
2024-10-31 04:37:22,855 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:38:00,663 - INFO - Trial 274: Train MSE=2.4836808357919966, Train R²=0.5864028653928212
2024-10-31 04:38:00,663 - INFO - Trial 274: Test MSE=2.232860633305141, Test R²=0.6365431291716439
2024-10-31 04:38:00,663 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:38:36,151 - INFO - Trial 275: Train MSE=2.4582620007651195, Train R²=0.5904068925551006
2024-10-31 04:38:36,151 - INFO - Trial 275: Test MSE=2.2653913838522777, Test R²=0.6314776028905597
2024-10-31 04:38:36,151 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:39:15,110 - INFO - Trial 276: Train MSE=1.9397926671164376, Train R²=0.6766972712108067
2024-10-31 04:39:15,110 - INFO - Trial 276: Test MSE=2.293588876724243, Test R²=0.6267932142530169
2024-10-31 04:39:15,110 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:39:50,695 - INFO - Trial 277: Train MSE=2.4705997109413147, Train R²=0.5895452925137111
2024-10-31 04:39:50,695 - INFO - Trial 277: Test MSE=2.238101499421256, Test R²=0.6356845583234515
2024-10-31 04:39:50,695 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:41:13,236 - INFO - Trial 278: Train MSE=2.2265616761786595, Train R²=0.6243448869458267
2024-10-31 04:41:13,236 - INFO - Trial 278: Test MSE=2.2317107362406596, Test R²=0.6294541358947754
2024-10-31 04:41:13,236 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:41:51,153 - INFO - Trial 279: Train MSE=2.4538627096584866, Train R²=0.5909724618707385
2024-10-31 04:41:51,153 - INFO - Trial 279: Test MSE=2.282497729573931, Test R²=0.6286044376237052
2024-10-31 04:41:51,153 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:42:26,590 - INFO - Trial 280: Train MSE=2.2312507033348083, Train R²=0.6291508036000388
2024-10-31 04:42:26,590 - INFO - Trial 280: Test MSE=2.260553939001901, Test R²=0.6320698346410479
2024-10-31 04:42:26,590 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:43:02,220 - INFO - Trial 281: Train MSE=2.4275973779814586, Train R²=0.5958910669599261
2024-10-31 04:43:02,220 - INFO - Trial 281: Test MSE=2.2314301218305315, Test R²=0.6367016775267464
2024-10-31 04:43:02,220 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:43:38,015 - INFO - Trial 282: Train MSE=2.275342788015093, Train R²=0.6216008492878505
2024-10-31 04:43:38,015 - INFO - Trial 282: Test MSE=2.236318383898054, Test R²=0.6360952428409031
2024-10-31 04:43:38,015 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:44:13,592 - INFO - Trial 283: Train MSE=2.346627984728132, Train R²=0.6088710044111524
2024-10-31 04:44:13,592 - INFO - Trial 283: Test MSE=2.2571724142347063, Test R²=0.6325494987624032
2024-10-31 04:44:13,592 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:44:50,987 - INFO - Trial 284: Train MSE=2.505920044013432, Train R²=0.582916892000607
2024-10-31 04:44:50,987 - INFO - Trial 284: Test MSE=2.266186032976423, Test R²=0.6312505091939654
2024-10-31 04:44:50,987 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:45:26,433 - INFO - Trial 285: Train MSE=2.1406856094087874, Train R²=0.6442804549421582
2024-10-31 04:45:26,433 - INFO - Trial 285: Test MSE=2.2645218202045987, Test R²=0.6314704843929836
2024-10-31 04:45:26,433 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:46:15,350 - INFO - Trial 286: Train MSE=2.013036016907011, Train R²=0.6647034585475922
2024-10-31 04:46:15,350 - INFO - Trial 286: Test MSE=2.2360386167253767, Test R²=0.6359152368136815
2024-10-31 04:46:15,350 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:47:13,949 - INFO - Trial 287: Train MSE=2.2561962200062617, Train R²=0.6237848986472402
2024-10-31 04:47:13,949 - INFO - Trial 287: Test MSE=2.244447444166456, Test R²=0.6325963139533997
2024-10-31 04:47:13,949 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:47:51,859 - INFO - Trial 288: Train MSE=0.7370601381574359, Train R²=0.8777743130922318
2024-10-31 04:47:51,860 - INFO - Trial 288: Test MSE=2.4687580381120955, Test R²=0.5977508766310555
2024-10-31 04:47:51,860 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:48:27,138 - INFO - Trial 289: Train MSE=7.307427406311035, Train R²=-0.21729553171566554
2024-10-31 04:48:27,139 - INFO - Trial 289: Test MSE=2.445009163447789, Test R²=0.6021783011300224
2024-10-31 04:48:27,139 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:49:03,273 - INFO - Trial 290: Train MSE=2.4122636573655263, Train R²=0.5990757473877498
2024-10-31 04:49:03,274 - INFO - Trial 290: Test MSE=2.2707748413085938, Test R²=0.6303932070732117
2024-10-31 04:49:03,274 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:49:42,233 - INFO - Trial 291: Train MSE=2.262732501540865, Train R²=0.6238899976015091
2024-10-31 04:49:42,233 - INFO - Trial 291: Test MSE=2.2339653628213063, Test R²=0.6363614882741656
2024-10-31 04:49:42,233 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:50:18,097 - INFO - Trial 292: Train MSE=2.445318673338209, Train R²=0.5935842948300498
2024-10-31 04:50:18,097 - INFO - Trial 292: Test MSE=2.3004694325583324, Test R²=0.625535079411098
2024-10-31 04:50:18,097 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:50:48,397 - INFO - Trial 293: Train MSE=2.4864679064069475, Train R²=0.5868363210133144
2024-10-31 04:50:48,397 - INFO - Trial 293: Test MSE=2.256321966648102, Test R²=0.6300691366195679
2024-10-31 04:50:48,397 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:51:26,043 - INFO - Trial 294: Train MSE=2.401508237634386, Train R²=0.6005606161696571
2024-10-31 04:51:26,043 - INFO - Trial 294: Test MSE=2.2989799976348877, Test R²=0.6257661325590951
2024-10-31 04:51:26,044 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:52:04,584 - INFO - Trial 295: Train MSE=2.2959571395601546, Train R²=0.6175797283649445
2024-10-31 04:52:04,585 - INFO - Trial 295: Test MSE=2.254209416253226, Test R²=0.632930474621909
2024-10-31 04:52:04,585 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:52:43,514 - INFO - Trial 296: Train MSE=2.1315843718392506, Train R²=0.6458525317055839
2024-10-31 04:52:43,514 - INFO - Trial 296: Test MSE=2.233226469584874, Test R²=0.6365242344992501
2024-10-31 04:52:43,514 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:53:19,980 - INFO - Trial 297: Train MSE=2.40254761491503, Train R²=0.5999989381858281
2024-10-31 04:53:19,980 - INFO - Trial 297: Test MSE=2.266232422419957, Test R²=0.6310320496559143
2024-10-31 04:53:19,980 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:53:55,315 - INFO - Trial 298: Train MSE=2.546766562121255, Train R²=0.5748138683182853
2024-10-31 04:53:55,315 - INFO - Trial 298: Test MSE=2.238236665725708, Test R²=0.6357101457459586
2024-10-31 04:53:55,316 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:54:32,657 - INFO - Trial 299: Train MSE=2.5130977630615234, Train R²=0.5817090741225651
2024-10-31 04:54:32,657 - INFO - Trial 299: Test MSE=2.2821148463657925, Test R²=0.6286637953349522
2024-10-31 04:54:32,657 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:55:09,718 - INFO - Trial 300: Train MSE=2.5772161909512112, Train R²=0.5715201326778957
2024-10-31 04:55:09,718 - INFO - Trial 300: Test MSE=2.2549554961068288, Test R²=0.6329049382890973
2024-10-31 04:55:09,718 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:55:48,185 - INFO - Trial 301: Train MSE=2.936403385230473, Train R²=0.511964208313397
2024-10-31 04:55:48,185 - INFO - Trial 301: Test MSE=2.3929290430886403, Test R²=0.6105112518583026
2024-10-31 04:55:48,185 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:57:08,690 - INFO - Trial 302: Train MSE=2.2762872108391354, Train R²=0.6173598180924144
2024-10-31 04:57:08,691 - INFO - Trial 302: Test MSE=2.2894900909491946, Test R²=0.6204299543585096
2024-10-31 04:57:08,691 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:57:46,305 - INFO - Trial 303: Train MSE=0.9272432987179074, Train R²=0.8460352314370019
2024-10-31 04:57:46,305 - INFO - Trial 303: Test MSE=2.374887091772897, Test R²=0.6131973607199532
2024-10-31 04:57:46,305 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:58:34,812 - INFO - Trial 304: Train MSE=1.9801322647503443, Train R²=0.6710688088621412
2024-10-31 04:58:34,812 - INFO - Trial 304: Test MSE=2.260139056614467, Test R²=0.632022670337132
2024-10-31 04:58:34,812 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:59:10,057 - INFO - Trial 305: Train MSE=2.481178547654833, Train R²=0.5861135976655143
2024-10-31 04:59:10,057 - INFO - Trial 305: Test MSE=2.2880900587354387, Test R²=0.627639821597508
2024-10-31 04:59:10,057 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 04:59:47,034 - INFO - Trial 306: Train MSE=2.4595275776726857, Train R²=0.5904124059847423
2024-10-31 04:59:47,035 - INFO - Trial 306: Test MSE=2.278205292565482, Test R²=0.6291433147021702
2024-10-31 04:59:47,035 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:00:22,249 - INFO - Trial 307: Train MSE=2.453566304274968, Train R²=0.5911221674510411
2024-10-31 05:00:22,249 - INFO - Trial 307: Test MSE=2.237014753477914, Test R²=0.6358523028237479
2024-10-31 05:00:22,249 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:00:59,768 - INFO - Trial 308: Train MSE=2.4497735244887218, Train R²=0.5910840204783848
2024-10-31 05:00:59,768 - INFO - Trial 308: Test MSE=2.271241698946272, Test R²=0.6303204127720424
2024-10-31 05:00:59,768 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:01:40,871 - INFO - Trial 309: Train MSE=2.531344311577933, Train R²=0.5791797893387931
2024-10-31 05:01:40,871 - INFO - Trial 309: Test MSE=2.3097563130514964, Test R²=0.6240125383649554
2024-10-31 05:01:40,872 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:02:16,407 - INFO - Trial 310: Train MSE=2.4236732721328735, Train R²=0.5958271878106254
2024-10-31 05:02:16,408 - INFO - Trial 310: Test MSE=2.248218468257359, Test R²=0.6341434972626823
2024-10-31 05:02:16,408 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:03:17,992 - INFO - Trial 311: Train MSE=2.0431672100509917, Train R²=0.6579180189541408
2024-10-31 05:03:17,992 - INFO - Trial 311: Test MSE=2.30541683946337, Test R²=0.6227318729673114
2024-10-31 05:03:17,992 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:03:54,928 - INFO - Trial 312: Train MSE=1.3461391925811768, Train R²=0.7753533103636333
2024-10-31 05:03:54,928 - INFO - Trial 312: Test MSE=2.367560863494873, Test R²=0.6146855524608067
2024-10-31 05:03:54,928 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:04:32,129 - INFO - Trial 313: Train MSE=1.5749212162835258, Train R²=0.7382972666195461
2024-10-31 05:04:32,129 - INFO - Trial 313: Test MSE=2.3991030624934604, Test R²=0.60919303553445
2024-10-31 05:04:32,129 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:05:08,291 - INFO - Trial 314: Train MSE=2.8759666425841197, Train R²=0.5218379369803837
2024-10-31 05:05:08,292 - INFO - Trial 314: Test MSE=2.264634132385254, Test R²=0.6314137492861066
2024-10-31 05:05:08,292 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:05:43,868 - INFO - Trial 315: Train MSE=2.262626984289714, Train R²=0.6236775262015206
2024-10-31 05:05:43,868 - INFO - Trial 315: Test MSE=2.267743076596941, Test R²=0.6308603371892657
2024-10-31 05:05:43,868 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:06:21,370 - INFO - Trial 316: Train MSE=2.4897186926433017, Train R²=0.5841356409447533
2024-10-31 05:06:21,370 - INFO - Trial 316: Test MSE=2.2194372585841586, Test R²=0.6388825263295855
2024-10-31 05:06:21,370 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:06:59,172 - INFO - Trial 317: Train MSE=2.126807851450784, Train R²=0.6472357085772923
2024-10-31 05:06:59,172 - INFO - Trial 317: Test MSE=2.2702649235725403, Test R²=0.627657875418663
2024-10-31 05:06:59,172 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:07:37,261 - INFO - Trial 318: Train MSE=1.6503361463546753, Train R²=0.7259285066808973
2024-10-31 05:07:37,261 - INFO - Trial 318: Test MSE=2.2941061769212996, Test R²=0.6262868131910052
2024-10-31 05:07:37,262 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:08:15,157 - INFO - Trial 319: Train MSE=2.535927312714713, Train R²=0.5775168985128403
2024-10-31 05:08:15,157 - INFO - Trial 319: Test MSE=2.3946084635598317, Test R²=0.6104017921856472
2024-10-31 05:08:15,157 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:08:50,210 - INFO - Trial 320: Train MSE=2.702716512339456, Train R²=0.5499258232968194
2024-10-31 05:08:50,210 - INFO - Trial 320: Test MSE=2.2952373708997453, Test R²=0.626507146017892
2024-10-31 05:08:50,210 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:09:27,263 - INFO - Trial 321: Train MSE=2.480806257043566, Train R²=0.586752495595387
2024-10-31 05:09:27,263 - INFO - Trial 321: Test MSE=2.2695096220288957, Test R²=0.6306720120566232
2024-10-31 05:09:27,263 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:10:04,803 - INFO - Trial 322: Train MSE=2.4592882139342174, Train R²=0.5907099140541894
2024-10-31 05:10:04,803 - INFO - Trial 322: Test MSE=2.3066373893192837, Test R²=0.624481805733272
2024-10-31 05:10:04,803 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:10:42,254 - INFO - Trial 323: Train MSE=2.4834506852286204, Train R²=0.5874399436371667
2024-10-31 05:10:42,254 - INFO - Trial 323: Test MSE=2.273055451256888, Test R²=0.6298700485910688
2024-10-31 05:10:42,254 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:11:19,709 - INFO - Trial 324: Train MSE=2.3595806530543735, Train R²=0.6072107170309339
2024-10-31 05:11:19,709 - INFO - Trial 324: Test MSE=2.2444036347525462, Test R²=0.63473813022886
2024-10-31 05:11:19,709 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:11:54,218 - INFO - Trial 325: Train MSE=3.091036481516702, Train R²=0.48529237721647533
2024-10-31 05:11:54,218 - INFO - Trial 325: Test MSE=2.274092503956386, Test R²=0.6300041505268642
2024-10-31 05:11:54,218 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:12:30,278 - INFO - Trial 326: Train MSE=2.4298451117106845, Train R²=0.5961460620164871
2024-10-31 05:12:30,278 - INFO - Trial 326: Test MSE=2.2856766496385847, Test R²=0.627949629511152
2024-10-31 05:12:30,278 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:13:07,753 - INFO - Trial 327: Train MSE=2.1570945935589925, Train R²=0.641019486955234
2024-10-31 05:13:07,753 - INFO - Trial 327: Test MSE=2.312955617904663, Test R²=0.6234788639204842
2024-10-31 05:13:07,753 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:14:52,257 - INFO - Trial 328: Train MSE=1.2602692246437073, Train R²=0.7874592707625457
2024-10-31 05:14:52,257 - INFO - Trial 328: Test MSE=2.5770043347563063, Test R²=0.5747498720884323
2024-10-31 05:14:52,257 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:15:28,878 - INFO - Trial 329: Train MSE=2.4758189831461226, Train R²=0.5877434717757362
2024-10-31 05:15:28,878 - INFO - Trial 329: Test MSE=2.293093340737479, Test R²=0.6267314723559788
2024-10-31 05:15:28,879 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:16:05,588 - INFO - Trial 330: Train MSE=2.299868183476584, Train R²=0.6167665464537484
2024-10-31 05:16:05,588 - INFO - Trial 330: Test MSE=2.211059025355748, Test R²=0.6401682070323399
2024-10-31 05:16:05,588 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:16:41,638 - INFO - Trial 331: Train MSE=2.3866985184805736, Train R²=0.602940348642213
2024-10-31 05:16:41,638 - INFO - Trial 331: Test MSE=2.228564943586077, Test R²=0.6372057965823582
2024-10-31 05:16:41,638 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:17:15,755 - INFO - Trial 332: Train MSE=2.4615416484219685, Train R²=0.5900251971823829
2024-10-31 05:17:15,755 - INFO - Trial 332: Test MSE=2.2816756793430875, Test R²=0.6287215181759426
2024-10-31 05:17:15,755 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:17:51,506 - INFO - Trial 333: Train MSE=2.407179091657911, Train R²=0.5988954816545758
2024-10-31 05:17:51,507 - INFO - Trial 333: Test MSE=2.296912295477731, Test R²=0.6260954397065299
2024-10-31 05:17:51,507 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:18:27,062 - INFO - Trial 334: Train MSE=2.2401155701705386, Train R²=0.6271328989948545
2024-10-31 05:18:27,062 - INFO - Trial 334: Test MSE=2.214784894670759, Test R²=0.6395817909921918
2024-10-31 05:18:27,062 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:19:26,035 - INFO - Trial 335: Train MSE=2.2005078813859393, Train R²=0.6321280875376293
2024-10-31 05:19:26,035 - INFO - Trial 335: Test MSE=2.267225239958082, Test R²=0.629269174167088
2024-10-31 05:19:26,035 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:20:01,977 - INFO - Trial 336: Train MSE=2.1381431009088243, Train R²=0.6441679554326194
2024-10-31 05:20:01,977 - INFO - Trial 336: Test MSE=2.248220239366804, Test R²=0.6342721922057015
2024-10-31 05:20:01,977 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:20:41,423 - INFO - Trial 337: Train MSE=1.6207326224872045, Train R²=0.7302588799170086
2024-10-31 05:20:41,423 - INFO - Trial 337: Test MSE=2.2965115138462613, Test R²=0.6259343198367527
2024-10-31 05:20:41,423 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:21:17,406 - INFO - Trial 338: Train MSE=2.0928252041339874, Train R²=0.6514118952410561
2024-10-31 05:21:17,407 - INFO - Trial 338: Test MSE=2.2615372453417097, Test R²=0.6318956187793187
2024-10-31 05:21:17,407 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:21:52,954 - INFO - Trial 339: Train MSE=2.2485787102154324, Train R²=0.6263086519071034
2024-10-31 05:21:52,954 - INFO - Trial 339: Test MSE=2.256115334374564, Test R²=0.6327908294541496
2024-10-31 05:21:52,954 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:22:28,576 - INFO - Trial 340: Train MSE=2.4374133348464966, Train R²=0.5943368311439242
2024-10-31 05:22:28,576 - INFO - Trial 340: Test MSE=2.243496469088963, Test R²=0.6347648927143642
2024-10-31 05:22:28,577 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:23:04,162 - INFO - Trial 341: Train MSE=2.239507781607764, Train R²=0.6267867854663304
2024-10-31 05:23:04,162 - INFO - Trial 341: Test MSE=2.2302871431623186, Test R²=0.6368778433118548
2024-10-31 05:23:04,162 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:23:43,247 - INFO - Trial 342: Train MSE=2.0238606802054813, Train R²=0.6629305630922318
2024-10-31 05:23:43,247 - INFO - Trial 342: Test MSE=2.230888945715768, Test R²=0.6366437929017204
2024-10-31 05:23:43,247 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:24:18,892 - INFO - Trial 343: Train MSE=2.373760368142809, Train R²=0.6050848343542644
2024-10-31 05:24:18,892 - INFO - Trial 343: Test MSE=2.2223993710109164, Test R²=0.6383324520928519
2024-10-31 05:24:18,892 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:25:00,298 - INFO - Trial 344: Train MSE=2.869220886911665, Train R²=0.521740585565567
2024-10-31 05:25:00,299 - INFO - Trial 344: Test MSE=2.285058856010437, Test R²=0.6279431581497192
2024-10-31 05:25:00,299 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:25:33,367 - INFO - Trial 345: Train MSE=2.6609998430524553, Train R²=0.5576311009270805
2024-10-31 05:25:33,367 - INFO - Trial 345: Test MSE=2.24323707818985, Test R²=0.6322271823883057
2024-10-31 05:25:33,367 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:26:09,322 - INFO - Trial 346: Train MSE=2.4139882070677623, Train R²=0.5992410182952881
2024-10-31 05:26:09,322 - INFO - Trial 346: Test MSE=2.2233847890581404, Test R²=0.6378914543560573
2024-10-31 05:26:09,322 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:26:44,489 - INFO - Trial 347: Train MSE=2.465303352900914, Train R²=0.5906118303537369
2024-10-31 05:26:44,490 - INFO - Trial 347: Test MSE=2.2232854877199446, Test R²=0.638003579207829
2024-10-31 05:26:44,490 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:27:23,087 - INFO - Trial 348: Train MSE=2.4889768191746304, Train R²=0.5849681666919163
2024-10-31 05:27:23,087 - INFO - Trial 348: Test MSE=2.2405517441885814, Test R²=0.6353280714579991
2024-10-31 05:27:23,087 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:27:59,405 - INFO - Trial 349: Train MSE=2.3971971699169705, Train R²=0.6015258069549289
2024-10-31 05:27:59,405 - INFO - Trial 349: Test MSE=2.2228888954435075, Test R²=0.6382722003119332
2024-10-31 05:27:59,405 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:28:35,573 - INFO - Trial 350: Train MSE=2.5414739847183228, Train R²=0.5765147932938167
2024-10-31 05:28:35,574 - INFO - Trial 350: Test MSE=2.214503458568028, Test R²=0.6396249617849078
2024-10-31 05:28:35,574 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:29:10,889 - INFO - Trial 351: Train MSE=2.568370827606746, Train R²=0.5715901894228799
2024-10-31 05:29:10,889 - INFO - Trial 351: Test MSE=2.2415993554251537, Test R²=0.635200994355338
2024-10-31 05:29:10,889 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:29:46,017 - INFO - Trial 352: Train MSE=2.6258808629853383, Train R²=0.5629563821213586
2024-10-31 05:29:46,017 - INFO - Trial 352: Test MSE=2.2360385145459856, Test R²=0.6361439738954816
2024-10-31 05:29:46,017 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:30:22,152 - INFO - Trial 353: Train MSE=2.4968338353293285, Train R²=0.5847726655857903
2024-10-31 05:30:22,152 - INFO - Trial 353: Test MSE=2.2555259466171265, Test R²=0.6328986627714974
2024-10-31 05:30:22,152 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:30:58,465 - INFO - Trial 354: Train MSE=2.4382233789988925, Train R²=0.5938876760857446
2024-10-31 05:30:58,465 - INFO - Trial 354: Test MSE=2.2268925734928677, Test R²=0.6374720164707729
2024-10-31 05:30:58,465 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:32:18,490 - INFO - Trial 355: Train MSE=1.8122655749320984, Train R²=0.6945907425667558
2024-10-31 05:32:18,490 - INFO - Trial 355: Test MSE=2.3061873572213307, Test R²=0.6182233031306948
2024-10-31 05:32:18,490 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:32:53,645 - INFO - Trial 356: Train MSE=2.527464270591736, Train R²=0.5806174980742591
2024-10-31 05:32:53,645 - INFO - Trial 356: Test MSE=2.247266275542123, Test R²=0.63419828244618
2024-10-31 05:32:53,645 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:33:30,808 - INFO - Trial 357: Train MSE=2.2317507437297275, Train R²=0.6296230916466031
2024-10-31 05:33:30,808 - INFO - Trial 357: Test MSE=2.2277611323765347, Test R²=0.6375476121902466
2024-10-31 05:33:30,808 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:34:06,521 - INFO - Trial 358: Train MSE=2.4675610406058177, Train R²=0.589255554335458
2024-10-31 05:34:06,521 - INFO - Trial 358: Test MSE=2.237214973994664, Test R²=0.6359006847654071
2024-10-31 05:34:06,521 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:34:42,898 - INFO - Trial 359: Train MSE=2.7234709347997392, Train R²=0.5474029736859458
2024-10-31 05:34:42,898 - INFO - Trial 359: Test MSE=2.2372422218322754, Test R²=0.6359606470380511
2024-10-31 05:34:42,898 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:35:18,476 - INFO - Trial 360: Train MSE=2.3834987793649947, Train R²=0.6026788034609386
2024-10-31 05:35:18,476 - INFO - Trial 360: Test MSE=2.222227079527719, Test R²=0.6382178919655936
2024-10-31 05:35:18,476 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:35:53,994 - INFO - Trial 361: Train MSE=2.4094784940992082, Train R²=0.5981388113328389
2024-10-31 05:35:53,994 - INFO - Trial 361: Test MSE=2.205092804772513, Test R²=0.6409881029810224
2024-10-31 05:35:53,994 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:36:56,218 - INFO - Trial 362: Train MSE=2.1720445581844876, Train R²=0.6352904492190906
2024-10-31 05:36:56,219 - INFO - Trial 362: Test MSE=2.2385707838194713, Test R²=0.6340546352522713
2024-10-31 05:36:56,219 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:37:35,800 - INFO - Trial 363: Train MSE=2.4517663972718373, Train R²=0.5918456677879605
2024-10-31 05:37:35,801 - INFO - Trial 363: Test MSE=2.2627698183059692, Test R²=0.6316831111907959
2024-10-31 05:37:35,801 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:38:24,052 - INFO - Trial 364: Train MSE=0.8325105437210628, Train R²=0.8613459531749997
2024-10-31 05:38:24,052 - INFO - Trial 364: Test MSE=2.5696167264665877, Test R²=0.581774754183633
2024-10-31 05:38:24,052 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:38:59,799 - INFO - Trial 365: Train MSE=2.5816123144967213, Train R²=0.5696314083678382
2024-10-31 05:38:59,799 - INFO - Trial 365: Test MSE=2.254703606878008, Test R²=0.632981368473598
2024-10-31 05:38:59,799 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:39:35,900 - INFO - Trial 366: Train MSE=2.5241908175604686, Train R²=0.5789777487516403
2024-10-31 05:39:35,900 - INFO - Trial 366: Test MSE=2.237692322049822, Test R²=0.6356541854994637
2024-10-31 05:39:35,900 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:40:13,506 - INFO - Trial 367: Train MSE=2.4901746937206815, Train R²=0.5855140196425574
2024-10-31 05:40:13,507 - INFO - Trial 367: Test MSE=2.232853991644723, Test R²=0.6364454712186541
2024-10-31 05:40:13,507 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:40:50,129 - INFO - Trial 368: Train MSE=2.6281014595712935, Train R²=0.5627100680555616
2024-10-31 05:40:50,129 - INFO - Trial 368: Test MSE=2.2470448868615285, Test R²=0.6342656442097255
2024-10-31 05:40:50,129 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:41:25,790 - INFO - Trial 369: Train MSE=2.535593254225595, Train R²=0.5780327469110489
2024-10-31 05:41:25,790 - INFO - Trial 369: Test MSE=2.256194829940796, Test R²=0.6327278103147235
2024-10-31 05:41:25,790 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:42:02,016 - INFO - Trial 370: Train MSE=2.8378916553088596, Train R²=0.5272788426705769
2024-10-31 05:42:02,016 - INFO - Trial 370: Test MSE=2.2627665315355574, Test R²=0.6317332642418998
2024-10-31 05:42:02,016 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:42:38,395 - INFO - Trial 371: Train MSE=2.3855911791324615, Train R²=0.6032299825123378
2024-10-31 05:42:38,395 - INFO - Trial 371: Test MSE=2.2308030469076976, Test R²=0.6369506461279733
2024-10-31 05:42:38,395 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:43:08,650 - INFO - Trial 372: Train MSE=1.9652539321354456, Train R²=0.673646309546062
2024-10-31 05:43:08,651 - INFO - Trial 372: Test MSE=2.3148276805877686, Test R²=0.6203107535839081
2024-10-31 05:43:08,651 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:43:43,772 - INFO - Trial 373: Train MSE=2.3662434348038266, Train R²=0.6066283924239022
2024-10-31 05:43:43,772 - INFO - Trial 373: Test MSE=2.270875930786133, Test R²=0.6303494998386928
2024-10-31 05:43:43,772 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:44:19,161 - INFO - Trial 374: Train MSE=2.371669271162578, Train R²=0.6050766600029809
2024-10-31 05:44:19,162 - INFO - Trial 374: Test MSE=2.2291723489761353, Test R²=0.6371842282158988
2024-10-31 05:44:19,162 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:44:54,539 - INFO - Trial 375: Train MSE=2.4685037561825345, Train R²=0.5896766909531185
2024-10-31 05:44:54,539 - INFO - Trial 375: Test MSE=2.2386934416634694, Test R²=0.6357049686568124
2024-10-31 05:44:54,539 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:45:33,458 - INFO - Trial 376: Train MSE=2.3984100307737077, Train R²=0.6011188051530293
2024-10-31 05:45:33,458 - INFO - Trial 376: Test MSE=2.232338683945792, Test R²=0.6366932306970868
2024-10-31 05:45:33,458 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:46:07,034 - INFO - Trial 377: Train MSE=2.8015222123691013, Train R²=0.5343238370759147
2024-10-31 05:46:07,034 - INFO - Trial 377: Test MSE=2.331815617425101, Test R²=0.6205170665468488
2024-10-31 05:46:07,035 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:46:45,560 - INFO - Trial 378: Train MSE=2.235163778066635, Train R²=0.6280521920749119
2024-10-31 05:46:45,560 - INFO - Trial 378: Test MSE=2.2118939331599643, Test R²=0.6399265953472683
2024-10-31 05:46:45,560 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:47:21,980 - INFO - Trial 379: Train MSE=2.130529280219759, Train R²=0.6461105325392315
2024-10-31 05:47:21,980 - INFO - Trial 379: Test MSE=2.2618799890790666, Test R²=0.6318831103188651
2024-10-31 05:47:21,980 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:48:43,187 - INFO - Trial 380: Train MSE=1.299316500446626, Train R²=0.7797537898378712
2024-10-31 05:48:43,187 - INFO - Trial 380: Test MSE=2.4900278576782773, Test R²=0.5886583370821816
2024-10-31 05:48:43,187 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:49:18,886 - INFO - Trial 381: Train MSE=2.281863199813025, Train R²=0.6202518045902252
2024-10-31 05:49:18,886 - INFO - Trial 381: Test MSE=2.259048342704773, Test R²=0.6323797362191337
2024-10-31 05:49:18,886 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:50:07,432 - INFO - Trial 382: Train MSE=1.6720588632992335, Train R²=0.7216098095689502
2024-10-31 05:50:07,432 - INFO - Trial 382: Test MSE=2.2973331723894392, Test R²=0.6259854861668178
2024-10-31 05:50:07,433 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:50:43,414 - INFO - Trial 383: Train MSE=2.207708703620093, Train R²=0.6331250837871006
2024-10-31 05:50:43,414 - INFO - Trial 383: Test MSE=2.22412599836077, Test R²=0.6377989649772644
2024-10-31 05:50:43,415 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:51:19,617 - INFO - Trial 384: Train MSE=2.646880422319685, Train R²=0.5595257005521229
2024-10-31 05:51:19,618 - INFO - Trial 384: Test MSE=2.2423036439078197, Test R²=0.635147477899279
2024-10-31 05:51:19,618 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:51:56,205 - INFO - Trial 385: Train MSE=2.242350310087204, Train R²=0.6269024248634066
2024-10-31 05:51:56,205 - INFO - Trial 385: Test MSE=2.239530495234898, Test R²=0.6353222046579633
2024-10-31 05:51:56,205 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:52:32,275 - INFO - Trial 386: Train MSE=2.3719066892351424, Train R²=0.6053940866674695
2024-10-31 05:52:32,275 - INFO - Trial 386: Test MSE=2.2195256778172086, Test R²=0.6386115891592843
2024-10-31 05:52:32,275 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:53:31,656 - INFO - Trial 387: Train MSE=2.551659658551216, Train R²=0.5740513152309826
2024-10-31 05:53:31,657 - INFO - Trial 387: Test MSE=2.291445757661547, Test R²=0.6250043979712895
2024-10-31 05:53:31,657 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:54:07,987 - INFO - Trial 388: Train MSE=2.155273505619594, Train R²=0.6411970108747482
2024-10-31 05:54:07,987 - INFO - Trial 388: Test MSE=2.2754094430378506, Test R²=0.629571795463562
2024-10-31 05:54:07,987 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:54:43,892 - INFO - Trial 389: Train MSE=2.012976016317095, Train R²=0.6646398625203541
2024-10-31 05:54:43,892 - INFO - Trial 389: Test MSE=2.272414582116263, Test R²=0.630076025213514
2024-10-31 05:54:43,892 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:55:22,924 - INFO - Trial 390: Train MSE=2.548010221549443, Train R²=0.5755565570933479
2024-10-31 05:55:22,924 - INFO - Trial 390: Test MSE=2.277219499860491, Test R²=0.6291593824114118
2024-10-31 05:55:22,924 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:55:58,771 - INFO - Trial 391: Train MSE=2.355718808514731, Train R²=0.6077567636966705
2024-10-31 05:55:58,771 - INFO - Trial 391: Test MSE=2.2423350300107683, Test R²=0.6351373536246163
2024-10-31 05:55:58,771 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:56:34,347 - INFO - Trial 392: Train MSE=1.6931395488125938, Train R²=0.7184477129152843
2024-10-31 05:56:34,347 - INFO - Trial 392: Test MSE=2.2789889063153947, Test R²=0.6289160847663879
2024-10-31 05:56:34,347 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:57:10,986 - INFO - Trial 393: Train MSE=2.132485112973622, Train R²=0.6453555332762855
2024-10-31 05:57:10,986 - INFO - Trial 393: Test MSE=2.2377805028642928, Test R²=0.6356244853564671
2024-10-31 05:57:10,986 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:57:49,904 - INFO - Trial 394: Train MSE=2.948472099644797, Train R²=0.5094876672540393
2024-10-31 05:57:49,904 - INFO - Trial 394: Test MSE=2.259167500904628, Test R²=0.6322313717433384
2024-10-31 05:57:49,904 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:58:28,962 - INFO - Trial 395: Train MSE=2.0416271005358015, Train R²=0.6596710767064776
2024-10-31 05:58:28,962 - INFO - Trial 395: Test MSE=2.2322889396122525, Test R²=0.636747522013528
2024-10-31 05:58:28,963 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:58:59,266 - INFO - Trial 396: Train MSE=2.461929270199367, Train R²=0.590659865311214
2024-10-31 05:58:59,266 - INFO - Trial 396: Test MSE=2.2355775833129883, Test R²=0.6335651129484177
2024-10-31 05:58:59,266 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 05:59:35,377 - INFO - Trial 397: Train MSE=2.4465217334883556, Train R²=0.591804387313979
2024-10-31 05:59:35,377 - INFO - Trial 397: Test MSE=2.2454914706093922, Test R²=0.6346447552953448
2024-10-31 05:59:35,377 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:00:11,663 - INFO - Trial 398: Train MSE=2.283908094678606, Train R²=0.6184138464076179
2024-10-31 06:00:11,663 - INFO - Trial 398: Test MSE=2.235009125300816, Test R²=0.6362083383968898
2024-10-31 06:00:11,663 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:00:46,835 - INFO - Trial 399: Train MSE=2.1354143619537354, Train R²=0.6448148425136294
2024-10-31 06:00:46,835 - INFO - Trial 399: Test MSE=2.2392708574022566, Test R²=0.6353371824537005
2024-10-31 06:00:46,835 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:01:23,153 - INFO - Trial 400: Train MSE=2.2676128489630565, Train R²=0.6227748543024063
2024-10-31 06:01:23,153 - INFO - Trial 400: Test MSE=2.2329297746930803, Test R²=0.6365484169551304
2024-10-31 06:01:23,153 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:01:58,561 - INFO - Trial 401: Train MSE=2.8022847941943576, Train R²=0.5325165284531457
2024-10-31 06:01:58,561 - INFO - Trial 401: Test MSE=2.2722692830221995, Test R²=0.6302199193409511
2024-10-31 06:01:58,561 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:02:34,236 - INFO - Trial 402: Train MSE=2.360417289393289, Train R²=0.6060901880264282
2024-10-31 06:02:34,236 - INFO - Trial 402: Test MSE=2.2421652589525496, Test R²=0.6348698905536106
2024-10-31 06:02:34,237 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:03:09,624 - INFO - Trial 403: Train MSE=2.142126679420471, Train R²=0.6437753907271794
2024-10-31 06:03:09,624 - INFO - Trial 403: Test MSE=2.2594165120806013, Test R²=0.6321942806243896
2024-10-31 06:03:09,624 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:03:44,620 - INFO - Trial 404: Train MSE=2.234487840107509, Train R²=0.6281043738126755
2024-10-31 06:03:44,620 - INFO - Trial 404: Test MSE=2.213744112423488, Test R²=0.6395653315952846
2024-10-31 06:03:44,620 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:05:05,026 - INFO - Trial 405: Train MSE=2.1439224800893237, Train R²=0.6375192132379327
2024-10-31 06:05:05,026 - INFO - Trial 405: Test MSE=2.2534343898296356, Test R²=0.6269282017435346
2024-10-31 06:05:05,026 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:05:40,742 - INFO - Trial 406: Train MSE=2.096024227993829, Train R²=0.651351124048233
2024-10-31 06:05:40,743 - INFO - Trial 406: Test MSE=2.262979575565883, Test R²=0.631588910307203
2024-10-31 06:05:40,743 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:06:16,519 - INFO - Trial 407: Train MSE=2.281054620231901, Train R²=0.6204027278082711
2024-10-31 06:06:16,519 - INFO - Trial 407: Test MSE=2.2621110507420132, Test R²=0.631594581263406
2024-10-31 06:06:16,519 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:07:05,000 - INFO - Trial 408: Train MSE=1.7404934636184148, Train R²=0.7098655679396221
2024-10-31 06:07:05,000 - INFO - Trial 408: Test MSE=2.33250321660723, Test R²=0.6203648362840924
2024-10-31 06:07:05,000 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:07:49,350 - INFO - Trial 409: Train MSE=2.640947903905596, Train R²=0.5607068815401622
2024-10-31 06:07:49,350 - INFO - Trial 409: Test MSE=2.256711278642927, Test R²=0.6327760475022453
2024-10-31 06:07:49,350 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:08:25,276 - INFO - Trial 410: Train MSE=2.25947414125715, Train R²=0.6239250898361206
2024-10-31 06:08:25,276 - INFO - Trial 410: Test MSE=2.219691446849278, Test R²=0.6387342044285366
2024-10-31 06:08:25,276 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:09:26,134 - INFO - Trial 411: Train MSE=2.1579367241689136, Train R²=0.6398096712572234
2024-10-31 06:09:26,134 - INFO - Trial 411: Test MSE=2.2241513643945967, Test R²=0.6363240650721959
2024-10-31 06:09:26,134 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:10:03,434 - INFO - Trial 412: Train MSE=2.3124810457229614, Train R²=0.6154917074101312
2024-10-31 06:10:03,434 - INFO - Trial 412: Test MSE=2.2460146290915355, Test R²=0.6344714931079319
2024-10-31 06:10:03,434 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:10:39,633 - INFO - Trial 413: Train MSE=2.22736548100199, Train R²=0.629528420312064
2024-10-31 06:10:39,633 - INFO - Trial 413: Test MSE=2.302467175892421, Test R²=0.6252550312450954
2024-10-31 06:10:39,633 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:11:15,335 - INFO - Trial 414: Train MSE=2.1307798453739712, Train R²=0.6448582091501781
2024-10-31 06:11:15,335 - INFO - Trial 414: Test MSE=2.2741482768739973, Test R²=0.6298594389642987
2024-10-31 06:11:15,335 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:11:51,105 - INFO - Trial 415: Train MSE=2.3433606028556824, Train R²=0.6099109692232949
2024-10-31 06:11:51,105 - INFO - Trial 415: Test MSE=2.269237450190953, Test R²=0.630718639918736
2024-10-31 06:11:51,105 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:12:26,311 - INFO - Trial 416: Train MSE=2.238224242414747, Train R²=0.6275607624224254
2024-10-31 06:12:26,311 - INFO - Trial 416: Test MSE=2.273813452039446, Test R²=0.6299768686294556
2024-10-31 06:12:26,311 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:13:01,911 - INFO - Trial 417: Train MSE=2.34320296560015, Train R²=0.6095446390765054
2024-10-31 06:13:01,911 - INFO - Trial 417: Test MSE=2.274730614253453, Test R²=0.6295901026044574
2024-10-31 06:13:01,911 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:13:38,935 - INFO - Trial 418: Train MSE=2.112998992204666, Train R²=0.6474767710481372
2024-10-31 06:13:38,935 - INFO - Trial 418: Test MSE=2.2576257501329695, Test R²=0.6325451050485883
2024-10-31 06:13:38,935 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:14:16,423 - INFO - Trial 419: Train MSE=2.3128023786204204, Train R²=0.6148538908788136
2024-10-31 06:14:16,423 - INFO - Trial 419: Test MSE=2.262291056769235, Test R²=0.631800651550293
2024-10-31 06:14:16,423 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:14:46,844 - INFO - Trial 420: Train MSE=3.3500451871326993, Train R²=0.4432048073836735
2024-10-31 06:14:46,844 - INFO - Trial 420: Test MSE=2.3293926119804382, Test R²=0.6183660626411438
2024-10-31 06:14:46,844 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:15:22,646 - INFO - Trial 421: Train MSE=2.3282304789338792, Train R²=0.6118032996143613
2024-10-31 06:15:22,646 - INFO - Trial 421: Test MSE=2.2398880549839566, Test R²=0.6354073115757534
2024-10-31 06:15:22,646 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:15:58,379 - INFO - Trial 422: Train MSE=2.534323113305228, Train R²=0.5781286614281791
2024-10-31 06:15:58,379 - INFO - Trial 422: Test MSE=2.247891800744193, Test R²=0.6340424503598895
2024-10-31 06:15:58,379 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:16:37,390 - INFO - Trial 423: Train MSE=2.4125089858259474, Train R²=0.5982913758073535
2024-10-31 06:16:37,390 - INFO - Trial 423: Test MSE=2.274486626897539, Test R²=0.6298635346548898
2024-10-31 06:16:37,390 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:17:13,853 - INFO - Trial 424: Train MSE=2.2947480167661394, Train R²=0.6177032994372504
2024-10-31 06:17:13,853 - INFO - Trial 424: Test MSE=2.222890615463257, Test R²=0.6382196460451398
2024-10-31 06:17:13,853 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:17:50,479 - INFO - Trial 425: Train MSE=1.09297747697149, Train R²=0.8180103536163058
2024-10-31 06:17:50,479 - INFO - Trial 425: Test MSE=2.4528838225773404, Test R²=0.6006691796439034
2024-10-31 06:17:50,479 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:18:26,066 - INFO - Trial 426: Train MSE=2.3116807511874606, Train R²=0.6147854115281787
2024-10-31 06:18:26,066 - INFO - Trial 426: Test MSE=2.230433770588466, Test R²=0.636947512626648
2024-10-31 06:18:26,067 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:19:04,978 - INFO - Trial 427: Train MSE=1.9804990249020713, Train R²=0.6705317837851388
2024-10-31 06:19:04,978 - INFO - Trial 427: Test MSE=2.2586953980582103, Test R²=0.6323367016656058
2024-10-31 06:19:04,978 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:19:40,857 - INFO - Trial 428: Train MSE=2.0596704738480702, Train R²=0.6572419149535043
2024-10-31 06:19:40,857 - INFO - Trial 428: Test MSE=2.246418288775853, Test R²=0.6344107389450073
2024-10-31 06:19:40,857 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:20:16,555 - INFO - Trial 429: Train MSE=2.3621917452131, Train R²=0.6075441603149686
2024-10-31 06:20:16,555 - INFO - Trial 429: Test MSE=2.2414938381740024, Test R²=0.6353560941559928
2024-10-31 06:20:16,555 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:20:57,955 - INFO - Trial 430: Train MSE=2.6886480195181712, Train R²=0.5520178782088416
2024-10-31 06:20:57,955 - INFO - Trial 430: Test MSE=2.309532880783081, Test R²=0.6241314581462315
2024-10-31 06:20:57,955 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:22:19,396 - INFO - Trial 431: Train MSE=2.0538704874260083, Train R²=0.6520273685455322
2024-10-31 06:22:19,396 - INFO - Trial 431: Test MSE=2.2653492050511495, Test R²=0.624896981886455
2024-10-31 06:22:19,396 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:22:55,143 - INFO - Trial 432: Train MSE=2.097194594996316, Train R²=0.6517314506428582
2024-10-31 06:22:55,143 - INFO - Trial 432: Test MSE=2.2480054582868303, Test R²=0.6342974475451878
2024-10-31 06:22:55,143 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:23:34,814 - INFO - Trial 433: Train MSE=2.572031991822379, Train R²=0.5716470032930374
2024-10-31 06:23:34,815 - INFO - Trial 433: Test MSE=2.2963750702994212, Test R²=0.626294459615435
2024-10-31 06:23:34,815 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:24:12,974 - INFO - Trial 434: Train MSE=2.371403685637883, Train R²=0.6043733315808433
2024-10-31 06:24:12,974 - INFO - Trial 434: Test MSE=2.2295615673065186, Test R²=0.637050918170384
2024-10-31 06:24:12,974 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:24:48,263 - INFO - Trial 435: Train MSE=2.385562172957829, Train R²=0.6034218839236668
2024-10-31 06:24:48,263 - INFO - Trial 435: Test MSE=2.2262510572160994, Test R²=0.6376918724605015
2024-10-31 06:24:48,263 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:25:53,178 - INFO - Trial 436: Train MSE=2.2836902013846805, Train R²=0.6171897255948612
2024-10-31 06:25:53,179 - INFO - Trial 436: Test MSE=2.2625675201416016, Test R²=0.6302192424024854
2024-10-31 06:25:53,179 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:26:30,757 - INFO - Trial 437: Train MSE=2.207405081817082, Train R²=0.6325586204017911
2024-10-31 06:26:30,757 - INFO - Trial 437: Test MSE=2.2473364557538713, Test R²=0.6343171341078622
2024-10-31 06:26:30,758 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:27:19,740 - INFO - Trial 438: Train MSE=4.28857329913548, Train R²=0.2861859585557665
2024-10-31 06:27:19,740 - INFO - Trial 438: Test MSE=2.3523952620370046, Test R²=0.6172063095229012
2024-10-31 06:27:19,740 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:27:55,179 - INFO - Trial 439: Train MSE=3.184842688696725, Train R²=0.4694484429700034
2024-10-31 06:27:55,179 - INFO - Trial 439: Test MSE=2.2721568175724576, Test R²=0.6302135075841632
2024-10-31 06:27:55,179 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:28:31,202 - INFO - Trial 440: Train MSE=1.039032248514039, Train R²=0.8271151972668511
2024-10-31 06:28:31,202 - INFO - Trial 440: Test MSE=2.473766803741455, Test R²=0.5974068897111076
2024-10-31 06:28:31,202 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:29:06,745 - INFO - Trial 441: Train MSE=1.344732437814985, Train R²=0.7761364728212357
2024-10-31 06:29:06,745 - INFO - Trial 441: Test MSE=2.4230914456503734, Test R²=0.6057380437850952
2024-10-31 06:29:06,745 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:29:42,169 - INFO - Trial 442: Train MSE=2.1252507311957225, Train R²=0.645688418831144
2024-10-31 06:29:42,169 - INFO - Trial 442: Test MSE=2.27004075050354, Test R²=0.6304777264595032
2024-10-31 06:29:42,169 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:30:19,107 - INFO - Trial 443: Train MSE=2.477890278611864, Train R²=0.5866504503147942
2024-10-31 06:30:19,108 - INFO - Trial 443: Test MSE=2.211977515901838, Test R²=0.6398454053061349
2024-10-31 06:30:19,108 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:30:49,369 - INFO - Trial 444: Train MSE=2.4921870742525374, Train R²=0.5851157563073295
2024-10-31 06:30:49,369 - INFO - Trial 444: Test MSE=2.2466460466384888, Test R²=0.6316666603088379
2024-10-31 06:30:49,370 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:31:25,045 - INFO - Trial 445: Train MSE=2.2662941345146725, Train R²=0.6221357434988022
2024-10-31 06:31:25,046 - INFO - Trial 445: Test MSE=2.243762186595372, Test R²=0.6346411279269627
2024-10-31 06:31:25,046 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:32:00,606 - INFO - Trial 446: Train MSE=2.191301997218813, Train R²=0.6345646658114025
2024-10-31 06:32:00,607 - INFO - Trial 446: Test MSE=2.26211074420384, Test R²=0.6317585962159293
2024-10-31 06:32:00,607 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:32:36,203 - INFO - Trial 447: Train MSE=1.7563357949256897, Train R²=0.7075403077261788
2024-10-31 06:32:36,203 - INFO - Trial 447: Test MSE=2.3501076698303223, Test R²=0.6173056874956403
2024-10-31 06:32:36,204 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:33:12,475 - INFO - Trial 448: Train MSE=2.3854383741106306, Train R²=0.6032476340021405
2024-10-31 06:33:12,475 - INFO - Trial 448: Test MSE=2.230005536760603, Test R²=0.6370572362627301
2024-10-31 06:33:12,475 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:33:48,530 - INFO - Trial 449: Train MSE=2.187989209379469, Train R²=0.6346268611294883
2024-10-31 06:33:48,530 - INFO - Trial 449: Test MSE=2.248188086918422, Test R²=0.6340284092085702
2024-10-31 06:33:48,530 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:34:23,379 - INFO - Trial 450: Train MSE=2.5216074671064104, Train R²=0.5799401381186077
2024-10-31 06:34:23,379 - INFO - Trial 450: Test MSE=2.311312300818307, Test R²=0.6239209260259356
2024-10-31 06:34:23,379 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:35:02,553 - INFO - Trial 451: Train MSE=1.7514412615980421, Train R²=0.7089076893670219
2024-10-31 06:35:02,553 - INFO - Trial 451: Test MSE=2.3458917140960693, Test R²=0.6179474762507847
2024-10-31 06:35:02,553 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:35:38,527 - INFO - Trial 452: Train MSE=2.4199957932744707, Train R²=0.5975827106407711
2024-10-31 06:35:38,527 - INFO - Trial 452: Test MSE=2.225116865975516, Test R²=0.6378863709313529
2024-10-31 06:35:38,527 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:36:14,014 - INFO - Trial 453: Train MSE=2.5167884400912692, Train R²=0.5809990784951619
2024-10-31 06:36:14,014 - INFO - Trial 453: Test MSE=2.2817982775824412, Test R²=0.6285052214350019
2024-10-31 06:36:14,014 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:36:49,531 - INFO - Trial 454: Train MSE=2.0208563762051717, Train R²=0.6633925565651485
2024-10-31 06:36:49,531 - INFO - Trial 454: Test MSE=2.2793441840580533, Test R²=0.6291598422186715
2024-10-31 06:36:49,531 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:38:09,547 - INFO - Trial 455: Train MSE=2.2070587926677296, Train R²=0.6316749240670886
2024-10-31 06:38:09,547 - INFO - Trial 455: Test MSE=2.219188643353326, Test R²=0.6311440723282951
2024-10-31 06:38:09,548 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:39:13,706 - INFO - Trial 456: Train MSE=2.1683794260025024, Train R²=0.6364895137292998
2024-10-31 06:39:13,706 - INFO - Trial 456: Test MSE=2.2368419340678622, Test R²=0.6342053243092128
2024-10-31 06:39:13,706 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:39:50,390 - INFO - Trial 457: Train MSE=2.064074810062136, Train R²=0.655941733292171
2024-10-31 06:39:50,390 - INFO - Trial 457: Test MSE=2.2682407072612216, Test R²=0.6307778188160488
2024-10-31 06:39:50,390 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:41:12,879 - INFO - Trial 458: Train MSE=2.275301351078919, Train R²=0.6169079345251832
2024-10-31 06:41:12,879 - INFO - Trial 458: Test MSE=2.271475932427815, Test R²=0.6235713256256921
2024-10-31 06:41:12,879 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:42:57,077 - INFO - Trial 459: Train MSE=1.4514459493969167, Train R²=0.755697354142155
2024-10-31 06:42:57,077 - INFO - Trial 459: Test MSE=2.4733221105166843, Test R²=0.5917649120092392
2024-10-31 06:42:57,077 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:44:17,893 - INFO - Trial 460: Train MSE=2.3359432529125894, Train R²=0.6024124468011516
2024-10-31 06:44:17,893 - INFO - Trial 460: Test MSE=2.2553721240588596, Test R²=0.6260654905012676
2024-10-31 06:44:17,893 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:44:54,126 - INFO - Trial 461: Train MSE=2.294500163623265, Train R²=0.618421271443367
2024-10-31 06:44:54,126 - INFO - Trial 461: Test MSE=2.2328625236238753, Test R²=0.6364643744059971
2024-10-31 06:44:54,126 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:46:13,775 - INFO - Trial 462: Train MSE=2.1609250413519994, Train R²=0.6343870029917785
2024-10-31 06:46:13,775 - INFO - Trial 462: Test MSE=2.266944548913411, Test R²=0.6245198505265372
2024-10-31 06:46:13,775 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:47:33,887 - INFO - Trial 463: Train MSE=2.424693465232849, Train R²=0.5907051722918238
2024-10-31 06:47:33,887 - INFO - Trial 463: Test MSE=2.26208763888904, Test R²=0.6249714749200004
2024-10-31 06:47:33,887 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:48:54,922 - INFO - Trial 464: Train MSE=2.2341556857739175, Train R²=0.6228218057325908
2024-10-31 06:48:54,922 - INFO - Trial 464: Test MSE=2.2585515635354176, Test R²=0.6258733229977744
2024-10-31 06:48:54,922 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:50:15,002 - INFO - Trial 465: Train MSE=2.2985764497092793, Train R²=0.6122623160481453
2024-10-31 06:50:15,002 - INFO - Trial 465: Test MSE=2.277361418519701, Test R²=0.6224923836333411
2024-10-31 06:50:15,003 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:50:52,524 - INFO - Trial 466: Train MSE=3.926852898938315, Train R²=0.34624340917382923
2024-10-31 06:50:52,524 - INFO - Trial 466: Test MSE=2.3999389239719937, Test R²=0.6093285168920245
2024-10-31 06:50:52,524 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:52:12,715 - INFO - Trial 467: Train MSE=2.177884606378419, Train R²=0.6317094660231045
2024-10-31 06:52:12,715 - INFO - Trial 467: Test MSE=2.2536326476505826, Test R²=0.6270596001829419
2024-10-31 06:52:12,715 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:52:43,050 - INFO - Trial 468: Train MSE=2.2736708096095493, Train R²=0.6225880980491638
2024-10-31 06:52:43,050 - INFO - Trial 468: Test MSE=2.2638561129570007, Test R²=0.6290563941001892
2024-10-31 06:52:43,050 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:54:02,911 - INFO - Trial 469: Train MSE=2.384496882557869, Train R²=0.5998616734785693
2024-10-31 06:54:02,911 - INFO - Trial 469: Test MSE=2.2359940154211864, Test R²=0.6298136115074158
2024-10-31 06:54:02,911 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:54:42,103 - INFO - Trial 470: Train MSE=2.079663919551032, Train R²=0.6544191794736045
2024-10-31 06:54:42,103 - INFO - Trial 470: Test MSE=2.247527633394514, Test R²=0.6341077089309692
2024-10-31 06:54:42,103 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:55:17,305 - INFO - Trial 471: Train MSE=2.259002208709717, Train R²=0.6233152747154236
2024-10-31 06:55:17,305 - INFO - Trial 471: Test MSE=2.2727549416678294, Test R²=0.6300907135009766
2024-10-31 06:55:17,306 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:55:53,652 - INFO - Trial 472: Train MSE=2.298600511891501, Train R²=0.6172766855784825
2024-10-31 06:55:53,652 - INFO - Trial 472: Test MSE=2.2494166237967357, Test R²=0.6338258470807757
2024-10-31 06:55:53,652 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:56:30,663 - INFO - Trial 473: Train MSE=2.3973997235298157, Train R²=0.6014418367828641
2024-10-31 06:56:30,663 - INFO - Trial 473: Test MSE=2.243034873689924, Test R²=0.6348220961434501
2024-10-31 06:56:30,663 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:57:06,402 - INFO - Trial 474: Train MSE=2.345065338271005, Train R²=0.6095673569611141
2024-10-31 06:57:06,402 - INFO - Trial 474: Test MSE=2.217396685055324, Test R²=0.6389693447521755
2024-10-31 06:57:06,402 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:57:41,673 - INFO - Trial 475: Train MSE=2.2393768514905656, Train R²=0.6267680057457515
2024-10-31 06:57:41,673 - INFO - Trial 475: Test MSE=2.25051862852914, Test R²=0.6336401615824018
2024-10-31 06:57:41,673 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:58:17,094 - INFO - Trial 476: Train MSE=2.2423608132771085, Train R²=0.6260705866983959
2024-10-31 06:58:17,094 - INFO - Trial 476: Test MSE=2.248396873474121, Test R²=0.6340113111904689
2024-10-31 06:58:17,094 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:58:57,033 - INFO - Trial 477: Train MSE=2.6654357739857266, Train R²=0.5567123549325126
2024-10-31 06:58:57,034 - INFO - Trial 477: Test MSE=2.3154258728027344, Test R²=0.6231533118656704
2024-10-31 06:58:57,034 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 06:59:40,018 - INFO - Trial 478: Train MSE=2.8452552386692593, Train R²=0.5271856167486736
2024-10-31 06:59:40,018 - INFO - Trial 478: Test MSE=2.2778475965772356, Test R²=0.6294570565223694
2024-10-31 06:59:40,018 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:00:15,871 - INFO - Trial 479: Train MSE=2.1506900021008084, Train R²=0.6426726004907063
2024-10-31 07:00:15,871 - INFO - Trial 479: Test MSE=2.2782424858638217, Test R²=0.6291679995400565
2024-10-31 07:00:15,871 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:01:35,871 - INFO - Trial 480: Train MSE=2.293130579803671, Train R²=0.6146391097988401
2024-10-31 07:01:35,871 - INFO - Trial 480: Test MSE=2.3000382695879256, Test R²=0.6189250094549996
2024-10-31 07:01:35,871 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:02:24,501 - INFO - Trial 481: Train MSE=1.0891915134021215, Train R²=0.8189178364617484
2024-10-31 07:02:24,501 - INFO - Trial 481: Test MSE=2.456479106630598, Test R²=0.6001025268009731
2024-10-31 07:02:24,502 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:03:02,079 - INFO - Trial 482: Train MSE=6.425920350211007, Train R²=-0.0691204092332295
2024-10-31 07:03:02,079 - INFO - Trial 482: Test MSE=2.7091624396187917, Test R²=0.5592272366796222
2024-10-31 07:03:02,079 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:03:37,243 - INFO - Trial 483: Train MSE=2.2469999534743175, Train R²=0.6261768362351826
2024-10-31 07:03:37,243 - INFO - Trial 483: Test MSE=2.2599256379263744, Test R²=0.6322984439986092
2024-10-31 07:03:37,243 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:04:12,661 - INFO - Trial 484: Train MSE=2.1244520332132066, Train R²=0.6455848153148379
2024-10-31 07:04:12,661 - INFO - Trial 484: Test MSE=2.2585403578622, Test R²=0.632194527557918
2024-10-31 07:04:12,661 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:05:06,662 - INFO - Trial 485: Train MSE=2.173950269818306, Train R²=0.6376918682030269
2024-10-31 07:05:06,662 - INFO - Trial 485: Test MSE=2.2466935089656284, Test R²=0.6325745454856327
2024-10-31 07:05:06,662 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:05:41,870 - INFO - Trial 486: Train MSE=3.0110728570393155, Train R²=0.49929940913404736
2024-10-31 07:05:41,870 - INFO - Trial 486: Test MSE=2.4197604996817454, Test R²=0.6061320986066546
2024-10-31 07:05:41,870 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:06:17,371 - INFO - Trial 487: Train MSE=2.7677007743290494, Train R²=0.5388262548616954
2024-10-31 07:06:17,371 - INFO - Trial 487: Test MSE=2.3201592649732317, Test R²=0.6222932934761047
2024-10-31 07:06:17,371 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:06:53,595 - INFO - Trial 488: Train MSE=2.2303564293043956, Train R²=0.6289774541343961
2024-10-31 07:06:53,595 - INFO - Trial 488: Test MSE=2.2439973865236555, Test R²=0.6349776472364154
2024-10-31 07:06:53,595 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:07:31,261 - INFO - Trial 489: Train MSE=2.3063032925128937, Train R²=0.6159831391913551
2024-10-31 07:07:31,261 - INFO - Trial 489: Test MSE=2.244377374649048, Test R²=0.634588897228241
2024-10-31 07:07:31,261 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:08:08,834 - INFO - Trial 490: Train MSE=2.205471924373082, Train R²=0.6325869751828057
2024-10-31 07:08:08,834 - INFO - Trial 490: Test MSE=2.2395049163273404, Test R²=0.635468772479466
2024-10-31 07:08:08,835 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:08:45,504 - INFO - Trial 491: Train MSE=2.3984443971088956, Train R²=0.6011399520295007
2024-10-31 07:08:45,504 - INFO - Trial 491: Test MSE=2.257023436682565, Test R²=0.6325473444802421
2024-10-31 07:08:45,504 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:09:21,282 - INFO - Trial 492: Train MSE=2.2123214176722934, Train R²=0.6323066055774689
2024-10-31 07:09:21,282 - INFO - Trial 492: Test MSE=2.239506721496582, Test R²=0.635600881917136
2024-10-31 07:09:21,282 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:09:57,356 - INFO - Trial 493: Train MSE=2.2705961806433543, Train R²=0.6220070996454784
2024-10-31 07:09:57,356 - INFO - Trial 493: Test MSE=2.250815204211644, Test R²=0.6336662258420672
2024-10-31 07:09:57,356 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:10:30,470 - INFO - Trial 494: Train MSE=2.5396375826426913, Train R²=0.5782966486045292
2024-10-31 07:10:30,470 - INFO - Trial 494: Test MSE=2.260546863079071, Test R²=0.6294994801282883
2024-10-31 07:10:30,470 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:11:07,355 - INFO - Trial 495: Train MSE=1.2635395271437508, Train R²=0.7898208307368415
2024-10-31 07:11:07,356 - INFO - Trial 495: Test MSE=2.3034799098968506, Test R²=0.6247442449842181
2024-10-31 07:11:07,356 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:12:26,651 - INFO - Trial 496: Train MSE=2.262215352484158, Train R²=0.6192899958363601
2024-10-31 07:12:26,651 - INFO - Trial 496: Test MSE=2.2406898183482036, Test R²=0.6285763851233891
2024-10-31 07:12:26,651 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:13:04,454 - INFO - Trial 497: Train MSE=2.9709738748414174, Train R²=0.5061695447989872
2024-10-31 07:13:04,454 - INFO - Trial 497: Test MSE=2.2731777259281705, Test R²=0.6300661819321769
2024-10-31 07:13:04,454 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:13:40,521 - INFO - Trial 498: Train MSE=2.5105064681598117, Train R²=0.581517892224448
2024-10-31 07:13:40,521 - INFO - Trial 498: Test MSE=2.2854669775281633, Test R²=0.6280883465494428
2024-10-31 07:13:40,521 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:14:17,025 - INFO - Trial 499: Train MSE=2.067164340189525, Train R²=0.6558492971318108
2024-10-31 07:14:17,025 - INFO - Trial 499: Test MSE=2.2450912509645735, Test R²=0.6346553564071655
2024-10-31 07:14:17,025 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:14:53,398 - INFO - Trial 500: Train MSE=2.9043361204011098, Train R²=0.5169967817408698
2024-10-31 07:14:53,398 - INFO - Trial 500: Test MSE=2.248361894062587, Test R²=0.6341281533241272
2024-10-31 07:14:53,398 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:15:28,867 - INFO - Trial 501: Train MSE=2.202638259955815, Train R²=0.6332653973783765
2024-10-31 07:15:28,867 - INFO - Trial 501: Test MSE=2.2256591660635814, Test R²=0.6375378796032497
2024-10-31 07:15:28,868 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:16:05,722 - INFO - Trial 502: Train MSE=2.27716018472399, Train R²=0.6214183547667095
2024-10-31 07:16:05,723 - INFO - Trial 502: Test MSE=2.2711967400142123, Test R²=0.630274772644043
2024-10-31 07:16:05,723 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:16:41,663 - INFO - Trial 503: Train MSE=2.3958174884319305, Train R²=0.6014172115496227
2024-10-31 07:16:41,664 - INFO - Trial 503: Test MSE=2.27934159551348, Test R²=0.6289478114673069
2024-10-31 07:16:41,664 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:17:17,492 - INFO - Trial 504: Train MSE=2.184250886951174, Train R²=0.636359229683876
2024-10-31 07:17:17,492 - INFO - Trial 504: Test MSE=2.277278627668108, Test R²=0.6292469842093331
2024-10-31 07:17:17,492 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:17:51,458 - INFO - Trial 505: Train MSE=2.6506859745298113, Train R²=0.5594674072095326
2024-10-31 07:17:51,458 - INFO - Trial 505: Test MSE=2.2718323298863004, Test R²=0.6300885081291199
2024-10-31 07:17:51,458 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:18:25,111 - INFO - Trial 506: Train MSE=2.0666548439434598, Train R²=0.655640606369291
2024-10-31 07:18:25,111 - INFO - Trial 506: Test MSE=2.2595893996102467, Test R²=0.6322743977819171
2024-10-31 07:18:25,111 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:19:43,342 - INFO - Trial 507: Train MSE=2.203176401555538, Train R²=0.627263566745179
2024-10-31 07:19:43,342 - INFO - Trial 507: Test MSE=2.2623996266296933, Test R²=0.6246112393481391
2024-10-31 07:19:43,342 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:20:20,601 - INFO - Trial 508: Train MSE=2.3520108120782033, Train R²=0.6081047419990812
2024-10-31 07:20:20,601 - INFO - Trial 508: Test MSE=2.2416845730372836, Test R²=0.6350017189979553
2024-10-31 07:20:20,601 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:20:58,700 - INFO - Trial 509: Train MSE=2.515616008213588, Train R²=0.5805186757019588
2024-10-31 07:20:58,700 - INFO - Trial 509: Test MSE=2.226265754018511, Test R²=0.6376875383513314
2024-10-31 07:20:58,700 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:22:00,660 - INFO - Trial 510: Train MSE=2.181595600077084, Train R²=0.6364033254129546
2024-10-31 07:22:00,660 - INFO - Trial 510: Test MSE=2.2540072202682495, Test R²=0.6312232187816075
2024-10-31 07:22:00,660 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:22:38,331 - INFO - Trial 511: Train MSE=2.4963502969060625, Train R²=0.5846725595848901
2024-10-31 07:22:38,331 - INFO - Trial 511: Test MSE=2.232395989554269, Test R²=0.6366699934005737
2024-10-31 07:22:38,331 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:23:14,489 - INFO - Trial 512: Train MSE=2.1140261462756564, Train R²=0.6471766850778035
2024-10-31 07:23:14,489 - INFO - Trial 512: Test MSE=2.27839538029262, Test R²=0.629249564238957
2024-10-31 07:23:14,489 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:23:51,159 - INFO - Trial 513: Train MSE=2.088825579200472, Train R²=0.652919488293784
2024-10-31 07:23:51,159 - INFO - Trial 513: Test MSE=2.260542460850307, Test R²=0.6320403133119855
2024-10-31 07:23:51,159 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:24:26,948 - INFO - Trial 514: Train MSE=2.781942401613508, Train R²=0.5367309876850673
2024-10-31 07:24:26,948 - INFO - Trial 514: Test MSE=2.263673646109445, Test R²=0.6314594915934971
2024-10-31 07:24:26,948 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:25:05,413 - INFO - Trial 515: Train MSE=2.3818366272108897, Train R²=0.6038942486047745
2024-10-31 07:25:05,413 - INFO - Trial 515: Test MSE=2.2363003151757375, Test R²=0.6359977466719491
2024-10-31 07:25:05,413 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:25:42,720 - INFO - Trial 516: Train MSE=2.4802228212356567, Train R²=0.5867770122630256
2024-10-31 07:25:42,720 - INFO - Trial 516: Test MSE=2.237447943006243, Test R²=0.6357993738991874
2024-10-31 07:25:42,720 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:26:18,297 - INFO - Trial 517: Train MSE=2.287494795663016, Train R²=0.6185041453157153
2024-10-31 07:26:18,297 - INFO - Trial 517: Test MSE=2.2692227022988454, Test R²=0.6306120412690299
2024-10-31 07:26:18,298 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:26:50,019 - INFO - Trial 518: Train MSE=2.5122268199920654, Train R²=0.5827011210577828
2024-10-31 07:26:50,019 - INFO - Trial 518: Test MSE=2.2374786734580994, Test R²=0.6331330984830856
2024-10-31 07:26:50,019 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:27:29,443 - INFO - Trial 519: Train MSE=2.0086851034845625, Train R²=0.6656872459820339
2024-10-31 07:27:29,443 - INFO - Trial 519: Test MSE=2.2925287314823697, Test R²=0.6268614786011832
2024-10-31 07:27:29,443 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:28:07,357 - INFO - Trial 520: Train MSE=2.2257231133324757, Train R²=0.629354579108102
2024-10-31 07:28:07,358 - INFO - Trial 520: Test MSE=2.234163795198713, Test R²=0.6362688200814384
2024-10-31 07:28:07,358 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:28:48,153 - INFO - Trial 521: Train MSE=2.7393233946391513, Train R²=0.5440414994955063
2024-10-31 07:28:48,153 - INFO - Trial 521: Test MSE=2.3331658158983504, Test R²=0.620295524597168
2024-10-31 07:28:48,153 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:30:09,837 - INFO - Trial 522: Train MSE=2.155694829566138, Train R²=0.6400576036955629
2024-10-31 07:30:09,837 - INFO - Trial 522: Test MSE=2.262420343501227, Test R²=0.6261965781450272
2024-10-31 07:30:09,837 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:30:47,683 - INFO - Trial 523: Train MSE=2.096430297408785, Train R²=0.6516857870987484
2024-10-31 07:30:47,683 - INFO - Trial 523: Test MSE=2.3097687789372037, Test R²=0.6240045768874032
2024-10-31 07:30:47,683 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:31:24,023 - INFO - Trial 524: Train MSE=2.846911813531603, Train R²=0.5269156885998589
2024-10-31 07:31:24,023 - INFO - Trial 524: Test MSE=2.2563823631831577, Test R²=0.632780909538269
2024-10-31 07:31:24,023 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:31:59,285 - INFO - Trial 525: Train MSE=2.4050092782293047, Train R²=0.5990569634096963
2024-10-31 07:31:59,285 - INFO - Trial 525: Test MSE=2.2420656851359775, Test R²=0.6351087093353271
2024-10-31 07:31:59,285 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:32:34,646 - INFO - Trial 526: Train MSE=2.218349950654166, Train R²=0.6301354723317283
2024-10-31 07:32:34,646 - INFO - Trial 526: Test MSE=2.263711145945958, Test R²=0.6313759684562683
2024-10-31 07:32:34,646 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:33:10,124 - INFO - Trial 527: Train MSE=1.9965244276182992, Train R²=0.6687417285782951
2024-10-31 07:33:10,124 - INFO - Trial 527: Test MSE=2.3085588216781616, Test R²=0.6242831860269819
2024-10-31 07:33:10,124 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:33:46,402 - INFO - Trial 528: Train MSE=0.8829596894127982, Train R²=0.8529821059533528
2024-10-31 07:33:46,402 - INFO - Trial 528: Test MSE=2.4587937082563127, Test R²=0.5999351399285453
2024-10-31 07:33:46,402 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:34:35,265 - INFO - Trial 529: Train MSE=1.8454166650772095, Train R²=0.6930170421089444
2024-10-31 07:34:35,265 - INFO - Trial 529: Test MSE=2.236651965550014, Test R²=0.6358591573578971
2024-10-31 07:34:35,265 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:35:10,542 - INFO - Trial 530: Train MSE=2.1660584849970683, Train R²=0.6388733280556542
2024-10-31 07:35:10,542 - INFO - Trial 530: Test MSE=2.248122419629778, Test R²=0.6340526342391968
2024-10-31 07:35:10,542 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:35:45,948 - INFO - Trial 531: Train MSE=2.375705208097185, Train R²=0.6051112796579089
2024-10-31 07:35:45,949 - INFO - Trial 531: Test MSE=2.2370192323412215, Test R²=0.6359134827341352
2024-10-31 07:35:45,949 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:36:23,960 - INFO - Trial 532: Train MSE=2.6464103204863414, Train R²=0.5585072785615921
2024-10-31 07:36:23,960 - INFO - Trial 532: Test MSE=2.2617615291050504, Test R²=0.6318512644086566
2024-10-31 07:36:23,960 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:37:14,655 - INFO - Trial 533: Train MSE=2.1804144020591463, Train R²=0.6358391014592988
2024-10-31 07:37:14,655 - INFO - Trial 533: Test MSE=2.219240869794573, Test R²=0.6367753616401127
2024-10-31 07:37:14,655 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:38:11,960 - INFO - Trial 534: Train MSE=2.2273102211100713, Train R²=0.6281107717326709
2024-10-31 07:38:11,960 - INFO - Trial 534: Test MSE=2.222206405230931, Test R²=0.6368294656276703
2024-10-31 07:38:11,960 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:39:42,133 - INFO - Trial 535: Train MSE=2.0215926340648105, Train R²=0.6592887831585748
2024-10-31 07:39:42,134 - INFO - Trial 535: Test MSE=2.256583946091788, Test R²=0.6253815357174192
2024-10-31 07:39:42,134 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:40:39,463 - INFO - Trial 536: Train MSE=2.4376859686204364, Train R²=0.5938628134982926
2024-10-31 07:40:39,463 - INFO - Trial 536: Test MSE=2.295621539865221, Test R²=0.6246217659541539
2024-10-31 07:40:39,464 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:41:36,907 - INFO - Trial 537: Train MSE=2.4172838074820384, Train R²=0.5978822740060943
2024-10-31 07:41:36,907 - INFO - Trial 537: Test MSE=2.324025579861232, Test R²=0.6202888531344277
2024-10-31 07:41:36,907 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:42:34,079 - INFO - Trial 538: Train MSE=2.2830245750291005, Train R²=0.6169060479317393
2024-10-31 07:42:34,079 - INFO - Trial 538: Test MSE=2.2611959746905734, Test R²=0.6299745142459869
2024-10-31 07:42:34,079 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:43:31,379 - INFO - Trial 539: Train MSE=2.497879594564438, Train R²=0.5821889330233846
2024-10-31 07:43:31,379 - INFO - Trial 539: Test MSE=2.300194135734013, Test R²=0.6240018095288958
2024-10-31 07:43:31,380 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:44:28,806 - INFO - Trial 540: Train MSE=2.233494464840208, Train R²=0.6265499283160482
2024-10-31 07:44:28,806 - INFO - Trial 540: Test MSE=2.2401731865746632, Test R²=0.6338812325681958
2024-10-31 07:44:28,807 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:45:28,948 - INFO - Trial 541: Train MSE=2.09825756081513, Train R²=0.6506234971540314
2024-10-31 07:45:28,949 - INFO - Trial 541: Test MSE=2.276612256254469, Test R²=0.6273158192634583
2024-10-31 07:45:28,949 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:46:28,913 - INFO - Trial 542: Train MSE=1.3949096756322044, Train R²=0.7664803021720478
2024-10-31 07:46:28,913 - INFO - Trial 542: Test MSE=2.4195925337927684, Test R²=0.6043743108000074
2024-10-31 07:46:28,913 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:47:23,580 - INFO - Trial 543: Train MSE=1.635015960250582, Train R²=0.7262461738927024
2024-10-31 07:47:23,580 - INFO - Trial 543: Test MSE=2.441274404525757, Test R²=0.6017008338655744
2024-10-31 07:47:23,580 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:48:21,300 - INFO - Trial 544: Train MSE=2.381361965622221, Train R²=0.6014031778488841
2024-10-31 07:48:21,300 - INFO - Trial 544: Test MSE=2.250503276075636, Test R²=0.631953341620309
2024-10-31 07:48:21,300 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:49:00,366 - INFO - Trial 545: Train MSE=1.7860704234668188, Train R²=0.7029735914298466
2024-10-31 07:49:00,366 - INFO - Trial 545: Test MSE=2.2797564438411166, Test R²=0.628967889717647
2024-10-31 07:49:00,366 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:49:35,904 - INFO - Trial 546: Train MSE=2.2569446563720703, Train R²=0.6251370651381356
2024-10-31 07:49:35,904 - INFO - Trial 546: Test MSE=2.2575486387525285, Test R²=0.6322753599711827
2024-10-31 07:49:35,904 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:50:56,751 - INFO - Trial 547: Train MSE=1.906137072614261, Train R²=0.6791982688009739
2024-10-31 07:50:56,751 - INFO - Trial 547: Test MSE=2.272149886403765, Test R²=0.623388273375375
2024-10-31 07:50:56,751 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:51:32,906 - INFO - Trial 548: Train MSE=2.6235801662717546, Train R²=0.5631120119776044
2024-10-31 07:51:32,906 - INFO - Trial 548: Test MSE=2.2938850777489797, Test R²=0.6266487581389291
2024-10-31 07:51:32,906 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:52:03,159 - INFO - Trial 549: Train MSE=2.348376052720206, Train R²=0.6105430977685111
2024-10-31 07:52:03,159 - INFO - Trial 549: Test MSE=2.2458799481391907, Test R²=0.6317253410816193
2024-10-31 07:52:03,159 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:52:38,102 - INFO - Trial 550: Train MSE=1.8836671369416373, Train R²=0.6859948188066483
2024-10-31 07:52:38,102 - INFO - Trial 550: Test MSE=2.351271186556135, Test R²=0.6173003486224583
2024-10-31 07:52:38,102 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:53:15,639 - INFO - Trial 551: Train MSE=2.470669141837529, Train R²=0.5891861617565155
2024-10-31 07:53:15,639 - INFO - Trial 551: Test MSE=2.253119570868356, Test R²=0.6332870466368539
2024-10-31 07:53:15,639 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:53:51,369 - INFO - Trial 552: Train MSE=2.191736842904772, Train R²=0.6345122861010688
2024-10-31 07:53:51,369 - INFO - Trial 552: Test MSE=2.2715207849230086, Test R²=0.6301530855042594
2024-10-31 07:53:51,369 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:54:49,181 - INFO - Trial 553: Train MSE=2.2775045335292816, Train R²=0.6194928448115077
2024-10-31 07:54:49,181 - INFO - Trial 553: Test MSE=2.223107193197523, Test R²=0.6365109000887189
2024-10-31 07:54:49,181 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:55:27,444 - INFO - Trial 554: Train MSE=2.190317916018622, Train R²=0.63555979515825
2024-10-31 07:55:27,444 - INFO - Trial 554: Test MSE=2.3078713757651195, Test R²=0.6244772842952183
2024-10-31 07:55:27,444 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:56:05,186 - INFO - Trial 555: Train MSE=2.4222884944507053, Train R²=0.5968143258775983
2024-10-31 07:56:05,187 - INFO - Trial 555: Test MSE=2.2320989200047086, Test R²=0.6365424650056022
2024-10-31 07:56:05,187 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:56:41,176 - INFO - Trial 556: Train MSE=2.2513086029461453, Train R²=0.6254005708864757
2024-10-31 07:56:41,176 - INFO - Trial 556: Test MSE=2.2450993401663646, Test R²=0.6345414604459491
2024-10-31 07:56:41,177 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:57:29,971 - INFO - Trial 557: Train MSE=1.7054227377687181, Train R²=0.7161929990564074
2024-10-31 07:57:29,971 - INFO - Trial 557: Test MSE=2.299258061817714, Test R²=0.6257009931973049
2024-10-31 07:57:29,971 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:58:07,360 - INFO - Trial 558: Train MSE=2.794158322470529, Train R²=0.5347974491970879
2024-10-31 07:58:07,360 - INFO - Trial 558: Test MSE=2.2522011484418596, Test R²=0.6334105815206256
2024-10-31 07:58:07,360 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:58:43,554 - INFO - Trial 559: Train MSE=2.314134657382965, Train R²=0.6144237646034786
2024-10-31 07:58:43,555 - INFO - Trial 559: Test MSE=2.2239151341574535, Test R²=0.6379816617284503
2024-10-31 07:58:43,555 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:59:19,530 - INFO - Trial 560: Train MSE=2.400605951036726, Train R²=0.600354824747358
2024-10-31 07:59:19,530 - INFO - Trial 560: Test MSE=2.2349098920822144, Test R²=0.6363119568143573
2024-10-31 07:59:19,530 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 07:59:56,596 - INFO - Trial 561: Train MSE=2.33870997599193, Train R²=0.6102710579122815
2024-10-31 07:59:56,596 - INFO - Trial 561: Test MSE=2.215029375893729, Test R²=0.6394930396761213
2024-10-31 07:59:56,596 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:01:16,052 - INFO - Trial 562: Train MSE=1.9938395938702993, Train R²=0.6643119284084865
2024-10-31 08:01:16,053 - INFO - Trial 562: Test MSE=2.2674385138920377, Test R²=0.6235890580075127
2024-10-31 08:01:16,053 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:01:51,740 - INFO - Trial 563: Train MSE=8.074558905192784, Train R²=-0.3534103887421744
2024-10-31 08:01:51,741 - INFO - Trial 563: Test MSE=3.399310146059309, Test R²=0.44660656792776926
2024-10-31 08:01:51,741 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:02:30,935 - INFO - Trial 564: Train MSE=2.563684037753514, Train R²=0.5738180769341332
2024-10-31 08:02:30,935 - INFO - Trial 564: Test MSE=2.2180370092391968, Test R²=0.6390563249588013
2024-10-31 08:02:30,935 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:03:08,803 - INFO - Trial 565: Train MSE=2.454831761973245, Train R²=0.5918544679880142
2024-10-31 08:03:08,803 - INFO - Trial 565: Test MSE=2.2562121663774763, Test R²=0.6328633512769427
2024-10-31 08:03:08,803 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:03:42,760 - INFO - Trial 566: Train MSE=3.322138105119978, Train R²=0.44614922787461964
2024-10-31 08:03:42,760 - INFO - Trial 566: Test MSE=2.3605377674102783, Test R²=0.6158450671604702
2024-10-31 08:03:42,761 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:04:21,568 - INFO - Trial 567: Train MSE=2.4595039742333547, Train R²=0.5910002844674247
2024-10-31 08:04:21,568 - INFO - Trial 567: Test MSE=2.2592410360063826, Test R²=0.6321873324257987
2024-10-31 08:04:21,568 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:04:54,749 - INFO - Trial 568: Train MSE=2.8649570090430125, Train R²=0.5242001584597996
2024-10-31 08:04:54,749 - INFO - Trial 568: Test MSE=2.295891225337982, Test R²=0.62367844581604
2024-10-31 08:04:54,749 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:05:38,988 - INFO - Trial 569: Train MSE=1.8954981097153254, Train R²=0.6841538271733693
2024-10-31 08:05:38,989 - INFO - Trial 569: Test MSE=2.254101582935878, Test R²=0.6330100723675319
2024-10-31 08:05:38,989 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:06:35,078 - INFO - Trial 570: Train MSE=2.3859066175562993, Train R²=0.6024208696825164
2024-10-31 08:06:35,078 - INFO - Trial 570: Test MSE=2.2639563849994113, Test R²=0.6300009999956403
2024-10-31 08:06:35,078 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:07:13,938 - INFO - Trial 571: Train MSE=2.5911187699862888, Train R²=0.5676414285387311
2024-10-31 08:07:13,938 - INFO - Trial 571: Test MSE=2.295243399483817, Test R²=0.6264695269720895
2024-10-31 08:07:13,938 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:07:52,842 - INFO - Trial 572: Train MSE=2.7540893384388516, Train R²=0.542329307113375
2024-10-31 08:07:52,843 - INFO - Trial 572: Test MSE=2.311532769884382, Test R²=0.6238503200667245
2024-10-31 08:07:52,843 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:08:31,753 - INFO - Trial 573: Train MSE=2.523198970726558, Train R²=0.5797244523252759
2024-10-31 08:08:31,753 - INFO - Trial 573: Test MSE=2.2677836418151855, Test R²=0.6307734251022339
2024-10-31 08:08:31,754 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:09:08,764 - INFO - Trial 574: Train MSE=3.30886287348611, Train R²=0.45031953922339846
2024-10-31 08:09:08,764 - INFO - Trial 574: Test MSE=2.383239916392735, Test R²=0.612123932157244
2024-10-31 08:09:08,764 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:09:47,927 - INFO - Trial 575: Train MSE=2.992404673780714, Train R²=0.5022563189268112
2024-10-31 08:09:47,927 - INFO - Trial 575: Test MSE=2.254293203353882, Test R²=0.6330873710768563
2024-10-31 08:09:47,927 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:11:21,067 - INFO - Trial 576: Train MSE=2.1008080105696405, Train R²=0.647423191262143
2024-10-31 08:11:21,067 - INFO - Trial 576: Test MSE=2.2828892937728336, Test R²=0.6213713841778892
2024-10-31 08:11:21,067 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:12:00,080 - INFO - Trial 577: Train MSE=2.4798830492155894, Train R²=0.5876242241689137
2024-10-31 08:12:00,080 - INFO - Trial 577: Test MSE=2.2218291418892995, Test R²=0.6383420484406608
2024-10-31 08:12:00,080 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:12:38,927 - INFO - Trial 578: Train MSE=2.647799457822527, Train R²=0.5597056703908103
2024-10-31 08:12:38,927 - INFO - Trial 578: Test MSE=2.2521856342043196, Test R²=0.6335037350654602
2024-10-31 08:12:38,927 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:13:17,862 - INFO - Trial 579: Train MSE=2.9549721649714877, Train R²=0.5081246708120618
2024-10-31 08:13:17,862 - INFO - Trial 579: Test MSE=2.3334036554609026, Test R²=0.6202644450323922
2024-10-31 08:13:17,862 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:14:06,593 - INFO - Trial 580: Train MSE=2.010546909911292, Train R²=0.6653141102620533
2024-10-31 08:14:06,593 - INFO - Trial 580: Test MSE=2.260584694998605, Test R²=0.6321672541754586
2024-10-31 08:14:06,593 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:14:43,525 - INFO - Trial 581: Train MSE=0.7604844740458897, Train R²=0.8729561247995922
2024-10-31 08:14:43,525 - INFO - Trial 581: Test MSE=2.4889895234789168, Test R²=0.5951719284057617
2024-10-31 08:14:43,526 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:15:24,125 - INFO - Trial 582: Train MSE=2.4483490330832347, Train R²=0.592444143124989
2024-10-31 08:15:24,125 - INFO - Trial 582: Test MSE=2.234079803739275, Test R²=0.6363180194582257
2024-10-31 08:15:24,125 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:16:24,131 - INFO - Trial 583: Train MSE=2.1431516919817244, Train R²=0.6422900163701603
2024-10-31 08:16:24,131 - INFO - Trial 583: Test MSE=2.2278511694499423, Test R²=0.6353295360292707
2024-10-31 08:16:24,131 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:17:05,111 - INFO - Trial 584: Train MSE=2.9500442913600375, Train R²=0.5094365371125085
2024-10-31 08:17:05,111 - INFO - Trial 584: Test MSE=2.422015803200858, Test R²=0.6059205617223468
2024-10-31 08:17:05,111 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:17:41,050 - INFO - Trial 585: Train MSE=2.684017530509404, Train R²=0.5539665179593223
2024-10-31 08:17:41,051 - INFO - Trial 585: Test MSE=2.2742339883531844, Test R²=0.6298734290259225
2024-10-31 08:17:41,051 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:18:18,077 - INFO - Trial 586: Train MSE=5.097274712153843, Train R²=0.1473538258246013
2024-10-31 08:18:18,077 - INFO - Trial 586: Test MSE=2.76108717918396, Test R²=0.550715616771153
2024-10-31 08:18:18,077 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:18:55,484 - INFO - Trial 587: Train MSE=2.326703037534441, Train R²=0.6130841033799308
2024-10-31 08:18:55,484 - INFO - Trial 587: Test MSE=2.2193655967712402, Test R²=0.6387005363191877
2024-10-31 08:18:55,484 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:19:31,302 - INFO - Trial 588: Train MSE=2.7605459604944502, Train R²=0.5394000730344227
2024-10-31 08:19:31,302 - INFO - Trial 588: Test MSE=2.2703894887651717, Test R²=0.6304235288075039
2024-10-31 08:19:31,303 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:20:08,288 - INFO - Trial 589: Train MSE=2.2042316240923747, Train R²=0.6332387498446873
2024-10-31 08:20:08,288 - INFO - Trial 589: Test MSE=2.2514837128775462, Test R²=0.6335321494511196
2024-10-31 08:20:08,288 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:21:35,421 - INFO - Trial 590: Train MSE=2.1365824214049747, Train R²=0.6393189520708152
2024-10-31 08:21:35,421 - INFO - Trial 590: Test MSE=2.305197545460292, Test R²=0.6179279621158328
2024-10-31 08:21:35,421 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:22:12,863 - INFO - Trial 591: Train MSE=2.303298592567444, Train R²=0.61650969513825
2024-10-31 08:22:12,863 - INFO - Trial 591: Test MSE=2.242483769144331, Test R²=0.6349707841873169
2024-10-31 08:22:12,863 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:22:50,548 - INFO - Trial 592: Train MSE=2.549763653959547, Train R²=0.5758152859551566
2024-10-31 08:22:50,548 - INFO - Trial 592: Test MSE=2.273632117680141, Test R²=0.6299410292080471
2024-10-31 08:22:50,548 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:23:35,132 - INFO - Trial 593: Train MSE=1.4191175145762307, Train R²=0.7640221204076495
2024-10-31 08:23:35,132 - INFO - Trial 593: Test MSE=2.3077690601348877, Test R²=0.6240308455058506
2024-10-31 08:23:35,132 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:24:12,674 - INFO - Trial 594: Train MSE=2.3123626836708615, Train R²=0.6149771916014808
2024-10-31 08:24:12,674 - INFO - Trial 594: Test MSE=2.261178868157523, Test R²=0.6316780533109393
2024-10-31 08:24:12,674 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:24:48,168 - INFO - Trial 595: Train MSE=2.711476572922298, Train R²=0.5483945544276919
2024-10-31 08:24:48,169 - INFO - Trial 595: Test MSE=2.229302065713065, Test R²=0.6372044341904777
2024-10-31 08:24:48,169 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:25:19,769 - INFO - Trial 596: Train MSE=2.24029826266425, Train R²=0.6277753923620496
2024-10-31 08:25:19,769 - INFO - Trial 596: Test MSE=2.2798869609832764, Test R²=0.6260046511888504
2024-10-31 08:25:19,770 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:26:14,111 - INFO - Trial 597: Train MSE=2.2795626563685283, Train R²=0.6191906034946442
2024-10-31 08:26:14,111 - INFO - Trial 597: Test MSE=2.282703297478812, Test R²=0.6267888673714229
2024-10-31 08:26:14,111 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:26:51,743 - INFO - Trial 598: Train MSE=2.329516964299338, Train R²=0.612999656370708
2024-10-31 08:26:51,743 - INFO - Trial 598: Test MSE=2.2280862501689365, Test R²=0.6374397703579494
2024-10-31 08:26:51,743 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:27:29,441 - INFO - Trial 599: Train MSE=0.6591079660824367, Train R²=0.8900619213070188
2024-10-31 08:27:29,441 - INFO - Trial 599: Test MSE=2.477107456752232, Test R²=0.5969729934419904
2024-10-31 08:27:29,441 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:28:07,131 - INFO - Trial 600: Train MSE=2.364265501499176, Train R²=0.607262847679002
2024-10-31 08:28:07,132 - INFO - Trial 600: Test MSE=2.2364917482648576, Test R²=0.6359396662030902
2024-10-31 08:28:07,132 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:28:44,623 - INFO - Trial 601: Train MSE=2.4935271058763777, Train R²=0.5843407107251031
2024-10-31 08:28:44,623 - INFO - Trial 601: Test MSE=2.232325690133231, Test R²=0.6367397052901131
2024-10-31 08:28:44,623 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:29:21,010 - INFO - Trial 602: Train MSE=3.985392153263092, Train R²=0.3381991024528231
2024-10-31 08:29:21,010 - INFO - Trial 602: Test MSE=2.501115322113037, Test R²=0.5931614807673863
2024-10-31 08:29:21,010 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:30:41,241 - INFO - Trial 603: Train MSE=2.1235700813787326, Train R²=0.6415995205087321
2024-10-31 08:30:41,241 - INFO - Trial 603: Test MSE=2.281406338725771, Test R²=0.621896254164832
2024-10-31 08:30:41,241 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:31:30,116 - INFO - Trial 604: Train MSE=1.719843796321324, Train R²=0.7135324861322131
2024-10-31 08:31:30,117 - INFO - Trial 604: Test MSE=2.320946148463658, Test R²=0.6222434895379203
2024-10-31 08:31:30,117 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:32:09,523 - INFO - Trial 605: Train MSE=2.7443870987210954, Train R²=0.5437132652316775
2024-10-31 08:32:09,523 - INFO - Trial 605: Test MSE=2.268780095236642, Test R²=0.6306829537664141
2024-10-31 08:32:09,523 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:32:45,932 - INFO - Trial 606: Train MSE=7.050827605383737, Train R²=-0.17699899205139705
2024-10-31 08:32:45,932 - INFO - Trial 606: Test MSE=2.723682335444859, Test R²=0.5566235184669495
2024-10-31 08:32:45,932 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:33:22,491 - INFO - Trial 607: Train MSE=2.0401838549545834, Train R²=0.6596322698252541
2024-10-31 08:33:22,491 - INFO - Trial 607: Test MSE=2.226234333855765, Test R²=0.6377568415233067
2024-10-31 08:33:22,491 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:33:59,046 - INFO - Trial 608: Train MSE=2.732810454709189, Train R²=0.5453128921134132
2024-10-31 08:33:59,046 - INFO - Trial 608: Test MSE=2.286846229008266, Test R²=0.627927269254412
2024-10-31 08:33:59,046 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:34:32,718 - INFO - Trial 609: Train MSE=2.727393618651799, Train R²=0.5463340942348752
2024-10-31 08:34:32,718 - INFO - Trial 609: Test MSE=2.291788271495274, Test R²=0.6270591957228524
2024-10-31 08:34:32,718 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:35:36,956 - INFO - Trial 610: Train MSE=1.8989724602018083, Train R²=0.6820371012602534
2024-10-31 08:35:36,956 - INFO - Trial 610: Test MSE=2.297361331326621, Test R²=0.6235665593828473
2024-10-31 08:35:36,956 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:36:13,156 - INFO - Trial 611: Train MSE=2.2399665798459734, Train R²=0.6268635817936489
2024-10-31 08:36:13,157 - INFO - Trial 611: Test MSE=2.2540433406829834, Test R²=0.6330705029623849
2024-10-31 08:36:13,157 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:36:48,847 - INFO - Trial 612: Train MSE=2.3533837454659596, Train R²=0.608338747705732
2024-10-31 08:36:48,848 - INFO - Trial 612: Test MSE=2.2545388426099504, Test R²=0.6330926588603428
2024-10-31 08:36:48,848 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:37:24,757 - INFO - Trial 613: Train MSE=2.531980812549591, Train R²=0.5782979343618665
2024-10-31 08:37:24,757 - INFO - Trial 613: Test MSE=2.235878382410322, Test R²=0.6361043112618583
2024-10-31 08:37:24,757 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:38:03,603 - INFO - Trial 614: Train MSE=2.402149098260062, Train R²=0.6009505029235568
2024-10-31 08:38:03,603 - INFO - Trial 614: Test MSE=2.265848296029227, Test R²=0.6310169015611921
2024-10-31 08:38:03,604 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:38:41,572 - INFO - Trial 615: Train MSE=2.603577094418662, Train R²=0.566190630197525
2024-10-31 08:38:41,572 - INFO - Trial 615: Test MSE=2.240151984351022, Test R²=0.6353892173085894
2024-10-31 08:38:41,572 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:40:09,752 - INFO - Trial 616: Train MSE=2.1052544670445577, Train R²=0.6449170639472348
2024-10-31 08:40:09,753 - INFO - Trial 616: Test MSE=2.2757061507020677, Test R²=0.6225123448031289
2024-10-31 08:40:09,753 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:40:45,051 - INFO - Trial 617: Train MSE=3.269434094429016, Train R²=0.4566641662802015
2024-10-31 08:40:45,051 - INFO - Trial 617: Test MSE=2.5815478563308716, Test R²=0.5770659893751144
2024-10-31 08:40:45,052 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:41:24,935 - INFO - Trial 618: Train MSE=1.8039365368230003, Train R²=0.6991877811295646
2024-10-31 08:41:24,935 - INFO - Trial 618: Test MSE=2.2627405439104353, Test R²=0.6315280539648873
2024-10-31 08:41:24,935 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:42:00,521 - INFO - Trial 619: Train MSE=2.346857590334756, Train R²=0.6098393159253257
2024-10-31 08:42:00,522 - INFO - Trial 619: Test MSE=2.2341788155691966, Test R²=0.6363467829568046
2024-10-31 08:42:00,522 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:42:37,367 - INFO - Trial 620: Train MSE=2.326989327158247, Train R²=0.6127627130065646
2024-10-31 08:42:37,367 - INFO - Trial 620: Test MSE=2.2291649069104875, Test R²=0.6370903168405805
2024-10-31 08:42:37,367 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:43:15,522 - INFO - Trial 621: Train MSE=2.504369488784245, Train R²=0.5817457778113229
2024-10-31 08:43:15,522 - INFO - Trial 621: Test MSE=2.2516605172838484, Test R²=0.6333608286721366
2024-10-31 08:43:15,523 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:43:54,392 - INFO - Trial 622: Train MSE=1.3864504865237646, Train R²=0.7687232536928994
2024-10-31 08:43:54,392 - INFO - Trial 622: Test MSE=2.389617919921875, Test R²=0.6110159754753113
2024-10-31 08:43:54,392 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:44:28,241 - INFO - Trial 623: Train MSE=2.3136645214898244, Train R²=0.6156594029494694
2024-10-31 08:44:28,242 - INFO - Trial 623: Test MSE=2.2659218311309814, Test R²=0.6312289067677089
2024-10-31 08:44:28,242 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:45:23,134 - INFO - Trial 624: Train MSE=2.0937844599996294, Train R²=0.6505189442208835
2024-10-31 08:45:23,134 - INFO - Trial 624: Test MSE=2.26417019537517, Test R²=0.6295821411269051
2024-10-31 08:45:23,134 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:45:58,345 - INFO - Trial 625: Train MSE=2.3895884922572543, Train R²=0.603159487247467
2024-10-31 08:45:58,346 - INFO - Trial 625: Test MSE=2.2291628633226668, Test R²=0.6371149250439235
2024-10-31 08:45:58,346 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:46:39,349 - INFO - Trial 626: Train MSE=2.3044221656663075, Train R²=0.616274527141026
2024-10-31 08:46:39,349 - INFO - Trial 626: Test MSE=2.2418087891169955, Test R²=0.6349880525044033
2024-10-31 08:46:39,349 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:47:16,793 - INFO - Trial 627: Train MSE=2.3620774235044206, Train R²=0.6062236768858773
2024-10-31 08:47:16,793 - INFO - Trial 627: Test MSE=2.293905190059117, Test R²=0.6265619482312884
2024-10-31 08:47:16,793 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:48:05,533 - INFO - Trial 628: Train MSE=2.008703521319798, Train R²=0.6651304513216019
2024-10-31 08:48:05,533 - INFO - Trial 628: Test MSE=2.2329706294195995, Test R²=0.6363777262823922
2024-10-31 08:48:05,533 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:48:43,480 - INFO - Trial 629: Train MSE=2.350128855024065, Train R²=0.6092542452471597
2024-10-31 08:48:43,480 - INFO - Trial 629: Test MSE=2.270348378590175, Test R²=0.6303695269993373
2024-10-31 08:48:43,480 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:50:03,985 - INFO - Trial 630: Train MSE=2.191641998078142, Train R²=0.632062920502254
2024-10-31 08:50:03,985 - INFO - Trial 630: Test MSE=2.277578822204045, Test R²=0.6226491630077362
2024-10-31 08:50:03,985 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:50:39,590 - INFO - Trial 631: Train MSE=2.9336571097373962, Train R²=0.511231507573809
2024-10-31 08:50:39,590 - INFO - Trial 631: Test MSE=2.239402072770255, Test R²=0.6354743157114301
2024-10-31 08:50:39,590 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:51:14,350 - INFO - Trial 632: Train MSE=2.4111267072813853, Train R²=0.5985204726457596
2024-10-31 08:51:14,351 - INFO - Trial 632: Test MSE=2.273733922413417, Test R²=0.6298220157623291
2024-10-31 08:51:14,351 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:51:50,033 - INFO - Trial 633: Train MSE=2.0742748379707336, Train R²=0.6547330064432961
2024-10-31 08:51:50,033 - INFO - Trial 633: Test MSE=2.233654022216797, Test R²=0.6363273859024048
2024-10-31 08:51:50,033 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:52:28,935 - INFO - Trial 634: Train MSE=2.648072753633772, Train R²=0.5589907084192548
2024-10-31 08:52:28,935 - INFO - Trial 634: Test MSE=2.273961441857474, Test R²=0.6299119506563459
2024-10-31 08:52:28,935 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:53:05,086 - INFO - Trial 635: Train MSE=2.299234092235565, Train R²=0.6166331214564187
2024-10-31 08:53:05,086 - INFO - Trial 635: Test MSE=2.2416935307638988, Test R²=0.6351860421044486
2024-10-31 08:53:05,086 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:53:59,050 - INFO - Trial 636: Train MSE=2.170951781528337, Train R²=0.6370402095573289
2024-10-31 08:53:59,050 - INFO - Trial 636: Test MSE=2.281483232975006, Test R²=0.626856152500425
2024-10-31 08:53:59,050 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:54:36,334 - INFO - Trial 637: Train MSE=3.2358731968062266, Train R²=0.45932312309741974
2024-10-31 08:54:36,334 - INFO - Trial 637: Test MSE=2.2763562202453613, Test R²=0.6294729283877781
2024-10-31 08:54:36,334 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:55:11,720 - INFO - Trial 638: Train MSE=2.2283653361456737, Train R²=0.628729813865253
2024-10-31 08:55:11,720 - INFO - Trial 638: Test MSE=2.239194563456944, Test R²=0.635512479713985
2024-10-31 08:55:11,720 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:55:47,292 - INFO - Trial 639: Train MSE=0.8086804108960288, Train R²=0.865555824978011
2024-10-31 08:55:47,292 - INFO - Trial 639: Test MSE=2.4502584593636647, Test R²=0.6007309981754848
2024-10-31 08:55:47,292 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:56:23,467 - INFO - Trial 640: Train MSE=1.988200102533613, Train R²=0.6692476889916829
2024-10-31 08:56:23,467 - INFO - Trial 640: Test MSE=2.226182835442679, Test R²=0.6376469901629856
2024-10-31 08:56:23,467 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:56:57,085 - INFO - Trial 641: Train MSE=2.698093363216945, Train R²=0.5523362159729004
2024-10-31 08:56:57,085 - INFO - Trial 641: Test MSE=2.2496442794799805, Test R²=0.6312250792980194
2024-10-31 08:56:57,085 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:57:36,249 - INFO - Trial 642: Train MSE=2.049077425684248, Train R²=0.6592000020401818
2024-10-31 08:57:36,249 - INFO - Trial 642: Test MSE=2.2552764415740967, Test R²=0.6330033370426723
2024-10-31 08:57:36,249 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:58:13,590 - INFO - Trial 643: Train MSE=2.284720629453659, Train R²=0.6198613877807345
2024-10-31 08:58:13,590 - INFO - Trial 643: Test MSE=2.2440684863499234, Test R²=0.6345978379249573
2024-10-31 08:58:13,590 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 08:59:33,819 - INFO - Trial 644: Train MSE=2.0913271393094743, Train R²=0.6467646184776511
2024-10-31 08:59:33,819 - INFO - Trial 644: Test MSE=2.297177003962653, Test R²=0.6207903623580933
2024-10-31 08:59:33,819 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:00:10,129 - INFO - Trial 645: Train MSE=3.5404070956366405, Train R²=0.40981339769704
2024-10-31 09:00:10,129 - INFO - Trial 645: Test MSE=2.3873070308140347, Test R²=0.611533488546099
2024-10-31 09:00:10,129 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:00:45,829 - INFO - Trial 646: Train MSE=2.309808841773442, Train R²=0.6155151384217399
2024-10-31 09:00:45,829 - INFO - Trial 646: Test MSE=2.2250915936061313, Test R²=0.6376000131879535
2024-10-31 09:00:45,829 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:01:21,210 - INFO - Trial 647: Train MSE=2.4262728009905135, Train R²=0.5959432274103165
2024-10-31 09:01:21,210 - INFO - Trial 647: Test MSE=2.2544049194880893, Test R²=0.6330880096980503
2024-10-31 09:01:21,210 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:01:56,511 - INFO - Trial 648: Train MSE=2.231793667588915, Train R²=0.6283869785921914
2024-10-31 09:01:56,512 - INFO - Trial 648: Test MSE=2.227244121687753, Test R²=0.6375501666750226
2024-10-31 09:01:56,512 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:02:34,045 - INFO - Trial 649: Train MSE=1.4628463855811529, Train R²=0.7564272071634021
2024-10-31 09:02:34,045 - INFO - Trial 649: Test MSE=2.4416943958827426, Test R²=0.6023473995072501
2024-10-31 09:02:34,045 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:03:34,369 - INFO - Trial 650: Train MSE=2.126404958111899, Train R²=0.6445931142994336
2024-10-31 09:03:34,369 - INFO - Trial 650: Test MSE=2.260999177183424, Test R²=0.629939615726471
2024-10-31 09:03:34,369 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:04:19,306 - INFO - Trial 651: Train MSE=2.4535121747425626, Train R²=0.5907473223549979
2024-10-31 09:04:19,306 - INFO - Trial 651: Test MSE=2.2842060157230923, Test R²=0.6282691529818943
2024-10-31 09:04:19,306 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:04:55,743 - INFO - Trial 652: Train MSE=2.2704594816480363, Train R²=0.6227422654628754
2024-10-31 09:04:55,744 - INFO - Trial 652: Test MSE=2.2301567622593472, Test R²=0.6371410744530814
2024-10-31 09:04:55,744 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:05:44,452 - INFO - Trial 653: Train MSE=1.989331534930638, Train R²=0.6692868747881481
2024-10-31 09:05:44,452 - INFO - Trial 653: Test MSE=2.2757293496813094, Test R²=0.629602951662881
2024-10-31 09:05:44,452 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:06:20,001 - INFO - Trial 654: Train MSE=2.3921399286815097, Train R²=0.6021355433123452
2024-10-31 09:06:20,001 - INFO - Trial 654: Test MSE=2.2376781702041626, Test R²=0.6356633901596069
2024-10-31 09:06:20,001 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:06:57,779 - INFO - Trial 655: Train MSE=2.381808272429875, Train R²=0.6038723140954971
2024-10-31 09:06:57,779 - INFO - Trial 655: Test MSE=2.2396137373788014, Test R²=0.6353021774973188
2024-10-31 09:06:57,779 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:07:34,315 - INFO - Trial 656: Train MSE=2.1717786278043474, Train R²=0.6379917370421546
2024-10-31 09:07:34,315 - INFO - Trial 656: Test MSE=2.2200634138924733, Test R²=0.6385073065757751
2024-10-31 09:07:34,315 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:08:54,504 - INFO - Trial 657: Train MSE=2.2783626339265277, Train R²=0.6158445402979851
2024-10-31 09:08:54,504 - INFO - Trial 657: Test MSE=2.2356842713696614, Test R²=0.6293712769235883
2024-10-31 09:08:54,504 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:09:33,582 - INFO - Trial 658: Train MSE=2.635470347745078, Train R²=0.5613162772996085
2024-10-31 09:09:33,582 - INFO - Trial 658: Test MSE=2.2583372933523997, Test R²=0.6324223024504525
2024-10-31 09:09:33,582 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:10:13,244 - INFO - Trial 659: Train MSE=1.9219165784972054, Train R²=0.6811826590980802
2024-10-31 09:10:13,244 - INFO - Trial 659: Test MSE=2.5125060422079906, Test R²=0.5911109958376203
2024-10-31 09:10:13,244 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:10:50,269 - INFO - Trial 660: Train MSE=2.5371610266821727, Train R²=0.5772312666688647
2024-10-31 09:10:50,269 - INFO - Trial 660: Test MSE=2.2275848729269847, Test R²=0.6375151532036918
2024-10-31 09:10:50,269 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:11:27,916 - INFO - Trial 661: Train MSE=3.800669882978712, Train R²=0.36703538468905855
2024-10-31 09:11:27,916 - INFO - Trial 661: Test MSE=2.4242275101797923, Test R²=0.6055405735969543
2024-10-31 09:11:27,916 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:12:03,412 - INFO - Trial 662: Train MSE=1.9269479513168335, Train R²=0.6795508457081658
2024-10-31 09:12:03,412 - INFO - Trial 662: Test MSE=2.261158517428807, Test R²=0.6319940260478428
2024-10-31 09:12:03,412 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:12:56,368 - INFO - Trial 663: Train MSE=1.8278286350624902, Train R²=0.6941836987222944
2024-10-31 09:12:56,368 - INFO - Trial 663: Test MSE=2.3267631105014255, Test R²=0.6194016890866416
2024-10-31 09:12:56,369 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:13:35,138 - INFO - Trial 664: Train MSE=1.158312935914312, Train R²=0.806814872792789
2024-10-31 09:13:35,139 - INFO - Trial 664: Test MSE=2.3950581891196117, Test R²=0.6099010365349906
2024-10-31 09:13:35,139 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:14:12,365 - INFO - Trial 665: Train MSE=1.265723168849945, Train R²=0.7893626987934113
2024-10-31 09:14:12,365 - INFO - Trial 665: Test MSE=2.4449048382895335, Test R²=0.6020187309810093
2024-10-31 09:14:12,365 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:14:48,649 - INFO - Trial 666: Train MSE=2.413583755493164, Train R²=0.5978717676230839
2024-10-31 09:14:48,649 - INFO - Trial 666: Test MSE=2.268425226211548, Test R²=0.6308330467769078
2024-10-31 09:14:48,649 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:15:26,469 - INFO - Trial 667: Train MSE=6.535893099648612, Train R²=-0.08577124561582293
2024-10-31 09:15:26,469 - INFO - Trial 667: Test MSE=2.7420056462287903, Test R²=0.5509665608406067
2024-10-31 09:15:26,469 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:16:04,871 - INFO - Trial 668: Train MSE=2.6929466894694736, Train R²=0.5512899820293699
2024-10-31 09:16:04,871 - INFO - Trial 668: Test MSE=2.320777654647827, Test R²=0.6223122562680926
2024-10-31 09:16:04,871 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:16:41,667 - INFO - Trial 669: Train MSE=2.147136701004846, Train R²=0.6428992386375155
2024-10-31 09:16:41,667 - INFO - Trial 669: Test MSE=2.277767998831613, Test R²=0.6294185263769967
2024-10-31 09:16:41,667 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:17:17,807 - INFO - Trial 670: Train MSE=2.0645250507763455, Train R²=0.6556106486490795
2024-10-31 09:17:17,807 - INFO - Trial 670: Test MSE=2.2501544611794606, Test R²=0.6335070048059736
2024-10-31 09:17:17,807 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:18:37,290 - INFO - Trial 671: Train MSE=2.2983418064458028, Train R²=0.6122198567858764
2024-10-31 09:18:37,290 - INFO - Trial 671: Test MSE=2.266977288893291, Test R²=0.6247395979506629
2024-10-31 09:18:37,290 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:19:13,105 - INFO - Trial 672: Train MSE=1.295292194400515, Train R²=0.7844745261328561
2024-10-31 09:19:13,105 - INFO - Trial 672: Test MSE=2.3356456756591797, Test R²=0.6196641411100116
2024-10-31 09:19:13,105 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:19:55,768 - INFO - Trial 673: Train MSE=2.9480944871902466, Train R²=0.5086467883416584
2024-10-31 09:19:55,768 - INFO - Trial 673: Test MSE=2.255052328109741, Test R²=0.6328009026391166
2024-10-31 09:19:55,768 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:20:32,638 - INFO - Trial 674: Train MSE=2.2238475680351257, Train R²=0.6301578772919518
2024-10-31 09:20:32,638 - INFO - Trial 674: Test MSE=2.2373362609318326, Test R²=0.635736482484
2024-10-31 09:20:32,638 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:21:08,566 - INFO - Trial 675: Train MSE=2.496897961412157, Train R²=0.5840771517583302
2024-10-31 09:21:08,566 - INFO - Trial 675: Test MSE=2.2751781599862233, Test R²=0.6295560768672398
2024-10-31 09:21:08,566 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:21:47,310 - INFO - Trial 676: Train MSE=2.674381358282907, Train R²=0.5548878567559379
2024-10-31 09:21:47,310 - INFO - Trial 676: Test MSE=2.294820649283273, Test R²=0.6264243466513497
2024-10-31 09:21:47,310 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:22:53,893 - INFO - Trial 677: Train MSE=1.880233617765563, Train R²=0.6858502009085247
2024-10-31 09:22:53,893 - INFO - Trial 677: Test MSE=2.3062354241098677, Test R²=0.6225758876119342
2024-10-31 09:22:53,893 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:23:31,370 - INFO - Trial 678: Train MSE=2.1586916915008, Train R²=0.6408682103667941
2024-10-31 09:23:31,370 - INFO - Trial 678: Test MSE=2.25629871232169, Test R²=0.6326435719217572
2024-10-31 09:23:31,370 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:24:08,238 - INFO - Trial 679: Train MSE=2.3562996898378645, Train R²=0.607390576175281
2024-10-31 09:24:08,238 - INFO - Trial 679: Test MSE=2.228726489203317, Test R²=0.6373177766799927
2024-10-31 09:24:08,238 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:24:46,509 - INFO - Trial 680: Train MSE=2.780402217592512, Train R²=0.5376925553594317
2024-10-31 09:24:46,509 - INFO - Trial 680: Test MSE=2.250356980732509, Test R²=0.6335100020681109
2024-10-31 09:24:46,509 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:25:23,561 - INFO - Trial 681: Train MSE=0.8805953498397555, Train R²=0.8534338687147413
2024-10-31 09:25:23,561 - INFO - Trial 681: Test MSE=2.4607250349862233, Test R²=0.5992799656731742
2024-10-31 09:25:23,561 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:26:00,937 - INFO - Trial 682: Train MSE=2.9409819756235396, Train R²=0.510883378131049
2024-10-31 09:26:00,937 - INFO - Trial 682: Test MSE=2.255814688546317, Test R²=0.6327823911394391
2024-10-31 09:26:00,937 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:27:22,658 - INFO - Trial 683: Train MSE=2.314551616353648, Train R²=0.6083503104746342
2024-10-31 09:27:22,658 - INFO - Trial 683: Test MSE=2.2252031820161, Test R²=0.6313074976205826
2024-10-31 09:27:22,658 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:27:58,893 - INFO - Trial 684: Train MSE=1.5884007258074624, Train R²=0.7358829613242831
2024-10-31 09:27:58,893 - INFO - Trial 684: Test MSE=2.3376340525490895, Test R²=0.6193814277648926
2024-10-31 09:27:58,893 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:28:39,843 - INFO - Trial 685: Train MSE=2.674869648047856, Train R²=0.555148754801069
2024-10-31 09:28:39,843 - INFO - Trial 685: Test MSE=2.3141346999577115, Test R²=0.6233883500099182
2024-10-31 09:28:39,843 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:29:16,631 - INFO - Trial 686: Train MSE=2.094894677400589, Train R²=0.651468311037336
2024-10-31 09:29:16,632 - INFO - Trial 686: Test MSE=2.24076999936785, Test R²=0.635276232446943
2024-10-31 09:29:16,632 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:29:58,285 - INFO - Trial 687: Train MSE=2.486860385962895, Train R²=0.5866713609014239
2024-10-31 09:29:58,285 - INFO - Trial 687: Test MSE=2.256467240197318, Test R²=0.6326241748673576
2024-10-31 09:29:58,285 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:30:35,597 - INFO - Trial 688: Train MSE=2.4146738052368164, Train R²=0.5980355846030372
2024-10-31 09:30:35,597 - INFO - Trial 688: Test MSE=2.294584240232195, Test R²=0.6265531352588108
2024-10-31 09:30:35,597 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:31:08,825 - INFO - Trial 689: Train MSE=2.5167453289031982, Train R²=0.5825404397078923
2024-10-31 09:31:08,825 - INFO - Trial 689: Test MSE=2.2907543778419495, Test R²=0.624475747346878
2024-10-31 09:31:08,826 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:31:48,096 - INFO - Trial 690: Train MSE=1.8316477026258196, Train R²=0.6952972667557853
2024-10-31 09:31:48,097 - INFO - Trial 690: Test MSE=2.251058680670602, Test R²=0.6336146593093872
2024-10-31 09:31:48,097 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:32:41,291 - INFO - Trial 691: Train MSE=2.4211509291614806, Train R²=0.5951270450438771
2024-10-31 09:32:41,291 - INFO - Trial 691: Test MSE=2.272130608558655, Test R²=0.628642771925245
2024-10-31 09:32:41,291 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:33:18,763 - INFO - Trial 692: Train MSE=2.542947973523821, Train R²=0.5777525923081807
2024-10-31 09:33:18,763 - INFO - Trial 692: Test MSE=2.2429836818150113, Test R²=0.6349013447761536
2024-10-31 09:33:18,763 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:33:54,169 - INFO - Trial 693: Train MSE=2.300956973007747, Train R²=0.6169201327221734
2024-10-31 09:33:54,169 - INFO - Trial 693: Test MSE=2.260718379701887, Test R²=0.6319069606917245
2024-10-31 09:33:54,169 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:34:34,021 - INFO - Trial 694: Train MSE=2.525378567831857, Train R²=0.5799861188445773
2024-10-31 09:34:34,022 - INFO - Trial 694: Test MSE=2.289761883871896, Test R²=0.6271679827145168
2024-10-31 09:34:34,022 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:35:09,801 - INFO - Trial 695: Train MSE=2.3060505219868253, Train R²=0.6153750419616699
2024-10-31 09:35:09,801 - INFO - Trial 695: Test MSE=2.238732865878514, Test R²=0.6355901871408735
2024-10-31 09:35:09,801 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:35:45,940 - INFO - Trial 696: Train MSE=2.3703601956367493, Train R²=0.6054983990533012
2024-10-31 09:35:45,940 - INFO - Trial 696: Test MSE=2.2598281587873186, Test R²=0.6321984359196254
2024-10-31 09:35:45,940 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:36:23,714 - INFO - Trial 697: Train MSE=2.8122449772698537, Train R²=0.5323803318398339
2024-10-31 09:36:23,714 - INFO - Trial 697: Test MSE=2.2425710133143832, Test R²=0.6351042645318168
2024-10-31 09:36:23,714 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:37:57,516 - INFO - Trial 698: Train MSE=2.152370129312788, Train R²=0.6389499040586608
2024-10-31 09:37:57,516 - INFO - Trial 698: Test MSE=2.238019657986505, Test R²=0.6288777568510601
2024-10-31 09:37:57,517 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:38:34,140 - INFO - Trial 699: Train MSE=2.2920431792736053, Train R²=0.6184920434440885
2024-10-31 09:38:34,140 - INFO - Trial 699: Test MSE=2.229668038231986, Test R²=0.6370365704808917
2024-10-31 09:38:34,140 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:39:22,703 - INFO - Trial 700: Train MSE=1.7925209999084473, Train R²=0.7011251854045051
2024-10-31 09:39:22,703 - INFO - Trial 700: Test MSE=2.2867664950234547, Test R²=0.6277441723006112
2024-10-31 09:39:22,703 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:39:58,889 - INFO - Trial 701: Train MSE=2.143092078822, Train R²=0.6442149707249233
2024-10-31 09:39:58,889 - INFO - Trial 701: Test MSE=2.2652297701154436, Test R²=0.6311667731830052
2024-10-31 09:39:58,889 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:40:39,917 - INFO - Trial 702: Train MSE=3.0222670691353932, Train R²=0.4972584162439619
2024-10-31 09:40:39,917 - INFO - Trial 702: Test MSE=2.244304214205061, Test R²=0.6348847661699567
2024-10-31 09:40:39,917 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:41:17,663 - INFO - Trial 703: Train MSE=2.5808324302945818, Train R²=0.5701301715203694
2024-10-31 09:41:17,663 - INFO - Trial 703: Test MSE=2.245666129248483, Test R²=0.6343928320067269
2024-10-31 09:41:17,663 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:42:14,515 - INFO - Trial 704: Train MSE=2.0743260766778673, Train R²=0.6525588801928929
2024-10-31 09:42:14,515 - INFO - Trial 704: Test MSE=2.251507418496268, Test R²=0.6310382102216993
2024-10-31 09:42:14,515 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:42:52,731 - INFO - Trial 705: Train MSE=0.8225481723036084, Train R²=0.8630287860121045
2024-10-31 09:42:52,731 - INFO - Trial 705: Test MSE=2.438408783503941, Test R²=0.6028495175497872
2024-10-31 09:42:52,731 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:43:29,174 - INFO - Trial 706: Train MSE=2.441671780177525, Train R²=0.5936032256909779
2024-10-31 09:43:29,174 - INFO - Trial 706: Test MSE=2.243764502661569, Test R²=0.634734468800681
2024-10-31 09:43:29,174 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:44:05,251 - INFO - Trial 707: Train MSE=0.810602816087859, Train R²=0.8649543545075825
2024-10-31 09:44:05,251 - INFO - Trial 707: Test MSE=2.440063340323312, Test R²=0.6026409608977181
2024-10-31 09:44:05,251 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:44:41,212 - INFO - Trial 708: Train MSE=2.8574738672801425, Train R²=0.5259315137352262
2024-10-31 09:44:41,212 - INFO - Trial 708: Test MSE=2.3280221053532193, Test R²=0.6210184437888009
2024-10-31 09:44:41,212 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:45:17,288 - INFO - Trial 709: Train MSE=2.3222804495266507, Train R²=0.6135346314736775
2024-10-31 09:45:17,288 - INFO - Trial 709: Test MSE=2.2471834421157837, Test R²=0.6341817208698818
2024-10-31 09:45:17,288 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:46:46,373 - INFO - Trial 710: Train MSE=2.310096474630492, Train R²=0.6119579108698028
2024-10-31 09:46:46,373 - INFO - Trial 710: Test MSE=2.287997535296849, Test R²=0.6206203209502357
2024-10-31 09:46:46,373 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:47:21,687 - INFO - Trial 711: Train MSE=2.379302280289786, Train R²=0.6042203775474003
2024-10-31 09:47:21,687 - INFO - Trial 711: Test MSE=2.218247021947588, Test R²=0.6388142108917236
2024-10-31 09:47:21,687 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:47:58,342 - INFO - Trial 712: Train MSE=2.4201639464923312, Train R²=0.5980248004198074
2024-10-31 09:47:58,342 - INFO - Trial 712: Test MSE=2.2455064398901805, Test R²=0.6345182657241821
2024-10-31 09:47:58,342 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:48:34,926 - INFO - Trial 713: Train MSE=2.3386669073786055, Train R²=0.6114309153386525
2024-10-31 09:48:34,926 - INFO - Trial 713: Test MSE=2.2657919100352695, Test R²=0.6312254667282104
2024-10-31 09:48:34,926 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:49:06,455 - INFO - Trial 714: Train MSE=2.3373353481292725, Train R²=0.6125193962029049
2024-10-31 09:49:06,455 - INFO - Trial 714: Test MSE=2.2504082322120667, Test R²=0.6310409158468246
2024-10-31 09:49:06,456 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:49:46,557 - INFO - Trial 715: Train MSE=4.2026621614183695, Train R²=0.3010226083653314
2024-10-31 09:49:46,557 - INFO - Trial 715: Test MSE=2.3331050191606795, Test R²=0.6204213159424918
2024-10-31 09:49:46,558 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:50:26,135 - INFO - Trial 716: Train MSE=2.01041328055518, Train R²=0.6656221747398376
2024-10-31 09:50:26,135 - INFO - Trial 716: Test MSE=2.245224816458566, Test R²=0.6344566004616874
2024-10-31 09:50:26,135 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:51:02,951 - INFO - Trial 717: Train MSE=2.204153380223683, Train R²=0.6327885985374451
2024-10-31 09:51:02,951 - INFO - Trial 717: Test MSE=2.2153501510620117, Test R²=0.63944901738848
2024-10-31 09:51:02,952 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:51:56,026 - INFO - Trial 718: Train MSE=2.2299623021057675, Train R²=0.6282136312552861
2024-10-31 09:51:56,026 - INFO - Trial 718: Test MSE=2.2503047585487366, Test R²=0.6320524343422481
2024-10-31 09:51:56,026 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:52:32,928 - INFO - Trial 719: Train MSE=2.3554418087005615, Train R²=0.607792813863073
2024-10-31 09:52:32,928 - INFO - Trial 719: Test MSE=2.213700601032802, Test R²=0.6395449553217206
2024-10-31 09:52:32,928 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:53:10,131 - INFO - Trial 720: Train MSE=2.383534984929221, Train R²=0.6029688928808484
2024-10-31 09:53:10,131 - INFO - Trial 720: Test MSE=2.2683059658323015, Test R²=0.6308620316641671
2024-10-31 09:53:10,131 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:53:55,972 - INFO - A new study created in memory with name: no-name-d23449aa-63d0-4b09-a48c-fa3e4960b61c
2024-10-31 09:55:19,431 - WARNING - Trial 0 failed with parameters: {'hidden_layers': 3, 'hidden_units': 512, 'dropout_rate': 0.30088231310932195, 'learning_rate': 0.00028152740683603866, 'weight_decay': 0.0004261444490296227, 'batch_size': 128, 'tree_depth': 10} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\optuna\study\_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\3592968231.py", line 41, in objective
    metrics = trainer.fit(dl_train, dl_test, num_epochs=100)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\2713248567.py", line 80, in fit
    train_loss, train_r2 = self.train_step(dataloader_train)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\2713248567.py", line 41, in train_step
    r2 = self.r2_metric(pred_y, batch_y)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torchmetrics\metric.py", line 312, in forward
    self._forward_cache = self._forward_reduce_state_update(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torchmetrics\metric.py", line 381, in _forward_reduce_state_update
    self.update(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torchmetrics\metric.py", line 483, in wrapped_func
    update(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torchmetrics\regression\r2.py", line 144, in update
    sum_squared_error, sum_error, residual, total = _r2_score_update(preds, target)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torchmetrics\functional\regression\r2.py", line 40, in _r2_score_update
    sum_obs = torch.sum(target, dim=0)
KeyboardInterrupt
2024-10-31 09:55:19,434 - WARNING - Trial 0 failed with value None.
2024-10-31 09:55:20,735 - INFO - A new study created in memory with name: no-name-26431391-672a-4ad3-b1d2-11e46ebe147b
2024-10-31 09:55:29,927 - WARNING - Trial 0 failed with parameters: {'hidden_layers': 2, 'hidden_units': 512, 'dropout_rate': 0.7210820105475142, 'learning_rate': 0.00026995265112485695, 'weight_decay': 0.000665203141313391, 'batch_size': 1024, 'tree_depth': 11} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\optuna\study\_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\3592968231.py", line 41, in objective
    metrics = trainer.fit(dl_train, dl_test, num_epochs=100)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\2713248567.py", line 80, in fit
    train_loss, train_r2 = self.train_step(dataloader_train)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\2713248567.py", line 41, in train_step
    r2 = self.r2_metric(pred_y, batch_y)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torchmetrics\metric.py", line 312, in forward
    self._forward_cache = self._forward_reduce_state_update(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torchmetrics\metric.py", line 382, in _forward_reduce_state_update
    batch_val = self.compute()
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torchmetrics\metric.py", line 633, in wrapped_func
    value = _squeeze_if_scalar(compute(*args, **kwargs))
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torchmetrics\regression\r2.py", line 153, in compute
    return _r2_score_compute(
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torchmetrics\functional\regression\r2.py", line 77, in _r2_score_compute
    if num_obs < 2:
KeyboardInterrupt
2024-10-31 09:55:29,927 - WARNING - Trial 0 failed with value None.
2024-10-31 09:55:33,955 - INFO - A new study created in memory with name: no-name-5d76bbe6-07f7-4a0d-9247-cba3909e563a
2024-10-31 09:56:10,180 - INFO - Trial 0: Train MSE=1.674649600471769, Train R²=0.7208518918071475
2024-10-31 09:56:10,180 - INFO - Trial 0: Test MSE=2.3198165552956715, Test R²=0.6223437019756862
2024-10-31 09:56:10,180 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 09:56:10,183 - INFO - Trial 0 finished with value: 2.3198165552956715 and parameters: {'hidden_layers': 3, 'hidden_units': 512, 'dropout_rate': 0.7208089460633437, 'learning_rate': 0.00224108222113318, 'weight_decay': 0.00010811376213320458, 'batch_size': 512, 'tree_depth': 10}. Best is trial 0 with value: 2.3198165552956715.
2024-10-31 09:56:21,267 - WARNING - Trial 1 failed with parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.738081523028094, 'learning_rate': 0.001324599787980482, 'weight_decay': 0.00033123494589636543, 'batch_size': 512, 'tree_depth': 6} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\optuna\study\_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\383003963.py", line 41, in objective
    metrics = trainer.fit(dl_train, dl_test, num_epochs=100)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\2713248567.py", line 81, in fit
    test_loss, test_r2 = self.test_step(dataloader_test)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\2713248567.py", line 61, in test_step
    pred_y = self.model(batch_x)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\nn\modules\container.py", line 219, in forward
    input = module(input)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\nn\modules\linear.py", line 117, in forward
    return F.linear(input, self.weight, self.bias)
KeyboardInterrupt
2024-10-31 09:56:21,272 - WARNING - Trial 1 failed with value None.
2024-10-31 09:59:45,113 - INFO - A new study created in memory with name: no-name-6d287149-bb58-4d65-ab19-e3925138ecb2
2024-10-31 10:00:27,622 - INFO - Trial 0 finished with value: 2.733866035938263 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.5663567501618574, 'learning_rate': 0.00012291305879425494, 'weight_decay': 0.0009017658594331733, 'batch_size': 1024, 'tree_depth': 6}. Best is trial 0 with value: 2.733866035938263.
2024-10-31 10:01:48,807 - INFO - Trial 1 finished with value: 2.422694069998605 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7387329914727925, 'learning_rate': 0.0068878410879292295, 'weight_decay': 0.0005503708714467666, 'batch_size': 512, 'tree_depth': 6}. Best is trial 1 with value: 2.422694069998605.
2024-10-31 10:03:49,950 - INFO - Trial number: 0
2024-10-31 10:03:49,951 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.5663567501618574, 'learning_rate': 0.00012291305879425494, 'weight_decay': 0.0009017658594331733, 'batch_size': 1024, 'tree_depth': 6}
2024-10-31 10:03:49,951 - INFO - Value (MSE): 2.733866035938263
2024-10-31 10:03:49,951 - INFO - Trial number: 1
2024-10-31 10:03:49,951 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7387329914727925, 'learning_rate': 0.0068878410879292295, 'weight_decay': 0.0005503708714467666, 'batch_size': 512, 'tree_depth': 6}
2024-10-31 10:03:49,951 - INFO - Value (MSE): 2.422694069998605
2024-10-31 10:04:02,343 - INFO - A new study created in memory with name: no-name-8ad6a0e7-a801-46c1-94e8-4be6bf52b886
2024-10-31 10:04:05,180 - WARNING - Trial 0 failed with parameters: {'hidden_layers': 3, 'hidden_units': 1024, 'dropout_rate': 0.4466028098190823, 'learning_rate': 0.00019557752620186577, 'weight_decay': 0.00037897929402631, 'batch_size': 1024, 'tree_depth': 6} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\optuna\study\_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\4174905845.py", line 41, in objective
    metrics = trainer.fit(dl_train, dl_test, num_epochs=100)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\2713248567.py", line 81, in fit
    test_loss, test_r2 = self.test_step(dataloader_test)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\2713248567.py", line 67, in test_step
    r2 = self.r2_metric(pred_y, batch_y)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\nn\modules\module.py", line 1553, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\nn\modules\module.py", line 1562, in _call_impl
    return forward_call(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torchmetrics\metric.py", line 312, in forward
    self._forward_cache = self._forward_reduce_state_update(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torchmetrics\metric.py", line 387, in _forward_reduce_state_update
    self._reduce_states(global_state)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torchmetrics\metric.py", line 433, in _reduce_states
    setattr(self, attr, reduced)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torchmetrics\metric.py", line 734, in __setattr__
    def __setattr__(self, name: str, value: Any) -> None:
KeyboardInterrupt
2024-10-31 10:04:05,181 - WARNING - Trial 0 failed with value None.
2024-10-31 10:04:20,976 - INFO - A new study created in memory with name: no-name-4933e0ad-a9d3-423f-84c5-48d9d2b69ba1
2024-10-31 10:06:04,892 - WARNING - Trial 0 failed with parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.30436882918229713, 'learning_rate': 0.0010976657256142048, 'weight_decay': 0.0009590485013504912, 'batch_size': 256, 'tree_depth': 8} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\optuna\study\_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\1284544714.py", line 41, in objective
    metrics = trainer.fit(dl_train, dl_test, num_epochs=100)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\2713248567.py", line 80, in fit
    train_loss, train_r2 = self.train_step(dataloader_train)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\2713248567.py", line 24, in train_step
    for iteration, (batch_x, batch_y) in enumerate(dataloader):
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\utils\data\dataloader.py", line 630, in __next__
    data = self._next_data()
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\utils\data\dataloader.py", line 673, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\utils\data\_utils\fetch.py", line 55, in fetch
    return self.collate_fn(data)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\utils\data\_utils\collate.py", line 317, in default_collate
    return collate(batch, collate_fn_map=default_collate_fn_map)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\utils\data\_utils\collate.py", line 174, in collate
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\utils\data\_utils\collate.py", line 174, in <listcomp>
    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\utils\data\_utils\collate.py", line 142, in collate
    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\utils\data\_utils\collate.py", line 214, in collate_tensor_fn
    return torch.stack(batch, 0, out=out)
KeyboardInterrupt
2024-10-31 10:06:04,905 - WARNING - Trial 0 failed with value None.
2024-10-31 10:06:44,894 - INFO - A new study created in memory with name: no-name-0406e6e1-9742-4a2d-8a37-d562664dc991
2024-10-31 10:07:41,569 - INFO - Trial 0 finished with value: 2.3350892663002014 and parameters: {'hidden_layers': 3, 'hidden_units': 512, 'dropout_rate': 0.6711745830927888, 'learning_rate': 0.0052623728130298305, 'weight_decay': 0.000415112577305699, 'batch_size': 1024, 'tree_depth': 12}. Best is trial 0 with value: 2.3350892663002014.
2024-10-31 10:08:19,432 - INFO - Trial 1 finished with value: 2.9048869013786316 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.5277090060510381, 'learning_rate': 0.00015774055289169506, 'weight_decay': 0.0002669113959443583, 'batch_size': 1024, 'tree_depth': 6}. Best is trial 0 with value: 2.3350892663002014.
2024-10-31 10:09:50,567 - INFO - A new study created in memory with name: no-name-7c0a08f7-c67f-49d5-88ef-7e7e66cce3bf
2024-10-31 10:12:35,983 - WARNING - Trial 0 failed with parameters: {'hidden_layers': 4, 'hidden_units': 128, 'dropout_rate': 0.40984687399863645, 'learning_rate': 0.0015354657620293799, 'weight_decay': 0.0003253691499915003, 'batch_size': 128, 'tree_depth': 9} because of the following error: ValueError('No trials are completed yet.').
Traceback (most recent call last):
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\optuna\study\_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\2686767681.py", line 53, in objective
    print(f"最佳參數: {study.best_params}")
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\optuna\study\study.py", line 119, in best_params
    return self.best_trial.params
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\optuna\study\study.py", line 162, in best_trial
    best_trial = self._storage.get_best_trial(self._study_id)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\optuna\storages\_in_memory.py", line 232, in get_best_trial
    raise ValueError("No trials are completed yet.")
ValueError: No trials are completed yet.
2024-10-31 10:12:35,986 - WARNING - Trial 0 failed with value None.
2024-10-31 10:13:50,653 - INFO - A new study created in memory with name: no-name-8ff608e3-722c-448b-bad3-45a4b6c084ec
2024-10-31 10:13:54,845 - WARNING - Trial 0 failed with parameters: {'hidden_layers': 3, 'hidden_units': 512, 'dropout_rate': 0.7539856231255171, 'learning_rate': 0.0035897621703080904, 'weight_decay': 0.00027383533027138587, 'batch_size': 1024, 'tree_depth': 8} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\optuna\study\_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\2695735953.py", line 41, in objective
    metrics = trainer.fit(dl_train, dl_test, num_epochs=100)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\2713248567.py", line 81, in fit
    test_loss, test_r2 = self.test_step(dataloader_test)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\2713248567.py", line 57, in test_step
    for batch_x, batch_y in dataloader:
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\utils\data\dataloader.py", line 630, in __next__
    data = self._next_data()
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\utils\data\dataloader.py", line 673, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\utils\data\dataset.py", line 211, in __getitem__
    return tuple(tensor[index] for tensor in self.tensors)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\utils\data\dataset.py", line 211, in <genexpr>
    return tuple(tensor[index] for tensor in self.tensors)
KeyboardInterrupt
2024-10-31 10:13:54,847 - WARNING - Trial 0 failed with value None.
2024-10-31 10:14:15,122 - INFO - A new study created in memory with name: no-name-69ab1b1d-bfd4-404c-a92a-cf431a86b47b
2024-10-31 10:18:02,556 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 1024, 'dropout_rate': 0.4187100418219091, 'learning_rate': 0.0003174077427345149, 'weight_decay': 0.00017452413550431113, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 10:18:02,556 - INFO - Trial 0: Train MSE=0.6601551954767534, Train R²=0.8882952162197658
2024-10-31 10:18:02,556 - INFO - Trial 0: Test MSE=2.4791237882205417, Test R²=0.5885741540363857
2024-10-31 10:18:02,556 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:18:02,558 - INFO - Trial 0 finished with value: 2.4791237882205417 and parameters: {'hidden_layers': 2, 'hidden_units': 1024, 'dropout_rate': 0.4187100418219091, 'learning_rate': 0.0003174077427345149, 'weight_decay': 0.00017452413550431113, 'batch_size': 128, 'tree_depth': 11}. Best is trial 0 with value: 2.4791237882205417.
2024-10-31 10:18:55,591 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.47641602723876286, 'learning_rate': 0.008529670101702806, 'weight_decay': 0.0009988098662988248, 'batch_size': 1024, 'tree_depth': 12}
2024-10-31 10:18:55,592 - INFO - Trial 1: Train MSE=1.3646704384258814, Train R²=0.7734536698886326
2024-10-31 10:18:55,592 - INFO - Trial 1: Test MSE=2.415984630584717, Test R²=0.6037010848522186
2024-10-31 10:18:55,592 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:18:55,595 - INFO - Trial 1 finished with value: 2.415984630584717 and parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.47641602723876286, 'learning_rate': 0.008529670101702806, 'weight_decay': 0.0009988098662988248, 'batch_size': 1024, 'tree_depth': 12}. Best is trial 1 with value: 2.415984630584717.
2024-10-31 10:20:07,588 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 512, 'dropout_rate': 0.3958255370146791, 'learning_rate': 0.0004587088315100256, 'weight_decay': 0.000680239322850629, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 10:20:07,589 - INFO - Trial 2: Train MSE=1.1218806675502233, Train R²=0.8128689719097955
2024-10-31 10:20:07,590 - INFO - Trial 2: Test MSE=2.5135222503117154, Test R²=0.5906861850193569
2024-10-31 10:20:07,590 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:20:07,592 - INFO - Trial 2 finished with value: 2.5135222503117154 and parameters: {'hidden_layers': 2, 'hidden_units': 512, 'dropout_rate': 0.3958255370146791, 'learning_rate': 0.0004587088315100256, 'weight_decay': 0.000680239322850629, 'batch_size': 512, 'tree_depth': 10}. Best is trial 1 with value: 2.415984630584717.
2024-10-31 10:20:49,793 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 512, 'dropout_rate': 0.6453568665495353, 'learning_rate': 0.005429811759080869, 'weight_decay': 0.0008053707999247414, 'batch_size': 1024, 'tree_depth': 10}
2024-10-31 10:20:49,793 - INFO - Trial 3: Train MSE=1.3763095566204615, Train R²=0.7715301981994084
2024-10-31 10:20:49,794 - INFO - Trial 3: Test MSE=2.356587827205658, Test R²=0.61372309923172
2024-10-31 10:20:49,794 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:20:49,794 - INFO - Trial 3 finished with value: 2.356587827205658 and parameters: {'hidden_layers': 2, 'hidden_units': 512, 'dropout_rate': 0.6453568665495353, 'learning_rate': 0.005429811759080869, 'weight_decay': 0.0008053707999247414, 'batch_size': 1024, 'tree_depth': 10}. Best is trial 3 with value: 2.356587827205658.
2024-10-31 10:21:35,695 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.42736243570344307, 'learning_rate': 0.0016412956938509232, 'weight_decay': 0.00022673162391216963, 'batch_size': 1024, 'tree_depth': 7}
2024-10-31 10:21:35,695 - INFO - Trial 4: Train MSE=1.6374141488756453, Train R²=0.7280742057732174
2024-10-31 10:21:35,695 - INFO - Trial 4: Test MSE=2.434241473674774, Test R²=0.6012215614318848
2024-10-31 10:21:35,695 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:21:35,696 - INFO - Trial 4 finished with value: 2.434241473674774 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.42736243570344307, 'learning_rate': 0.0016412956938509232, 'weight_decay': 0.00022673162391216963, 'batch_size': 1024, 'tree_depth': 7}. Best is trial 3 with value: 2.356587827205658.
2024-10-31 10:25:23,984 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 1024, 'dropout_rate': 0.5649827708177766, 'learning_rate': 0.0006250937555549244, 'weight_decay': 0.00012109436195538007, 'batch_size': 128, 'tree_depth': 6}
2024-10-31 10:25:23,984 - INFO - Trial 5: Train MSE=2.1768747302038327, Train R²=0.631538137793541
2024-10-31 10:25:23,984 - INFO - Trial 5: Test MSE=2.421499490737915, Test R²=0.6000220711742129
2024-10-31 10:25:23,984 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:25:23,985 - INFO - Trial 5 finished with value: 2.421499490737915 and parameters: {'hidden_layers': 2, 'hidden_units': 1024, 'dropout_rate': 0.5649827708177766, 'learning_rate': 0.0006250937555549244, 'weight_decay': 0.00012109436195538007, 'batch_size': 128, 'tree_depth': 6}. Best is trial 3 with value: 2.356587827205658.
2024-10-31 10:27:42,375 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 1024, 'dropout_rate': 0.6612043036463369, 'learning_rate': 0.0029093138167612465, 'weight_decay': 0.0003042487909052301, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 10:27:42,375 - INFO - Trial 6: Train MSE=1.2951134677444185, Train R²=0.783400433404105
2024-10-31 10:27:42,376 - INFO - Trial 6: Test MSE=2.4106775862830028, Test R²=0.6059377065726689
2024-10-31 10:27:42,376 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:27:42,376 - INFO - Trial 6 finished with value: 2.4106775862830028 and parameters: {'hidden_layers': 3, 'hidden_units': 1024, 'dropout_rate': 0.6612043036463369, 'learning_rate': 0.0029093138167612465, 'weight_decay': 0.0003042487909052301, 'batch_size': 256, 'tree_depth': 11}. Best is trial 3 with value: 2.356587827205658.
2024-10-31 10:31:08,625 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7487396845718308, 'learning_rate': 0.0009244550100650817, 'weight_decay': 0.0006259377052001034, 'batch_size': 128, 'tree_depth': 10}
2024-10-31 10:31:08,625 - INFO - Trial 7: Train MSE=1.9786330269915717, Train R²=0.6660139283963612
2024-10-31 10:31:08,625 - INFO - Trial 7: Test MSE=2.300841518810817, Test R²=0.6191944820540292
2024-10-31 10:31:08,625 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:31:08,628 - INFO - Trial 7 finished with value: 2.300841518810817 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7487396845718308, 'learning_rate': 0.0009244550100650817, 'weight_decay': 0.0006259377052001034, 'batch_size': 128, 'tree_depth': 10}. Best is trial 7 with value: 2.300841518810817.
2024-10-31 10:33:14,839 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 1024, 'dropout_rate': 0.7677552796541323, 'learning_rate': 0.00045365756075704344, 'weight_decay': 0.0003835486081517991, 'batch_size': 256, 'tree_depth': 6}
2024-10-31 10:33:14,839 - INFO - Trial 8: Train MSE=2.9190242205347334, Train R²=0.5128059365919658
2024-10-31 10:33:14,839 - INFO - Trial 8: Test MSE=2.482683403151376, Test R²=0.5939325519970485
2024-10-31 10:33:14,840 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:33:14,841 - INFO - Trial 8 finished with value: 2.482683403151376 and parameters: {'hidden_layers': 2, 'hidden_units': 1024, 'dropout_rate': 0.7677552796541323, 'learning_rate': 0.00045365756075704344, 'weight_decay': 0.0003835486081517991, 'batch_size': 256, 'tree_depth': 6}. Best is trial 7 with value: 2.300841518810817.
2024-10-31 10:36:27,235 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 1024, 'dropout_rate': 0.6762384262403405, 'learning_rate': 0.00019841268511079952, 'weight_decay': 0.0008841175565435295, 'batch_size': 256, 'tree_depth': 8}
2024-10-31 10:36:27,235 - INFO - Trial 9: Train MSE=2.978272633893149, Train R²=0.5019503427403313
2024-10-31 10:36:27,235 - INFO - Trial 9: Test MSE=2.3167381627219066, Test R²=0.6209185421466827
2024-10-31 10:36:27,236 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:36:27,238 - INFO - Trial 9 finished with value: 2.3167381627219066 and parameters: {'hidden_layers': 4, 'hidden_units': 1024, 'dropout_rate': 0.6762384262403405, 'learning_rate': 0.00019841268511079952, 'weight_decay': 0.0008841175565435295, 'batch_size': 256, 'tree_depth': 8}. Best is trial 7 with value: 2.300841518810817.
2024-10-31 10:39:57,855 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7807805634771691, 'learning_rate': 0.0011837402201597342, 'weight_decay': 0.000497857567807634, 'batch_size': 128, 'tree_depth': 9}
2024-10-31 10:39:57,855 - INFO - Trial 10: Train MSE=2.3330505809613635, Train R²=0.6079960050327438
2024-10-31 10:39:57,855 - INFO - Trial 10: Test MSE=2.240706899336406, Test R²=0.628321002636637
2024-10-31 10:39:57,855 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:39:57,856 - INFO - Trial 10 finished with value: 2.240706899336406 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7807805634771691, 'learning_rate': 0.0011837402201597342, 'weight_decay': 0.000497857567807634, 'batch_size': 128, 'tree_depth': 9}. Best is trial 10 with value: 2.240706899336406.
2024-10-31 10:42:58,281 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7949824993078319, 'learning_rate': 0.0013095227721988455, 'weight_decay': 0.0004767451677768874, 'batch_size': 128, 'tree_depth': 9}
2024-10-31 10:42:58,281 - INFO - Trial 11: Train MSE=2.380228162876197, Train R²=0.5933935711426395
2024-10-31 10:42:58,281 - INFO - Trial 11: Test MSE=2.2355153220040456, Test R²=0.6302647441625595
2024-10-31 10:42:58,281 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:42:58,282 - INFO - Trial 11 finished with value: 2.2355153220040456 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7949824993078319, 'learning_rate': 0.0013095227721988455, 'weight_decay': 0.0004767451677768874, 'batch_size': 128, 'tree_depth': 9}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 10:46:26,736 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7640772657967212, 'learning_rate': 0.0018176083174522252, 'weight_decay': 0.0004616855634262608, 'batch_size': 128, 'tree_depth': 8}
2024-10-31 10:46:26,736 - INFO - Trial 12: Train MSE=2.4012468457221985, Train R²=0.5952253794031483
2024-10-31 10:46:26,736 - INFO - Trial 12: Test MSE=2.384457562650953, Test R²=0.6042075135878154
2024-10-31 10:46:26,736 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:46:26,737 - INFO - Trial 12 finished with value: 2.384457562650953 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7640772657967212, 'learning_rate': 0.0018176083174522252, 'weight_decay': 0.0004616855634262608, 'batch_size': 128, 'tree_depth': 8}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 10:50:06,307 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.3247193828844981, 'learning_rate': 0.001349852201323865, 'weight_decay': 0.0004883845274565764, 'batch_size': 128, 'tree_depth': 9}
2024-10-31 10:50:06,307 - INFO - Trial 13: Train MSE=0.9475583689553397, Train R²=0.8381777576037815
2024-10-31 10:50:06,308 - INFO - Trial 13: Test MSE=2.498584415231432, Test R²=0.5868834469999585
2024-10-31 10:50:06,308 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:50:06,309 - INFO - Trial 13 finished with value: 2.498584415231432 and parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.3247193828844981, 'learning_rate': 0.001349852201323865, 'weight_decay': 0.0004883845274565764, 'batch_size': 128, 'tree_depth': 9}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 10:51:19,465 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7929337651581639, 'learning_rate': 0.00010919349122583283, 'weight_decay': 0.00028031894971983787, 'batch_size': 512, 'tree_depth': 8}
2024-10-31 10:51:19,465 - INFO - Trial 14: Train MSE=9.57238497052874, Train R²=-0.6021641067096165
2024-10-31 10:51:19,465 - INFO - Trial 14: Test MSE=5.020614079066685, Test R²=0.18302136659622192
2024-10-31 10:51:19,466 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:51:19,467 - INFO - Trial 14 finished with value: 5.020614079066685 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7929337651581639, 'learning_rate': 0.00010919349122583283, 'weight_decay': 0.00028031894971983787, 'batch_size': 512, 'tree_depth': 8}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 10:54:00,791 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.5778205294265528, 'learning_rate': 0.0030598733674236755, 'weight_decay': 0.0005273777380927648, 'batch_size': 128, 'tree_depth': 9}
2024-10-31 10:54:00,792 - INFO - Trial 15: Train MSE=1.802946265254702, Train R²=0.6957142672368458
2024-10-31 10:54:00,792 - INFO - Trial 15: Test MSE=2.354028101478304, Test R²=0.6104882636240551
2024-10-31 10:54:00,792 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:54:00,794 - INFO - Trial 15 finished with value: 2.354028101478304 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.5778205294265528, 'learning_rate': 0.0030598733674236755, 'weight_decay': 0.0005273777380927648, 'batch_size': 128, 'tree_depth': 9}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 10:57:29,414 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7052218870810235, 'learning_rate': 0.0008443855879380703, 'weight_decay': 0.00039553622122919635, 'batch_size': 128, 'tree_depth': 9}
2024-10-31 10:57:29,414 - INFO - Trial 16: Train MSE=1.891230704528945, Train R²=0.6794340120894569
2024-10-31 10:57:29,414 - INFO - Trial 16: Test MSE=2.3230366153376445, Test R²=0.6154548972845078
2024-10-31 10:57:29,414 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 10:57:29,415 - INFO - Trial 16 finished with value: 2.3230366153376445 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7052218870810235, 'learning_rate': 0.0008443855879380703, 'weight_decay': 0.00039553622122919635, 'batch_size': 128, 'tree_depth': 9}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:01:04,449 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.5976987032269037, 'learning_rate': 0.0029269228675276385, 'weight_decay': 0.00020755586397497953, 'batch_size': 128, 'tree_depth': 7}
2024-10-31 11:01:04,449 - INFO - Trial 17: Train MSE=2.2480554474251613, Train R²=0.6201240947203976
2024-10-31 11:01:04,449 - INFO - Trial 17: Test MSE=2.346848964691162, Test R²=0.6105814129114151
2024-10-31 11:01:04,449 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:01:04,451 - INFO - Trial 17 finished with value: 2.346848964691162 and parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.5976987032269037, 'learning_rate': 0.0029269228675276385, 'weight_decay': 0.00020755586397497953, 'batch_size': 128, 'tree_depth': 7}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:02:25,089 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7178542108610289, 'learning_rate': 0.0012249451693814254, 'weight_decay': 0.0006368968043926775, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 11:02:25,089 - INFO - Trial 18: Train MSE=2.0496651232242584, Train R²=0.6590909042528698
2024-10-31 11:02:25,089 - INFO - Trial 18: Test MSE=2.2725734199796404, Test R²=0.6300674251147679
2024-10-31 11:02:25,089 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:02:25,090 - INFO - Trial 18 finished with value: 2.2725734199796404 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7178542108610289, 'learning_rate': 0.0012249451693814254, 'weight_decay': 0.0006368968043926775, 'batch_size': 512, 'tree_depth': 11}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:06:06,598 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 512, 'dropout_rate': 0.4934220338304901, 'learning_rate': 0.005305602551973253, 'weight_decay': 0.0003665709449133424, 'batch_size': 128, 'tree_depth': 7}
2024-10-31 11:06:06,598 - INFO - Trial 19: Train MSE=2.365095709051405, Train R²=0.6019367389380932
2024-10-31 11:06:06,598 - INFO - Trial 19: Test MSE=2.505279447351183, Test R²=0.5874426109450204
2024-10-31 11:06:06,598 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:06:06,600 - INFO - Trial 19 finished with value: 2.505279447351183 and parameters: {'hidden_layers': 4, 'hidden_units': 512, 'dropout_rate': 0.4934220338304901, 'learning_rate': 0.005305602551973253, 'weight_decay': 0.0003665709449133424, 'batch_size': 128, 'tree_depth': 7}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:09:24,527 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 128, 'dropout_rate': 0.7239697839775887, 'learning_rate': 0.0002441997184107029, 'weight_decay': 0.00010306072118612039, 'batch_size': 128, 'tree_depth': 10}
2024-10-31 11:09:24,527 - INFO - Trial 20: Train MSE=2.789763436785766, Train R²=0.5282641074487141
2024-10-31 11:09:24,527 - INFO - Trial 20: Test MSE=2.346024508987154, Test R²=0.6115443706512451
2024-10-31 11:09:24,527 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:09:24,528 - INFO - Trial 20 finished with value: 2.346024508987154 and parameters: {'hidden_layers': 3, 'hidden_units': 128, 'dropout_rate': 0.7239697839775887, 'learning_rate': 0.0002441997184107029, 'weight_decay': 0.00010306072118612039, 'batch_size': 128, 'tree_depth': 10}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:10:40,786 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7140159211055277, 'learning_rate': 0.001243971251547632, 'weight_decay': 0.0006192427925854134, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 11:10:40,786 - INFO - Trial 21: Train MSE=2.008732404027666, Train R²=0.6658668943813869
2024-10-31 11:10:40,786 - INFO - Trial 21: Test MSE=2.246224982397897, Test R²=0.634399243763515
2024-10-31 11:10:40,786 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:10:40,788 - INFO - Trial 21 finished with value: 2.246224982397897 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7140159211055277, 'learning_rate': 0.001243971251547632, 'weight_decay': 0.0006192427925854134, 'batch_size': 512, 'tree_depth': 12}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:11:57,176 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7900431747055914, 'learning_rate': 0.002060741473598195, 'weight_decay': 0.000548471372752603, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 11:11:57,176 - INFO - Trial 22: Train MSE=2.50711452960968, Train R²=0.5832785069942474
2024-10-31 11:11:57,177 - INFO - Trial 22: Test MSE=2.2764382362365723, Test R²=0.6295999714306423
2024-10-31 11:11:57,177 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:11:57,180 - INFO - Trial 22 finished with value: 2.2764382362365723 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7900431747055914, 'learning_rate': 0.002060741473598195, 'weight_decay': 0.000548471372752603, 'batch_size': 512, 'tree_depth': 12}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:12:57,384 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.6250609057944423, 'learning_rate': 0.0007304503209774393, 'weight_decay': 0.0007835231193353927, 'batch_size': 512, 'tree_depth': 8}
2024-10-31 11:12:57,385 - INFO - Trial 23: Train MSE=2.3904310720307484, Train R²=0.6020239400012153
2024-10-31 11:12:57,385 - INFO - Trial 23: Test MSE=2.3088100978306363, Test R²=0.6241508977753776
2024-10-31 11:12:57,385 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:12:57,386 - INFO - Trial 23 finished with value: 2.3088100978306363 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.6250609057944423, 'learning_rate': 0.0007304503209774393, 'weight_decay': 0.0007835231193353927, 'batch_size': 512, 'tree_depth': 8}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:13:57,812 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7993913612982798, 'learning_rate': 0.0011690612795614945, 'weight_decay': 0.00043753841858705576, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 11:13:57,812 - INFO - Trial 24: Train MSE=2.8936767833573476, Train R²=0.5183744409254619
2024-10-31 11:13:57,812 - INFO - Trial 24: Test MSE=2.2551888738359724, Test R²=0.6328083021300179
2024-10-31 11:13:57,812 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:13:57,813 - INFO - Trial 24 finished with value: 2.2551888738359724 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7993913612982798, 'learning_rate': 0.0011690612795614945, 'weight_decay': 0.00043753841858705576, 'batch_size': 512, 'tree_depth': 9}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:14:59,599 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.6898604923548336, 'learning_rate': 0.00047744984912704056, 'weight_decay': 0.0005691019050448373, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 11:14:59,600 - INFO - Trial 25: Train MSE=3.1364854148456027, Train R²=0.4778380734579904
2024-10-31 11:14:59,600 - INFO - Trial 25: Test MSE=2.3211182185581754, Test R²=0.6223645295415606
2024-10-31 11:14:59,600 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:14:59,602 - INFO - Trial 25 finished with value: 2.3211182185581754 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.6898604923548336, 'learning_rate': 0.00047744984912704056, 'weight_decay': 0.0005691019050448373, 'batch_size': 512, 'tree_depth': 9}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:15:52,045 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7372728873917178, 'learning_rate': 0.0022535108014760277, 'weight_decay': 0.0003385032077553584, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 11:15:52,046 - INFO - Trial 26: Train MSE=2.4276405913489207, Train R²=0.5967328889029366
2024-10-31 11:15:52,046 - INFO - Trial 26: Test MSE=2.30610728263855, Test R²=0.6221100389957428
2024-10-31 11:15:52,046 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:15:52,047 - INFO - Trial 26 finished with value: 2.30610728263855 and parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7372728873917178, 'learning_rate': 0.0022535108014760277, 'weight_decay': 0.0003385032077553584, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:17:44,741 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.6286601694493861, 'learning_rate': 0.004396937539329732, 'weight_decay': 0.0002798259131329299, 'batch_size': 256, 'tree_depth': 10}
2024-10-31 11:17:44,742 - INFO - Trial 27: Train MSE=1.5979005502802985, Train R²=0.7323710875851768
2024-10-31 11:17:44,742 - INFO - Trial 27: Test MSE=2.356054033551897, Test R²=0.6144347616604396
2024-10-31 11:17:44,742 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:17:44,744 - INFO - Trial 27 finished with value: 2.356054033551897 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.6286601694493861, 'learning_rate': 0.004396937539329732, 'weight_decay': 0.0002798259131329299, 'batch_size': 256, 'tree_depth': 10}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:21:04,611 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 512, 'dropout_rate': 0.5230064089203376, 'learning_rate': 0.0006596725490054366, 'weight_decay': 0.000676156137778361, 'batch_size': 128, 'tree_depth': 12}
2024-10-31 11:21:04,612 - INFO - Trial 28: Train MSE=0.8673022054135799, Train R²=0.8537524198847157
2024-10-31 11:21:04,612 - INFO - Trial 28: Test MSE=2.31227679337774, Test R²=0.6166965620858329
2024-10-31 11:21:04,612 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:21:04,614 - INFO - Trial 28 finished with value: 2.31227679337774 and parameters: {'hidden_layers': 2, 'hidden_units': 512, 'dropout_rate': 0.5230064089203376, 'learning_rate': 0.0006596725490054366, 'weight_decay': 0.000676156137778361, 'batch_size': 128, 'tree_depth': 12}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:24:51,460 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 128, 'dropout_rate': 0.7541459860078874, 'learning_rate': 0.00032862716767291365, 'weight_decay': 0.0004373819226777001, 'batch_size': 128, 'tree_depth': 9}
2024-10-31 11:24:51,460 - INFO - Trial 29: Train MSE=2.7289059651749477, Train R²=0.539987212313073
2024-10-31 11:24:51,460 - INFO - Trial 29: Test MSE=2.316240872655596, Test R²=0.6159315279551915
2024-10-31 11:24:51,460 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:24:51,462 - INFO - Trial 29 finished with value: 2.316240872655596 and parameters: {'hidden_layers': 2, 'hidden_units': 128, 'dropout_rate': 0.7541459860078874, 'learning_rate': 0.00032862716767291365, 'weight_decay': 0.0004373819226777001, 'batch_size': 128, 'tree_depth': 9}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:26:08,640 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.6874475535789291, 'learning_rate': 0.0015558718615319505, 'weight_decay': 0.00016028229713034036, 'batch_size': 512, 'tree_depth': 8}
2024-10-31 11:26:08,640 - INFO - Trial 30: Train MSE=2.2770060215677534, Train R²=0.6208501011133194
2024-10-31 11:26:08,640 - INFO - Trial 30: Test MSE=2.3019600936344693, Test R²=0.6252582924706596
2024-10-31 11:26:08,640 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:26:08,641 - INFO - Trial 30 finished with value: 2.3019600936344693 and parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.6874475535789291, 'learning_rate': 0.0015558718615319505, 'weight_decay': 0.00016028229713034036, 'batch_size': 512, 'tree_depth': 8}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:27:21,627 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.788489521482443, 'learning_rate': 0.0011103287472523722, 'weight_decay': 0.00043424196986502475, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 11:27:21,628 - INFO - Trial 31: Train MSE=2.794232521738325, Train R²=0.5358278219188962
2024-10-31 11:27:21,628 - INFO - Trial 31: Test MSE=2.246668134416853, Test R²=0.6345322302409581
2024-10-31 11:27:21,628 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:27:21,630 - INFO - Trial 31 finished with value: 2.246668134416853 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.788489521482443, 'learning_rate': 0.0011103287472523722, 'weight_decay': 0.00043424196986502475, 'batch_size': 512, 'tree_depth': 9}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:28:26,367 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.799776627740047, 'learning_rate': 0.0010576485585691887, 'weight_decay': 0.0005091497405742398, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 11:28:26,367 - INFO - Trial 32: Train MSE=2.5341894711766924, Train R²=0.5778851296220507
2024-10-31 11:28:26,367 - INFO - Trial 32: Test MSE=2.249178954533168, Test R²=0.6339100258690971
2024-10-31 11:28:26,367 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:28:26,368 - INFO - Trial 32 finished with value: 2.249178954533168 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.799776627740047, 'learning_rate': 0.0010576485585691887, 'weight_decay': 0.0005091497405742398, 'batch_size': 512, 'tree_depth': 10}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:29:37,848 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7632851440069397, 'learning_rate': 0.0009221495382083849, 'weight_decay': 0.0004179178177069606, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 11:29:37,848 - INFO - Trial 33: Train MSE=2.7223804678235735, Train R²=0.5476061276027134
2024-10-31 11:29:37,848 - INFO - Trial 33: Test MSE=2.2678272894450595, Test R²=0.6309200525283813
2024-10-31 11:29:37,848 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:29:37,849 - INFO - Trial 33 finished with value: 2.2678272894450595 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7632851440069397, 'learning_rate': 0.0009221495382083849, 'weight_decay': 0.0004179178177069606, 'batch_size': 512, 'tree_depth': 9}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:30:57,898 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7279072174752721, 'learning_rate': 0.0023060834022468482, 'weight_decay': 0.0007179819586585992, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 11:30:57,898 - INFO - Trial 34: Train MSE=2.04325299177851, Train R²=0.6593705671174186
2024-10-31 11:30:57,898 - INFO - Trial 34: Test MSE=2.3037314414978027, Test R²=0.6250619377408709
2024-10-31 11:30:57,898 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:30:57,899 - INFO - Trial 34 finished with value: 2.3037314414978027 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7279072174752721, 'learning_rate': 0.0023060834022468482, 'weight_decay': 0.0007179819586585992, 'batch_size': 512, 'tree_depth': 10}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:31:55,860 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 512, 'dropout_rate': 0.7750975865290651, 'learning_rate': 0.000558656759874084, 'weight_decay': 0.0005878017604618401, 'batch_size': 1024, 'tree_depth': 8}
2024-10-31 11:31:55,860 - INFO - Trial 35: Train MSE=3.9137875011989047, Train R²=0.35045704671314787
2024-10-31 11:31:55,861 - INFO - Trial 35: Test MSE=2.4249438047409058, Test R²=0.602680504322052
2024-10-31 11:31:55,861 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:31:55,862 - INFO - Trial 35 finished with value: 2.4249438047409058 and parameters: {'hidden_layers': 2, 'hidden_units': 512, 'dropout_rate': 0.7750975865290651, 'learning_rate': 0.000558656759874084, 'weight_decay': 0.0005878017604618401, 'batch_size': 1024, 'tree_depth': 8}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:33:05,471 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7112212735323835, 'learning_rate': 0.0014942044570109962, 'weight_decay': 0.0009607804690231151, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 11:33:05,471 - INFO - Trial 36: Train MSE=1.9065777233668737, Train R²=0.6823201860700335
2024-10-31 11:33:05,472 - INFO - Trial 36: Test MSE=2.2817441735948836, Test R²=0.628622659615108
2024-10-31 11:33:05,472 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:33:05,473 - INFO - Trial 36 finished with value: 2.2817441735948836 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7112212735323835, 'learning_rate': 0.0014942044570109962, 'weight_decay': 0.0009607804690231151, 'batch_size': 512, 'tree_depth': 9}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:34:00,841 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7383424482152411, 'learning_rate': 0.004166680162723684, 'weight_decay': 0.00034503700116641676, 'batch_size': 1024, 'tree_depth': 10}
2024-10-31 11:34:00,841 - INFO - Trial 37: Train MSE=2.143743736403329, Train R²=0.6441612073353359
2024-10-31 11:34:00,842 - INFO - Trial 37: Test MSE=2.296881318092346, Test R²=0.623444452881813
2024-10-31 11:34:00,842 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:34:00,844 - INFO - Trial 37 finished with value: 2.296881318092346 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7383424482152411, 'learning_rate': 0.004166680162723684, 'weight_decay': 0.00034503700116641676, 'batch_size': 1024, 'tree_depth': 10}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:38:17,614 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 1024, 'dropout_rate': 0.6520352686839861, 'learning_rate': 0.0008016084698359635, 'weight_decay': 0.0007537246197630356, 'batch_size': 128, 'tree_depth': 12}
2024-10-31 11:38:17,614 - INFO - Trial 38: Train MSE=1.1591889224946499, Train R²=0.8034418480736869
2024-10-31 11:38:17,614 - INFO - Trial 38: Test MSE=2.2841720453330447, Test R²=0.6218828154461724
2024-10-31 11:38:17,614 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:38:17,616 - INFO - Trial 38 finished with value: 2.2841720453330447 and parameters: {'hidden_layers': 2, 'hidden_units': 1024, 'dropout_rate': 0.6520352686839861, 'learning_rate': 0.0008016084698359635, 'weight_decay': 0.0007537246197630356, 'batch_size': 128, 'tree_depth': 12}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:40:20,756 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 128, 'dropout_rate': 0.39299597729541946, 'learning_rate': 0.009961571432556991, 'weight_decay': 0.0003037147605226242, 'batch_size': 256, 'tree_depth': 7}
2024-10-31 11:40:20,757 - INFO - Trial 39: Train MSE=2.1713364166872844, Train R²=0.6390329556805747
2024-10-31 11:40:20,757 - INFO - Trial 39: Test MSE=2.3199099813188826, Test R²=0.6211300321987697
2024-10-31 11:40:20,757 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:40:20,758 - INFO - Trial 39 finished with value: 2.3199099813188826 and parameters: {'hidden_layers': 3, 'hidden_units': 128, 'dropout_rate': 0.39299597729541946, 'learning_rate': 0.009961571432556991, 'weight_decay': 0.0003037147605226242, 'batch_size': 256, 'tree_depth': 7}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:41:38,390 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 512, 'dropout_rate': 0.7724153202109649, 'learning_rate': 0.0003867075486734135, 'weight_decay': 0.0004848420190983101, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 11:41:38,390 - INFO - Trial 40: Train MSE=3.4108231493404935, Train R²=0.43200680187770296
2024-10-31 11:41:38,390 - INFO - Trial 40: Test MSE=2.3492083890097484, Test R²=0.6177816305841718
2024-10-31 11:41:38,390 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:41:38,391 - INFO - Trial 40 finished with value: 2.3492083890097484 and parameters: {'hidden_layers': 2, 'hidden_units': 512, 'dropout_rate': 0.7724153202109649, 'learning_rate': 0.0003867075486734135, 'weight_decay': 0.0004848420190983101, 'batch_size': 512, 'tree_depth': 11}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:42:44,850 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.794879048251316, 'learning_rate': 0.0011395324792644625, 'weight_decay': 0.0005289703893008228, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 11:42:44,850 - INFO - Trial 41: Train MSE=2.506826792444502, Train R²=0.5827324794871467
2024-10-31 11:42:44,851 - INFO - Trial 41: Test MSE=2.241095611027309, Test R²=0.6352374127932957
2024-10-31 11:42:44,851 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:42:44,851 - INFO - Trial 41 finished with value: 2.241095611027309 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.794879048251316, 'learning_rate': 0.0011395324792644625, 'weight_decay': 0.0005289703893008228, 'batch_size': 512, 'tree_depth': 10}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:43:47,062 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7480866556078701, 'learning_rate': 0.0011653468840172477, 'weight_decay': 0.0006159415570992353, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 11:43:47,063 - INFO - Trial 42: Train MSE=2.0618036559649875, Train R²=0.6568938472441265
2024-10-31 11:43:47,063 - INFO - Trial 42: Test MSE=2.254327263150896, Test R²=0.6331884350095477
2024-10-31 11:43:47,063 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:43:47,066 - INFO - Trial 42 finished with value: 2.254327263150896 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7480866556078701, 'learning_rate': 0.0011653468840172477, 'weight_decay': 0.0006159415570992353, 'batch_size': 512, 'tree_depth': 10}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:45:00,308 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.775034945132925, 'learning_rate': 0.0017050970587857229, 'weight_decay': 0.0008379556369552464, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 11:45:00,308 - INFO - Trial 43: Train MSE=2.1017759357179915, Train R²=0.6502956130674907
2024-10-31 11:45:00,308 - INFO - Trial 43: Test MSE=2.2578552620751515, Test R²=0.6324911117553711
2024-10-31 11:45:00,308 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:45:00,310 - INFO - Trial 43 finished with value: 2.2578552620751515 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.775034945132925, 'learning_rate': 0.0017050970587857229, 'weight_decay': 0.0008379556369552464, 'batch_size': 512, 'tree_depth': 11}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:46:17,207 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7477554518809001, 'learning_rate': 0.0010303682522547824, 'weight_decay': 0.0004618140387436453, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 11:46:17,207 - INFO - Trial 44: Train MSE=2.693609254700797, Train R²=0.5523418337106705
2024-10-31 11:46:17,208 - INFO - Trial 44: Test MSE=2.2739384174346924, Test R²=0.6299543891634259
2024-10-31 11:46:17,208 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:46:17,209 - INFO - Trial 44 finished with value: 2.2739384174346924 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7477554518809001, 'learning_rate': 0.0010303682522547824, 'weight_decay': 0.0004618140387436453, 'batch_size': 512, 'tree_depth': 9}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:49:58,482 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7806528722981457, 'learning_rate': 0.0006266126671222861, 'weight_decay': 0.0005406182144821066, 'batch_size': 128, 'tree_depth': 8}
2024-10-31 11:49:58,482 - INFO - Trial 45: Train MSE=2.0744381211698055, Train R²=0.6506928077765873
2024-10-31 11:49:58,482 - INFO - Trial 45: Test MSE=2.2916233369282315, Test R²=0.6203975869076592
2024-10-31 11:49:58,482 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:49:58,485 - INFO - Trial 45 finished with value: 2.2916233369282315 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7806528722981457, 'learning_rate': 0.0006266126671222861, 'weight_decay': 0.0005406182144821066, 'batch_size': 128, 'tree_depth': 8}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:51:55,799 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7031283447674863, 'learning_rate': 0.001320750253590853, 'weight_decay': 0.0003923279828535525, 'batch_size': 256, 'tree_depth': 12}
2024-10-31 11:51:55,800 - INFO - Trial 46: Train MSE=1.658269933291844, Train R²=0.7228243744799069
2024-10-31 11:51:55,800 - INFO - Trial 46: Test MSE=2.274058963571276, Test R²=0.6283978862421853
2024-10-31 11:51:55,800 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:51:55,801 - INFO - Trial 46 finished with value: 2.274058963571276 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7031283447674863, 'learning_rate': 0.001320750253590853, 'weight_decay': 0.0003923279828535525, 'batch_size': 256, 'tree_depth': 12}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:55:24,632 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.6723072118144303, 'learning_rate': 0.002091967672497386, 'weight_decay': 0.0006824851576297837, 'batch_size': 128, 'tree_depth': 10}
2024-10-31 11:55:24,632 - INFO - Trial 47: Train MSE=1.9151576363614626, Train R²=0.6768982490258557
2024-10-31 11:55:24,633 - INFO - Trial 47: Test MSE=2.317900227648871, Test R²=0.6156764860664096
2024-10-31 11:55:24,633 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:55:24,635 - INFO - Trial 47 finished with value: 2.317900227648871 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.6723072118144303, 'learning_rate': 0.002091967672497386, 'weight_decay': 0.0006824851576297837, 'batch_size': 128, 'tree_depth': 10}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:56:23,335 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7997340254145536, 'learning_rate': 0.0009470294286310811, 'weight_decay': 0.0006042175320940876, 'batch_size': 1024, 'tree_depth': 9}
2024-10-31 11:56:23,335 - INFO - Trial 48: Train MSE=3.7925034080232893, Train R²=0.37147726331438335
2024-10-31 11:56:23,335 - INFO - Trial 48: Test MSE=2.6076061129570007, Test R²=0.5729980617761612
2024-10-31 11:56:23,336 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:56:23,337 - INFO - Trial 48 finished with value: 2.6076061129570007 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7997340254145536, 'learning_rate': 0.0009470294286310811, 'weight_decay': 0.0006042175320940876, 'batch_size': 1024, 'tree_depth': 9}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 11:57:40,173 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.300163594460496, 'learning_rate': 0.002602534700569137, 'weight_decay': 0.0005055065168557395, 'batch_size': 512, 'tree_depth': 8}
2024-10-31 11:57:40,173 - INFO - Trial 49: Train MSE=0.789101025887898, Train R²=0.8687620077814374
2024-10-31 11:57:40,173 - INFO - Trial 49: Test MSE=2.5780857631138394, Test R²=0.580175348690578
2024-10-31 11:57:40,173 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 11:57:40,175 - INFO - Trial 49 finished with value: 2.5780857631138394 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.300163594460496, 'learning_rate': 0.002602534700569137, 'weight_decay': 0.0005055065168557395, 'batch_size': 512, 'tree_depth': 8}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 12:02:24,054 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 1024, 'dropout_rate': 0.759312413641887, 'learning_rate': 0.0036792535298351622, 'weight_decay': 0.00042235577629940656, 'batch_size': 128, 'tree_depth': 10}
2024-10-31 12:02:24,054 - INFO - Trial 50: Train MSE=2.366508881960596, Train R²=0.6003656802432877
2024-10-31 12:02:24,054 - INFO - Trial 50: Test MSE=2.3227263391017914, Test R²=0.6148403435945511
2024-10-31 12:02:24,054 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:02:24,056 - INFO - Trial 50 finished with value: 2.3227263391017914 and parameters: {'hidden_layers': 3, 'hidden_units': 1024, 'dropout_rate': 0.759312413641887, 'learning_rate': 0.0036792535298351622, 'weight_decay': 0.00042235577629940656, 'batch_size': 128, 'tree_depth': 10}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 12:03:30,169 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7996886942707498, 'learning_rate': 0.0017146071261998777, 'weight_decay': 0.0004853969034599153, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 12:03:30,170 - INFO - Trial 51: Train MSE=2.384993485042027, Train R²=0.601358026266098
2024-10-31 12:03:30,170 - INFO - Trial 51: Test MSE=2.2633341380528043, Test R²=0.6314814516476223
2024-10-31 12:03:30,170 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:03:30,171 - INFO - Trial 51 finished with value: 2.2633341380528043 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7996886942707498, 'learning_rate': 0.0017146071261998777, 'weight_decay': 0.0004853969034599153, 'batch_size': 512, 'tree_depth': 10}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 12:04:41,986 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7791942786495561, 'learning_rate': 0.0010274012168256105, 'weight_decay': 0.0005159780823750042, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:04:41,987 - INFO - Trial 52: Train MSE=2.2686178428786143, Train R²=0.6218671947717667
2024-10-31 12:04:41,987 - INFO - Trial 52: Test MSE=2.2365188768931796, Test R²=0.6359049933297294
2024-10-31 12:04:41,987 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:04:41,988 - INFO - Trial 52 finished with value: 2.2365188768931796 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7791942786495561, 'learning_rate': 0.0010274012168256105, 'weight_decay': 0.0005159780823750042, 'batch_size': 512, 'tree_depth': 11}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 12:05:57,398 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7769571806505591, 'learning_rate': 0.0007694097228678055, 'weight_decay': 0.0006539524985493234, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:05:57,398 - INFO - Trial 53: Train MSE=2.4994491253580366, Train R²=0.5833631668772016
2024-10-31 12:05:57,398 - INFO - Trial 53: Test MSE=2.237601178033011, Test R²=0.6358708483832223
2024-10-31 12:05:57,398 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:05:57,400 - INFO - Trial 53 finished with value: 2.237601178033011 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7769571806505591, 'learning_rate': 0.0007694097228678055, 'weight_decay': 0.0006539524985493234, 'batch_size': 512, 'tree_depth': 11}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 12:07:10,967 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7417504772534782, 'learning_rate': 0.0005473047777788125, 'weight_decay': 0.000634005585552564, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:07:10,968 - INFO - Trial 54: Train MSE=2.5926762223243713, Train R²=0.5677983909845352
2024-10-31 12:07:10,968 - INFO - Trial 54: Test MSE=2.250788790839059, Test R²=0.6335945129394531
2024-10-31 12:07:10,969 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:07:10,971 - INFO - Trial 54 finished with value: 2.250788790839059 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7417504772534782, 'learning_rate': 0.0005473047777788125, 'weight_decay': 0.000634005585552564, 'batch_size': 512, 'tree_depth': 11}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 12:08:35,756 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7182089402448653, 'learning_rate': 0.0007578299329080534, 'weight_decay': 0.0008932810967487501, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:08:35,757 - INFO - Trial 55: Train MSE=2.0599514288561687, Train R²=0.6572482628481728
2024-10-31 12:08:35,757 - INFO - Trial 55: Test MSE=2.2936714717320035, Test R²=0.6268301010131836
2024-10-31 12:08:35,757 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:08:35,759 - INFO - Trial 55 finished with value: 2.2936714717320035 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7182089402448653, 'learning_rate': 0.0007578299329080534, 'weight_decay': 0.0008932810967487501, 'batch_size': 512, 'tree_depth': 12}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 12:12:17,661 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.4365894909362352, 'learning_rate': 0.0013321406734129269, 'weight_decay': 0.0005557231620957867, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 12:12:17,661 - INFO - Trial 56: Train MSE=0.9793844744563103, Train R²=0.8333501794508525
2024-10-31 12:12:17,661 - INFO - Trial 56: Test MSE=2.466228178569249, Test R²=0.5896018083606448
2024-10-31 12:12:17,661 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:12:17,662 - INFO - Trial 56 finished with value: 2.466228178569249 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.4365894909362352, 'learning_rate': 0.0013321406734129269, 'weight_decay': 0.0005557231620957867, 'batch_size': 128, 'tree_depth': 11}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 12:13:39,784 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7658343341126131, 'learning_rate': 0.000818496878758456, 'weight_decay': 0.0006865352797856871, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:13:39,784 - INFO - Trial 57: Train MSE=2.285946709769113, Train R²=0.6195127453122821
2024-10-31 12:13:39,785 - INFO - Trial 57: Test MSE=2.262990270342146, Test R²=0.6315644979476929
2024-10-31 12:13:39,785 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:13:39,786 - INFO - Trial 57 finished with value: 2.262990270342146 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7658343341126131, 'learning_rate': 0.000818496878758456, 'weight_decay': 0.0006865352797856871, 'batch_size': 512, 'tree_depth': 11}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 12:17:19,726 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7288940799698718, 'learning_rate': 0.0018942275681936834, 'weight_decay': 0.0007742223436075106, 'batch_size': 128, 'tree_depth': 12}
2024-10-31 12:17:19,726 - INFO - Trial 58: Train MSE=1.8604060006993157, Train R²=0.6852563034210887
2024-10-31 12:17:19,727 - INFO - Trial 58: Test MSE=2.338557792561395, Test R²=0.6126405490296227
2024-10-31 12:17:19,727 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:17:19,729 - INFO - Trial 58 finished with value: 2.338557792561395 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7288940799698718, 'learning_rate': 0.0018942275681936834, 'weight_decay': 0.0007742223436075106, 'batch_size': 128, 'tree_depth': 12}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 12:19:36,379 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 512, 'dropout_rate': 0.7812563183993487, 'learning_rate': 0.0013571890486667104, 'weight_decay': 0.0005734745596057662, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 12:19:36,380 - INFO - Trial 59: Train MSE=2.0004293684448515, Train R²=0.6652818183813777
2024-10-31 12:19:36,380 - INFO - Trial 59: Test MSE=2.260484346321651, Test R²=0.6299026012420654
2024-10-31 12:19:36,380 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:19:36,383 - INFO - Trial 59 finished with value: 2.260484346321651 and parameters: {'hidden_layers': 4, 'hidden_units': 512, 'dropout_rate': 0.7812563183993487, 'learning_rate': 0.0013571890486667104, 'weight_decay': 0.0005734745596057662, 'batch_size': 256, 'tree_depth': 11}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 12:20:56,704 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.692339906541981, 'learning_rate': 0.0004908533579705707, 'weight_decay': 0.00023857974678005383, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:20:56,704 - INFO - Trial 60: Train MSE=3.0961882642337253, Train R²=0.48348104528018404
2024-10-31 12:20:56,704 - INFO - Trial 60: Test MSE=2.2885491847991943, Test R²=0.6275088957377842
2024-10-31 12:20:56,704 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:20:56,705 - INFO - Trial 60 finished with value: 2.2885491847991943 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.692339906541981, 'learning_rate': 0.0004908533579705707, 'weight_decay': 0.00023857974678005383, 'batch_size': 512, 'tree_depth': 12}. Best is trial 11 with value: 2.2355153220040456.
2024-10-31 12:21:58,943 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7808830346676304, 'learning_rate': 0.0011419170618450815, 'weight_decay': 0.00046647362879288345, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 12:21:58,944 - INFO - Trial 61: Train MSE=2.5389423881258284, Train R²=0.5781325144427163
2024-10-31 12:21:58,944 - INFO - Trial 61: Test MSE=2.2282741921288625, Test R²=0.6372610330581665
2024-10-31 12:21:58,944 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:21:58,946 - INFO - Trial 61 finished with value: 2.2282741921288625 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7808830346676304, 'learning_rate': 0.0011419170618450815, 'weight_decay': 0.00046647362879288345, 'batch_size': 512, 'tree_depth': 9}. Best is trial 61 with value: 2.2282741921288625.
2024-10-31 12:22:49,148 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7583244209890848, 'learning_rate': 0.0009658326621539509, 'weight_decay': 0.00046250630734460686, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:22:49,148 - INFO - Trial 62: Train MSE=2.186973214149475, Train R²=0.6350415710891996
2024-10-31 12:22:49,148 - INFO - Trial 62: Test MSE=2.2456311838967458, Test R²=0.6345122115952628
2024-10-31 12:22:49,148 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:22:49,150 - INFO - Trial 62 finished with value: 2.2456311838967458 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7583244209890848, 'learning_rate': 0.0009658326621539509, 'weight_decay': 0.00046250630734460686, 'batch_size': 512, 'tree_depth': 11}. Best is trial 61 with value: 2.2282741921288625.
2024-10-31 12:23:28,004 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7596856018253849, 'learning_rate': 0.0006831142797183733, 'weight_decay': 0.0003738614335667116, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:23:28,004 - INFO - Trial 63: Train MSE=2.4610082507133484, Train R²=0.5895106984036309
2024-10-31 12:23:28,004 - INFO - Trial 63: Test MSE=2.28311174256461, Test R²=0.6283412831170219
2024-10-31 12:23:28,004 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:23:28,006 - INFO - Trial 63 finished with value: 2.28311174256461 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7596856018253849, 'learning_rate': 0.0006831142797183733, 'weight_decay': 0.0003738614335667116, 'batch_size': 512, 'tree_depth': 11}. Best is trial 61 with value: 2.2282741921288625.
2024-10-31 12:24:05,929 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.78239609490902, 'learning_rate': 0.0009384403396335634, 'weight_decay': 0.0004731619168586565, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 12:24:05,929 - INFO - Trial 64: Train MSE=2.496741669518607, Train R²=0.5830565478120532
2024-10-31 12:24:05,929 - INFO - Trial 64: Test MSE=2.2351443426949635, Test R²=0.6363831503050668
2024-10-31 12:24:05,929 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:24:05,930 - INFO - Trial 64 finished with value: 2.2351443426949635 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.78239609490902, 'learning_rate': 0.0009384403396335634, 'weight_decay': 0.0004731619168586565, 'batch_size': 512, 'tree_depth': 10}. Best is trial 61 with value: 2.2282741921288625.
2024-10-31 12:24:44,126 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7818248385810582, 'learning_rate': 0.0008892932274447738, 'weight_decay': 0.0005232491569321345, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 12:24:44,126 - INFO - Trial 65: Train MSE=2.699811007295336, Train R²=0.5515112153121403
2024-10-31 12:24:44,126 - INFO - Trial 65: Test MSE=2.2508939674922397, Test R²=0.633528334753854
2024-10-31 12:24:44,126 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:24:44,128 - INFO - Trial 65 finished with value: 2.2508939674922397 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7818248385810582, 'learning_rate': 0.0008892932274447738, 'weight_decay': 0.0005232491569321345, 'batch_size': 512, 'tree_depth': 9}. Best is trial 61 with value: 2.2282741921288625.
2024-10-31 12:26:09,272 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7366701523115173, 'learning_rate': 0.0014132535815935324, 'weight_decay': 0.00035564605784944213, 'batch_size': 128, 'tree_depth': 10}
2024-10-31 12:26:09,272 - INFO - Trial 66: Train MSE=1.7431236409715243, Train R²=0.7057189169738974
2024-10-31 12:26:09,272 - INFO - Trial 66: Test MSE=2.3344617017677853, Test R²=0.6134675656046186
2024-10-31 12:26:09,272 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:26:09,273 - INFO - Trial 66 finished with value: 2.3344617017677853 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7366701523115173, 'learning_rate': 0.0014132535815935324, 'weight_decay': 0.00035564605784944213, 'batch_size': 128, 'tree_depth': 10}. Best is trial 61 with value: 2.2282741921288625.
2024-10-31 12:26:50,221 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7823117941293422, 'learning_rate': 0.00012701512074993603, 'weight_decay': 0.0003981663088809725, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 12:26:50,221 - INFO - Trial 67: Train MSE=7.47154564516885, Train R²=-0.24636005929538182
2024-10-31 12:26:50,221 - INFO - Trial 67: Test MSE=2.6598294462476457, Test R²=0.56715042250497
2024-10-31 12:26:50,221 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:26:50,222 - INFO - Trial 67 finished with value: 2.6598294462476457 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7823117941293422, 'learning_rate': 0.00012701512074993603, 'weight_decay': 0.0003981663088809725, 'batch_size': 512, 'tree_depth': 9}. Best is trial 61 with value: 2.2282741921288625.
2024-10-31 12:27:27,804 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7483796571368411, 'learning_rate': 0.0011125518411963155, 'weight_decay': 0.0005189675078627674, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 12:27:27,804 - INFO - Trial 68: Train MSE=2.682488662855966, Train R²=0.5539196899959019
2024-10-31 12:27:27,804 - INFO - Trial 68: Test MSE=2.251838139125279, Test R²=0.6336997151374817
2024-10-31 12:27:27,804 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:27:27,805 - INFO - Trial 68 finished with value: 2.251838139125279 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7483796571368411, 'learning_rate': 0.0011125518411963155, 'weight_decay': 0.0005189675078627674, 'batch_size': 512, 'tree_depth': 9}. Best is trial 61 with value: 2.2282741921288625.
2024-10-31 12:29:15,949 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.5471618120884595, 'learning_rate': 0.0003919284314245324, 'weight_decay': 0.0004716368952190893, 'batch_size': 128, 'tree_depth': 10}
2024-10-31 12:29:15,949 - INFO - Trial 69: Train MSE=0.8838083855807781, Train R²=0.8513325532632214
2024-10-31 12:29:15,949 - INFO - Trial 69: Test MSE=2.4722712337970734, Test R²=0.5892055119786944
2024-10-31 12:29:15,949 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:29:15,950 - INFO - Trial 69 finished with value: 2.4722712337970734 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.5471618120884595, 'learning_rate': 0.0003919284314245324, 'weight_decay': 0.0004716368952190893, 'batch_size': 128, 'tree_depth': 10}. Best is trial 61 with value: 2.2282741921288625.
2024-10-31 12:29:46,647 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7694625311514001, 'learning_rate': 0.0007321654670778624, 'weight_decay': 0.0006516271611789068, 'batch_size': 1024, 'tree_depth': 10}
2024-10-31 12:29:46,647 - INFO - Trial 70: Train MSE=3.311778800828116, Train R²=0.44968987362725393
2024-10-31 12:29:46,647 - INFO - Trial 70: Test MSE=2.271475315093994, Test R²=0.6277419626712799
2024-10-31 12:29:46,647 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:29:46,648 - INFO - Trial 70 finished with value: 2.271475315093994 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7694625311514001, 'learning_rate': 0.0007321654670778624, 'weight_decay': 0.0006516271611789068, 'batch_size': 1024, 'tree_depth': 10}. Best is trial 61 with value: 2.2282741921288625.
2024-10-31 12:30:16,581 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7880710371044848, 'learning_rate': 0.0010171677565096414, 'weight_decay': 0.00047269080469750465, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:30:16,581 - INFO - Trial 71: Train MSE=2.4023787464414323, Train R²=0.5988881417683193
2024-10-31 12:30:16,581 - INFO - Trial 71: Test MSE=2.2171244961874828, Test R²=0.6391094752720424
2024-10-31 12:30:16,581 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:30:16,582 - INFO - Trial 71 finished with value: 2.2171244961874828 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7880710371044848, 'learning_rate': 0.0010171677565096414, 'weight_decay': 0.00047269080469750465, 'batch_size': 512, 'tree_depth': 11}. Best is trial 71 with value: 2.2171244961874828.
2024-10-31 12:30:54,244 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7882593756164985, 'learning_rate': 0.0015451650590928678, 'weight_decay': 0.00031769887426425793, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:30:54,244 - INFO - Trial 72: Train MSE=2.1639454449926103, Train R²=0.6394598803349903
2024-10-31 12:30:54,244 - INFO - Trial 72: Test MSE=2.2163165637425015, Test R²=0.6391593558447701
2024-10-31 12:30:54,245 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:30:54,246 - INFO - Trial 72 finished with value: 2.2163165637425015 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7882593756164985, 'learning_rate': 0.0015451650590928678, 'weight_decay': 0.00031769887426425793, 'batch_size': 512, 'tree_depth': 11}. Best is trial 72 with value: 2.2163165637425015.
2024-10-31 12:31:32,266 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7840372619538002, 'learning_rate': 0.0015225164952580284, 'weight_decay': 0.00032050025340631106, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:31:32,266 - INFO - Trial 73: Train MSE=2.2030075703348433, Train R²=0.6313656185354505
2024-10-31 12:31:32,266 - INFO - Trial 73: Test MSE=2.245856319155012, Test R²=0.6343412228993007
2024-10-31 12:31:32,266 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:31:32,268 - INFO - Trial 73 finished with value: 2.245856319155012 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7840372619538002, 'learning_rate': 0.0015225164952580284, 'weight_decay': 0.00032050025340631106, 'batch_size': 512, 'tree_depth': 11}. Best is trial 72 with value: 2.2163165637425015.
2024-10-31 12:32:07,607 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7612692732128806, 'learning_rate': 0.00083559650649334, 'weight_decay': 0.0002536483551213401, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:32:07,607 - INFO - Trial 74: Train MSE=2.3028258851596286, Train R²=0.6165211605174201
2024-10-31 12:32:07,608 - INFO - Trial 74: Test MSE=2.234851700919015, Test R²=0.6363084486552647
2024-10-31 12:32:07,608 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:32:07,609 - INFO - Trial 74 finished with value: 2.234851700919015 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7612692732128806, 'learning_rate': 0.00083559650649334, 'weight_decay': 0.0002536483551213401, 'batch_size': 512, 'tree_depth': 11}. Best is trial 72 with value: 2.2163165637425015.
2024-10-31 12:32:45,979 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7268304698410085, 'learning_rate': 0.0008331985501202144, 'weight_decay': 0.00023689091429637287, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:32:45,979 - INFO - Trial 75: Train MSE=2.0734300145081113, Train R²=0.6543323482785907
2024-10-31 12:32:45,980 - INFO - Trial 75: Test MSE=2.263540267944336, Test R²=0.6314776710101536
2024-10-31 12:32:45,980 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:32:45,981 - INFO - Trial 75 finished with value: 2.263540267944336 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7268304698410085, 'learning_rate': 0.0008331985501202144, 'weight_decay': 0.00023689091429637287, 'batch_size': 512, 'tree_depth': 11}. Best is trial 72 with value: 2.2163165637425015.
2024-10-31 12:33:24,299 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7654278397439568, 'learning_rate': 0.0005941399677981248, 'weight_decay': 0.00019339084963380354, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:33:24,300 - INFO - Trial 76: Train MSE=2.6362008452415466, Train R²=0.5616854982716697
2024-10-31 12:33:24,300 - INFO - Trial 76: Test MSE=2.224835923739842, Test R²=0.6378520131111145
2024-10-31 12:33:24,300 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:33:24,301 - INFO - Trial 76 finished with value: 2.224835923739842 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7654278397439568, 'learning_rate': 0.0005941399677981248, 'weight_decay': 0.00019339084963380354, 'batch_size': 512, 'tree_depth': 11}. Best is trial 72 with value: 2.2163165637425015.
2024-10-31 12:34:01,913 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6042374933136334, 'learning_rate': 0.0005609204837060557, 'weight_decay': 0.00018247213800771413, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:34:01,913 - INFO - Trial 77: Train MSE=1.7058555952140264, Train R²=0.7153759854180473
2024-10-31 12:34:01,913 - INFO - Trial 77: Test MSE=2.3507814747946605, Test R²=0.6174513357026237
2024-10-31 12:34:01,914 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:34:01,915 - INFO - Trial 77 finished with value: 2.3507814747946605 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6042374933136334, 'learning_rate': 0.0005609204837060557, 'weight_decay': 0.00018247213800771413, 'batch_size': 512, 'tree_depth': 11}. Best is trial 72 with value: 2.2163165637425015.
2024-10-31 12:34:43,431 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7537454167089829, 'learning_rate': 0.0009866804882267045, 'weight_decay': 0.0002695040511068107, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:34:43,431 - INFO - Trial 78: Train MSE=1.8983257498059953, Train R²=0.684381365776062
2024-10-31 12:34:43,431 - INFO - Trial 78: Test MSE=2.247733507837568, Test R²=0.6341649975095477
2024-10-31 12:34:43,431 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:34:43,432 - INFO - Trial 78 finished with value: 2.247733507837568 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7537454167089829, 'learning_rate': 0.0009866804882267045, 'weight_decay': 0.0002695040511068107, 'batch_size': 512, 'tree_depth': 11}. Best is trial 72 with value: 2.2163165637425015.
2024-10-31 12:35:20,815 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7637021446210694, 'learning_rate': 0.0019056774251893852, 'weight_decay': 0.00013738712571606412, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:35:20,815 - INFO - Trial 79: Train MSE=1.9024115800857544, Train R²=0.6831586807966232
2024-10-31 12:35:20,815 - INFO - Trial 79: Test MSE=2.23751814024789, Test R²=0.6355492642947606
2024-10-31 12:35:20,815 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:35:20,816 - INFO - Trial 79 finished with value: 2.23751814024789 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7637021446210694, 'learning_rate': 0.0019056774251893852, 'weight_decay': 0.00013738712571606412, 'batch_size': 512, 'tree_depth': 11}. Best is trial 72 with value: 2.2163165637425015.
2024-10-31 12:36:01,334 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7032502152799457, 'learning_rate': 0.000620796283336584, 'weight_decay': 0.000195385444761399, 'batch_size': 512, 'tree_depth': 6}
2024-10-31 12:36:01,334 - INFO - Trial 80: Train MSE=3.0774715627942766, Train R²=0.48808735821928295
2024-10-31 12:36:01,334 - INFO - Trial 80: Test MSE=2.438591684613909, Test R²=0.6029768330710275
2024-10-31 12:36:01,334 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:36:01,334 - INFO - Trial 80 finished with value: 2.438591684613909 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7032502152799457, 'learning_rate': 0.000620796283336584, 'weight_decay': 0.000195385444761399, 'batch_size': 512, 'tree_depth': 6}. Best is trial 72 with value: 2.2163165637425015.
2024-10-31 12:36:39,339 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7663981502256131, 'learning_rate': 0.0025303471267687926, 'weight_decay': 0.00014871601321006124, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:36:39,339 - INFO - Trial 81: Train MSE=1.8359528992857252, Train R²=0.6941531811441694
2024-10-31 12:36:39,339 - INFO - Trial 81: Test MSE=2.278803927557809, Test R²=0.6290351322719029
2024-10-31 12:36:39,339 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:36:39,340 - INFO - Trial 81 finished with value: 2.278803927557809 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7663981502256131, 'learning_rate': 0.0025303471267687926, 'weight_decay': 0.00014871601321006124, 'batch_size': 512, 'tree_depth': 11}. Best is trial 72 with value: 2.2163165637425015.
2024-10-31 12:37:17,150 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902126574930642, 'learning_rate': 0.0018446526967683709, 'weight_decay': 0.00013281624598592663, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:37:17,151 - INFO - Trial 82: Train MSE=2.1491001418658664, Train R²=0.6421542593411037
2024-10-31 12:37:17,151 - INFO - Trial 82: Test MSE=2.225222042628697, Test R²=0.6376107590539115
2024-10-31 12:37:17,151 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:37:17,152 - INFO - Trial 82 finished with value: 2.225222042628697 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902126574930642, 'learning_rate': 0.0018446526967683709, 'weight_decay': 0.00013281624598592663, 'batch_size': 512, 'tree_depth': 11}. Best is trial 72 with value: 2.2163165637425015.
2024-10-31 12:37:54,945 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7839399723367159, 'learning_rate': 0.0016076068982865672, 'weight_decay': 0.00010300660010200377, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:37:54,945 - INFO - Trial 83: Train MSE=2.1803304638181413, Train R²=0.6366606972047261
2024-10-31 12:37:54,945 - INFO - Trial 83: Test MSE=2.243169443947928, Test R²=0.6348466277122498
2024-10-31 12:37:54,945 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:37:54,947 - INFO - Trial 83 finished with value: 2.243169443947928 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7839399723367159, 'learning_rate': 0.0016076068982865672, 'weight_decay': 0.00010300660010200377, 'batch_size': 512, 'tree_depth': 11}. Best is trial 72 with value: 2.2163165637425015.
2024-10-31 12:38:33,365 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7913020385182069, 'learning_rate': 0.0009081949606264948, 'weight_decay': 0.0002171135466211596, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:38:33,365 - INFO - Trial 84: Train MSE=2.5266106724739075, Train R²=0.5799072938305991
2024-10-31 12:38:33,365 - INFO - Trial 84: Test MSE=2.213188546044486, Test R²=0.6397732836859567
2024-10-31 12:38:33,365 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:38:33,366 - INFO - Trial 84 finished with value: 2.213188546044486 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7913020385182069, 'learning_rate': 0.0009081949606264948, 'weight_decay': 0.0002171135466211596, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:39:10,849 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902569126213086, 'learning_rate': 0.0012610940196402778, 'weight_decay': 0.00021984951667613792, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:39:10,849 - INFO - Trial 85: Train MSE=2.3177719243935178, Train R²=0.6136146805116108
2024-10-31 12:39:10,849 - INFO - Trial 85: Test MSE=2.231537784848894, Test R²=0.636867914881025
2024-10-31 12:39:10,849 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:39:10,851 - INFO - Trial 85 finished with value: 2.231537784848894 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902569126213086, 'learning_rate': 0.0012610940196402778, 'weight_decay': 0.00021984951667613792, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:39:48,566 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7916405536296015, 'learning_rate': 0.0008732377605253231, 'weight_decay': 0.00025924184964589775, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:39:48,566 - INFO - Trial 86: Train MSE=2.5500742622784207, Train R²=0.5757716596126556
2024-10-31 12:39:48,566 - INFO - Trial 86: Test MSE=2.2494213581085205, Test R²=0.6338679960795811
2024-10-31 12:39:48,566 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:39:48,567 - INFO - Trial 86 finished with value: 2.2494213581085205 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7916405536296015, 'learning_rate': 0.0008732377605253231, 'weight_decay': 0.00025924184964589775, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:40:26,160 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7428722355279115, 'learning_rate': 0.0012321708968920943, 'weight_decay': 0.00021829599810015512, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:40:26,160 - INFO - Trial 87: Train MSE=1.9050962626934052, Train R²=0.6829232083899635
2024-10-31 12:40:26,160 - INFO - Trial 87: Test MSE=2.2345377717699324, Test R²=0.6362914528165545
2024-10-31 12:40:26,160 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:40:26,162 - INFO - Trial 87 finished with value: 2.2345377717699324 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7428722355279115, 'learning_rate': 0.0012321708968920943, 'weight_decay': 0.00021829599810015512, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:41:03,938 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7392329255639313, 'learning_rate': 0.0032357042274194924, 'weight_decay': 0.0002140490030402415, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:41:03,938 - INFO - Trial 88: Train MSE=1.6692817424024855, Train R²=0.722245774098805
2024-10-31 12:41:03,938 - INFO - Trial 88: Test MSE=2.255857195172991, Test R²=0.6329101834978376
2024-10-31 12:41:03,938 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:41:03,939 - INFO - Trial 88 finished with value: 2.255857195172991 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7392329255639313, 'learning_rate': 0.0032357042274194924, 'weight_decay': 0.0002140490030402415, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:41:54,230 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7472206627965422, 'learning_rate': 0.0012032633139622032, 'weight_decay': 0.000215492727362648, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:41:54,230 - INFO - Trial 89: Train MSE=1.6193672205720628, Train R²=0.7306743391922542
2024-10-31 12:41:54,230 - INFO - Trial 89: Test MSE=2.280296802520752, Test R²=0.6286370158195496
2024-10-31 12:41:54,230 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:41:54,231 - INFO - Trial 89 finished with value: 2.280296802520752 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7472206627965422, 'learning_rate': 0.0012032633139622032, 'weight_decay': 0.000215492727362648, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:42:31,596 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.3595787637642466, 'learning_rate': 0.0012412196172423796, 'weight_decay': 0.00019234716313312845, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:42:31,596 - INFO - Trial 90: Train MSE=0.687256898198809, Train R²=0.8854216358491352
2024-10-31 12:42:31,596 - INFO - Trial 90: Test MSE=2.477945395878383, Test R²=0.59663473708289
2024-10-31 12:42:31,596 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:42:31,597 - INFO - Trial 90 finished with value: 2.477945395878383 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.3595787637642466, 'learning_rate': 0.0012412196172423796, 'weight_decay': 0.00019234716313312845, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:43:09,843 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.770042768440143, 'learning_rate': 0.001452559026162681, 'weight_decay': 0.00011288451233947129, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:43:09,843 - INFO - Trial 91: Train MSE=2.071725232260568, Train R²=0.6553695436034884
2024-10-31 12:43:09,843 - INFO - Trial 91: Test MSE=2.24980936731611, Test R²=0.6338279587881905
2024-10-31 12:43:09,843 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:43:09,845 - INFO - Trial 91 finished with value: 2.24980936731611 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.770042768440143, 'learning_rate': 0.001452559026162681, 'weight_decay': 0.00011288451233947129, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:43:48,086 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7992134078622899, 'learning_rate': 0.0006797178840572084, 'weight_decay': 0.00023220918251005626, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:43:48,086 - INFO - Trial 92: Train MSE=2.8010392444474355, Train R²=0.5331871637276241
2024-10-31 12:43:48,086 - INFO - Trial 92: Test MSE=2.2374352727617537, Test R²=0.635870133127485
2024-10-31 12:43:48,086 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:43:48,087 - INFO - Trial 92 finished with value: 2.2374352727617537 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7992134078622899, 'learning_rate': 0.0006797178840572084, 'weight_decay': 0.00023220918251005626, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:44:25,668 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7317894673654113, 'learning_rate': 0.001774200000013902, 'weight_decay': 0.00016968875113077746, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:44:25,668 - INFO - Trial 93: Train MSE=1.7157127516610282, Train R²=0.7139236458710262
2024-10-31 12:44:25,668 - INFO - Trial 93: Test MSE=2.2736791031701222, Test R²=0.6298991782324654
2024-10-31 12:44:25,668 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:44:25,669 - INFO - Trial 93 finished with value: 2.2736791031701222 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7317894673654113, 'learning_rate': 0.001774200000013902, 'weight_decay': 0.00016968875113077746, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:45:03,567 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7881215452435033, 'learning_rate': 0.0010413226792592252, 'weight_decay': 0.0002540503453706361, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:45:03,567 - INFO - Trial 94: Train MSE=2.3804031227316176, Train R²=0.6038893397365298
2024-10-31 12:45:03,567 - INFO - Trial 94: Test MSE=2.226370334625244, Test R²=0.6376663105828422
2024-10-31 12:45:03,567 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:45:03,569 - INFO - Trial 94 finished with value: 2.226370334625244 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7881215452435033, 'learning_rate': 0.0010413226792592252, 'weight_decay': 0.0002540503453706361, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:45:57,433 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7552712625061822, 'learning_rate': 0.0010966566458346406, 'weight_decay': 0.0002488991107673045, 'batch_size': 256, 'tree_depth': 12}
2024-10-31 12:45:57,433 - INFO - Trial 95: Train MSE=1.8249145618506841, Train R²=0.6944843743528638
2024-10-31 12:45:57,433 - INFO - Trial 95: Test MSE=2.2674316593578885, Test R²=0.6290941749300275
2024-10-31 12:45:57,433 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:45:57,434 - INFO - Trial 95 finished with value: 2.2674316593578885 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7552712625061822, 'learning_rate': 0.0010966566458346406, 'weight_decay': 0.0002488991107673045, 'batch_size': 256, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:46:34,875 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.790895878784681, 'learning_rate': 0.007031019536735402, 'weight_decay': 0.00028776831895242907, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:46:34,875 - INFO - Trial 96: Train MSE=2.021463304758072, Train R²=0.6632984280586243
2024-10-31 12:46:34,875 - INFO - Trial 96: Test MSE=2.231043883732387, Test R²=0.6367899860654559
2024-10-31 12:46:34,875 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:46:34,877 - INFO - Trial 96 finished with value: 2.231043883732387 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.790895878784681, 'learning_rate': 0.007031019536735402, 'weight_decay': 0.00028776831895242907, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:47:13,306 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7891312144966653, 'learning_rate': 0.00026901085266717333, 'weight_decay': 0.0002875177092546549, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:47:13,306 - INFO - Trial 97: Train MSE=4.3816390718732565, Train R²=0.2702383292572839
2024-10-31 12:47:13,307 - INFO - Trial 97: Test MSE=2.284793036324637, Test R²=0.6280823349952698
2024-10-31 12:47:13,307 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:47:13,308 - INFO - Trial 97 finished with value: 2.284793036324637 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7891312144966653, 'learning_rate': 0.00026901085266717333, 'weight_decay': 0.0002875177092546549, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:47:50,701 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7926437813499658, 'learning_rate': 0.0021553061747470897, 'weight_decay': 0.000299686777136311, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:47:50,701 - INFO - Trial 98: Train MSE=2.1462277386869704, Train R²=0.6424352590526853
2024-10-31 12:47:50,701 - INFO - Trial 98: Test MSE=2.2178172724587575, Test R²=0.6389721802302769
2024-10-31 12:47:50,701 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:47:50,702 - INFO - Trial 98 finished with value: 2.2178172724587575 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7926437813499658, 'learning_rate': 0.0021553061747470897, 'weight_decay': 0.000299686777136311, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:48:30,331 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 512, 'dropout_rate': 0.7923103167841181, 'learning_rate': 0.005121128934854074, 'weight_decay': 0.00030619963966621274, 'batch_size': 1024, 'tree_depth': 12}
2024-10-31 12:48:30,332 - INFO - Trial 99: Train MSE=2.0315924116543362, Train R²=0.6624678713934762
2024-10-31 12:48:30,332 - INFO - Trial 99: Test MSE=2.2569390535354614, Test R²=0.6299253106117249
2024-10-31 12:48:30,332 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:48:30,333 - INFO - Trial 99 finished with value: 2.2569390535354614 and parameters: {'hidden_layers': 2, 'hidden_units': 512, 'dropout_rate': 0.7923103167841181, 'learning_rate': 0.005121128934854074, 'weight_decay': 0.00030619963966621274, 'batch_size': 1024, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:49:08,026 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.48768204837076784, 'learning_rate': 0.007148913160599132, 'weight_decay': 0.0001316715971944612, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:49:08,026 - INFO - Trial 100: Train MSE=0.8566437661647797, Train R²=0.8573289620024818
2024-10-31 12:49:08,026 - INFO - Trial 100: Test MSE=2.3428219727107455, Test R²=0.6185983504567828
2024-10-31 12:49:08,026 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:49:08,028 - INFO - Trial 100 finished with value: 2.3428219727107455 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.48768204837076784, 'learning_rate': 0.007148913160599132, 'weight_decay': 0.0001316715971944612, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:49:45,538 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7738453196189283, 'learning_rate': 0.007258123000549299, 'weight_decay': 0.00032445241862073424, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:49:45,538 - INFO - Trial 101: Train MSE=2.037572992699487, Train R²=0.6606542319059372
2024-10-31 12:49:45,538 - INFO - Trial 101: Test MSE=2.2169771875653947, Test R²=0.6392065712383815
2024-10-31 12:49:45,538 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:49:45,539 - INFO - Trial 101 finished with value: 2.2169771875653947 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7738453196189283, 'learning_rate': 0.007258123000549299, 'weight_decay': 0.00032445241862073424, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:50:23,264 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7733077756151296, 'learning_rate': 0.006667140287859847, 'weight_decay': 0.00032729674579349183, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:50:23,264 - INFO - Trial 102: Train MSE=1.9929803780147008, Train R²=0.6683998129197529
2024-10-31 12:50:23,265 - INFO - Trial 102: Test MSE=2.233080880982535, Test R²=0.6366152933665684
2024-10-31 12:50:23,265 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:50:23,266 - INFO - Trial 102 finished with value: 2.233080880982535 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7733077756151296, 'learning_rate': 0.006667140287859847, 'weight_decay': 0.00032729674579349183, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:51:01,335 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999611341366736, 'learning_rate': 0.00834063842362042, 'weight_decay': 0.00028254772774998307, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:51:01,335 - INFO - Trial 103: Train MSE=2.1031093639986858, Train R²=0.6503403655120304
2024-10-31 12:51:01,335 - INFO - Trial 103: Test MSE=2.2454536982945035, Test R²=0.6344410351344517
2024-10-31 12:51:01,335 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:51:01,337 - INFO - Trial 103 finished with value: 2.2454536982945035 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999611341366736, 'learning_rate': 0.00834063842362042, 'weight_decay': 0.00028254772774998307, 'batch_size': 512, 'tree_depth': 12}. Best is trial 84 with value: 2.213188546044486.
2024-10-31 12:51:38,599 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.789658862808241, 'learning_rate': 0.00990265583542275, 'weight_decay': 0.0002666493527551526, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:51:38,599 - INFO - Trial 104: Train MSE=2.091930615050452, Train R²=0.6525907410042626
2024-10-31 12:51:38,599 - INFO - Trial 104: Test MSE=2.1955713714872087, Test R²=0.6425435798508781
2024-10-31 12:51:38,599 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:51:38,601 - INFO - Trial 104 finished with value: 2.1955713714872087 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.789658862808241, 'learning_rate': 0.00990265583542275, 'weight_decay': 0.0002666493527551526, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 12:52:16,319 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7735064687399877, 'learning_rate': 0.008960773322419938, 'weight_decay': 0.0002652621971492366, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:52:16,319 - INFO - Trial 105: Train MSE=1.9924260931355613, Train R²=0.6692639057125364
2024-10-31 12:52:16,319 - INFO - Trial 105: Test MSE=2.270797150475638, Test R²=0.6301435487610954
2024-10-31 12:52:16,319 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:52:16,321 - INFO - Trial 105 finished with value: 2.270797150475638 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7735064687399877, 'learning_rate': 0.008960773322419938, 'weight_decay': 0.0002652621971492366, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 12:52:56,667 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7880589348865287, 'learning_rate': 0.00855669040634178, 'weight_decay': 0.000296999817776088, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:52:56,667 - INFO - Trial 106: Train MSE=2.1022469997406006, Train R²=0.6507334006684167
2024-10-31 12:52:56,667 - INFO - Trial 106: Test MSE=2.2745990412575856, Test R²=0.6297455430030823
2024-10-31 12:52:56,667 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:52:56,669 - INFO - Trial 106 finished with value: 2.2745990412575856 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7880589348865287, 'learning_rate': 0.00855669040634178, 'weight_decay': 0.000296999817776088, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 12:53:33,863 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7702094156168354, 'learning_rate': 0.005926966114679636, 'weight_decay': 0.0002487228385319221, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:53:33,863 - INFO - Trial 107: Train MSE=1.9245623648166656, Train R²=0.6794532239437103
2024-10-31 12:53:33,864 - INFO - Trial 107: Test MSE=2.2387355736323764, Test R²=0.6355870621544975
2024-10-31 12:53:33,864 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:53:33,865 - INFO - Trial 107 finished with value: 2.2387355736323764 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7702094156168354, 'learning_rate': 0.005926966114679636, 'weight_decay': 0.0002487228385319221, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 12:54:13,147 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7543146074128683, 'learning_rate': 0.004703312167052124, 'weight_decay': 0.0002724786262363254, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:54:13,147 - INFO - Trial 108: Train MSE=1.8147410537515367, Train R²=0.6984248289040157
2024-10-31 12:54:13,147 - INFO - Trial 108: Test MSE=2.266191669872829, Test R²=0.6312836578914097
2024-10-31 12:54:13,147 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:54:13,148 - INFO - Trial 108 finished with value: 2.266191669872829 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7543146074128683, 'learning_rate': 0.004703312167052124, 'weight_decay': 0.0002724786262363254, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 12:55:05,044 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7176152361177842, 'learning_rate': 0.007642904566740153, 'weight_decay': 0.0003392500426400662, 'batch_size': 256, 'tree_depth': 12}
2024-10-31 12:55:05,044 - INFO - Trial 109: Train MSE=2.0327469131776263, Train R²=0.6600291909916061
2024-10-31 12:55:05,045 - INFO - Trial 109: Test MSE=2.2868993963514055, Test R²=0.6260071780000415
2024-10-31 12:55:05,045 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:55:05,046 - INFO - Trial 109 finished with value: 2.2868993963514055 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7176152361177842, 'learning_rate': 0.007642904566740153, 'weight_decay': 0.0003392500426400662, 'batch_size': 256, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 12:55:37,455 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7773236549931103, 'learning_rate': 0.009585026006082313, 'weight_decay': 0.00029608963806618895, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:55:37,455 - INFO - Trial 110: Train MSE=2.1064813009330203, Train R²=0.6501867302826473
2024-10-31 12:55:37,455 - INFO - Trial 110: Test MSE=2.226897750582014, Test R²=0.6375103337424142
2024-10-31 12:55:37,455 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:55:37,456 - INFO - Trial 110 finished with value: 2.226897750582014 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7773236549931103, 'learning_rate': 0.009585026006082313, 'weight_decay': 0.00029608963806618895, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 12:56:13,320 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7754918895132855, 'learning_rate': 0.009912480864949622, 'weight_decay': 0.0002934342302308339, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:56:13,321 - INFO - Trial 111: Train MSE=2.144543847867421, Train R²=0.6426752784422466
2024-10-31 12:56:13,321 - INFO - Trial 111: Test MSE=2.3438010215759277, Test R²=0.6184797286987305
2024-10-31 12:56:13,321 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:56:13,322 - INFO - Trial 111 finished with value: 2.3438010215759277 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7754918895132855, 'learning_rate': 0.009912480864949622, 'weight_decay': 0.0002934342302308339, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 12:56:43,520 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7620832715012865, 'learning_rate': 0.006448262386417974, 'weight_decay': 0.00031368017084115046, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:56:43,521 - INFO - Trial 112: Train MSE=2.0344112856047496, Train R²=0.6597032483134951
2024-10-31 12:56:43,521 - INFO - Trial 112: Test MSE=2.2626664468220303, Test R²=0.6316272020339966
2024-10-31 12:56:43,521 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:56:43,522 - INFO - Trial 112 finished with value: 2.2626664468220303 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7620832715012865, 'learning_rate': 0.006448262386417974, 'weight_decay': 0.00031368017084115046, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 12:57:14,511 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7902154093966266, 'learning_rate': 0.009305131421014731, 'weight_decay': 0.0003285561769793049, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 12:57:14,512 - INFO - Trial 113: Train MSE=2.155809611082077, Train R²=0.6412867626973561
2024-10-31 12:57:14,512 - INFO - Trial 113: Test MSE=2.2543925046920776, Test R²=0.6331587348665509
2024-10-31 12:57:14,512 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:57:14,514 - INFO - Trial 113 finished with value: 2.2543925046920776 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7902154093966266, 'learning_rate': 0.009305131421014731, 'weight_decay': 0.0003285561769793049, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 12:57:46,545 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7791188710438731, 'learning_rate': 0.007968262828057808, 'weight_decay': 0.0003566820817526422, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:57:46,545 - INFO - Trial 114: Train MSE=2.134201560701643, Train R²=0.6453169669423785
2024-10-31 12:57:46,545 - INFO - Trial 114: Test MSE=2.2298197746276855, Test R²=0.6369995219366891
2024-10-31 12:57:46,545 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:57:46,546 - INFO - Trial 114 finished with value: 2.2298197746276855 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7791188710438731, 'learning_rate': 0.007968262828057808, 'weight_decay': 0.0003566820817526422, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 12:58:17,806 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7754762432381859, 'learning_rate': 0.0022528957644911704, 'weight_decay': 0.00036689318189098835, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:58:17,807 - INFO - Trial 115: Train MSE=2.436208128929138, Train R²=0.5951626896858215
2024-10-31 12:58:17,807 - INFO - Trial 115: Test MSE=2.253809486116682, Test R²=0.6331319553511483
2024-10-31 12:58:17,807 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:58:17,808 - INFO - Trial 115 finished with value: 2.253809486116682 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7754762432381859, 'learning_rate': 0.0022528957644911704, 'weight_decay': 0.00036689318189098835, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 12:58:48,929 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7493285287521811, 'learning_rate': 0.006247066447370456, 'weight_decay': 0.00035672838318597026, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:58:48,929 - INFO - Trial 116: Train MSE=2.0045641660690308, Train R²=0.6659790447780064
2024-10-31 12:58:48,929 - INFO - Trial 116: Test MSE=2.225678188460214, Test R²=0.6379051038197109
2024-10-31 12:58:48,929 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:58:48,930 - INFO - Trial 116 finished with value: 2.225678188460214 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7493285287521811, 'learning_rate': 0.006247066447370456, 'weight_decay': 0.00035672838318597026, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 12:59:19,649 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7427732492680498, 'learning_rate': 0.005647832640373059, 'weight_decay': 0.00038807680644849094, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:59:19,649 - INFO - Trial 117: Train MSE=2.0069114480699812, Train R²=0.6659972987004689
2024-10-31 12:59:19,649 - INFO - Trial 117: Test MSE=2.248116765703474, Test R²=0.6340416499546596
2024-10-31 12:59:19,649 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:59:19,651 - INFO - Trial 117 finished with value: 2.248116765703474 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7427732492680498, 'learning_rate': 0.005647832640373059, 'weight_decay': 0.00038807680644849094, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 12:59:50,125 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7536948899182667, 'learning_rate': 0.003943504681722837, 'weight_decay': 0.00019820129819858178, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 12:59:50,125 - INFO - Trial 118: Train MSE=2.009753261293684, Train R²=0.6656611285039357
2024-10-31 12:59:50,125 - INFO - Trial 118: Test MSE=2.2655433927263533, Test R²=0.631360479763576
2024-10-31 12:59:50,125 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 12:59:50,127 - INFO - Trial 118 finished with value: 2.2655433927263533 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7536948899182667, 'learning_rate': 0.003943504681722837, 'weight_decay': 0.00019820129819858178, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:00:14,963 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.4598585163623651, 'learning_rate': 0.006157740164154586, 'weight_decay': 0.0004163537628291068, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 13:00:14,963 - INFO - Trial 119: Train MSE=0.9894988877432687, Train R²=0.8357749027865273
2024-10-31 13:00:14,964 - INFO - Trial 119: Test MSE=2.437063753604889, Test R²=0.6005831211805344
2024-10-31 13:00:14,964 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:00:14,965 - INFO - Trial 119 finished with value: 2.437063753604889 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.4598585163623651, 'learning_rate': 0.006157740164154586, 'weight_decay': 0.0004163537628291068, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:00:46,063 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7628384392875951, 'learning_rate': 0.0020459636709819432, 'weight_decay': 0.00031013225140655195, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:00:46,063 - INFO - Trial 120: Train MSE=2.3916634491511752, Train R²=0.6023264974355698
2024-10-31 13:00:46,063 - INFO - Trial 120: Test MSE=2.264127152306693, Test R²=0.6315250056130546
2024-10-31 13:00:46,063 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:00:46,064 - INFO - Trial 120 finished with value: 2.264127152306693 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7628384392875951, 'learning_rate': 0.0020459636709819432, 'weight_decay': 0.00031013225140655195, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:01:18,235 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7814164931090185, 'learning_rate': 0.007746106868087547, 'weight_decay': 0.0003542162773782494, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:01:18,235 - INFO - Trial 121: Train MSE=2.1749213891369954, Train R²=0.638607599905559
2024-10-31 13:01:18,235 - INFO - Trial 121: Test MSE=2.242235933031355, Test R²=0.6350383247647967
2024-10-31 13:01:18,235 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:01:18,236 - INFO - Trial 121 finished with value: 2.242235933031355 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7814164931090185, 'learning_rate': 0.007746106868087547, 'weight_decay': 0.0003542162773782494, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:01:53,221 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7697233625486483, 'learning_rate': 0.0080030280444143, 'weight_decay': 0.0003458388525487768, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:01:53,221 - INFO - Trial 122: Train MSE=2.0415627360343933, Train R²=0.6606235823460987
2024-10-31 13:01:53,221 - INFO - Trial 122: Test MSE=2.294417585645403, Test R²=0.6264382771083287
2024-10-31 13:01:53,221 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:01:53,222 - INFO - Trial 122 finished with value: 2.294417585645403 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7697233625486483, 'learning_rate': 0.0080030280444143, 'weight_decay': 0.0003458388525487768, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:02:25,102 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.799518903961071, 'learning_rate': 0.006880376292735146, 'weight_decay': 0.0002419867783961952, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:02:25,102 - INFO - Trial 123: Train MSE=2.1014622918197086, Train R²=0.6498421515737262
2024-10-31 13:02:25,102 - INFO - Trial 123: Test MSE=2.245457649230957, Test R²=0.6343173044068473
2024-10-31 13:02:25,102 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:02:25,103 - INFO - Trial 123 finished with value: 2.245457649230957 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.799518903961071, 'learning_rate': 0.006880376292735146, 'weight_decay': 0.0002419867783961952, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:02:56,804 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7870326151985101, 'learning_rate': 0.009663986712612056, 'weight_decay': 0.0003300233967728466, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:02:56,804 - INFO - Trial 124: Train MSE=2.214871270315988, Train R²=0.6317119193928582
2024-10-31 13:02:56,804 - INFO - Trial 124: Test MSE=2.2453127929142545, Test R²=0.634613173348563
2024-10-31 13:02:56,804 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:02:56,805 - INFO - Trial 124 finished with value: 2.2453127929142545 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7870326151985101, 'learning_rate': 0.009663986712612056, 'weight_decay': 0.0003300233967728466, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:03:31,290 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7788721659299244, 'learning_rate': 0.009165834363357408, 'weight_decay': 0.00027186924923657576, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:03:31,290 - INFO - Trial 125: Train MSE=1.8963612190314703, Train R²=0.6843899531023843
2024-10-31 13:03:31,290 - INFO - Trial 125: Test MSE=2.2781186444418773, Test R²=0.6290004423686436
2024-10-31 13:03:31,290 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:03:31,291 - INFO - Trial 125 finished with value: 2.2781186444418773 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7788721659299244, 'learning_rate': 0.009165834363357408, 'weight_decay': 0.00027186924923657576, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:04:02,637 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7495279920120382, 'learning_rate': 0.007450193565443567, 'weight_decay': 0.0004063845594199321, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:04:02,637 - INFO - Trial 126: Train MSE=2.0783186682632993, Train R²=0.65422323346138
2024-10-31 13:04:02,637 - INFO - Trial 126: Test MSE=2.261284215109689, Test R²=0.6319215638296944
2024-10-31 13:04:02,637 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:04:02,639 - INFO - Trial 126 finished with value: 2.261284215109689 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7495279920120382, 'learning_rate': 0.007450193565443567, 'weight_decay': 0.0004063845594199321, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:04:35,641 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7648745713062586, 'learning_rate': 0.003294196611388931, 'weight_decay': 0.0004384799621188928, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:04:35,641 - INFO - Trial 127: Train MSE=1.6943064842905318, Train R²=0.7178254957709994
2024-10-31 13:04:35,641 - INFO - Trial 127: Test MSE=2.331763676234654, Test R²=0.6205176285334996
2024-10-31 13:04:35,641 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:04:35,642 - INFO - Trial 127 finished with value: 2.331763676234654 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7648745713062586, 'learning_rate': 0.003294196611388931, 'weight_decay': 0.0004384799621188928, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:05:07,173 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7827303610643047, 'learning_rate': 0.0016421215805943413, 'weight_decay': 0.0002273145604320658, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:05:07,173 - INFO - Trial 128: Train MSE=2.1481619008949826, Train R²=0.6426552555390767
2024-10-31 13:05:07,173 - INFO - Trial 128: Test MSE=2.248482312474932, Test R²=0.634118744305202
2024-10-31 13:05:07,173 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:05:07,174 - INFO - Trial 128 finished with value: 2.248482312474932 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7827303610643047, 'learning_rate': 0.0016421215805943413, 'weight_decay': 0.0002273145604320658, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:05:39,080 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7991286299530309, 'learning_rate': 0.005239387810851871, 'weight_decay': 0.0003713635110457824, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:05:39,080 - INFO - Trial 129: Train MSE=2.139783948659897, Train R²=0.6437999989305224
2024-10-31 13:05:39,080 - INFO - Trial 129: Test MSE=2.233109337942941, Test R²=0.6363608496529716
2024-10-31 13:05:39,081 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:05:39,082 - INFO - Trial 129 finished with value: 2.233109337942941 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7991286299530309, 'learning_rate': 0.005239387810851871, 'weight_decay': 0.0003713635110457824, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:06:10,750 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.5205282859767496, 'learning_rate': 0.002660260419310541, 'weight_decay': 0.00025828026298468416, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:06:10,750 - INFO - Trial 130: Train MSE=1.0616853897060667, Train R²=0.8232960743563515
2024-10-31 13:06:10,751 - INFO - Trial 130: Test MSE=2.3798268181937083, Test R²=0.6128596493176052
2024-10-31 13:06:10,751 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:06:10,752 - INFO - Trial 130 finished with value: 2.3798268181937083 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.5205282859767496, 'learning_rate': 0.002660260419310541, 'weight_decay': 0.00025828026298468416, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:06:42,757 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7896744694437857, 'learning_rate': 0.008352006220640302, 'weight_decay': 0.0002879567002437322, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:06:42,757 - INFO - Trial 131: Train MSE=2.089751056262425, Train R²=0.6513165341956275
2024-10-31 13:06:42,757 - INFO - Trial 131: Test MSE=2.215327194758824, Test R²=0.6392314178603036
2024-10-31 13:06:42,758 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:06:42,759 - INFO - Trial 131 finished with value: 2.215327194758824 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7896744694437857, 'learning_rate': 0.008352006220640302, 'weight_decay': 0.0002879567002437322, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:07:15,382 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902047610837446, 'learning_rate': 0.008282141987018227, 'weight_decay': 0.0003127191574733237, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:07:15,382 - INFO - Trial 132: Train MSE=2.0672891480582103, Train R²=0.6561406297343118
2024-10-31 13:07:15,382 - INFO - Trial 132: Test MSE=2.2151052270616804, Test R²=0.6394456710134234
2024-10-31 13:07:15,382 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:07:15,383 - INFO - Trial 132 finished with value: 2.2151052270616804 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902047610837446, 'learning_rate': 0.008282141987018227, 'weight_decay': 0.0003127191574733237, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:07:48,312 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7892650336799423, 'learning_rate': 0.008976367752585684, 'weight_decay': 0.0003061241840207134, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:07:48,312 - INFO - Trial 133: Train MSE=2.157313870532172, Train R²=0.6409429290464946
2024-10-31 13:07:48,312 - INFO - Trial 133: Test MSE=2.264901263373239, Test R²=0.6313549109867641
2024-10-31 13:07:48,312 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:07:48,313 - INFO - Trial 133 finished with value: 2.264901263373239 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7892650336799423, 'learning_rate': 0.008976367752585684, 'weight_decay': 0.0003061241840207134, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:08:20,478 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7585906276815503, 'learning_rate': 0.008244002880574555, 'weight_decay': 0.0002757527024303129, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:08:20,478 - INFO - Trial 134: Train MSE=1.9398781103747231, Train R²=0.6756125901426587
2024-10-31 13:08:20,478 - INFO - Trial 134: Test MSE=2.2470549855913435, Test R²=0.6342435308865139
2024-10-31 13:08:20,478 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:08:20,481 - INFO - Trial 134 finished with value: 2.2470549855913435 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7585906276815503, 'learning_rate': 0.008244002880574555, 'weight_decay': 0.0002757527024303129, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:08:52,855 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.771445148585046, 'learning_rate': 0.0010461023419910663, 'weight_decay': 0.0003167364355842784, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:08:52,855 - INFO - Trial 135: Train MSE=2.2164411885397777, Train R²=0.6309625804424286
2024-10-31 13:08:52,855 - INFO - Trial 135: Test MSE=2.251919150352478, Test R²=0.633464515209198
2024-10-31 13:08:52,855 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:08:52,856 - INFO - Trial 135 finished with value: 2.251919150352478 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.771445148585046, 'learning_rate': 0.0010461023419910663, 'weight_decay': 0.0003167364355842784, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:09:38,764 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7920679940332177, 'learning_rate': 0.00627836956673669, 'weight_decay': 0.00020371521082733853, 'batch_size': 256, 'tree_depth': 12}
2024-10-31 13:09:38,764 - INFO - Trial 136: Train MSE=1.9589723284755434, Train R²=0.6735437225018229
2024-10-31 13:09:38,764 - INFO - Trial 136: Test MSE=2.2591107061931064, Test R²=0.6303452168192182
2024-10-31 13:09:38,764 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:09:38,765 - INFO - Trial 136 finished with value: 2.2591107061931064 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7920679940332177, 'learning_rate': 0.00627836956673669, 'weight_decay': 0.00020371521082733853, 'batch_size': 256, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:10:10,975 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7994009909998624, 'learning_rate': 0.0014917310883821363, 'weight_decay': 0.00029358097694133934, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:10:10,975 - INFO - Trial 137: Train MSE=2.28023966721126, Train R²=0.6205761177199227
2024-10-31 13:10:10,975 - INFO - Trial 137: Test MSE=2.2271520580564226, Test R²=0.6373442752020699
2024-10-31 13:10:10,975 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:10:10,976 - INFO - Trial 137 finished with value: 2.2271520580564226 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7994009909998624, 'learning_rate': 0.0014917310883821363, 'weight_decay': 0.00029358097694133934, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:10:43,152 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999479460539793, 'learning_rate': 0.009957331161412784, 'weight_decay': 0.00029002697881774764, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:10:43,152 - INFO - Trial 138: Train MSE=2.1317746298653737, Train R²=0.6446083124194827
2024-10-31 13:10:43,152 - INFO - Trial 138: Test MSE=2.2478020020893643, Test R²=0.6341087647846767
2024-10-31 13:10:43,152 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:10:43,154 - INFO - Trial 138 finished with value: 2.2478020020893643 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999479460539793, 'learning_rate': 0.009957331161412784, 'weight_decay': 0.00029002697881774764, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:11:14,710 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7662716912224117, 'learning_rate': 0.0014641836814814318, 'weight_decay': 0.00015421945970436958, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:11:14,710 - INFO - Trial 139: Train MSE=2.035968725170408, Train R²=0.6605536320379802
2024-10-31 13:11:14,710 - INFO - Trial 139: Test MSE=2.2468973227909634, Test R²=0.6342246873038155
2024-10-31 13:11:14,710 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:11:14,712 - INFO - Trial 139 finished with value: 2.2468973227909634 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7662716912224117, 'learning_rate': 0.0014641836814814318, 'weight_decay': 0.00015421945970436958, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:11:47,391 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7874540654375772, 'learning_rate': 0.0004308431485320132, 'weight_decay': 0.00018170039073403166, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:11:47,391 - INFO - Trial 140: Train MSE=3.694422721862793, Train R²=0.3843275989804949
2024-10-31 13:11:47,391 - INFO - Trial 140: Test MSE=2.3667677470615933, Test R²=0.6149421760014125
2024-10-31 13:11:47,391 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:11:47,393 - INFO - Trial 140 finished with value: 2.3667677470615933 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7874540654375772, 'learning_rate': 0.0004308431485320132, 'weight_decay': 0.00018170039073403166, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:12:19,307 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7834213317678868, 'learning_rate': 0.00139919216610213, 'weight_decay': 0.0002932220014653225, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:12:19,307 - INFO - Trial 141: Train MSE=2.1909216174057553, Train R²=0.6345745921134949
2024-10-31 13:12:19,308 - INFO - Trial 141: Test MSE=2.2544559751238142, Test R²=0.6332124556813922
2024-10-31 13:12:19,308 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:12:19,309 - INFO - Trial 141 finished with value: 2.2544559751238142 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7834213317678868, 'learning_rate': 0.00139919216610213, 'weight_decay': 0.0002932220014653225, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:12:51,172 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7724808123735252, 'learning_rate': 0.008677714177874014, 'weight_decay': 0.00011169564950629451, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:12:51,172 - INFO - Trial 142: Train MSE=1.732084755386625, Train R²=0.7122034834963935
2024-10-31 13:12:51,172 - INFO - Trial 142: Test MSE=2.2477473531450545, Test R²=0.6340740323066711
2024-10-31 13:12:51,172 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:12:51,174 - INFO - Trial 142 finished with value: 2.2477473531450545 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7724808123735252, 'learning_rate': 0.008677714177874014, 'weight_decay': 0.00011169564950629451, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:13:23,788 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7537571588562723, 'learning_rate': 0.001561683619597805, 'weight_decay': 0.0002583297098923996, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:13:23,788 - INFO - Trial 143: Train MSE=1.9034440176827567, Train R²=0.6834240960223334
2024-10-31 13:13:23,788 - INFO - Trial 143: Test MSE=2.268850701195853, Test R²=0.6305079204695565
2024-10-31 13:13:23,788 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:13:23,789 - INFO - Trial 143 finished with value: 2.268850701195853 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7537571588562723, 'learning_rate': 0.001561683619597805, 'weight_decay': 0.0002583297098923996, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:13:55,553 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7911453810195509, 'learning_rate': 0.00197469669152225, 'weight_decay': 0.0002998323994707933, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:13:55,553 - INFO - Trial 144: Train MSE=2.152810275554657, Train R²=0.6416688369853156
2024-10-31 13:13:55,553 - INFO - Trial 144: Test MSE=2.237187623977661, Test R²=0.6357393435069493
2024-10-31 13:13:55,553 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:13:55,555 - INFO - Trial 144 finished with value: 2.237187623977661 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7911453810195509, 'learning_rate': 0.00197469669152225, 'weight_decay': 0.0002998323994707933, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:14:26,617 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7790352649389781, 'learning_rate': 0.007417679158295383, 'weight_decay': 0.0002803522106921987, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 13:14:26,617 - INFO - Trial 145: Train MSE=2.1989010529858724, Train R²=0.6343423468726022
2024-10-31 13:14:26,617 - INFO - Trial 145: Test MSE=2.2286152499062672, Test R²=0.6372271350451878
2024-10-31 13:14:26,618 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:14:26,618 - INFO - Trial 145 finished with value: 2.2286152499062672 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7790352649389781, 'learning_rate': 0.007417679158295383, 'weight_decay': 0.0002803522106921987, 'batch_size': 512, 'tree_depth': 9}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:14:57,843 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7365345867253893, 'learning_rate': 0.0011263687199730302, 'weight_decay': 0.00033535872925104536, 'batch_size': 512, 'tree_depth': 7}
2024-10-31 13:14:57,843 - INFO - Trial 146: Train MSE=2.623101685728346, Train R²=0.5630803150790078
2024-10-31 13:14:57,843 - INFO - Trial 146: Test MSE=2.340689182281494, Test R²=0.6190090520041329
2024-10-31 13:14:57,843 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:14:57,844 - INFO - Trial 146 finished with value: 2.340689182281494 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7365345867253893, 'learning_rate': 0.0011263687199730302, 'weight_decay': 0.00033535872925104536, 'batch_size': 512, 'tree_depth': 7}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:15:29,897 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7669967109572472, 'learning_rate': 0.0017121690234476196, 'weight_decay': 0.0003171747586561619, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:15:29,897 - INFO - Trial 147: Train MSE=2.016118884086609, Train R²=0.6642966164009911
2024-10-31 13:15:29,897 - INFO - Trial 147: Test MSE=2.266331604548863, Test R²=0.631141722202301
2024-10-31 13:15:29,897 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:15:29,898 - INFO - Trial 147 finished with value: 2.266331604548863 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7669967109572472, 'learning_rate': 0.0017121690234476196, 'weight_decay': 0.0003171747586561619, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:15:56,120 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7997438178918272, 'learning_rate': 0.000998775120032745, 'weight_decay': 0.0002474663094431545, 'batch_size': 1024, 'tree_depth': 12}
2024-10-31 13:15:56,121 - INFO - Trial 148: Train MSE=3.07223904132843, Train R²=0.4905721204621451
2024-10-31 13:15:56,121 - INFO - Trial 148: Test MSE=2.251884937286377, Test R²=0.6309898197650909
2024-10-31 13:15:56,121 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:15:56,122 - INFO - Trial 148 finished with value: 2.251884937286377 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7997438178918272, 'learning_rate': 0.000998775120032745, 'weight_decay': 0.0002474663094431545, 'batch_size': 1024, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:16:28,473 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7785050060107833, 'learning_rate': 0.0013148968858659445, 'weight_decay': 0.0002629641476437325, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:16:28,473 - INFO - Trial 149: Train MSE=2.131516788687025, Train R²=0.6455673894711903
2024-10-31 13:16:28,473 - INFO - Trial 149: Test MSE=2.2553547280175343, Test R²=0.6328298960413251
2024-10-31 13:16:28,474 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:16:28,475 - INFO - Trial 149 finished with value: 2.2553547280175343 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7785050060107833, 'learning_rate': 0.0013148968858659445, 'weight_decay': 0.0002629641476437325, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:17:04,356 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.6340690391094567, 'learning_rate': 0.0008947267685486787, 'weight_decay': 0.0002778117912292508, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:17:04,357 - INFO - Trial 150: Train MSE=1.2046639791556768, Train R²=0.7994616329669952
2024-10-31 13:17:04,357 - INFO - Trial 150: Test MSE=2.3786325454711914, Test R²=0.6126310399600438
2024-10-31 13:17:04,357 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:17:04,358 - INFO - Trial 150 finished with value: 2.3786325454711914 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.6340690391094567, 'learning_rate': 0.0008947267685486787, 'weight_decay': 0.0002778117912292508, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:17:34,831 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7794044820016195, 'learning_rate': 0.006894699846924142, 'weight_decay': 0.0002788824640448321, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 13:17:34,831 - INFO - Trial 151: Train MSE=2.1503777418817793, Train R²=0.6419318616390228
2024-10-31 13:17:34,832 - INFO - Trial 151: Test MSE=2.249605417251587, Test R²=0.6338279673031398
2024-10-31 13:17:34,832 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:17:34,832 - INFO - Trial 151 finished with value: 2.249605417251587 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7794044820016195, 'learning_rate': 0.006894699846924142, 'weight_decay': 0.0002788824640448321, 'batch_size': 512, 'tree_depth': 9}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:18:05,567 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.790977005195582, 'learning_rate': 0.007722672112871971, 'weight_decay': 0.0002964814857111828, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 13:18:05,568 - INFO - Trial 152: Train MSE=2.2659129415239607, Train R²=0.6236977108887264
2024-10-31 13:18:05,568 - INFO - Trial 152: Test MSE=2.229471138545445, Test R²=0.637090265750885
2024-10-31 13:18:05,568 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:18:05,569 - INFO - Trial 152 finished with value: 2.229471138545445 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.790977005195582, 'learning_rate': 0.007722672112871971, 'weight_decay': 0.0002964814857111828, 'batch_size': 512, 'tree_depth': 9}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:18:36,705 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7723637585770556, 'learning_rate': 0.0073327622527718, 'weight_decay': 0.0003174694862211488, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 13:18:36,705 - INFO - Trial 153: Train MSE=2.1976301074028015, Train R²=0.6348341767277036
2024-10-31 13:18:36,706 - INFO - Trial 153: Test MSE=2.233969177518572, Test R²=0.6361661383083889
2024-10-31 13:18:36,706 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:18:36,707 - INFO - Trial 153 finished with value: 2.233969177518572 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7723637585770556, 'learning_rate': 0.0073327622527718, 'weight_decay': 0.0003174694862211488, 'batch_size': 512, 'tree_depth': 9}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:19:07,665 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7838535919753087, 'learning_rate': 0.008531668339826076, 'weight_decay': 0.0002678002052200714, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 13:19:07,666 - INFO - Trial 154: Train MSE=2.266880993332182, Train R²=0.6228681994335992
2024-10-31 13:19:07,666 - INFO - Trial 154: Test MSE=2.2692429338182722, Test R²=0.6306601337024144
2024-10-31 13:19:07,666 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:19:07,667 - INFO - Trial 154 finished with value: 2.2692429338182722 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7838535919753087, 'learning_rate': 0.008531668339826076, 'weight_decay': 0.0002678002052200714, 'batch_size': 512, 'tree_depth': 9}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:19:38,629 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.759698195836632, 'learning_rate': 0.0022766076818867714, 'weight_decay': 0.0003047608294868312, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 13:19:38,629 - INFO - Trial 155: Train MSE=2.154580648456301, Train R²=0.6412520344768252
2024-10-31 13:19:38,629 - INFO - Trial 155: Test MSE=2.237518991742815, Test R²=0.6357880064419338
2024-10-31 13:19:38,629 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:19:38,630 - INFO - Trial 155 finished with value: 2.237518991742815 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.759698195836632, 'learning_rate': 0.0022766076818867714, 'weight_decay': 0.0003047608294868312, 'batch_size': 512, 'tree_depth': 9}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:20:15,439 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7463710826639864, 'learning_rate': 0.005595022431533179, 'weight_decay': 0.00023337737328766445, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:20:15,439 - INFO - Trial 156: Train MSE=1.750654697418213, Train R²=0.7076364606618881
2024-10-31 13:20:15,439 - INFO - Trial 156: Test MSE=2.326348304748535, Test R²=0.6211306623050145
2024-10-31 13:20:15,439 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:20:15,440 - INFO - Trial 156 finished with value: 2.326348304748535 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7463710826639864, 'learning_rate': 0.005595022431533179, 'weight_decay': 0.00023337737328766445, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:20:49,058 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7912359966531028, 'learning_rate': 0.009170971379558655, 'weight_decay': 0.00032825990288526635, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:20:49,058 - INFO - Trial 157: Train MSE=2.06876534649304, Train R²=0.6558846916471209
2024-10-31 13:20:49,058 - INFO - Trial 157: Test MSE=2.2400806631360735, Test R²=0.6352090580122811
2024-10-31 13:20:49,058 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:20:49,060 - INFO - Trial 157 finished with value: 2.2400806631360735 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7912359966531028, 'learning_rate': 0.009170971379558655, 'weight_decay': 0.00032825990288526635, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:21:17,921 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7762926214274811, 'learning_rate': 0.001842682831206392, 'weight_decay': 0.0002831223281902638, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:21:17,921 - INFO - Trial 158: Train MSE=2.0008158556052615, Train R²=0.6668702108519418
2024-10-31 13:21:17,921 - INFO - Trial 158: Test MSE=2.2771290710994174, Test R²=0.6294064947537014
2024-10-31 13:21:17,921 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:21:17,922 - INFO - Trial 158 finished with value: 2.2771290710994174 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7762926214274811, 'learning_rate': 0.001842682831206392, 'weight_decay': 0.0002831223281902638, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:22:00,475 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.799615722779274, 'learning_rate': 0.00034072305245182367, 'weight_decay': 0.00034750995084196514, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 13:22:00,476 - INFO - Trial 159: Train MSE=3.526329525879451, Train R²=0.41307171966348377
2024-10-31 13:22:00,476 - INFO - Trial 159: Test MSE=2.5994598184313094, Test R²=0.576927832194737
2024-10-31 13:22:00,476 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:22:00,476 - INFO - Trial 159 finished with value: 2.5994598184313094 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.799615722779274, 'learning_rate': 0.00034072305245182367, 'weight_decay': 0.00034750995084196514, 'batch_size': 512, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:22:56,620 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.762641495743888, 'learning_rate': 0.0005085778753917073, 'weight_decay': 0.00012865032816145467, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 13:22:56,620 - INFO - Trial 160: Train MSE=2.1708015693085536, Train R²=0.6380476195897374
2024-10-31 13:22:56,620 - INFO - Trial 160: Test MSE=2.236884960106441, Test R²=0.633817298071725
2024-10-31 13:22:56,620 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:22:56,621 - INFO - Trial 160 finished with value: 2.236884960106441 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.762641495743888, 'learning_rate': 0.0005085778753917073, 'weight_decay': 0.00012865032816145467, 'batch_size': 256, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:23:35,509 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7879810734951909, 'learning_rate': 0.008057790419456125, 'weight_decay': 0.00029571464763644695, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 13:23:35,509 - INFO - Trial 161: Train MSE=2.2641445866652896, Train R²=0.6233681972537722
2024-10-31 13:23:35,509 - INFO - Trial 161: Test MSE=2.2736172335488454, Test R²=0.6299028737204415
2024-10-31 13:23:35,509 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:23:35,510 - INFO - Trial 161 finished with value: 2.2736172335488454 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7879810734951909, 'learning_rate': 0.008057790419456125, 'weight_decay': 0.00029571464763644695, 'batch_size': 512, 'tree_depth': 9}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:24:16,253 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7915412768372092, 'learning_rate': 0.004839460651425009, 'weight_decay': 0.0003088991929594517, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 13:24:16,254 - INFO - Trial 162: Train MSE=2.219297409057617, Train R²=0.6303791595356805
2024-10-31 13:24:16,254 - INFO - Trial 162: Test MSE=2.277472870690482, Test R²=0.6292189529963902
2024-10-31 13:24:16,254 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:24:16,255 - INFO - Trial 162 finished with value: 2.277472870690482 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7915412768372092, 'learning_rate': 0.004839460651425009, 'weight_decay': 0.0003088991929594517, 'batch_size': 512, 'tree_depth': 9}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:24:51,611 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7760706448861063, 'learning_rate': 0.0074426309233581525, 'weight_decay': 0.00028770815729086996, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 13:24:51,611 - INFO - Trial 163: Train MSE=2.212753253323691, Train R²=0.6322620127882276
2024-10-31 13:24:51,611 - INFO - Trial 163: Test MSE=2.2534402438572476, Test R²=0.6331938249724252
2024-10-31 13:24:51,612 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:24:51,613 - INFO - Trial 163 finished with value: 2.2534402438572476 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7760706448861063, 'learning_rate': 0.0074426309233581525, 'weight_decay': 0.00028770815729086996, 'batch_size': 512, 'tree_depth': 9}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:25:27,760 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.78323068985822, 'learning_rate': 0.006312902845643595, 'weight_decay': 0.00044566632566568577, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 13:25:27,760 - INFO - Trial 164: Train MSE=2.313210976975305, Train R²=0.6151948996952602
2024-10-31 13:25:27,761 - INFO - Trial 164: Test MSE=2.2625370706830705, Test R²=0.6316967947142464
2024-10-31 13:25:27,761 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:25:27,762 - INFO - Trial 164 finished with value: 2.2625370706830705 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.78323068985822, 'learning_rate': 0.006312902845643595, 'weight_decay': 0.00044566632566568577, 'batch_size': 512, 'tree_depth': 9}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:25:57,666 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.573003959128336, 'learning_rate': 0.006775971829136694, 'weight_decay': 0.0002574712259760768, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 13:25:57,667 - INFO - Trial 165: Train MSE=1.332624158688954, Train R²=0.7784877525908607
2024-10-31 13:25:57,667 - INFO - Trial 165: Test MSE=2.373598643711635, Test R²=0.6136206133025033
2024-10-31 13:25:57,667 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:25:57,668 - INFO - Trial 165 finished with value: 2.373598643711635 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.573003959128336, 'learning_rate': 0.006775971829136694, 'weight_decay': 0.0002574712259760768, 'batch_size': 512, 'tree_depth': 9}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:26:25,666 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7929764155167881, 'learning_rate': 0.00998485746864115, 'weight_decay': 0.0003330005679698934, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 13:26:25,666 - INFO - Trial 166: Train MSE=2.3705777866499766, Train R²=0.6058236339262554
2024-10-31 13:26:25,666 - INFO - Trial 166: Test MSE=2.2675558158329556, Test R²=0.6309116056987217
2024-10-31 13:26:25,667 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:26:25,668 - INFO - Trial 166 finished with value: 2.2675558158329556 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7929764155167881, 'learning_rate': 0.00998485746864115, 'weight_decay': 0.0003330005679698934, 'batch_size': 512, 'tree_depth': 9}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:27:00,950 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7707997860345139, 'learning_rate': 0.007583706124146204, 'weight_decay': 0.0002700951588997013, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:27:00,951 - INFO - Trial 167: Train MSE=1.9550416001251765, Train R²=0.6746118707316262
2024-10-31 13:27:00,951 - INFO - Trial 167: Test MSE=2.254381367138454, Test R²=0.6329695241791862
2024-10-31 13:27:00,951 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:27:00,952 - INFO - Trial 167 finished with value: 2.254381367138454 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7707997860345139, 'learning_rate': 0.007583706124146204, 'weight_decay': 0.0002700951588997013, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:27:37,736 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995329128346005, 'learning_rate': 0.008376757761800045, 'weight_decay': 0.00014212140812667998, 'batch_size': 512, 'tree_depth': 8}
2024-10-31 13:27:37,736 - INFO - Trial 168: Train MSE=2.218397923878261, Train R²=0.6310465676443917
2024-10-31 13:27:37,737 - INFO - Trial 168: Test MSE=2.261589459010533, Test R²=0.6317615509033203
2024-10-31 13:27:37,737 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:27:37,737 - INFO - Trial 168 finished with value: 2.261589459010533 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995329128346005, 'learning_rate': 0.008376757761800045, 'weight_decay': 0.00014212140812667998, 'batch_size': 512, 'tree_depth': 8}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:28:15,335 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7562326693292867, 'learning_rate': 0.0007267206778309936, 'weight_decay': 0.00029789450182273104, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:28:15,335 - INFO - Trial 169: Train MSE=2.3897588082722256, Train R²=0.6018501136984143
2024-10-31 13:28:15,335 - INFO - Trial 169: Test MSE=2.2450492722647533, Test R²=0.6346432651792254
2024-10-31 13:28:15,335 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:28:15,337 - INFO - Trial 169 finished with value: 2.2450492722647533 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7562326693292867, 'learning_rate': 0.0007267206778309936, 'weight_decay': 0.00029789450182273104, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:28:52,248 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7797292243953713, 'learning_rate': 0.005952788944152352, 'weight_decay': 0.00016684171743861558, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:28:52,248 - INFO - Trial 170: Train MSE=1.8341747309480394, Train R²=0.694634844149862
2024-10-31 13:28:52,248 - INFO - Trial 170: Test MSE=2.2569359711238315, Test R²=0.6325695003782
2024-10-31 13:28:52,248 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:28:52,249 - INFO - Trial 170 finished with value: 2.2569359711238315 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7797292243953713, 'learning_rate': 0.005952788944152352, 'weight_decay': 0.00016684171743861558, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:29:28,246 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7834401040751022, 'learning_rate': 0.007792030222724494, 'weight_decay': 0.0003459714758825725, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:29:28,246 - INFO - Trial 171: Train MSE=2.175919843571527, Train R²=0.6384376691920417
2024-10-31 13:29:28,246 - INFO - Trial 171: Test MSE=2.3610938617161343, Test R²=0.6155370729310172
2024-10-31 13:29:28,246 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:29:28,248 - INFO - Trial 171 finished with value: 2.3610938617161343 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7834401040751022, 'learning_rate': 0.007792030222724494, 'weight_decay': 0.0003459714758825725, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:30:03,140 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7669081482594402, 'learning_rate': 0.008892408954289449, 'weight_decay': 0.00038183025141325994, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:30:03,141 - INFO - Trial 172: Train MSE=2.13594228880746, Train R²=0.6446022923503604
2024-10-31 13:30:03,141 - INFO - Trial 172: Test MSE=2.253218037741525, Test R²=0.6333039658410209
2024-10-31 13:30:03,141 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:30:03,142 - INFO - Trial 172 finished with value: 2.253218037741525 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7669081482594402, 'learning_rate': 0.008892408954289449, 'weight_decay': 0.00038183025141325994, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:30:31,507 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7758034206855283, 'learning_rate': 0.008105510867272004, 'weight_decay': 0.0003658443624452337, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:30:31,507 - INFO - Trial 173: Train MSE=2.126604744366237, Train R²=0.6464408827679498
2024-10-31 13:30:31,507 - INFO - Trial 173: Test MSE=2.2229763780321394, Test R²=0.6381809115409851
2024-10-31 13:30:31,507 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:30:31,509 - INFO - Trial 173 finished with value: 2.2229763780321394 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7758034206855283, 'learning_rate': 0.008105510867272004, 'weight_decay': 0.0003658443624452337, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:31:08,205 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7896106776158454, 'learning_rate': 0.001176846714183904, 'weight_decay': 0.00031312624046928755, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:31:08,205 - INFO - Trial 174: Train MSE=2.3171508695398058, Train R²=0.6142578508172717
2024-10-31 13:31:08,205 - INFO - Trial 174: Test MSE=2.2129399265561784, Test R²=0.6397565858704704
2024-10-31 13:31:08,205 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:31:08,206 - INFO - Trial 174 finished with value: 2.2129399265561784 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7896106776158454, 'learning_rate': 0.001176846714183904, 'weight_decay': 0.00031312624046928755, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:31:45,222 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7709248904666834, 'learning_rate': 0.0011225267512895913, 'weight_decay': 0.00032106738214754833, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:31:45,222 - INFO - Trial 175: Train MSE=2.1873036665575847, Train R²=0.6356293899672372
2024-10-31 13:31:45,222 - INFO - Trial 175: Test MSE=2.218040636607579, Test R²=0.6388981257166181
2024-10-31 13:31:45,222 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:31:45,223 - INFO - Trial 175 finished with value: 2.218040636607579 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7709248904666834, 'learning_rate': 0.0011225267512895913, 'weight_decay': 0.00032106738214754833, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:32:34,091 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7643432158816894, 'learning_rate': 0.001175898261309807, 'weight_decay': 0.0003626117739399305, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:32:34,091 - INFO - Trial 176: Train MSE=1.7491008383887154, Train R²=0.7099888239588056
2024-10-31 13:32:34,091 - INFO - Trial 176: Test MSE=2.2682385614940097, Test R²=0.630806531224932
2024-10-31 13:32:34,091 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:32:34,092 - INFO - Trial 176 finished with value: 2.2682385614940097 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7643432158816894, 'learning_rate': 0.001175898261309807, 'weight_decay': 0.0003626117739399305, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:33:14,990 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7512260841549954, 'learning_rate': 0.001069629129809031, 'weight_decay': 0.0003202924852985759, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 13:33:14,990 - INFO - Trial 177: Train MSE=2.9930854184286937, Train R²=0.5033307203224727
2024-10-31 13:33:14,990 - INFO - Trial 177: Test MSE=2.2319790720939636, Test R²=0.6343071609735489
2024-10-31 13:33:14,990 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:33:14,992 - INFO - Trial 177 finished with value: 2.2319790720939636 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7512260841549954, 'learning_rate': 0.001069629129809031, 'weight_decay': 0.0003202924852985759, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:33:52,014 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6016647024292117, 'learning_rate': 0.001264340823566805, 'weight_decay': 0.00033738032488235374, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:33:52,015 - INFO - Trial 178: Train MSE=1.1434106252023153, Train R²=0.8094290367194584
2024-10-31 13:33:52,015 - INFO - Trial 178: Test MSE=2.3678841590881348, Test R²=0.6145918624741691
2024-10-31 13:33:52,015 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:33:52,016 - INFO - Trial 178 finished with value: 2.3678841590881348 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6016647024292117, 'learning_rate': 0.001264340823566805, 'weight_decay': 0.00033738032488235374, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:34:30,368 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7722414629870005, 'learning_rate': 0.000978225331960038, 'weight_decay': 0.0004958559959590662, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:34:30,368 - INFO - Trial 179: Train MSE=2.308227138859885, Train R²=0.6156486123800278
2024-10-31 13:34:30,368 - INFO - Trial 179: Test MSE=2.2613539014543806, Test R²=0.632180494921548
2024-10-31 13:34:30,368 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:34:30,370 - INFO - Trial 179 finished with value: 2.2613539014543806 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7722414629870005, 'learning_rate': 0.000978225331960038, 'weight_decay': 0.0004958559959590662, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:35:07,994 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.787992887156105, 'learning_rate': 0.0014437465515094326, 'weight_decay': 0.00031658650840205764, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:35:07,994 - INFO - Trial 180: Train MSE=2.231641743864332, Train R²=0.628081847514425
2024-10-31 13:35:07,994 - INFO - Trial 180: Test MSE=2.250669138772147, Test R²=0.6335279856409345
2024-10-31 13:35:07,994 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:35:07,995 - INFO - Trial 180 finished with value: 2.250669138772147 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.787992887156105, 'learning_rate': 0.0014437465515094326, 'weight_decay': 0.00031658650840205764, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:35:45,125 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7784086376649103, 'learning_rate': 0.0001789333093848736, 'weight_decay': 0.0002805846714555983, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:35:45,125 - INFO - Trial 181: Train MSE=5.692476766450064, Train R²=0.04962324670382908
2024-10-31 13:35:45,125 - INFO - Trial 181: Test MSE=2.4727204527173723, Test R²=0.5975881133760724
2024-10-31 13:35:45,125 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:35:45,126 - INFO - Trial 181 finished with value: 2.4727204527173723 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7784086376649103, 'learning_rate': 0.0001789333093848736, 'weight_decay': 0.0002805846714555983, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:36:21,979 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7872381145738119, 'learning_rate': 0.0011303972771200808, 'weight_decay': 0.00030592615233481803, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:36:21,979 - INFO - Trial 182: Train MSE=2.304970417703901, Train R²=0.6156309438603265
2024-10-31 13:36:21,979 - INFO - Trial 182: Test MSE=2.2279113020215715, Test R²=0.6372483032090324
2024-10-31 13:36:21,979 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:36:21,980 - INFO - Trial 182 finished with value: 2.2279113020215715 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7872381145738119, 'learning_rate': 0.0011303972771200808, 'weight_decay': 0.00030592615233481803, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:36:59,282 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7985075017608307, 'learning_rate': 0.0011802362992179064, 'weight_decay': 0.0003053176668778794, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:36:59,282 - INFO - Trial 183: Train MSE=2.37237777028765, Train R²=0.6054817544562476
2024-10-31 13:36:59,282 - INFO - Trial 183: Test MSE=2.2365587949752808, Test R²=0.6359683445521763
2024-10-31 13:36:59,282 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:36:59,283 - INFO - Trial 183 finished with value: 2.2365587949752808 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7985075017608307, 'learning_rate': 0.0011802362992179064, 'weight_decay': 0.0003053176668778794, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:37:35,627 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7885210475701044, 'learning_rate': 0.0009141200417809101, 'weight_decay': 0.00032492306369453133, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:37:35,627 - INFO - Trial 184: Train MSE=2.4284395149775913, Train R²=0.5959994282041278
2024-10-31 13:37:35,627 - INFO - Trial 184: Test MSE=2.2513937609536305, Test R²=0.6336364150047302
2024-10-31 13:37:35,627 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:37:35,628 - INFO - Trial 184 finished with value: 2.2513937609536305 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7885210475701044, 'learning_rate': 0.0009141200417809101, 'weight_decay': 0.00032492306369453133, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:38:12,996 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7678478263241372, 'learning_rate': 0.001358166306851204, 'weight_decay': 0.0003553404798372207, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:38:12,996 - INFO - Trial 185: Train MSE=2.068633556365967, Train R²=0.6559850743838719
2024-10-31 13:38:12,996 - INFO - Trial 185: Test MSE=2.2592593942369734, Test R²=0.6322422453335353
2024-10-31 13:38:12,996 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:38:12,998 - INFO - Trial 185 finished with value: 2.2592593942369734 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7678478263241372, 'learning_rate': 0.001358166306851204, 'weight_decay': 0.0003553404798372207, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:38:48,757 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7844224504646242, 'learning_rate': 0.0011083966915192884, 'weight_decay': 0.00038430491800467637, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:38:48,757 - INFO - Trial 186: Train MSE=2.8680747662271773, Train R²=0.5231424357209887
2024-10-31 13:38:48,757 - INFO - Trial 186: Test MSE=2.2506582736968994, Test R²=0.6336831024714878
2024-10-31 13:38:48,757 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:38:48,759 - INFO - Trial 186 finished with value: 2.2506582736968994 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7844224504646242, 'learning_rate': 0.0011083966915192884, 'weight_decay': 0.00038430491800467637, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:39:25,405 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7574555150445479, 'learning_rate': 0.00099491284219132, 'weight_decay': 0.0003088243228060068, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:39:25,405 - INFO - Trial 187: Train MSE=2.2173154013497487, Train R²=0.6291381248406002
2024-10-31 13:39:25,405 - INFO - Trial 187: Test MSE=2.24925320489066, Test R²=0.6340081436293465
2024-10-31 13:39:25,405 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:39:25,406 - INFO - Trial 187 finished with value: 2.24925320489066 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7574555150445479, 'learning_rate': 0.00099491284219132, 'weight_decay': 0.0003088243228060068, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:40:05,892 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7991242373168636, 'learning_rate': 0.0008040790614273976, 'weight_decay': 0.000341042438427233, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:40:05,892 - INFO - Trial 188: Train MSE=2.3535913825035095, Train R²=0.6066930570772716
2024-10-31 13:40:05,892 - INFO - Trial 188: Test MSE=2.317626340048654, Test R²=0.6227839503969465
2024-10-31 13:40:05,892 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:40:05,893 - INFO - Trial 188 finished with value: 2.317626340048654 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7991242373168636, 'learning_rate': 0.0008040790614273976, 'weight_decay': 0.000341042438427233, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:40:43,004 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.774346623459486, 'learning_rate': 0.0012481924571631033, 'weight_decay': 0.0002459320606971206, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:40:43,004 - INFO - Trial 189: Train MSE=2.182592890092305, Train R²=0.63661932519504
2024-10-31 13:40:43,004 - INFO - Trial 189: Test MSE=2.235335503305708, Test R²=0.6361441101346698
2024-10-31 13:40:43,004 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:40:43,006 - INFO - Trial 189 finished with value: 2.235335503305708 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.774346623459486, 'learning_rate': 0.0012481924571631033, 'weight_decay': 0.0002459320606971206, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:42:05,165 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7888288781537455, 'learning_rate': 0.0016329451671352716, 'weight_decay': 0.00029317798159481367, 'batch_size': 128, 'tree_depth': 12}
2024-10-31 13:42:05,165 - INFO - Trial 190: Train MSE=1.8262182995676994, Train R²=0.6913437539977687
2024-10-31 13:42:05,165 - INFO - Trial 190: Test MSE=2.279766729899815, Test R²=0.6222368500062397
2024-10-31 13:42:05,165 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:42:05,166 - INFO - Trial 190 finished with value: 2.279766729899815 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7888288781537455, 'learning_rate': 0.0016329451671352716, 'weight_decay': 0.00029317798159481367, 'batch_size': 128, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:42:41,937 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7791526155397629, 'learning_rate': 0.0010437666445842174, 'weight_decay': 0.0002821054452408127, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:42:41,938 - INFO - Trial 191: Train MSE=2.2873976145471846, Train R²=0.6189620558704648
2024-10-31 13:42:41,938 - INFO - Trial 191: Test MSE=2.2735177789415633, Test R²=0.630050003528595
2024-10-31 13:42:41,938 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:42:41,941 - INFO - Trial 191 finished with value: 2.2735177789415633 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7791526155397629, 'learning_rate': 0.0010437666445842174, 'weight_decay': 0.0002821054452408127, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:43:18,455 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7713600322341461, 'learning_rate': 0.0014669175964689828, 'weight_decay': 0.0003253027676493955, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:43:18,455 - INFO - Trial 192: Train MSE=2.0734183490276337, Train R²=0.6551370301416942
2024-10-31 13:43:18,455 - INFO - Trial 192: Test MSE=2.2238817044666837, Test R²=0.6381147674151829
2024-10-31 13:43:18,455 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:43:18,457 - INFO - Trial 192 finished with value: 2.2238817044666837 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7713600322341461, 'learning_rate': 0.0014669175964689828, 'weight_decay': 0.0003253027676493955, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:43:55,092 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6648491770565107, 'learning_rate': 0.0013448772418055176, 'weight_decay': 0.0003205887213499682, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:43:55,092 - INFO - Trial 193: Train MSE=1.4016741897378648, Train R²=0.7667080483266285
2024-10-31 13:43:55,092 - INFO - Trial 193: Test MSE=2.3296150820595876, Test R²=0.6205599733761379
2024-10-31 13:43:55,092 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:43:55,093 - INFO - Trial 193 finished with value: 2.3296150820595876 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6648491770565107, 'learning_rate': 0.0013448772418055176, 'weight_decay': 0.0003205887213499682, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:44:32,045 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7685238513125536, 'learning_rate': 0.001541798571290758, 'weight_decay': 0.00036953776729065497, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:44:32,045 - INFO - Trial 194: Train MSE=2.0188374561922893, Train R²=0.6640945907149997
2024-10-31 13:44:32,046 - INFO - Trial 194: Test MSE=2.2379209995269775, Test R²=0.635692800794329
2024-10-31 13:44:32,046 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:44:32,047 - INFO - Trial 194 finished with value: 2.2379209995269775 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7685238513125536, 'learning_rate': 0.001541798571290758, 'weight_decay': 0.00036953776729065497, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:45:09,662 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7901253130445807, 'learning_rate': 0.0011356115810688195, 'weight_decay': 0.0003060089364163102, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:45:09,662 - INFO - Trial 195: Train MSE=2.33393166746412, Train R²=0.6115870092596326
2024-10-31 13:45:09,662 - INFO - Trial 195: Test MSE=2.2461575099400113, Test R²=0.6344442708151681
2024-10-31 13:45:09,662 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:45:09,664 - INFO - Trial 195 finished with value: 2.2461575099400113 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7901253130445807, 'learning_rate': 0.0011356115810688195, 'weight_decay': 0.0003060089364163102, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:45:45,404 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7602464249421998, 'learning_rate': 0.00176360796037837, 'weight_decay': 0.000186515504333974, 'batch_size': 512, 'tree_depth': 6}
2024-10-31 13:45:45,404 - INFO - Trial 196: Train MSE=2.925394126347133, Train R²=0.5135710878031594
2024-10-31 13:45:45,404 - INFO - Trial 196: Test MSE=2.437955788203648, Test R²=0.6030876891953605
2024-10-31 13:45:45,404 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:45:45,405 - INFO - Trial 196 finished with value: 2.437955788203648 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7602464249421998, 'learning_rate': 0.00176360796037837, 'weight_decay': 0.000186515504333974, 'batch_size': 512, 'tree_depth': 6}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:46:37,959 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998731867425362, 'learning_rate': 0.0014226044531113681, 'weight_decay': 0.00033117392030576685, 'batch_size': 256, 'tree_depth': 12}
2024-10-31 13:46:37,960 - INFO - Trial 197: Train MSE=2.0512944949524745, Train R²=0.6576737346393722
2024-10-31 13:46:37,960 - INFO - Trial 197: Test MSE=2.22670716047287, Test R²=0.6359201329095023
2024-10-31 13:46:37,960 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:46:37,961 - INFO - Trial 197 finished with value: 2.22670716047287 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998731867425362, 'learning_rate': 0.0014226044531113681, 'weight_decay': 0.00033117392030576685, 'batch_size': 256, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:47:23,445 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7938958578288642, 'learning_rate': 0.0013913919066674161, 'weight_decay': 0.0003449980905003337, 'batch_size': 256, 'tree_depth': 12}
2024-10-31 13:47:23,445 - INFO - Trial 198: Train MSE=2.367401278444699, Train R²=0.6042068643229348
2024-10-31 13:47:23,446 - INFO - Trial 198: Test MSE=2.27898257119315, Test R²=0.6270677191870553
2024-10-31 13:47:23,446 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:47:23,447 - INFO - Trial 198 finished with value: 2.27898257119315 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7938958578288642, 'learning_rate': 0.0013913919066674161, 'weight_decay': 0.0003449980905003337, 'batch_size': 256, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:48:02,283 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995083293484607, 'learning_rate': 0.001511354334027596, 'weight_decay': 0.00032893172756851886, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:48:02,283 - INFO - Trial 199: Train MSE=2.2812735395772115, Train R²=0.6198061193738665
2024-10-31 13:48:02,284 - INFO - Trial 199: Test MSE=2.2182255472455705, Test R²=0.638833395072392
2024-10-31 13:48:02,284 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:48:02,285 - INFO - Trial 199 finished with value: 2.2182255472455705 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995083293484607, 'learning_rate': 0.001511354334027596, 'weight_decay': 0.00032893172756851886, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:48:56,684 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7992345728348457, 'learning_rate': 0.001525041874593063, 'weight_decay': 0.000331028591054444, 'batch_size': 256, 'tree_depth': 12}
2024-10-31 13:48:56,684 - INFO - Trial 200: Train MSE=2.012196823954582, Train R²=0.6647106260061264
2024-10-31 13:48:56,685 - INFO - Trial 200: Test MSE=2.261957730565752, Test R²=0.6298555859497615
2024-10-31 13:48:56,685 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:48:56,686 - INFO - Trial 200 finished with value: 2.261957730565752 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7992345728348457, 'learning_rate': 0.001525041874593063, 'weight_decay': 0.000331028591054444, 'batch_size': 256, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:49:36,677 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.783525262787094, 'learning_rate': 0.001821360500522675, 'weight_decay': 0.00032357084268877506, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:49:36,677 - INFO - Trial 201: Train MSE=2.0807488645826067, Train R²=0.6531098016670772
2024-10-31 13:49:36,677 - INFO - Trial 201: Test MSE=2.242073042052133, Test R²=0.635015470641
2024-10-31 13:49:36,677 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:49:36,680 - INFO - Trial 201 finished with value: 2.242073042052133 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.783525262787094, 'learning_rate': 0.001821360500522675, 'weight_decay': 0.00032357084268877506, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:50:34,356 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7891170366561016, 'learning_rate': 0.0016346387439027889, 'weight_decay': 0.00030936481064616756, 'batch_size': 256, 'tree_depth': 12}
2024-10-31 13:50:34,356 - INFO - Trial 202: Train MSE=1.9605801446097237, Train R²=0.6708553497280393
2024-10-31 13:50:34,356 - INFO - Trial 202: Test MSE=2.2693844607898166, Test R²=0.628663991178785
2024-10-31 13:50:34,356 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:50:34,357 - INFO - Trial 202 finished with value: 2.2693844607898166 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7891170366561016, 'learning_rate': 0.0016346387439027889, 'weight_decay': 0.00030936481064616756, 'batch_size': 256, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:51:15,542 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7731823382131247, 'learning_rate': 0.0012681201107649605, 'weight_decay': 0.00035733157758500024, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:51:15,542 - INFO - Trial 203: Train MSE=2.1502092565808977, Train R²=0.6417695113590786
2024-10-31 13:51:15,542 - INFO - Trial 203: Test MSE=2.256451742989676, Test R²=0.6327189292226519
2024-10-31 13:51:15,542 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:51:15,544 - INFO - Trial 203 finished with value: 2.256451742989676 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7731823382131247, 'learning_rate': 0.0012681201107649605, 'weight_decay': 0.00035733157758500024, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:52:13,230 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.3923941373645666, 'learning_rate': 0.0014933751184929482, 'weight_decay': 0.0002939761496977113, 'batch_size': 256, 'tree_depth': 12}
2024-10-31 13:52:13,231 - INFO - Trial 204: Train MSE=0.6658136727554458, Train R²=0.8888243596468653
2024-10-31 13:52:13,232 - INFO - Trial 204: Test MSE=2.3932227236883983, Test R²=0.6081983617373875
2024-10-31 13:52:13,232 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:52:13,234 - INFO - Trial 204 finished with value: 2.3932227236883983 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.3923941373645666, 'learning_rate': 0.0014933751184929482, 'weight_decay': 0.0002939761496977113, 'batch_size': 256, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:53:10,829 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.78365077492427, 'learning_rate': 0.0020854587848492374, 'weight_decay': 0.00033627444535577137, 'batch_size': 256, 'tree_depth': 12}
2024-10-31 13:53:10,829 - INFO - Trial 205: Train MSE=1.9140240933213915, Train R²=0.6804125394139972
2024-10-31 13:53:10,829 - INFO - Trial 205: Test MSE=2.264316133090428, Test R²=0.6300104217869895
2024-10-31 13:53:10,829 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:53:10,831 - INFO - Trial 205 finished with value: 2.264316133090428 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.78365077492427, 'learning_rate': 0.0020854587848492374, 'weight_decay': 0.00033627444535577137, 'batch_size': 256, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:53:51,793 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995103891972268, 'learning_rate': 0.001364487179659017, 'weight_decay': 0.0003166763834776905, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:53:51,794 - INFO - Trial 206: Train MSE=2.3379863670894077, Train R²=0.6104091150420052
2024-10-31 13:53:51,794 - INFO - Trial 206: Test MSE=2.2260798726763045, Test R²=0.6375722118786403
2024-10-31 13:53:51,794 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:53:51,795 - INFO - Trial 206 finished with value: 2.2260798726763045 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995103891972268, 'learning_rate': 0.001364487179659017, 'weight_decay': 0.0003166763834776905, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:54:43,476 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7983067585561677, 'learning_rate': 0.0016813802617379838, 'weight_decay': 0.00032297917193850666, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:54:43,477 - INFO - Trial 207: Train MSE=2.9274163331304277, Train R²=0.5128527517829623
2024-10-31 13:54:43,477 - INFO - Trial 207: Test MSE=2.3425819192613875, Test R²=0.61874920129776
2024-10-31 13:54:43,477 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:54:43,478 - INFO - Trial 207 finished with value: 2.3425819192613875 and parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7983067585561677, 'learning_rate': 0.0016813802617379838, 'weight_decay': 0.00032297917193850666, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:55:24,244 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7987734820191038, 'learning_rate': 0.0013378090809821775, 'weight_decay': 0.00020496384654473254, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:55:24,245 - INFO - Trial 208: Train MSE=2.29208556669099, Train R²=0.6192720511129924
2024-10-31 13:55:24,245 - INFO - Trial 208: Test MSE=2.2313874108450755, Test R²=0.6368802956172398
2024-10-31 13:55:24,245 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:55:24,246 - INFO - Trial 208 finished with value: 2.2313874108450755 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7987734820191038, 'learning_rate': 0.0013378090809821775, 'weight_decay': 0.00020496384654473254, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:56:04,554 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7757237283375691, 'learning_rate': 0.009148472609492015, 'weight_decay': 0.000352927116835491, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:56:04,554 - INFO - Trial 209: Train MSE=2.1454407445022037, Train R²=0.6438812166452408
2024-10-31 13:56:04,554 - INFO - Trial 209: Test MSE=2.242261137281145, Test R²=0.6350261739322117
2024-10-31 13:56:04,554 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:56:04,555 - INFO - Trial 209 finished with value: 2.242261137281145 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7757237283375691, 'learning_rate': 0.009148472609492015, 'weight_decay': 0.000352927116835491, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:56:45,468 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999622450826992, 'learning_rate': 0.0014489365680501016, 'weight_decay': 0.00026925367929002246, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:56:45,468 - INFO - Trial 210: Train MSE=2.332348644733429, Train R²=0.6119548784834998
2024-10-31 13:56:45,469 - INFO - Trial 210: Test MSE=2.2355204480034963, Test R²=0.6362595473017011
2024-10-31 13:56:45,469 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:56:45,471 - INFO - Trial 210 finished with value: 2.2355204480034963 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999622450826992, 'learning_rate': 0.0014489365680501016, 'weight_decay': 0.00026925367929002246, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:57:25,759 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7870739707783676, 'learning_rate': 0.0012020324257506852, 'weight_decay': 0.00030519771328026455, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:57:25,759 - INFO - Trial 211: Train MSE=2.29234231369836, Train R²=0.6187662354537419
2024-10-31 13:57:25,760 - INFO - Trial 211: Test MSE=2.228439382144383, Test R²=0.6372198462486267
2024-10-31 13:57:25,760 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:57:25,761 - INFO - Trial 211 finished with value: 2.228439382144383 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7870739707783676, 'learning_rate': 0.0012020324257506852, 'weight_decay': 0.00030519771328026455, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:58:06,521 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7821555769189312, 'learning_rate': 0.0015700555071386404, 'weight_decay': 0.00029236569021421634, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:58:06,521 - INFO - Trial 212: Train MSE=2.214722045830318, Train R²=0.6310725573982511
2024-10-31 13:58:06,521 - INFO - Trial 212: Test MSE=2.2363483735493253, Test R²=0.6359942896025521
2024-10-31 13:58:06,521 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:58:06,522 - INFO - Trial 212 finished with value: 2.2363483735493253 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7821555769189312, 'learning_rate': 0.0015700555071386404, 'weight_decay': 0.00029236569021421634, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:58:47,398 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7897384724394712, 'learning_rate': 0.0010662305924527596, 'weight_decay': 0.00031636944516502907, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 13:58:47,398 - INFO - Trial 213: Train MSE=2.3756632847445354, Train R²=0.6046319050448281
2024-10-31 13:58:47,398 - INFO - Trial 213: Test MSE=2.2640602588653564, Test R²=0.6314826352255685
2024-10-31 13:58:47,398 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:58:47,400 - INFO - Trial 213 finished with value: 2.2640602588653564 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7897384724394712, 'learning_rate': 0.0010662305924527596, 'weight_decay': 0.00031636944516502907, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 13:59:28,019 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7671438994106607, 'learning_rate': 0.0008918552015419408, 'weight_decay': 0.00033397408773547547, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 13:59:28,020 - INFO - Trial 214: Train MSE=2.294854917696544, Train R²=0.6177737585135868
2024-10-31 13:59:28,020 - INFO - Trial 214: Test MSE=2.248956595148359, Test R²=0.6339532818113055
2024-10-31 13:59:28,020 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 13:59:28,021 - INFO - Trial 214 finished with value: 2.248956595148359 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7671438994106607, 'learning_rate': 0.0008918552015419408, 'weight_decay': 0.00033397408773547547, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:00:08,676 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7766316439733308, 'learning_rate': 0.0019278149919523474, 'weight_decay': 0.00030777931183435873, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:00:08,676 - INFO - Trial 215: Train MSE=2.0418800243309567, Train R²=0.6601459703275135
2024-10-31 14:00:08,676 - INFO - Trial 215: Test MSE=2.2166845968791415, Test R²=0.6393214293888637
2024-10-31 14:00:08,676 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:00:08,677 - INFO - Trial 215 finished with value: 2.2166845968791415 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7766316439733308, 'learning_rate': 0.0019278149919523474, 'weight_decay': 0.00030777931183435873, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:00:41,986 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7770718663104199, 'learning_rate': 0.0020062207409380565, 'weight_decay': 0.0003243295700073022, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:00:41,986 - INFO - Trial 216: Train MSE=1.5970158747264318, Train R²=0.7351208754948207
2024-10-31 14:00:41,986 - INFO - Trial 216: Test MSE=2.309312275477818, Test R²=0.6239189079829625
2024-10-31 14:00:41,986 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:00:41,986 - INFO - Trial 216 finished with value: 2.309312275477818 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7770718663104199, 'learning_rate': 0.0020062207409380565, 'weight_decay': 0.0003243295700073022, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:01:09,919 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7703006661615954, 'learning_rate': 0.0018604153118710403, 'weight_decay': 0.000285099863808316, 'batch_size': 1024, 'tree_depth': 12}
2024-10-31 14:01:09,919 - INFO - Trial 217: Train MSE=2.280042733464922, Train R²=0.6212717975888934
2024-10-31 14:01:09,919 - INFO - Trial 217: Test MSE=2.263847231864929, Test R²=0.6288122087717056
2024-10-31 14:01:09,920 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:01:09,921 - INFO - Trial 217 finished with value: 2.263847231864929 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7703006661615954, 'learning_rate': 0.0018604153118710403, 'weight_decay': 0.000285099863808316, 'batch_size': 1024, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:01:51,070 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7611113771797584, 'learning_rate': 0.0025080933374040386, 'weight_decay': 0.00034124462249438366, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:01:51,070 - INFO - Trial 218: Train MSE=1.8264686933585577, Train R²=0.6961803351129804
2024-10-31 14:01:51,071 - INFO - Trial 218: Test MSE=2.2340905496052335, Test R²=0.636398698602404
2024-10-31 14:01:51,071 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:01:51,072 - INFO - Trial 218 finished with value: 2.2340905496052335 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7611113771797584, 'learning_rate': 0.0025080933374040386, 'weight_decay': 0.00034124462249438366, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:02:30,671 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7915127902104762, 'learning_rate': 0.0016611893507762806, 'weight_decay': 0.0003660953089093344, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:02:30,672 - INFO - Trial 219: Train MSE=2.22218890275274, Train R²=0.6303623488971165
2024-10-31 14:02:30,672 - INFO - Trial 219: Test MSE=2.2282657963888988, Test R²=0.6372856327465602
2024-10-31 14:02:30,672 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:02:30,673 - INFO - Trial 219 finished with value: 2.2282657963888988 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7915127902104762, 'learning_rate': 0.0016611893507762806, 'weight_decay': 0.0003660953089093344, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:03:03,345 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.77751828081481, 'learning_rate': 0.0021988559626187395, 'weight_decay': 0.00022153873088772322, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:03:03,345 - INFO - Trial 220: Train MSE=2.4714652470179965, Train R²=0.5886105469294957
2024-10-31 14:03:03,346 - INFO - Trial 220: Test MSE=2.286024740764073, Test R²=0.6279199378831046
2024-10-31 14:03:03,346 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:03:03,347 - INFO - Trial 220 finished with value: 2.286024740764073 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.77751828081481, 'learning_rate': 0.0021988559626187395, 'weight_decay': 0.00022153873088772322, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:03:35,503 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7874507470832011, 'learning_rate': 0.0013125533456225232, 'weight_decay': 0.0003024692470949272, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:03:35,503 - INFO - Trial 221: Train MSE=2.1968275351183757, Train R²=0.6344376355409622
2024-10-31 14:03:35,503 - INFO - Trial 221: Test MSE=2.2437547274998257, Test R²=0.6346744980130877
2024-10-31 14:03:35,503 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:03:35,504 - INFO - Trial 221 finished with value: 2.2437547274998257 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7874507470832011, 'learning_rate': 0.0013125533456225232, 'weight_decay': 0.0003024692470949272, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:04:17,286 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.799824296997185, 'learning_rate': 0.008394827436096926, 'weight_decay': 0.0003145770465594066, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:04:17,287 - INFO - Trial 222: Train MSE=2.118679485150746, Train R²=0.6469922895942416
2024-10-31 14:04:17,287 - INFO - Trial 222: Test MSE=2.242599844932556, Test R²=0.6349187578473773
2024-10-31 14:04:17,287 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:04:17,289 - INFO - Trial 222 finished with value: 2.242599844932556 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.799824296997185, 'learning_rate': 0.008394827436096926, 'weight_decay': 0.0003145770465594066, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:04:56,693 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7838802461904029, 'learning_rate': 0.00144069803230997, 'weight_decay': 0.0002974740950382131, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:04:56,693 - INFO - Trial 223: Train MSE=2.218133785894939, Train R²=0.6310518490416663
2024-10-31 14:04:56,693 - INFO - Trial 223: Test MSE=2.243441036769322, Test R²=0.6346930435725621
2024-10-31 14:04:56,693 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:04:56,695 - INFO - Trial 223 finished with value: 2.243441036769322 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7838802461904029, 'learning_rate': 0.00144069803230997, 'weight_decay': 0.0002974740950382131, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:05:34,783 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7756027234787671, 'learning_rate': 0.0006200808154952465, 'weight_decay': 0.00011871277165195598, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:05:34,783 - INFO - Trial 224: Train MSE=2.7716723339898244, Train R²=0.5377315155097416
2024-10-31 14:05:34,783 - INFO - Trial 224: Test MSE=2.249338388442993, Test R²=0.633902268750327
2024-10-31 14:05:34,783 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:05:34,784 - INFO - Trial 224 finished with value: 2.249338388442993 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7756027234787671, 'learning_rate': 0.0006200808154952465, 'weight_decay': 0.00011871277165195598, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:06:06,927 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7907803208533964, 'learning_rate': 0.009841748206761449, 'weight_decay': 0.0003103620358164864, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:06:06,927 - INFO - Trial 225: Train MSE=2.173363459961755, Train R²=0.6386242040566036
2024-10-31 14:06:06,928 - INFO - Trial 225: Test MSE=2.242883937699454, Test R²=0.6351375324385506
2024-10-31 14:06:06,928 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:06:06,929 - INFO - Trial 225 finished with value: 2.242883937699454 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7907803208533964, 'learning_rate': 0.009841748206761449, 'weight_decay': 0.0003103620358164864, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:06:36,818 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7686757148373127, 'learning_rate': 0.0011902238287934278, 'weight_decay': 0.0003335632333355751, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:06:36,818 - INFO - Trial 226: Train MSE=2.144901522568294, Train R²=0.6427351172481265
2024-10-31 14:06:36,818 - INFO - Trial 226: Test MSE=2.2705884660993303, Test R²=0.6303530250276838
2024-10-31 14:06:36,818 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:06:36,820 - INFO - Trial 226 finished with value: 2.2705884660993303 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7686757148373127, 'learning_rate': 0.0011902238287934278, 'weight_decay': 0.0003335632333355751, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:07:13,812 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7830577124842849, 'learning_rate': 0.0018423892598842747, 'weight_decay': 0.0002703322925639368, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:07:13,813 - INFO - Trial 227: Train MSE=2.049632123538426, Train R²=0.6586321996791022
2024-10-31 14:07:13,813 - INFO - Trial 227: Test MSE=2.2310986859457835, Test R²=0.6369059341294425
2024-10-31 14:07:13,813 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:07:13,814 - INFO - Trial 227 finished with value: 2.2310986859457835 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7830577124842849, 'learning_rate': 0.0018423892598842747, 'weight_decay': 0.0002703322925639368, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:07:52,963 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7504838899400165, 'learning_rate': 0.0009680028876214508, 'weight_decay': 0.00028774973432765246, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:07:52,963 - INFO - Trial 228: Train MSE=2.1358360605580464, Train R²=0.6444845838206155
2024-10-31 14:07:52,963 - INFO - Trial 228: Test MSE=2.28370932170323, Test R²=0.6282516632761274
2024-10-31 14:07:52,963 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:07:52,964 - INFO - Trial 228 finished with value: 2.28370932170323 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7504838899400165, 'learning_rate': 0.0009680028876214508, 'weight_decay': 0.00028774973432765246, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:08:47,713 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7899421288290024, 'learning_rate': 0.0012783401071930014, 'weight_decay': 0.000321292934834507, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 14:08:47,713 - INFO - Trial 229: Train MSE=2.001468409385, Train R²=0.6663055377347129
2024-10-31 14:08:47,714 - INFO - Trial 229: Test MSE=2.2694715006010875, Test R²=0.6287057186876025
2024-10-31 14:08:47,714 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:08:47,715 - INFO - Trial 229 finished with value: 2.2694715006010875 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7899421288290024, 'learning_rate': 0.0012783401071930014, 'weight_decay': 0.000321292934834507, 'batch_size': 256, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:09:30,891 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7760411082994154, 'learning_rate': 0.0015548364307240215, 'weight_decay': 0.00030008925824136803, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:09:30,891 - INFO - Trial 230: Train MSE=1.777481632573264, Train R²=0.7036315543310983
2024-10-31 14:09:30,891 - INFO - Trial 230: Test MSE=2.3470681735447476, Test R²=0.6180514437811715
2024-10-31 14:09:30,891 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:09:30,892 - INFO - Trial 230 finished with value: 2.3470681735447476 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7760411082994154, 'learning_rate': 0.0015548364307240215, 'weight_decay': 0.00030008925824136803, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:10:06,755 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7931499364716077, 'learning_rate': 0.0017076848668314951, 'weight_decay': 0.00036889701533448886, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:10:06,756 - INFO - Trial 231: Train MSE=2.203471226351602, Train R²=0.6324136917080198
2024-10-31 14:10:06,756 - INFO - Trial 231: Test MSE=2.259873492377145, Test R²=0.6319954480443682
2024-10-31 14:10:06,756 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:10:06,757 - INFO - Trial 231 finished with value: 2.259873492377145 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7931499364716077, 'learning_rate': 0.0017076848668314951, 'weight_decay': 0.00036889701533448886, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:10:45,308 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7919510298766786, 'learning_rate': 0.001717360658646486, 'weight_decay': 0.00035363261772628206, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:10:45,308 - INFO - Trial 232: Train MSE=2.1795428778444017, Train R²=0.6371863377945763
2024-10-31 14:10:45,308 - INFO - Trial 232: Test MSE=2.2332280022757396, Test R²=0.6365057740892682
2024-10-31 14:10:45,308 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:10:45,310 - INFO - Trial 232 finished with value: 2.2332280022757396 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7919510298766786, 'learning_rate': 0.001717360658646486, 'weight_decay': 0.00035363261772628206, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:11:24,360 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7996184569233542, 'learning_rate': 0.0014604379701983964, 'weight_decay': 0.00038607684286913436, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:11:24,360 - INFO - Trial 233: Train MSE=2.320723933832986, Train R²=0.6130822449922562
2024-10-31 14:11:24,361 - INFO - Trial 233: Test MSE=2.232090098517282, Test R²=0.6367064544132778
2024-10-31 14:11:24,361 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:11:24,364 - INFO - Trial 233 finished with value: 2.232090098517282 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7996184569233542, 'learning_rate': 0.0014604379701983964, 'weight_decay': 0.00038607684286913436, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:11:58,465 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7825402694294568, 'learning_rate': 0.008876966166147615, 'weight_decay': 0.0004059696093533778, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:11:58,465 - INFO - Trial 234: Train MSE=2.1562401482037137, Train R²=0.6411406376532146
2024-10-31 14:11:58,465 - INFO - Trial 234: Test MSE=2.22696966784341, Test R²=0.63751163652965
2024-10-31 14:11:58,465 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:11:58,466 - INFO - Trial 234 finished with value: 2.22696966784341 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7825402694294568, 'learning_rate': 0.008876966166147615, 'weight_decay': 0.0004059696093533778, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:12:38,780 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7818381671699486, 'learning_rate': 0.00848719306135097, 'weight_decay': 0.0004130002331616737, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:12:38,780 - INFO - Trial 235: Train MSE=2.1647919757025584, Train R²=0.6391913039343697
2024-10-31 14:12:38,781 - INFO - Trial 235: Test MSE=2.2706442219870433, Test R²=0.6303758195468357
2024-10-31 14:12:38,781 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:12:38,782 - INFO - Trial 235 finished with value: 2.2706442219870433 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7818381671699486, 'learning_rate': 0.00848719306135097, 'weight_decay': 0.0004130002331616737, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:13:09,269 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7615573849395035, 'learning_rate': 0.009979602553234655, 'weight_decay': 0.0003450008383305206, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:13:09,269 - INFO - Trial 236: Train MSE=2.110330820083618, Train R²=0.648994471345629
2024-10-31 14:13:09,269 - INFO - Trial 236: Test MSE=2.2546347209385464, Test R²=0.6330965331622532
2024-10-31 14:13:09,269 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:13:09,271 - INFO - Trial 236 finished with value: 2.2546347209385464 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7615573849395035, 'learning_rate': 0.009979602553234655, 'weight_decay': 0.0003450008383305206, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:14:21,372 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7731243847598668, 'learning_rate': 0.009055762956451434, 'weight_decay': 0.00031431047757588524, 'batch_size': 128, 'tree_depth': 12}
2024-10-31 14:14:21,372 - INFO - Trial 237: Train MSE=2.6718297749757767, Train R²=0.5488265140780381
2024-10-31 14:14:21,372 - INFO - Trial 237: Test MSE=2.3270218585218703, Test R²=0.6134314515760967
2024-10-31 14:14:21,372 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:14:21,374 - INFO - Trial 237 finished with value: 2.3270218585218703 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7731243847598668, 'learning_rate': 0.009055762956451434, 'weight_decay': 0.00031431047757588524, 'batch_size': 128, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:15:01,648 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7819154804322677, 'learning_rate': 0.007127252117056729, 'weight_decay': 0.00032975986625059794, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:15:01,649 - INFO - Trial 238: Train MSE=2.0810387091977254, Train R²=0.654641255736351
2024-10-31 14:15:01,649 - INFO - Trial 238: Test MSE=2.2782870701381137, Test R²=0.6292029534067426
2024-10-31 14:15:01,649 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:15:01,651 - INFO - Trial 238 finished with value: 2.2782870701381137 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7819154804322677, 'learning_rate': 0.007127252117056729, 'weight_decay': 0.00032975986625059794, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:15:43,285 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7645413864774674, 'learning_rate': 0.00814028141861586, 'weight_decay': 0.00040019990369521177, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:15:43,285 - INFO - Trial 239: Train MSE=2.0638913895402635, Train R²=0.6563287228345871
2024-10-31 14:15:43,285 - INFO - Trial 239: Test MSE=2.2618487562452043, Test R²=0.6318392753601074
2024-10-31 14:15:43,285 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:15:43,287 - INFO - Trial 239 finished with value: 2.2618487562452043 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7645413864774674, 'learning_rate': 0.00814028141861586, 'weight_decay': 0.00040019990369521177, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:16:23,362 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7894031801252345, 'learning_rate': 0.0010936491768132283, 'weight_decay': 0.00030576140901552207, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:16:23,362 - INFO - Trial 240: Train MSE=2.369579178946359, Train R²=0.6057053272213254
2024-10-31 14:16:23,362 - INFO - Trial 240: Test MSE=2.205315487725394, Test R²=0.6410455363137382
2024-10-31 14:16:23,362 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:16:23,364 - INFO - Trial 240 finished with value: 2.205315487725394 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7894031801252345, 'learning_rate': 0.0010936491768132283, 'weight_decay': 0.00030576140901552207, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:17:06,106 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902731224553816, 'learning_rate': 0.0010683713857874378, 'weight_decay': 0.0003060519099325379, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:17:06,106 - INFO - Trial 241: Train MSE=2.262588475431715, Train R²=0.6238639737878527
2024-10-31 14:17:06,107 - INFO - Trial 241: Test MSE=2.211419871875218, Test R²=0.6399835348129272
2024-10-31 14:17:06,107 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:17:06,107 - INFO - Trial 241 finished with value: 2.211419871875218 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902731224553816, 'learning_rate': 0.0010683713857874378, 'weight_decay': 0.0003060519099325379, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:17:44,562 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7920597228438828, 'learning_rate': 0.0009962707000992926, 'weight_decay': 0.0002888982891093066, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:17:44,562 - INFO - Trial 242: Train MSE=2.4914146661758423, Train R²=0.5846280178853444
2024-10-31 14:17:44,562 - INFO - Trial 242: Test MSE=2.207803879465376, Test R²=0.6406415700912476
2024-10-31 14:17:44,562 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:17:44,563 - INFO - Trial 242 finished with value: 2.207803879465376 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7920597228438828, 'learning_rate': 0.0009962707000992926, 'weight_decay': 0.0002888982891093066, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:18:27,865 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7766925573765739, 'learning_rate': 0.0010235727450770532, 'weight_decay': 0.00032068163214422137, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:18:27,866 - INFO - Trial 243: Train MSE=2.3320091707365855, Train R²=0.61122727394104
2024-10-31 14:18:27,866 - INFO - Trial 243: Test MSE=2.239066175052098, Test R²=0.6356027552059719
2024-10-31 14:18:27,866 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:18:27,867 - INFO - Trial 243 finished with value: 2.239066175052098 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7766925573765739, 'learning_rate': 0.0010235727450770532, 'weight_decay': 0.00032068163214422137, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:19:04,176 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7893877425542603, 'learning_rate': 0.0009284503361065259, 'weight_decay': 0.00027815490966815354, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:19:04,176 - INFO - Trial 244: Train MSE=2.459108965737479, Train R²=0.5906815656593868
2024-10-31 14:19:04,177 - INFO - Trial 244: Test MSE=2.249708022390093, Test R²=0.6337740165846688
2024-10-31 14:19:04,177 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:19:04,178 - INFO - Trial 244 finished with value: 2.249708022390093 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7893877425542603, 'learning_rate': 0.0009284503361065259, 'weight_decay': 0.00027815490966815354, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:19:46,521 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7819494107468521, 'learning_rate': 0.0008186939460102119, 'weight_decay': 0.0002970496166753432, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:19:46,521 - INFO - Trial 245: Train MSE=2.497953849179404, Train R²=0.5839005815131324
2024-10-31 14:19:46,521 - INFO - Trial 245: Test MSE=2.239493114607675, Test R²=0.6355375562395368
2024-10-31 14:19:46,521 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:19:46,523 - INFO - Trial 245 finished with value: 2.239493114607675 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7819494107468521, 'learning_rate': 0.0008186939460102119, 'weight_decay': 0.0002970496166753432, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:20:23,078 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7721450035904197, 'learning_rate': 0.0010824260379000948, 'weight_decay': 0.0003378803509578769, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:20:23,078 - INFO - Trial 246: Train MSE=2.206098054136549, Train R²=0.6335319301911763
2024-10-31 14:20:23,078 - INFO - Trial 246: Test MSE=2.2323472840445384, Test R²=0.6367160763059344
2024-10-31 14:20:23,078 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:20:23,079 - INFO - Trial 246 finished with value: 2.2323472840445384 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7721450035904197, 'learning_rate': 0.0010824260379000948, 'weight_decay': 0.0003378803509578769, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:21:00,551 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7912726927859254, 'learning_rate': 0.0009955497587735463, 'weight_decay': 0.0003104054397008536, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:21:00,551 - INFO - Trial 247: Train MSE=2.4390909331185475, Train R²=0.5930486896208355
2024-10-31 14:21:00,551 - INFO - Trial 247: Test MSE=2.266057712691171, Test R²=0.6312976053782872
2024-10-31 14:21:00,551 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:21:00,553 - INFO - Trial 247 finished with value: 2.266057712691171 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7912726927859254, 'learning_rate': 0.0009955497587735463, 'weight_decay': 0.0003104054397008536, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:21:32,799 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7827329977545616, 'learning_rate': 0.008953361513897824, 'weight_decay': 0.00028870891391407174, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:21:32,799 - INFO - Trial 248: Train MSE=2.0234948779855455, Train R²=0.6635910315173013
2024-10-31 14:21:32,800 - INFO - Trial 248: Test MSE=2.231624126434326, Test R²=0.636686418737684
2024-10-31 14:21:32,800 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:21:32,804 - INFO - Trial 248 finished with value: 2.231624126434326 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7827329977545616, 'learning_rate': 0.008953361513897824, 'weight_decay': 0.00028870891391407174, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:22:11,642 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7993850019815616, 'learning_rate': 0.0011451951366110353, 'weight_decay': 0.00025810039330946604, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:22:11,643 - INFO - Trial 249: Train MSE=3.087042357240404, Train R²=0.48571238986083437
2024-10-31 14:22:11,643 - INFO - Trial 249: Test MSE=2.2604301316397533, Test R²=0.6321469289915902
2024-10-31 14:22:11,643 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:22:11,644 - INFO - Trial 249 finished with value: 2.2604301316397533 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7993850019815616, 'learning_rate': 0.0011451951366110353, 'weight_decay': 0.00025810039330946604, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:22:49,716 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7695166315479577, 'learning_rate': 0.0008472830045906141, 'weight_decay': 0.00017447479567777392, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:22:49,716 - INFO - Trial 250: Train MSE=2.3121023092951094, Train R²=0.6145557484456471
2024-10-31 14:22:49,716 - INFO - Trial 250: Test MSE=2.232231225286211, Test R²=0.6367234417370388
2024-10-31 14:22:49,716 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:22:49,718 - INFO - Trial 250 finished with value: 2.232231225286211 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7695166315479577, 'learning_rate': 0.0008472830045906141, 'weight_decay': 0.00017447479567777392, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:23:24,076 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7899508427164685, 'learning_rate': 0.0012261823222937008, 'weight_decay': 0.0003291215033220515, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:23:24,076 - INFO - Trial 251: Train MSE=2.2561358213424683, Train R²=0.6233336201735905
2024-10-31 14:23:24,076 - INFO - Trial 251: Test MSE=2.211742264883859, Test R²=0.6401325123650687
2024-10-31 14:23:24,076 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:23:24,077 - INFO - Trial 251 finished with value: 2.211742264883859 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7899508427164685, 'learning_rate': 0.0012261823222937008, 'weight_decay': 0.0003291215033220515, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:24:13,452 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7913145855512557, 'learning_rate': 0.0011932444057581374, 'weight_decay': 0.00032709110279826106, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 14:24:13,452 - INFO - Trial 252: Train MSE=2.028482049703598, Train R²=0.6605770321828979
2024-10-31 14:24:13,452 - INFO - Trial 252: Test MSE=2.2660785061972484, Test R²=0.6292558269841331
2024-10-31 14:24:13,452 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:24:13,453 - INFO - Trial 252 finished with value: 2.2660785061972484 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7913145855512557, 'learning_rate': 0.0011932444057581374, 'weight_decay': 0.00032709110279826106, 'batch_size': 256, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:24:51,157 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.789900375949423, 'learning_rate': 0.0013045933470463838, 'weight_decay': 0.00030133334645551194, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:24:51,157 - INFO - Trial 253: Train MSE=1.807823704821723, Train R²=0.6985730848142079
2024-10-31 14:24:51,157 - INFO - Trial 253: Test MSE=2.257737295968192, Test R²=0.6324978470802307
2024-10-31 14:24:51,157 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:24:51,159 - INFO - Trial 253 finished with value: 2.257737295968192 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.789900375949423, 'learning_rate': 0.0013045933470463838, 'weight_decay': 0.00030133334645551194, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:25:19,133 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7757976906842453, 'learning_rate': 0.0010564578301078223, 'weight_decay': 0.00031453043604469784, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 14:25:19,134 - INFO - Trial 254: Train MSE=2.77305155141013, Train R²=0.5394834109715053
2024-10-31 14:25:19,134 - INFO - Trial 254: Test MSE=2.260608196258545, Test R²=0.6294194608926773
2024-10-31 14:25:19,134 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:25:19,135 - INFO - Trial 254 finished with value: 2.260608196258545 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7757976906842453, 'learning_rate': 0.0010564578301078223, 'weight_decay': 0.00031453043604469784, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:25:53,436 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7995122864266795, 'learning_rate': 0.0009462585414815267, 'weight_decay': 0.0002821211264140643, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:25:53,436 - INFO - Trial 255: Train MSE=3.1417715634618486, Train R²=0.477296199117388
2024-10-31 14:25:53,436 - INFO - Trial 255: Test MSE=2.295411995479039, Test R²=0.6264267989567348
2024-10-31 14:25:53,436 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:25:53,438 - INFO - Trial 255 finished with value: 2.295411995479039 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7995122864266795, 'learning_rate': 0.0009462585414815267, 'weight_decay': 0.0002821211264140643, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:26:28,362 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5882977112059433, 'learning_rate': 0.0036535376355622635, 'weight_decay': 0.0003399881918483534, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:26:28,362 - INFO - Trial 256: Train MSE=1.13605740240642, Train R²=0.8106634851012912
2024-10-31 14:26:28,362 - INFO - Trial 256: Test MSE=2.3350514343806674, Test R²=0.6197178108351571
2024-10-31 14:26:28,362 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:26:28,363 - INFO - Trial 256 finished with value: 2.3350514343806674 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5882977112059433, 'learning_rate': 0.0036535376355622635, 'weight_decay': 0.0003399881918483534, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:27:03,748 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7611705419737819, 'learning_rate': 0.0012501447979256627, 'weight_decay': 0.0002692418316568665, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:27:03,749 - INFO - Trial 257: Train MSE=2.061615909848894, Train R²=0.6569511017629078
2024-10-31 14:27:03,749 - INFO - Trial 257: Test MSE=2.230088915143694, Test R²=0.6369145427431379
2024-10-31 14:27:03,749 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:27:03,750 - INFO - Trial 257 finished with value: 2.230088915143694 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7611705419737819, 'learning_rate': 0.0012501447979256627, 'weight_decay': 0.0002692418316568665, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:27:40,938 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7828759290415652, 'learning_rate': 0.0013766709673173555, 'weight_decay': 0.00032432677197847886, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:27:40,939 - INFO - Trial 258: Train MSE=2.165830820798874, Train R²=0.6385820763451713
2024-10-31 14:27:40,939 - INFO - Trial 258: Test MSE=2.2330487966537476, Test R²=0.6365885819707598
2024-10-31 14:27:40,940 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:27:40,941 - INFO - Trial 258 finished with value: 2.2330487966537476 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7828759290415652, 'learning_rate': 0.0013766709673173555, 'weight_decay': 0.00032432677197847886, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:28:17,815 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7702781895259979, 'learning_rate': 0.0011149113469978598, 'weight_decay': 0.0003039350163222974, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:28:17,815 - INFO - Trial 259: Train MSE=2.246490938322885, Train R²=0.6263044817107064
2024-10-31 14:28:17,815 - INFO - Trial 259: Test MSE=2.2422830377306258, Test R²=0.6349885293415615
2024-10-31 14:28:17,816 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:28:17,817 - INFO - Trial 259 finished with value: 2.2422830377306258 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7702781895259979, 'learning_rate': 0.0011149113469978598, 'weight_decay': 0.0003039350163222974, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:28:54,736 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7874429782138885, 'learning_rate': 0.00042433684815638674, 'weight_decay': 0.00035123861431803636, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:28:54,736 - INFO - Trial 260: Train MSE=3.325757009642465, Train R²=0.44701375705855234
2024-10-31 14:28:54,736 - INFO - Trial 260: Test MSE=2.387437582015991, Test R²=0.6114882486207145
2024-10-31 14:28:54,736 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:28:54,740 - INFO - Trial 260 finished with value: 2.387437582015991 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7874429782138885, 'learning_rate': 0.00042433684815638674, 'weight_decay': 0.00035123861431803636, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:29:28,891 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7553865245664733, 'learning_rate': 0.0010404930253204727, 'weight_decay': 0.0001544473738985297, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 14:29:28,891 - INFO - Trial 261: Train MSE=2.670979772295271, Train R²=0.5543557895081384
2024-10-31 14:29:28,891 - INFO - Trial 261: Test MSE=2.268834182194301, Test R²=0.6306495666503906
2024-10-31 14:29:28,891 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:29:28,893 - INFO - Trial 261 finished with value: 2.268834182194301 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7553865245664733, 'learning_rate': 0.0010404930253204727, 'weight_decay': 0.0001544473738985297, 'batch_size': 512, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:30:03,945 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5287659684147862, 'learning_rate': 0.0012007313626132253, 'weight_decay': 0.000241014744748256, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:30:03,945 - INFO - Trial 262: Train MSE=0.9542062772171838, Train R²=0.8407827019691467
2024-10-31 14:30:03,945 - INFO - Trial 262: Test MSE=2.430058002471924, Test R²=0.6044861504009792
2024-10-31 14:30:03,945 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:30:03,946 - INFO - Trial 262 finished with value: 2.430058002471924 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5287659684147862, 'learning_rate': 0.0012007313626132253, 'weight_decay': 0.000241014744748256, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:30:39,054 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7912616969827883, 'learning_rate': 0.0009355783985941697, 'weight_decay': 0.0002874596620870361, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:30:39,054 - INFO - Trial 263: Train MSE=2.160137491566794, Train R²=0.6406463874237878
2024-10-31 14:30:39,054 - INFO - Trial 263: Test MSE=2.2530863285064697, Test R²=0.6331769483430045
2024-10-31 14:30:39,054 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:30:39,055 - INFO - Trial 263 finished with value: 2.2530863285064697 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7912616969827883, 'learning_rate': 0.0009355783985941697, 'weight_decay': 0.0002874596620870361, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:31:12,065 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998246561649098, 'learning_rate': 0.0007220162834278009, 'weight_decay': 0.0003131746846211282, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:31:12,065 - INFO - Trial 264: Train MSE=2.71361175605229, Train R²=0.5488109056438718
2024-10-31 14:31:12,066 - INFO - Trial 264: Test MSE=2.2335491350718906, Test R²=0.6365000350134713
2024-10-31 14:31:12,066 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:31:12,068 - INFO - Trial 264 finished with value: 2.2335491350718906 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998246561649098, 'learning_rate': 0.0007220162834278009, 'weight_decay': 0.0003131746846211282, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:31:59,278 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7759910549930852, 'learning_rate': 0.001373148144713501, 'weight_decay': 0.0003314312038659845, 'batch_size': 256, 'tree_depth': 12}
2024-10-31 14:31:59,278 - INFO - Trial 265: Train MSE=1.8945576463426863, Train R²=0.6832976735063961
2024-10-31 14:31:59,278 - INFO - Trial 265: Test MSE=2.2621824996812, Test R²=0.6294733711651394
2024-10-31 14:31:59,279 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:31:59,280 - INFO - Trial 265 finished with value: 2.2621824996812 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7759910549930852, 'learning_rate': 0.001373148144713501, 'weight_decay': 0.0003314312038659845, 'batch_size': 256, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:33:15,542 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7643339216337499, 'learning_rate': 0.0011114442308786747, 'weight_decay': 0.0003003441039489181, 'batch_size': 128, 'tree_depth': 12}
2024-10-31 14:33:15,542 - INFO - Trial 266: Train MSE=1.7145900108984538, Train R²=0.7117738010627883
2024-10-31 14:33:15,542 - INFO - Trial 266: Test MSE=2.293543577194214, Test R²=0.620099099619048
2024-10-31 14:33:15,542 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:33:15,544 - INFO - Trial 266 finished with value: 2.293543577194214 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7643339216337499, 'learning_rate': 0.0011114442308786747, 'weight_decay': 0.0003003441039489181, 'batch_size': 128, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:33:48,903 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7824173670087472, 'learning_rate': 0.0005491900486519997, 'weight_decay': 0.0002289947205569662, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:33:48,903 - INFO - Trial 267: Train MSE=2.9968550886426653, Train R²=0.500798476593835
2024-10-31 14:33:48,903 - INFO - Trial 267: Test MSE=2.2912117753710066, Test R²=0.627132168837956
2024-10-31 14:33:48,903 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:33:48,905 - INFO - Trial 267 finished with value: 2.2912117753710066 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7824173670087472, 'learning_rate': 0.0005491900486519997, 'weight_decay': 0.0002289947205569662, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:34:22,416 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7908181677499604, 'learning_rate': 0.002021588859092198, 'weight_decay': 0.00032132582886131456, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:34:22,416 - INFO - Trial 268: Train MSE=2.085411242076329, Train R²=0.6532222905329296
2024-10-31 14:34:22,416 - INFO - Trial 268: Test MSE=2.2379387617111206, Test R²=0.6357392924172538
2024-10-31 14:34:22,416 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:34:22,417 - INFO - Trial 268 finished with value: 2.2379387617111206 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7908181677499604, 'learning_rate': 0.002021588859092198, 'weight_decay': 0.00032132582886131456, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:34:55,400 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7750971448618882, 'learning_rate': 0.000866514436604398, 'weight_decay': 0.00027611617749526417, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:34:55,401 - INFO - Trial 269: Train MSE=2.8864365901265825, Train R²=0.5192396832363946
2024-10-31 14:34:55,401 - INFO - Trial 269: Test MSE=2.2377511092594693, Test R²=0.6357458404132298
2024-10-31 14:34:55,401 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:34:55,402 - INFO - Trial 269 finished with value: 2.2377511092594693 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7750971448618882, 'learning_rate': 0.000866514436604398, 'weight_decay': 0.00027611617749526417, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:35:30,076 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7998921223015502, 'learning_rate': 0.006844736014675733, 'weight_decay': 0.0003442994093010978, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:35:30,077 - INFO - Trial 270: Train MSE=2.2692476383277347, Train R²=0.6226562687328884
2024-10-31 14:35:30,077 - INFO - Trial 270: Test MSE=2.2937137229102, Test R²=0.6265778541564941
2024-10-31 14:35:30,077 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:35:30,078 - INFO - Trial 270 finished with value: 2.2937137229102 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7998921223015502, 'learning_rate': 0.006844736014675733, 'weight_decay': 0.0003442994093010978, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:36:02,273 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.782021700707502, 'learning_rate': 0.0012397360651961499, 'weight_decay': 0.0002556311424051837, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:36:02,273 - INFO - Trial 271: Train MSE=2.213414111307689, Train R²=0.6319164293152946
2024-10-31 14:36:02,273 - INFO - Trial 271: Test MSE=2.238250800541469, Test R²=0.6356343967573983
2024-10-31 14:36:02,274 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:36:02,275 - INFO - Trial 271 finished with value: 2.238250800541469 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.782021700707502, 'learning_rate': 0.0012397360651961499, 'weight_decay': 0.0002556311424051837, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:36:35,745 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7687870852954353, 'learning_rate': 0.007960118268532811, 'weight_decay': 0.00029128426302068, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:36:35,745 - INFO - Trial 272: Train MSE=1.98371399300439, Train R²=0.6696095892361232
2024-10-31 14:36:35,745 - INFO - Trial 272: Test MSE=2.2681277138846263, Test R²=0.6305355685097831
2024-10-31 14:36:35,745 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:36:35,746 - INFO - Trial 272 finished with value: 2.2681277138846263 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7687870852954353, 'learning_rate': 0.007960118268532811, 'weight_decay': 0.00029128426302068, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:37:10,046 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7505168384224971, 'learning_rate': 0.0010023250809285294, 'weight_decay': 0.0002124360453142366, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:37:10,046 - INFO - Trial 273: Train MSE=2.043136958565031, Train R²=0.6603858598640987
2024-10-31 14:37:10,046 - INFO - Trial 273: Test MSE=2.245595710618155, Test R²=0.63437648330416
2024-10-31 14:37:10,046 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:37:10,047 - INFO - Trial 273 finished with value: 2.245595710618155 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7505168384224971, 'learning_rate': 0.0010023250809285294, 'weight_decay': 0.0002124360453142366, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:37:42,713 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7917442157381834, 'learning_rate': 0.0013569464841806387, 'weight_decay': 0.00030885976671120324, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:37:42,713 - INFO - Trial 274: Train MSE=2.3058442643710544, Train R²=0.6161621234246663
2024-10-31 14:37:42,714 - INFO - Trial 274: Test MSE=2.2518880707877025, Test R²=0.633493993963514
2024-10-31 14:37:42,714 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:37:42,717 - INFO - Trial 274 finished with value: 2.2518880707877025 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7917442157381834, 'learning_rate': 0.0013569464841806387, 'weight_decay': 0.00030885976671120324, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:38:15,650 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.3311216556304318, 'learning_rate': 0.0015046480018039068, 'weight_decay': 0.0003582738362795505, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 14:38:15,650 - INFO - Trial 275: Train MSE=0.5652177940521922, Train R²=0.9057534847940717
2024-10-31 14:38:15,650 - INFO - Trial 275: Test MSE=2.5016941683632985, Test R²=0.5927599157605853
2024-10-31 14:38:15,650 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:38:15,651 - INFO - Trial 275 finished with value: 2.5016941683632985 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.3311216556304318, 'learning_rate': 0.0015046480018039068, 'weight_decay': 0.0003582738362795505, 'batch_size': 512, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:38:49,122 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7818955561390791, 'learning_rate': 0.00240606419249386, 'weight_decay': 0.0003308650633546087, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:38:49,122 - INFO - Trial 276: Train MSE=2.5130482145718167, Train R²=0.5809590241738728
2024-10-31 14:38:49,123 - INFO - Trial 276: Test MSE=2.24042432648795, Test R²=0.6352784889084953
2024-10-31 14:38:49,123 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:38:49,125 - INFO - Trial 276 finished with value: 2.24042432648795 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7818955561390791, 'learning_rate': 0.00240606419249386, 'weight_decay': 0.0003308650633546087, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:39:15,980 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7661621937238419, 'learning_rate': 0.002759071007597807, 'weight_decay': 0.0003156546472454421, 'batch_size': 1024, 'tree_depth': 12}
2024-10-31 14:39:15,980 - INFO - Trial 277: Train MSE=2.0590569036347524, Train R²=0.6574164628982544
2024-10-31 14:39:15,980 - INFO - Trial 277: Test MSE=2.2525383830070496, Test R²=0.6307179629802704
2024-10-31 14:39:15,980 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:39:15,984 - INFO - Trial 277 finished with value: 2.2525383830070496 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7661621937238419, 'learning_rate': 0.002759071007597807, 'weight_decay': 0.0003156546472454421, 'batch_size': 1024, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:39:52,051 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.6181049511834312, 'learning_rate': 0.0011444388235316563, 'weight_decay': 0.00010064116826712129, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:39:52,051 - INFO - Trial 278: Train MSE=1.0692902590547289, Train R²=0.8216568848916462
2024-10-31 14:39:52,051 - INFO - Trial 278: Test MSE=2.359910862786429, Test R²=0.615546635219029
2024-10-31 14:39:52,051 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:39:52,052 - INFO - Trial 278 finished with value: 2.359910862786429 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.6181049511834312, 'learning_rate': 0.0011444388235316563, 'weight_decay': 0.00010064116826712129, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:40:43,301 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7894289704127617, 'learning_rate': 0.0018648010129776976, 'weight_decay': 0.0002972926439943469, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 14:40:43,301 - INFO - Trial 279: Train MSE=2.1030678365911757, Train R²=0.6485534289053508
2024-10-31 14:40:43,301 - INFO - Trial 279: Test MSE=2.3290969048227583, Test R²=0.618721855538232
2024-10-31 14:40:43,301 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:40:43,303 - INFO - Trial 279 finished with value: 2.3290969048227583 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7894289704127617, 'learning_rate': 0.0018648010129776976, 'weight_decay': 0.0002972926439943469, 'batch_size': 256, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:41:17,358 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.4585295778162986, 'learning_rate': 0.009251667890493791, 'weight_decay': 0.0002634392112859406, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:41:17,358 - INFO - Trial 280: Train MSE=1.0876674417938506, Train R²=0.8183840789965221
2024-10-31 14:41:17,358 - INFO - Trial 280: Test MSE=2.428939001900809, Test R²=0.604541574205671
2024-10-31 14:41:17,358 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:41:17,360 - INFO - Trial 280 finished with value: 2.428939001900809 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.4585295778162986, 'learning_rate': 0.009251667890493791, 'weight_decay': 0.0002634392112859406, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:41:51,300 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7737348123216938, 'learning_rate': 0.007680299611341865, 'weight_decay': 0.0002807792942635797, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 14:41:51,301 - INFO - Trial 281: Train MSE=1.968130303280694, Train R²=0.6711371839046478
2024-10-31 14:41:51,301 - INFO - Trial 281: Test MSE=2.234921932220459, Test R²=0.636165337903159
2024-10-31 14:41:51,301 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:41:51,303 - INFO - Trial 281 finished with value: 2.234921932220459 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7737348123216938, 'learning_rate': 0.007680299611341865, 'weight_decay': 0.0002807792942635797, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:42:26,101 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7996327737008238, 'learning_rate': 0.0015918590929411293, 'weight_decay': 0.00034146520331776697, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:42:26,101 - INFO - Trial 282: Train MSE=2.297034182718822, Train R²=0.6171681008168629
2024-10-31 14:42:26,101 - INFO - Trial 282: Test MSE=2.2151220866612027, Test R²=0.6394928608621869
2024-10-31 14:42:26,101 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:42:26,103 - INFO - Trial 282 finished with value: 2.2151220866612027 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7996327737008238, 'learning_rate': 0.0015918590929411293, 'weight_decay': 0.00034146520331776697, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:43:01,834 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998053705597707, 'learning_rate': 0.0015745135004875627, 'weight_decay': 0.00037184342805963614, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:43:01,834 - INFO - Trial 283: Train MSE=2.2531740409987315, Train R²=0.624996760061809
2024-10-31 14:43:01,834 - INFO - Trial 283: Test MSE=2.2328585386276245, Test R²=0.6364909836224147
2024-10-31 14:43:01,834 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:43:01,836 - INFO - Trial 283 finished with value: 2.2328585386276245 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998053705597707, 'learning_rate': 0.0015745135004875627, 'weight_decay': 0.00037184342805963614, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:43:37,750 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7909770105716318, 'learning_rate': 0.0014206123355273406, 'weight_decay': 0.0003454343283722435, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:43:37,750 - INFO - Trial 284: Train MSE=2.2242497376033237, Train R²=0.6304336360522679
2024-10-31 14:43:37,750 - INFO - Trial 284: Test MSE=2.2386019911084856, Test R²=0.6355670349938529
2024-10-31 14:43:37,750 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:43:37,751 - INFO - Trial 284 finished with value: 2.2386019911084856 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7909770105716318, 'learning_rate': 0.0014206123355273406, 'weight_decay': 0.0003454343283722435, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:44:12,601 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7991246153008683, 'learning_rate': 0.0015538459228306562, 'weight_decay': 0.0003316053989197241, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:44:12,602 - INFO - Trial 285: Train MSE=2.2832779543740407, Train R²=0.6201667210885456
2024-10-31 14:44:12,602 - INFO - Trial 285: Test MSE=2.2347004073006764, Test R²=0.6362246870994568
2024-10-31 14:44:12,602 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:44:12,603 - INFO - Trial 285 finished with value: 2.2347004073006764 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7991246153008683, 'learning_rate': 0.0015538459228306562, 'weight_decay': 0.0003316053989197241, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:44:48,228 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7840402287768855, 'learning_rate': 0.0017540636413645508, 'weight_decay': 0.0003581856466812781, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:44:48,228 - INFO - Trial 286: Train MSE=2.098204868180411, Train R²=0.6512136672224317
2024-10-31 14:44:48,228 - INFO - Trial 286: Test MSE=2.243680340903146, Test R²=0.6349509273256574
2024-10-31 14:44:48,228 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:44:48,230 - INFO - Trial 286 finished with value: 2.243680340903146 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7840402287768855, 'learning_rate': 0.0017540636413645508, 'weight_decay': 0.0003581856466812781, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:45:23,038 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6844000870277694, 'learning_rate': 0.0002675449856021971, 'weight_decay': 0.000730492168535059, 'batch_size': 512, 'tree_depth': 7}
2024-10-31 14:45:23,038 - INFO - Trial 287: Train MSE=3.8520665849958147, Train R²=0.35946934138025555
2024-10-31 14:45:23,038 - INFO - Trial 287: Test MSE=2.350741284234183, Test R²=0.6174196175166539
2024-10-31 14:45:23,038 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:45:23,039 - INFO - Trial 287 finished with value: 2.350741284234183 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6844000870277694, 'learning_rate': 0.0002675449856021971, 'weight_decay': 0.000730492168535059, 'batch_size': 512, 'tree_depth': 7}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:45:58,917 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7914271231535389, 'learning_rate': 0.0012035406853033164, 'weight_decay': 0.000319213095461897, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:45:58,917 - INFO - Trial 288: Train MSE=2.357184035437448, Train R²=0.607375830411911
2024-10-31 14:45:58,917 - INFO - Trial 288: Test MSE=2.235733526093619, Test R²=0.6361566611698696
2024-10-31 14:45:58,918 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:45:58,918 - INFO - Trial 288 finished with value: 2.235733526093619 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7914271231535389, 'learning_rate': 0.0012035406853033164, 'weight_decay': 0.000319213095461897, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:46:34,756 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7803787836564167, 'learning_rate': 0.002165534705502201, 'weight_decay': 0.0003440431832983634, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:46:34,757 - INFO - Trial 289: Train MSE=2.000139968735831, Train R²=0.6666755654982158
2024-10-31 14:46:34,757 - INFO - Trial 289: Test MSE=2.210393054144723, Test R²=0.6403107728276934
2024-10-31 14:46:34,757 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:46:34,758 - INFO - Trial 289 finished with value: 2.210393054144723 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7803787836564167, 'learning_rate': 0.002165534705502201, 'weight_decay': 0.0003440431832983634, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:47:09,259 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7585685594631918, 'learning_rate': 0.002413134905849788, 'weight_decay': 0.00038109511707005696, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:47:09,260 - INFO - Trial 290: Train MSE=1.8276701995304652, Train R²=0.6957778270755496
2024-10-31 14:47:09,261 - INFO - Trial 290: Test MSE=2.252627577100481, Test R²=0.6333288039479937
2024-10-31 14:47:09,261 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:47:09,263 - INFO - Trial 290 finished with value: 2.252627577100481 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7585685594631918, 'learning_rate': 0.002413134905849788, 'weight_decay': 0.00038109511707005696, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:47:43,666 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.777155806927077, 'learning_rate': 0.0020750483282841567, 'weight_decay': 0.00010661490522943051, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:47:43,666 - INFO - Trial 291: Train MSE=1.9915892907551356, Train R²=0.6689786698137011
2024-10-31 14:47:43,666 - INFO - Trial 291: Test MSE=2.2536118711744035, Test R²=0.6333579080445426
2024-10-31 14:47:43,666 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:47:43,667 - INFO - Trial 291 finished with value: 2.2536118711744035 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.777155806927077, 'learning_rate': 0.0020750483282841567, 'weight_decay': 0.00010661490522943051, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:48:19,451 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7451827464337323, 'learning_rate': 0.0022371725061753073, 'weight_decay': 0.0003419697879918518, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:48:19,451 - INFO - Trial 292: Train MSE=1.5141416319778986, Train R²=0.7481215681348529
2024-10-31 14:48:19,451 - INFO - Trial 292: Test MSE=2.26219494002206, Test R²=0.6316838434764317
2024-10-31 14:48:19,451 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:48:19,451 - INFO - Trial 292 finished with value: 2.26219494002206 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7451827464337323, 'learning_rate': 0.0022371725061753073, 'weight_decay': 0.0003419697879918518, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:48:55,765 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7702833791181103, 'learning_rate': 0.002036117071123203, 'weight_decay': 0.00013094885018123139, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:48:55,765 - INFO - Trial 293: Train MSE=1.970639271395547, Train R²=0.6704668317522321
2024-10-31 14:48:55,765 - INFO - Trial 293: Test MSE=2.276818803378514, Test R²=0.6292273572513035
2024-10-31 14:48:55,765 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:48:55,767 - INFO - Trial 293 finished with value: 2.276818803378514 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7702833791181103, 'learning_rate': 0.002036117071123203, 'weight_decay': 0.00013094885018123139, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:49:30,810 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7846786520513244, 'learning_rate': 0.000762953448420325, 'weight_decay': 0.000360424900340677, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:49:30,810 - INFO - Trial 294: Train MSE=2.5819922855922153, Train R²=0.569907580103193
2024-10-31 14:49:30,810 - INFO - Trial 294: Test MSE=2.237565806933812, Test R²=0.6358422296387809
2024-10-31 14:49:30,810 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:49:30,811 - INFO - Trial 294 finished with value: 2.237565806933812 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7846786520513244, 'learning_rate': 0.000762953448420325, 'weight_decay': 0.000360424900340677, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:50:06,164 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7804551726802365, 'learning_rate': 0.0019459117373883806, 'weight_decay': 0.0001900818735259794, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:50:06,164 - INFO - Trial 295: Train MSE=2.049704985959189, Train R²=0.658069201878139
2024-10-31 14:50:06,164 - INFO - Trial 295: Test MSE=2.2211368083953857, Test R²=0.6384285518101284
2024-10-31 14:50:06,165 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:50:06,166 - INFO - Trial 295 finished with value: 2.2211368083953857 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7804551726802365, 'learning_rate': 0.0019459117373883806, 'weight_decay': 0.0001900818735259794, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:50:42,534 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7599762674432128, 'learning_rate': 0.001836539519553, 'weight_decay': 0.00018449420522947027, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:50:42,534 - INFO - Trial 296: Train MSE=1.8949447572231293, Train R²=0.6850445866584778
2024-10-31 14:50:42,534 - INFO - Trial 296: Test MSE=2.2534898349217007, Test R²=0.6330956476075309
2024-10-31 14:50:42,534 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:50:42,536 - INFO - Trial 296 finished with value: 2.2534898349217007 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7599762674432128, 'learning_rate': 0.001836539519553, 'weight_decay': 0.00018449420522947027, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:52:04,108 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7772716017690793, 'learning_rate': 0.001953354402612553, 'weight_decay': 0.000194874952502525, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 14:52:04,108 - INFO - Trial 297: Train MSE=1.7839722824948174, Train R²=0.7001694078956332
2024-10-31 14:52:04,108 - INFO - Trial 297: Test MSE=2.265631688492639, Test R²=0.6251342871359417
2024-10-31 14:52:04,108 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:52:04,109 - INFO - Trial 297 finished with value: 2.265631688492639 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7772716017690793, 'learning_rate': 0.001953354402612553, 'weight_decay': 0.000194874952502525, 'batch_size': 128, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:52:39,260 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7684710775198348, 'learning_rate': 0.0021963673237968386, 'weight_decay': 0.00017938163609642453, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:52:39,260 - INFO - Trial 298: Train MSE=1.9625396515641893, Train R²=0.6726727187633514
2024-10-31 14:52:39,260 - INFO - Trial 298: Test MSE=2.263255766459874, Test R²=0.6314642344202314
2024-10-31 14:52:39,260 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:52:39,262 - INFO - Trial 298 finished with value: 2.263255766459874 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7684710775198348, 'learning_rate': 0.0021963673237968386, 'weight_decay': 0.00017938163609642453, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:53:14,299 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.780878233230344, 'learning_rate': 0.002892476064925624, 'weight_decay': 0.00014289085313307285, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:53:14,299 - INFO - Trial 299: Train MSE=2.0101898355143413, Train R²=0.66478288599423
2024-10-31 14:53:14,300 - INFO - Trial 299: Test MSE=2.2432235990251814, Test R²=0.6346819741385323
2024-10-31 14:53:14,300 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:53:14,301 - INFO - Trial 299 finished with value: 2.2432235990251814 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.780878233230344, 'learning_rate': 0.002892476064925624, 'weight_decay': 0.00014289085313307285, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:53:50,236 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902868166187041, 'learning_rate': 0.0017879690697374018, 'weight_decay': 0.00015991140236560483, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 14:53:50,236 - INFO - Trial 300: Train MSE=2.2466758702482497, Train R²=0.6262990555592945
2024-10-31 14:53:50,236 - INFO - Trial 300: Test MSE=2.2657629251480103, Test R²=0.6313471879277911
2024-10-31 14:53:50,236 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:53:50,237 - INFO - Trial 300 finished with value: 2.2657629251480103 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902868166187041, 'learning_rate': 0.0017879690697374018, 'weight_decay': 0.00015991140236560483, 'batch_size': 512, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:54:27,209 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.756660343749663, 'learning_rate': 0.001635313236222575, 'weight_decay': 0.00020681273519135477, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:54:27,209 - INFO - Trial 301: Train MSE=1.8803363229547227, Train R²=0.6873016847031457
2024-10-31 14:54:27,209 - INFO - Trial 301: Test MSE=2.2626734461103166, Test R²=0.6317713686398098
2024-10-31 14:54:27,210 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:54:27,212 - INFO - Trial 301 finished with value: 2.2626734461103166 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.756660343749663, 'learning_rate': 0.001635313236222575, 'weight_decay': 0.00020681273519135477, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:55:02,395 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7813846270793073, 'learning_rate': 0.001665031739166429, 'weight_decay': 0.0003096939933226339, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:55:02,395 - INFO - Trial 302: Train MSE=2.0896613129547665, Train R²=0.6526225975581578
2024-10-31 14:55:02,395 - INFO - Trial 302: Test MSE=2.215348550251552, Test R²=0.639419708933149
2024-10-31 14:55:02,395 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:55:02,397 - INFO - Trial 302 finished with value: 2.215348550251552 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7813846270793073, 'learning_rate': 0.001665031739166429, 'weight_decay': 0.0003096939933226339, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:55:37,413 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7706922771088563, 'learning_rate': 0.0019856384269517475, 'weight_decay': 0.00019267619596894934, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:55:37,413 - INFO - Trial 303: Train MSE=1.951871054513114, Train R²=0.6747430562973022
2024-10-31 14:55:37,413 - INFO - Trial 303: Test MSE=2.2743218626294817, Test R²=0.6296886035374233
2024-10-31 14:55:37,413 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:55:37,415 - INFO - Trial 303 finished with value: 2.2743218626294817 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7706922771088563, 'learning_rate': 0.0019856384269517475, 'weight_decay': 0.00019267619596894934, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:56:12,940 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7810820678531947, 'learning_rate': 0.00036334219171275267, 'weight_decay': 0.000576802323730633, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:56:12,940 - INFO - Trial 304: Train MSE=3.6504986030714854, Train R²=0.39136016581739697
2024-10-31 14:56:12,940 - INFO - Trial 304: Test MSE=2.331144230706351, Test R²=0.6205646395683289
2024-10-31 14:56:12,941 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:56:12,941 - INFO - Trial 304 finished with value: 2.331144230706351 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7810820678531947, 'learning_rate': 0.00036334219171275267, 'weight_decay': 0.000576802323730633, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:56:47,220 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7381333862412761, 'learning_rate': 0.0017325515998664082, 'weight_decay': 0.00030542310294009393, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:56:47,220 - INFO - Trial 305: Train MSE=1.7302497923374176, Train R²=0.7117474653891155
2024-10-31 14:56:47,220 - INFO - Trial 305: Test MSE=2.2541933059692383, Test R²=0.6329193200383868
2024-10-31 14:56:47,220 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:56:47,222 - INFO - Trial 305 finished with value: 2.2541933059692383 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7381333862412761, 'learning_rate': 0.0017325515998664082, 'weight_decay': 0.00030542310294009393, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:57:25,087 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.5520004819376748, 'learning_rate': 0.002170769786167899, 'weight_decay': 0.00017227622296580263, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:57:25,087 - INFO - Trial 306: Train MSE=0.8039975421769279, Train R²=0.8656996786594391
2024-10-31 14:57:25,087 - INFO - Trial 306: Test MSE=2.506347111293248, Test R²=0.59163156577519
2024-10-31 14:57:25,087 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:57:25,088 - INFO - Trial 306 finished with value: 2.506347111293248 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.5520004819376748, 'learning_rate': 0.002170769786167899, 'weight_decay': 0.00017227622296580263, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:57:59,825 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.763428812846829, 'learning_rate': 0.001874771478480956, 'weight_decay': 0.0003443772688514309, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:57:59,825 - INFO - Trial 307: Train MSE=1.8686578486646925, Train R²=0.6889734693935939
2024-10-31 14:57:59,825 - INFO - Trial 307: Test MSE=2.2406857694898332, Test R²=0.6352412360055106
2024-10-31 14:57:59,825 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:57:59,827 - INFO - Trial 307 finished with value: 2.2406857694898332 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.763428812846829, 'learning_rate': 0.001874771478480956, 'weight_decay': 0.0003443772688514309, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:58:34,969 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7755226583719302, 'learning_rate': 0.0016192814744963634, 'weight_decay': 0.0001653361529095966, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:58:34,969 - INFO - Trial 308: Train MSE=2.0952050941331044, Train R²=0.6504472089665276
2024-10-31 14:58:34,969 - INFO - Trial 308: Test MSE=2.244945696422032, Test R²=0.6347253833498273
2024-10-31 14:58:34,969 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:58:34,970 - INFO - Trial 308 finished with value: 2.244945696422032 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7755226583719302, 'learning_rate': 0.0016192814744963634, 'weight_decay': 0.0001653361529095966, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:59:12,495 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7852880438837107, 'learning_rate': 0.006163652463537492, 'weight_decay': 0.0003273865403640704, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 14:59:12,495 - INFO - Trial 309: Train MSE=2.031993533883776, Train R²=0.6617821731737682
2024-10-31 14:59:12,496 - INFO - Trial 309: Test MSE=2.2953629153115407, Test R²=0.6264039022581918
2024-10-31 14:59:12,496 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:59:12,498 - INFO - Trial 309 finished with value: 2.2953629153115407 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7852880438837107, 'learning_rate': 0.006163652463537492, 'weight_decay': 0.0003273865403640704, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 14:59:42,476 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7518302110481703, 'learning_rate': 0.007107565966205014, 'weight_decay': 0.00030494189799640335, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 14:59:42,476 - INFO - Trial 310: Train MSE=1.8057881423405238, Train R²=0.699681716305869
2024-10-31 14:59:42,476 - INFO - Trial 310: Test MSE=2.2802171111106873, Test R²=0.6262310147285461
2024-10-31 14:59:42,476 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 14:59:42,477 - INFO - Trial 310 finished with value: 2.2802171111106873 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7518302110481703, 'learning_rate': 0.007107565966205014, 'weight_decay': 0.00030494189799640335, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:00:17,111 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7668643429782007, 'learning_rate': 0.0004667623155987225, 'weight_decay': 0.0003734956399203295, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:00:17,111 - INFO - Trial 311: Train MSE=3.09432167666299, Train R²=0.48402600841862814
2024-10-31 15:00:17,111 - INFO - Trial 311: Test MSE=2.2749753849846974, Test R²=0.6298018523624965
2024-10-31 15:00:17,111 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:00:17,112 - INFO - Trial 311 finished with value: 2.2749753849846974 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7668643429782007, 'learning_rate': 0.0004667623155987225, 'weight_decay': 0.0003734956399203295, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:00:52,901 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.786489111308414, 'learning_rate': 0.000605330752512378, 'weight_decay': 0.0002896363917728532, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:00:52,901 - INFO - Trial 312: Train MSE=2.842351351465498, Train R²=0.5270121714898518
2024-10-31 15:00:52,902 - INFO - Trial 312: Test MSE=2.2235044070652554, Test R²=0.6381915467126029
2024-10-31 15:00:52,902 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:00:52,903 - INFO - Trial 312 finished with value: 2.2235044070652554 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.786489111308414, 'learning_rate': 0.000605330752512378, 'weight_decay': 0.0002896363917728532, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:01:27,749 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7878567217048233, 'learning_rate': 0.0005877923507205125, 'weight_decay': 0.0002883884295038998, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:01:27,749 - INFO - Trial 313: Train MSE=2.9256247537476674, Train R²=0.5129131419318063
2024-10-31 15:01:27,749 - INFO - Trial 313: Test MSE=2.2404095785958424, Test R²=0.6353983879089355
2024-10-31 15:01:27,749 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:01:27,750 - INFO - Trial 313 finished with value: 2.2404095785958424 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7878567217048233, 'learning_rate': 0.0005877923507205125, 'weight_decay': 0.0002883884295038998, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:02:03,262 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7911893458159905, 'learning_rate': 0.0006967946091419891, 'weight_decay': 0.0002975105650660572, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:02:03,262 - INFO - Trial 314: Train MSE=2.7621557457106456, Train R²=0.5405011411224093
2024-10-31 15:02:03,262 - INFO - Trial 314: Test MSE=2.257162775312151, Test R²=0.6326183165822711
2024-10-31 15:02:03,262 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:02:03,264 - INFO - Trial 314 finished with value: 2.257162775312151 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7911893458159905, 'learning_rate': 0.0006967946091419891, 'weight_decay': 0.0002975105650660572, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:02:40,112 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7791045275914096, 'learning_rate': 0.0005303679339995108, 'weight_decay': 0.0002778174348922288, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:02:40,112 - INFO - Trial 315: Train MSE=2.990746319293976, Train R²=0.5034572907856533
2024-10-31 15:02:40,113 - INFO - Trial 315: Test MSE=2.2425573553357805, Test R²=0.6350008164133344
2024-10-31 15:02:40,113 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:02:40,114 - INFO - Trial 315 finished with value: 2.2425573553357805 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7791045275914096, 'learning_rate': 0.0005303679339995108, 'weight_decay': 0.0002778174348922288, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:03:15,781 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7920495206512393, 'learning_rate': 0.00090686840307164, 'weight_decay': 0.0003119990365559097, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:03:15,781 - INFO - Trial 316: Train MSE=2.5261176994868686, Train R²=0.5797369735581535
2024-10-31 15:03:15,782 - INFO - Trial 316: Test MSE=2.213295715195792, Test R²=0.6397808279309954
2024-10-31 15:03:15,782 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:03:15,783 - INFO - Trial 316 finished with value: 2.213295715195792 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7920495206512393, 'learning_rate': 0.00090686840307164, 'weight_decay': 0.0003119990365559097, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:03:51,160 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7923255268109999, 'learning_rate': 0.0007835043569157785, 'weight_decay': 0.0003130510020200256, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:03:51,160 - INFO - Trial 317: Train MSE=2.6807574885232106, Train R²=0.5543123462370464
2024-10-31 15:03:51,160 - INFO - Trial 317: Test MSE=2.261257529258728, Test R²=0.6319500378199986
2024-10-31 15:03:51,160 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:03:51,161 - INFO - Trial 317 finished with value: 2.261257529258728 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7923255268109999, 'learning_rate': 0.0007835043569157785, 'weight_decay': 0.0003130510020200256, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:04:26,260 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7796822363036067, 'learning_rate': 0.0005956093244160369, 'weight_decay': 0.00031189703264511496, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 15:04:26,262 - INFO - Trial 318: Train MSE=2.9027320742607117, Train R²=0.5158046058246067
2024-10-31 15:04:26,262 - INFO - Trial 318: Test MSE=2.29692542552948, Test R²=0.6262370603425162
2024-10-31 15:04:26,262 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:04:26,264 - INFO - Trial 318 finished with value: 2.29692542552948 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7796822363036067, 'learning_rate': 0.0005956093244160369, 'weight_decay': 0.00031189703264511496, 'batch_size': 512, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:04:59,597 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7993204639830682, 'learning_rate': 0.0006454674671642585, 'weight_decay': 0.0002037989453626309, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:04:59,597 - INFO - Trial 319: Train MSE=2.892799300806863, Train R²=0.5183803204979215
2024-10-31 15:04:59,597 - INFO - Trial 319: Test MSE=2.2887275900159563, Test R²=0.6274818011692592
2024-10-31 15:04:59,597 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:04:59,599 - INFO - Trial 319 finished with value: 2.2887275900159563 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7993204639830682, 'learning_rate': 0.0006454674671642585, 'weight_decay': 0.0002037989453626309, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:05:32,885 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7714968807256841, 'learning_rate': 0.0008848762469025358, 'weight_decay': 0.000289719546902605, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:05:32,885 - INFO - Trial 320: Train MSE=2.3402422070503235, Train R²=0.610345048563821
2024-10-31 15:05:32,886 - INFO - Trial 320: Test MSE=2.231447764805385, Test R²=0.6367784142494202
2024-10-31 15:05:32,886 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:05:32,888 - INFO - Trial 320 finished with value: 2.231447764805385 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7714968807256841, 'learning_rate': 0.0008848762469025358, 'weight_decay': 0.000289719546902605, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:06:49,714 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7851791360086856, 'learning_rate': 0.0009396294712272587, 'weight_decay': 0.00032438316013634264, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 15:06:49,714 - INFO - Trial 321: Train MSE=1.6798520269138473, Train R²=0.7140897570976189
2024-10-31 15:06:49,714 - INFO - Trial 321: Test MSE=2.349821380206517, Test R²=0.6114542824881417
2024-10-31 15:06:49,715 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:06:49,715 - INFO - Trial 321 finished with value: 2.349821380206517 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7851791360086856, 'learning_rate': 0.0009396294712272587, 'weight_decay': 0.00032438316013634264, 'batch_size': 128, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:07:25,244 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7763419977575623, 'learning_rate': 0.0010327375042350902, 'weight_decay': 0.00030770730083694276, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:07:25,244 - INFO - Trial 322: Train MSE=2.297393492289952, Train R²=0.618145057133266
2024-10-31 15:07:25,244 - INFO - Trial 322: Test MSE=2.244136333465576, Test R²=0.6347389306340899
2024-10-31 15:07:25,245 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:07:25,246 - INFO - Trial 322 finished with value: 2.244136333465576 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7763419977575623, 'learning_rate': 0.0010327375042350902, 'weight_decay': 0.00030770730083694276, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:08:01,814 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7888640816532474, 'learning_rate': 0.0008819513999893183, 'weight_decay': 0.0003287920550691704, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:08:01,814 - INFO - Trial 323: Train MSE=2.5097916551998685, Train R²=0.5827829561063221
2024-10-31 15:08:01,814 - INFO - Trial 323: Test MSE=2.2124219962528775, Test R²=0.639921954699925
2024-10-31 15:08:01,814 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:08:01,815 - INFO - Trial 323 finished with value: 2.2124219962528775 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7888640816532474, 'learning_rate': 0.0008819513999893183, 'weight_decay': 0.0003287920550691704, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:08:38,107 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7906558562743297, 'learning_rate': 0.0009130629540293798, 'weight_decay': 0.00033254150481596453, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:08:38,107 - INFO - Trial 324: Train MSE=2.503662782055991, Train R²=0.5831605557884488
2024-10-31 15:08:38,108 - INFO - Trial 324: Test MSE=2.2424701281956265, Test R²=0.6349656922476632
2024-10-31 15:08:38,108 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:08:38,109 - INFO - Trial 324 finished with value: 2.2424701281956265 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7906558562743297, 'learning_rate': 0.0009130629540293798, 'weight_decay': 0.00033254150481596453, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:09:13,176 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999665722286972, 'learning_rate': 0.0008252592384630699, 'weight_decay': 0.00032184107713538945, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:09:13,176 - INFO - Trial 325: Train MSE=2.694188356399536, Train R²=0.5512027846915382
2024-10-31 15:09:13,177 - INFO - Trial 325: Test MSE=2.245104363986424, Test R²=0.6345803652490888
2024-10-31 15:09:13,177 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:09:13,178 - INFO - Trial 325 finished with value: 2.245104363986424 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999665722286972, 'learning_rate': 0.0008252592384630699, 'weight_decay': 0.00032184107713538945, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:09:54,397 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7850226379999211, 'learning_rate': 0.0009881844580770971, 'weight_decay': 0.0002969258281948992, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:09:54,397 - INFO - Trial 326: Train MSE=3.1050711699894498, Train R²=0.48411907255649567
2024-10-31 15:09:54,398 - INFO - Trial 326: Test MSE=2.835507903780256, Test R²=0.5386558771133423
2024-10-31 15:09:54,398 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:09:54,399 - INFO - Trial 326 finished with value: 2.835507903780256 and parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7850226379999211, 'learning_rate': 0.0009881844580770971, 'weight_decay': 0.0002969258281948992, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:10:30,188 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6551521416029433, 'learning_rate': 0.0010370094413067051, 'weight_decay': 0.00033911108172874835, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:10:30,189 - INFO - Trial 327: Train MSE=1.4531779629843575, Train R²=0.7577092115368161
2024-10-31 15:10:30,189 - INFO - Trial 327: Test MSE=2.305900079863412, Test R²=0.624696501663753
2024-10-31 15:10:30,189 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:10:30,191 - INFO - Trial 327 finished with value: 2.305900079863412 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6551521416029433, 'learning_rate': 0.0010370094413067051, 'weight_decay': 0.00033911108172874835, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:11:06,169 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7914104457237693, 'learning_rate': 0.0008343287381266479, 'weight_decay': 0.0003064624471668707, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:11:06,170 - INFO - Trial 328: Train MSE=2.548023922102792, Train R²=0.5754429889576775
2024-10-31 15:11:06,170 - INFO - Trial 328: Test MSE=2.2572464772633145, Test R²=0.6325533900942121
2024-10-31 15:11:06,170 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:11:06,171 - INFO - Trial 328 finished with value: 2.2572464772633145 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7914104457237693, 'learning_rate': 0.0008343287381266479, 'weight_decay': 0.0003064624471668707, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:11:41,409 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998486234915642, 'learning_rate': 0.0011182030938283606, 'weight_decay': 0.0002834881986118199, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:11:41,409 - INFO - Trial 329: Train MSE=2.4581492032323564, Train R²=0.591613552400044
2024-10-31 15:11:41,409 - INFO - Trial 329: Test MSE=2.239879778453282, Test R²=0.6354819280760629
2024-10-31 15:11:41,409 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:11:41,410 - INFO - Trial 329 finished with value: 2.239879778453282 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998486234915642, 'learning_rate': 0.0011182030938283606, 'weight_decay': 0.0002834881986118199, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:12:19,810 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7775774951436051, 'learning_rate': 0.0008932776768885634, 'weight_decay': 0.00032117576068363033, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:12:19,811 - INFO - Trial 330: Train MSE=2.912822587149484, Train R²=0.5153397108827319
2024-10-31 15:12:19,811 - INFO - Trial 330: Test MSE=2.301307031086513, Test R²=0.6255769729614258
2024-10-31 15:12:19,811 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:12:19,814 - INFO - Trial 330 finished with value: 2.301307031086513 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7775774951436051, 'learning_rate': 0.0008932776768885634, 'weight_decay': 0.00032117576068363033, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:13:02,113 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7859722185725075, 'learning_rate': 0.0013073632230609293, 'weight_decay': 0.00034583661822191575, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:13:02,113 - INFO - Trial 331: Train MSE=2.20357740351132, Train R²=0.6330579008374896
2024-10-31 15:13:02,114 - INFO - Trial 331: Test MSE=2.2529384068080356, Test R²=0.6334795951843262
2024-10-31 15:13:02,114 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:13:02,116 - INFO - Trial 331 finished with value: 2.2529384068080356 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7859722185725075, 'learning_rate': 0.0013073632230609293, 'weight_decay': 0.00034583661822191575, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:13:38,226 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7717486902739561, 'learning_rate': 0.0009419941024762069, 'weight_decay': 0.0003000878030125914, 'batch_size': 512, 'tree_depth': 8}
2024-10-31 15:13:38,226 - INFO - Trial 332: Train MSE=2.699412158557347, Train R²=0.5512591174670628
2024-10-31 15:13:38,226 - INFO - Trial 332: Test MSE=2.2439447471073697, Test R²=0.6348282098770142
2024-10-31 15:13:38,226 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:13:38,227 - INFO - Trial 332 finished with value: 2.2439447471073697 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7717486902739561, 'learning_rate': 0.0009419941024762069, 'weight_decay': 0.0003000878030125914, 'batch_size': 512, 'tree_depth': 8}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:14:19,002 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7916557946811515, 'learning_rate': 0.00017474672691126126, 'weight_decay': 0.000318528796300197, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:14:19,002 - INFO - Trial 333: Train MSE=6.260725583348956, Train R²=-0.04276930221489498
2024-10-31 15:14:19,002 - INFO - Trial 333: Test MSE=3.3347132205963135, Test R²=0.45746023314339773
2024-10-31 15:14:19,002 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:14:19,003 - INFO - Trial 333 finished with value: 3.3347132205963135 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7916557946811515, 'learning_rate': 0.00017474672691126126, 'weight_decay': 0.000318528796300197, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:14:50,230 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7844321680716642, 'learning_rate': 0.0012318980516242946, 'weight_decay': 0.00026835532157238196, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 15:14:50,230 - INFO - Trial 334: Train MSE=2.66746233190809, Train R²=0.5572893832411084
2024-10-31 15:14:50,230 - INFO - Trial 334: Test MSE=2.266469180583954, Test R²=0.6285449117422104
2024-10-31 15:14:50,231 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:14:50,232 - INFO - Trial 334 finished with value: 2.266469180583954 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7844321680716642, 'learning_rate': 0.0012318980516242946, 'weight_decay': 0.00026835532157238196, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:15:25,825 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.41349153561132806, 'learning_rate': 0.001084429454010414, 'weight_decay': 0.00033767979982701784, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 15:15:25,825 - INFO - Trial 335: Train MSE=0.733284918325288, Train R²=0.8777449173586709
2024-10-31 15:15:25,826 - INFO - Trial 335: Test MSE=2.382537909916469, Test R²=0.6121560505458287
2024-10-31 15:15:25,827 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:15:25,828 - INFO - Trial 335 finished with value: 2.382537909916469 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.41349153561132806, 'learning_rate': 0.001084429454010414, 'weight_decay': 0.00033767979982701784, 'batch_size': 512, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:16:04,284 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7634403386407178, 'learning_rate': 0.001510604368351299, 'weight_decay': 0.00028826118533161686, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:16:04,284 - INFO - Trial 336: Train MSE=1.616720357111522, Train R²=0.7298843371016639
2024-10-31 15:16:04,284 - INFO - Trial 336: Test MSE=2.372372899736677, Test R²=0.6139807275363377
2024-10-31 15:16:04,284 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:16:04,285 - INFO - Trial 336 finished with value: 2.372372899736677 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7634403386407178, 'learning_rate': 0.001510604368351299, 'weight_decay': 0.00028826118533161686, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:16:38,639 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7765349111516958, 'learning_rate': 0.0009965774541362844, 'weight_decay': 0.00035379291336985866, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:16:38,639 - INFO - Trial 337: Train MSE=2.3405382122312273, Train R²=0.6100868880748749
2024-10-31 15:16:38,640 - INFO - Trial 337: Test MSE=2.2466835294451033, Test R²=0.6343752826963153
2024-10-31 15:16:38,640 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:16:38,641 - INFO - Trial 337 finished with value: 2.2466835294451033 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7765349111516958, 'learning_rate': 0.0009965774541362844, 'weight_decay': 0.00035379291336985866, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:17:14,252 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7924378612763656, 'learning_rate': 0.004178052855245137, 'weight_decay': 0.00030921333874877547, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:17:14,253 - INFO - Trial 338: Train MSE=2.031421580484935, Train R²=0.6614812122923988
2024-10-31 15:17:14,253 - INFO - Trial 338: Test MSE=2.2655067443847656, Test R²=0.6311922584261213
2024-10-31 15:17:14,253 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:17:14,255 - INFO - Trial 338 finished with value: 2.2655067443847656 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7924378612763656, 'learning_rate': 0.004178052855245137, 'weight_decay': 0.00030921333874877547, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:17:49,666 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7816981280738478, 'learning_rate': 0.000775187524426296, 'weight_decay': 0.00033003176515281383, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:17:49,666 - INFO - Trial 339: Train MSE=2.574371772153037, Train R²=0.5717179583651679
2024-10-31 15:17:49,666 - INFO - Trial 339: Test MSE=2.2267645256859914, Test R²=0.6374759588922773
2024-10-31 15:17:49,666 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:17:49,669 - INFO - Trial 339 finished with value: 2.2267645256859914 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7816981280738478, 'learning_rate': 0.000775187524426296, 'weight_decay': 0.00033003176515281383, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:18:24,764 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7695783943583844, 'learning_rate': 0.0011341883683759781, 'weight_decay': 0.00029638985727156497, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 15:18:24,764 - INFO - Trial 340: Train MSE=2.151173919439316, Train R²=0.6417410671710968
2024-10-31 15:18:24,765 - INFO - Trial 340: Test MSE=2.26152127129691, Test R²=0.6317484378814697
2024-10-31 15:18:24,765 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:18:24,767 - INFO - Trial 340 finished with value: 2.26152127129691 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7695783943583844, 'learning_rate': 0.0011341883683759781, 'weight_decay': 0.00029638985727156497, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:19:00,057 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7835569572589732, 'learning_rate': 0.0016046672356021527, 'weight_decay': 0.00027275530271856973, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:19:00,058 - INFO - Trial 341: Train MSE=2.1256954840251376, Train R²=0.6463391951152256
2024-10-31 15:19:00,058 - INFO - Trial 341: Test MSE=2.22256110395704, Test R²=0.6381414958408901
2024-10-31 15:19:00,058 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:19:00,059 - INFO - Trial 341 finished with value: 2.22256110395704 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7835569572589732, 'learning_rate': 0.0016046672356021527, 'weight_decay': 0.00027275530271856973, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:19:34,862 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7915844332089188, 'learning_rate': 0.001677498012290463, 'weight_decay': 0.00027089671588699743, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:19:34,863 - INFO - Trial 342: Train MSE=2.183771299464362, Train R²=0.6366574551377978
2024-10-31 15:19:34,863 - INFO - Trial 342: Test MSE=2.2048958710261752, Test R²=0.6411034124238151
2024-10-31 15:19:34,863 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:19:34,865 - INFO - Trial 342 finished with value: 2.2048958710261752 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7915844332089188, 'learning_rate': 0.001677498012290463, 'weight_decay': 0.00027089671588699743, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:20:10,967 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7986995038456196, 'learning_rate': 0.0017848951635138894, 'weight_decay': 0.0002621196311945204, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:20:10,967 - INFO - Trial 343: Train MSE=2.2074220137936726, Train R²=0.6330381440264838
2024-10-31 15:20:10,967 - INFO - Trial 343: Test MSE=2.233358076640538, Test R²=0.6365452579089573
2024-10-31 15:20:10,968 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:20:10,969 - INFO - Trial 343 finished with value: 2.233358076640538 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7986995038456196, 'learning_rate': 0.0017848951635138894, 'weight_decay': 0.0002621196311945204, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:20:47,415 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.792872930818809, 'learning_rate': 0.0016790076951994188, 'weight_decay': 0.0002791687544324356, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:20:47,415 - INFO - Trial 344: Train MSE=2.1860054305621555, Train R²=0.6354978510311672
2024-10-31 15:20:47,415 - INFO - Trial 344: Test MSE=2.2450435842786516, Test R²=0.6346289941242763
2024-10-31 15:20:47,415 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:20:47,416 - INFO - Trial 344 finished with value: 2.2450435842786516 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.792872930818809, 'learning_rate': 0.0016790076951994188, 'weight_decay': 0.0002791687544324356, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:22:09,526 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7997119534268264, 'learning_rate': 0.002458113348059077, 'weight_decay': 0.0002759569868568042, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 15:22:09,526 - INFO - Trial 345: Train MSE=2.0293242377894267, Train R²=0.6583719540919576
2024-10-31 15:22:09,526 - INFO - Trial 345: Test MSE=2.2450916724545613, Test R²=0.6284203699656895
2024-10-31 15:22:09,526 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:22:09,530 - INFO - Trial 345 finished with value: 2.2450916724545613 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7997119534268264, 'learning_rate': 0.002458113348059077, 'weight_decay': 0.0002759569868568042, 'batch_size': 128, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:22:45,439 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7813473938784475, 'learning_rate': 0.001978333207819965, 'weight_decay': 0.00026956032198217764, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:22:45,439 - INFO - Trial 346: Train MSE=1.780921655041831, Train R²=0.7034452834299633
2024-10-31 15:22:45,439 - INFO - Trial 346: Test MSE=2.240797792162214, Test R²=0.6353034632546561
2024-10-31 15:22:45,439 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:22:45,440 - INFO - Trial 346 finished with value: 2.240797792162214 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7813473938784475, 'learning_rate': 0.001978333207819965, 'weight_decay': 0.00026956032198217764, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:23:19,714 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7897408883884194, 'learning_rate': 0.0008586031405681953, 'weight_decay': 0.00024664603277490464, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:23:19,715 - INFO - Trial 347: Train MSE=2.58403571162905, Train R²=0.5698658057621547
2024-10-31 15:23:19,715 - INFO - Trial 347: Test MSE=2.2428323541368758, Test R²=0.6349400707653591
2024-10-31 15:23:19,715 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:23:19,716 - INFO - Trial 347 finished with value: 2.2428323541368758 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7897408883884194, 'learning_rate': 0.0008586031405681953, 'weight_decay': 0.00024664603277490464, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:23:53,016 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7810477923809467, 'learning_rate': 0.0016127238442441398, 'weight_decay': 0.0002555737631167502, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:23:53,016 - INFO - Trial 348: Train MSE=2.13292926124164, Train R²=0.6437436384814126
2024-10-31 15:23:53,016 - INFO - Trial 348: Test MSE=2.2417307581220354, Test R²=0.6350193790027073
2024-10-31 15:23:53,016 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:23:53,018 - INFO - Trial 348 finished with value: 2.2417307581220354 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7810477923809467, 'learning_rate': 0.0016127238442441398, 'weight_decay': 0.0002555737631167502, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:24:28,560 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7911401315879018, 'learning_rate': 0.002267300900726031, 'weight_decay': 0.00030529674861542197, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:24:28,560 - INFO - Trial 349: Train MSE=2.114088854619435, Train R²=0.647758349776268
2024-10-31 15:24:28,560 - INFO - Trial 349: Test MSE=2.228482348578317, Test R²=0.637163656098502
2024-10-31 15:24:28,560 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:24:28,562 - INFO - Trial 349 finished with value: 2.228482348578317 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7911401315879018, 'learning_rate': 0.002267300900726031, 'weight_decay': 0.00030529674861542197, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:25:04,073 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7747379814875547, 'learning_rate': 0.0019815073843000306, 'weight_decay': 0.0002748142266365208, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:25:04,073 - INFO - Trial 350: Train MSE=1.995669811964035, Train R²=0.6678850735936847
2024-10-31 15:25:04,074 - INFO - Trial 350: Test MSE=2.219775881086077, Test R²=0.6388169612203326
2024-10-31 15:25:04,074 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:25:04,076 - INFO - Trial 350 finished with value: 2.219775881086077 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7747379814875547, 'learning_rate': 0.0019815073843000306, 'weight_decay': 0.0002748142266365208, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:25:39,201 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7644934513429658, 'learning_rate': 0.001948399748673526, 'weight_decay': 0.0002711956030669965, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:25:39,201 - INFO - Trial 351: Train MSE=1.9129455430167062, Train R²=0.6817335528986794
2024-10-31 15:25:39,201 - INFO - Trial 351: Test MSE=2.2848250014441356, Test R²=0.6279853752681187
2024-10-31 15:25:39,201 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:25:39,202 - INFO - Trial 351 finished with value: 2.2848250014441356 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7644934513429658, 'learning_rate': 0.001948399748673526, 'weight_decay': 0.0002711956030669965, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:26:14,825 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7808638121603468, 'learning_rate': 0.0021702519397332107, 'weight_decay': 0.00024586603730916413, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:26:14,825 - INFO - Trial 352: Train MSE=2.07574662566185, Train R²=0.6549440899065563
2024-10-31 15:26:14,826 - INFO - Trial 352: Test MSE=2.2524941308157787, Test R²=0.6333332402365548
2024-10-31 15:26:14,826 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:26:14,829 - INFO - Trial 352 finished with value: 2.2524941308157787 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7808638121603468, 'learning_rate': 0.0021702519397332107, 'weight_decay': 0.00024586603730916413, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:26:50,210 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7733607010961231, 'learning_rate': 0.0018661157845657902, 'weight_decay': 0.0002358591370462018, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:26:50,211 - INFO - Trial 353: Train MSE=2.02207881637982, Train R²=0.6629362383059093
2024-10-31 15:26:50,211 - INFO - Trial 353: Test MSE=2.2331630843026296, Test R²=0.6364996433258057
2024-10-31 15:26:50,211 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:26:50,212 - INFO - Trial 353 finished with value: 2.2331630843026296 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7733607010961231, 'learning_rate': 0.0018661157845657902, 'weight_decay': 0.0002358591370462018, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:27:24,426 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7930583937664785, 'learning_rate': 0.0026404353279076394, 'weight_decay': 0.0002666346340469055, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:27:24,426 - INFO - Trial 354: Train MSE=2.107599058321544, Train R²=0.6495285694088254
2024-10-31 15:27:24,426 - INFO - Trial 354: Test MSE=2.2218718017850603, Test R²=0.6382670657975333
2024-10-31 15:27:24,426 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:27:24,428 - INFO - Trial 354 finished with value: 2.2218718017850603 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7930583937664785, 'learning_rate': 0.0026404353279076394, 'weight_decay': 0.0002666346340469055, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:27:59,354 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7985237107026119, 'learning_rate': 0.0024393927727216613, 'weight_decay': 0.0005493681749774136, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:27:59,354 - INFO - Trial 355: Train MSE=2.228292235306331, Train R²=0.6276601340089526
2024-10-31 15:27:59,354 - INFO - Trial 355: Test MSE=2.2085209574018205, Test R²=0.64051525081907
2024-10-31 15:27:59,354 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:27:59,356 - INFO - Trial 355 finished with value: 2.2085209574018205 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7985237107026119, 'learning_rate': 0.0024393927727216613, 'weight_decay': 0.0005493681749774136, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:28:35,677 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7928140803084672, 'learning_rate': 0.0032113454784736197, 'weight_decay': 0.0004934773383274759, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:28:35,677 - INFO - Trial 356: Train MSE=2.140424417597907, Train R²=0.6441053684268679
2024-10-31 15:28:35,677 - INFO - Trial 356: Test MSE=2.250700984682356, Test R²=0.6335037180355617
2024-10-31 15:28:35,677 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:28:35,679 - INFO - Trial 356 finished with value: 2.250700984682356 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7928140803084672, 'learning_rate': 0.0032113454784736197, 'weight_decay': 0.0004934773383274759, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:29:10,764 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7993196927663786, 'learning_rate': 0.0020575283530379334, 'weight_decay': 0.00054015846707249, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:29:10,764 - INFO - Trial 357: Train MSE=2.2301831245422363, Train R²=0.6293641328811646
2024-10-31 15:29:10,764 - INFO - Trial 357: Test MSE=2.2949310030256, Test R²=0.6264887963022504
2024-10-31 15:29:10,765 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:29:10,766 - INFO - Trial 357 finished with value: 2.2949310030256 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7993196927663786, 'learning_rate': 0.0020575283530379334, 'weight_decay': 0.00054015846707249, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:29:47,723 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7986363372037022, 'learning_rate': 0.0022415664840773563, 'weight_decay': 0.000686582875932205, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:29:47,723 - INFO - Trial 358: Train MSE=2.245400939668928, Train R²=0.6271212377718517
2024-10-31 15:29:47,723 - INFO - Trial 358: Test MSE=2.2585882459368025, Test R²=0.6322902355875287
2024-10-31 15:29:47,723 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:29:47,725 - INFO - Trial 358 finished with value: 2.2585882459368025 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7986363372037022, 'learning_rate': 0.0022415664840773563, 'weight_decay': 0.000686582875932205, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:30:23,671 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7878354253562941, 'learning_rate': 0.0021120153546608073, 'weight_decay': 0.0004736887924513113, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:30:23,671 - INFO - Trial 359: Train MSE=2.076184515442167, Train R²=0.6535346720899854
2024-10-31 15:30:23,671 - INFO - Trial 359: Test MSE=2.223376444407872, Test R²=0.6382663590567452
2024-10-31 15:30:23,671 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:30:23,673 - INFO - Trial 359 finished with value: 2.223376444407872 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7878354253562941, 'learning_rate': 0.0021120153546608073, 'weight_decay': 0.0004736887924513113, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:30:52,997 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7751561807665448, 'learning_rate': 0.0024803548772027624, 'weight_decay': 0.0006163796986434591, 'batch_size': 1024, 'tree_depth': 12}
2024-10-31 15:30:52,997 - INFO - Trial 360: Train MSE=2.1543568883623396, Train R²=0.6420921129839761
2024-10-31 15:30:52,997 - INFO - Trial 360: Test MSE=2.250946342945099, Test R²=0.631117582321167
2024-10-31 15:30:52,997 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:30:52,998 - INFO - Trial 360 finished with value: 2.250946342945099 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7751561807665448, 'learning_rate': 0.0024803548772027624, 'weight_decay': 0.0006163796986434591, 'batch_size': 1024, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:31:28,741 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7592221576069778, 'learning_rate': 0.0009652576504227578, 'weight_decay': 0.0002880174565392892, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:31:28,741 - INFO - Trial 361: Train MSE=2.1557181690420424, Train R²=0.6411269392286029
2024-10-31 15:31:28,741 - INFO - Trial 361: Test MSE=2.2220589092799594, Test R²=0.6382444500923157
2024-10-31 15:31:28,742 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:31:28,743 - INFO - Trial 361 finished with value: 2.2220589092799594 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7592221576069778, 'learning_rate': 0.0009652576504227578, 'weight_decay': 0.0002880174565392892, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:32:05,995 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7846881799648973, 'learning_rate': 0.001888316917078822, 'weight_decay': 0.00022308549347483316, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 15:32:05,995 - INFO - Trial 362: Train MSE=2.218300619295665, Train R²=0.6308071528162275
2024-10-31 15:32:05,995 - INFO - Trial 362: Test MSE=2.231129135404314, Test R²=0.6369799971580505
2024-10-31 15:32:05,995 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:32:05,996 - INFO - Trial 362 finished with value: 2.231129135404314 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7846881799648973, 'learning_rate': 0.001888316917078822, 'weight_decay': 0.00022308549347483316, 'batch_size': 512, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:32:44,236 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7901814290763041, 'learning_rate': 0.001706429941489942, 'weight_decay': 0.0005242956443158954, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:32:44,236 - INFO - Trial 363: Train MSE=2.2055072699274336, Train R²=0.6326205134391785
2024-10-31 15:32:44,237 - INFO - Trial 363: Test MSE=2.2829552718571255, Test R²=0.62851539679936
2024-10-31 15:32:44,237 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:32:44,238 - INFO - Trial 363 finished with value: 2.2829552718571255 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7901814290763041, 'learning_rate': 0.001706429941489942, 'weight_decay': 0.0005242956443158954, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:33:17,082 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7719855714849672, 'learning_rate': 0.00010967706176049209, 'weight_decay': 0.0003136471271469932, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 15:33:17,082 - INFO - Trial 364: Train MSE=7.922784975596836, Train R²=-0.32353125725473675
2024-10-31 15:33:17,082 - INFO - Trial 364: Test MSE=4.32830149786813, Test R²=0.29558922563280376
2024-10-31 15:33:17,083 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:33:17,084 - INFO - Trial 364 finished with value: 4.32830149786813 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7719855714849672, 'learning_rate': 0.00010967706176049209, 'weight_decay': 0.0003136471271469932, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:33:48,410 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999064258771906, 'learning_rate': 0.0023803301074706833, 'weight_decay': 0.0002962375356954884, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:33:48,411 - INFO - Trial 365: Train MSE=2.1611338428088596, Train R²=0.6388971762997764
2024-10-31 15:33:48,411 - INFO - Trial 365: Test MSE=2.2416495255061557, Test R²=0.6351533106395176
2024-10-31 15:33:48,411 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:33:48,412 - INFO - Trial 365 finished with value: 2.2416495255061557 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999064258771906, 'learning_rate': 0.0023803301074706833, 'weight_decay': 0.0002962375356954884, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:34:22,923 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7822776922657445, 'learning_rate': 0.0010655831788406222, 'weight_decay': 0.000591932014138713, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:34:22,923 - INFO - Trial 366: Train MSE=1.874358662537166, Train R²=0.6869036214692252
2024-10-31 15:34:22,923 - INFO - Trial 366: Test MSE=2.2648272854941234, Test R²=0.6312355739729745
2024-10-31 15:34:22,923 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:34:22,924 - INFO - Trial 366 finished with value: 2.2648272854941234 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7822776922657445, 'learning_rate': 0.0010655831788406222, 'weight_decay': 0.000591932014138713, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:34:53,732 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7650911325312962, 'learning_rate': 0.0008919164703372046, 'weight_decay': 0.0003150432871426635, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 15:34:53,732 - INFO - Trial 367: Train MSE=2.271893552371434, Train R²=0.6221413505928857
2024-10-31 15:34:53,732 - INFO - Trial 367: Test MSE=2.2432654244559154, Test R²=0.6348879167011806
2024-10-31 15:34:53,732 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:34:53,734 - INFO - Trial 367 finished with value: 2.2432654244559154 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7650911325312962, 'learning_rate': 0.0008919164703372046, 'weight_decay': 0.0003150432871426635, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:35:23,985 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7895278148007142, 'learning_rate': 0.0019440211012825865, 'weight_decay': 0.0004424269379227047, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 15:35:23,985 - INFO - Trial 368: Train MSE=2.232711447136743, Train R²=0.6277587073189872
2024-10-31 15:35:23,986 - INFO - Trial 368: Test MSE=2.2353449889591763, Test R²=0.6361062015805926
2024-10-31 15:35:23,986 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:35:23,987 - INFO - Trial 368 finished with value: 2.2353449889591763 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7895278148007142, 'learning_rate': 0.0019440211012825865, 'weight_decay': 0.0004424269379227047, 'batch_size': 512, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:36:38,302 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999857970466584, 'learning_rate': 0.001274595742887798, 'weight_decay': 0.00028755225894894535, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 15:36:38,303 - INFO - Trial 369: Train MSE=1.9277615760053908, Train R²=0.674804304859468
2024-10-31 15:36:38,303 - INFO - Trial 369: Test MSE=2.2492929015840804, Test R²=0.6271112497363772
2024-10-31 15:36:38,303 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:36:38,305 - INFO - Trial 369 finished with value: 2.2492929015840804 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999857970466584, 'learning_rate': 0.001274595742887798, 'weight_decay': 0.00028755225894894535, 'batch_size': 128, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:37:12,068 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7782608460803274, 'learning_rate': 0.0017872379947161626, 'weight_decay': 0.00033373687006159927, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:37:12,068 - INFO - Trial 370: Train MSE=2.2413897854941234, Train R²=0.6267113877194268
2024-10-31 15:37:12,068 - INFO - Trial 370: Test MSE=2.237830638885498, Test R²=0.6358516812324524
2024-10-31 15:37:12,068 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:37:12,070 - INFO - Trial 370 finished with value: 2.237830638885498 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7782608460803274, 'learning_rate': 0.0017872379947161626, 'weight_decay': 0.00033373687006159927, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:37:46,849 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.36981724430267093, 'learning_rate': 0.0009544577095470984, 'weight_decay': 0.0008172787010538127, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 15:37:46,849 - INFO - Trial 371: Train MSE=0.7361799478530884, Train R²=0.877341594014849
2024-10-31 15:37:46,849 - INFO - Trial 371: Test MSE=2.4592249052865163, Test R²=0.5996817350387573
2024-10-31 15:37:46,849 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:37:46,850 - INFO - Trial 371 finished with value: 2.4592249052865163 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.36981724430267093, 'learning_rate': 0.0009544577095470984, 'weight_decay': 0.0008172787010538127, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:38:21,421 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7895147479415253, 'learning_rate': 0.0011569007799721856, 'weight_decay': 0.0003025598869087616, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:38:21,421 - INFO - Trial 372: Train MSE=2.363593578338623, Train R²=0.6069357352597373
2024-10-31 15:38:21,421 - INFO - Trial 372: Test MSE=2.231663244111197, Test R²=0.6366832171167646
2024-10-31 15:38:21,421 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:38:21,423 - INFO - Trial 372 finished with value: 2.231663244111197 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7895147479415253, 'learning_rate': 0.0011569007799721856, 'weight_decay': 0.0003025598869087616, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:38:55,167 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5007199419410542, 'learning_rate': 0.0007881361711350548, 'weight_decay': 0.0005601586546899752, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 15:38:55,168 - INFO - Trial 373: Train MSE=0.9957717295203891, Train R²=0.8342669414622443
2024-10-31 15:38:55,168 - INFO - Trial 373: Test MSE=2.3514353888375417, Test R²=0.6174353020531791
2024-10-31 15:38:55,168 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:38:55,169 - INFO - Trial 373 finished with value: 2.3514353888375417 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5007199419410542, 'learning_rate': 0.0007881361711350548, 'weight_decay': 0.0005601586546899752, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:39:30,944 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7735978714023503, 'learning_rate': 0.0021471990509283733, 'weight_decay': 0.00032149727352899716, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:39:30,944 - INFO - Trial 374: Train MSE=1.6963129086153848, Train R²=0.7176534746374402
2024-10-31 15:39:30,945 - INFO - Trial 374: Test MSE=2.2890706402914867, Test R²=0.6273288386208671
2024-10-31 15:39:30,945 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:39:30,946 - INFO - Trial 374 finished with value: 2.2890706402914867 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7735978714023503, 'learning_rate': 0.0021471990509283733, 'weight_decay': 0.00032149727352899716, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:40:03,582 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7831854045007873, 'learning_rate': 0.0014412491510841746, 'weight_decay': 0.00028481546129299637, 'batch_size': 512, 'tree_depth': 6}
2024-10-31 15:40:03,582 - INFO - Trial 375: Train MSE=3.0494919334139143, Train R²=0.4928646002496992
2024-10-31 15:40:03,582 - INFO - Trial 375: Test MSE=2.4377342632838657, Test R²=0.6031898260116577
2024-10-31 15:40:03,582 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:40:03,583 - INFO - Trial 375 finished with value: 2.4377342632838657 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7831854045007873, 'learning_rate': 0.0014412491510841746, 'weight_decay': 0.00028481546129299637, 'batch_size': 512, 'tree_depth': 6}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:40:36,801 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7567713135057258, 'learning_rate': 0.001029224290905351, 'weight_decay': 0.00030189518943020595, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:40:36,801 - INFO - Trial 376: Train MSE=2.142719771180834, Train R²=0.6426634043455124
2024-10-31 15:40:36,801 - INFO - Trial 376: Test MSE=2.2226150887353078, Test R²=0.6383516022137233
2024-10-31 15:40:36,801 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:40:36,802 - INFO - Trial 376 finished with value: 2.2226150887353078 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7567713135057258, 'learning_rate': 0.001029224290905351, 'weight_decay': 0.00030189518943020595, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:41:10,467 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999922560353009, 'learning_rate': 0.002851984376489109, 'weight_decay': 0.00034884335982532854, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 15:41:10,468 - INFO - Trial 377: Train MSE=2.106189578771591, Train R²=0.6487201963152204
2024-10-31 15:41:10,468 - INFO - Trial 377: Test MSE=2.224617464201791, Test R²=0.6378312536648342
2024-10-31 15:41:10,468 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:41:10,469 - INFO - Trial 377 finished with value: 2.224617464201791 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999922560353009, 'learning_rate': 0.002851984376489109, 'weight_decay': 0.00034884335982532854, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:41:43,528 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7683766489451886, 'learning_rate': 0.001731305627362397, 'weight_decay': 0.00032836067409473043, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:41:43,528 - INFO - Trial 378: Train MSE=1.919905811548233, Train R²=0.6805417984724045
2024-10-31 15:41:43,528 - INFO - Trial 378: Test MSE=2.239001069750105, Test R²=0.635615851197924
2024-10-31 15:41:43,529 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:41:43,530 - INFO - Trial 378 finished with value: 2.239001069750105 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7683766489451886, 'learning_rate': 0.001731305627362397, 'weight_decay': 0.00032836067409473043, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:42:17,708 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7830751155772149, 'learning_rate': 0.000853592025801277, 'weight_decay': 0.00030846619132250924, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:42:17,708 - INFO - Trial 379: Train MSE=2.4935359954833984, Train R²=0.5846366605588368
2024-10-31 15:42:17,708 - INFO - Trial 379: Test MSE=2.264147622244699, Test R²=0.6314484306744167
2024-10-31 15:42:17,708 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:42:17,709 - INFO - Trial 379 finished with value: 2.264147622244699 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7830751155772149, 'learning_rate': 0.000853592025801277, 'weight_decay': 0.00030846619132250924, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:42:53,323 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7904024097297362, 'learning_rate': 0.0015295327017265793, 'weight_decay': 0.0002764418768436864, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 15:42:53,323 - INFO - Trial 380: Train MSE=2.1670178856168474, Train R²=0.6390679883105415
2024-10-31 15:42:53,323 - INFO - Trial 380: Test MSE=2.2612008026668002, Test R²=0.6321482573236737
2024-10-31 15:42:53,324 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:42:53,325 - INFO - Trial 380 finished with value: 2.2612008026668002 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7904024097297362, 'learning_rate': 0.0015295327017265793, 'weight_decay': 0.0002764418768436864, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:43:24,815 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7998154984198763, 'learning_rate': 0.0012477499310816287, 'weight_decay': 0.0002972087154270757, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 15:43:24,815 - INFO - Trial 381: Train MSE=3.6564827476228987, Train R²=0.3926042446068355
2024-10-31 15:43:24,815 - INFO - Trial 381: Test MSE=2.8843096494674683, Test R²=0.5276606529951096
2024-10-31 15:43:24,815 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:43:24,816 - INFO - Trial 381 finished with value: 2.8843096494674683 and parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7998154984198763, 'learning_rate': 0.0012477499310816287, 'weight_decay': 0.0002972087154270757, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:44:00,787 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7769851898896528, 'learning_rate': 0.002351846362302588, 'weight_decay': 0.0009646423538239974, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 15:44:00,787 - INFO - Trial 382: Train MSE=2.0712322124413083, Train R²=0.6550673118659428
2024-10-31 15:44:00,787 - INFO - Trial 382: Test MSE=2.25266478742872, Test R²=0.6333814263343811
2024-10-31 15:44:00,787 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:44:00,788 - INFO - Trial 382 finished with value: 2.25266478742872 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7769851898896528, 'learning_rate': 0.002351846362302588, 'weight_decay': 0.0009646423538239974, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:44:38,709 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7895455893580535, 'learning_rate': 0.0010094448031972274, 'weight_decay': 0.0006368377440084063, 'batch_size': 512, 'tree_depth': 7}
2024-10-31 15:44:38,709 - INFO - Trial 383: Train MSE=2.9816481300762723, Train R²=0.5030647984572819
2024-10-31 15:44:38,710 - INFO - Trial 383: Test MSE=2.3446803774152483, Test R²=0.6184790134429932
2024-10-31 15:44:38,710 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:44:38,712 - INFO - Trial 383 finished with value: 2.3446803774152483 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7895455893580535, 'learning_rate': 0.0010094448031972274, 'weight_decay': 0.0006368377440084063, 'batch_size': 512, 'tree_depth': 7}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:45:13,588 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7682429375027264, 'learning_rate': 0.0010861583060654083, 'weight_decay': 0.0002567781742373057, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:45:13,588 - INFO - Trial 384: Train MSE=2.1752264073916843, Train R²=0.636912043605532
2024-10-31 15:45:13,588 - INFO - Trial 384: Test MSE=2.2378020967756, Test R²=0.6357358353478568
2024-10-31 15:45:13,588 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:45:13,589 - INFO - Trial 384 finished with value: 2.2378020967756 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7682429375027264, 'learning_rate': 0.0010861583060654083, 'weight_decay': 0.0002567781742373057, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:45:46,758 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7801402591574731, 'learning_rate': 0.0019875613686503014, 'weight_decay': 0.0003162920635691557, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:45:46,758 - INFO - Trial 385: Train MSE=2.006637530667441, Train R²=0.6660222411155701
2024-10-31 15:45:46,758 - INFO - Trial 385: Test MSE=2.2631947994232178, Test R²=0.6314875568662371
2024-10-31 15:45:46,758 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:45:46,760 - INFO - Trial 385 finished with value: 2.2631947994232178 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7801402591574731, 'learning_rate': 0.0019875613686503014, 'weight_decay': 0.0003162920635691557, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:46:19,251 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.760499378705531, 'learning_rate': 0.0013829866840224137, 'weight_decay': 0.00033653885681394526, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 15:46:19,252 - INFO - Trial 386: Train MSE=2.0050247269017354, Train R²=0.6659312801701682
2024-10-31 15:46:19,252 - INFO - Trial 386: Test MSE=2.2417738948549544, Test R²=0.6350895166397095
2024-10-31 15:46:19,252 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:46:19,253 - INFO - Trial 386 finished with value: 2.2417738948549544 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.760499378705531, 'learning_rate': 0.0013829866840224137, 'weight_decay': 0.00033653885681394526, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:46:53,228 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7907878707300827, 'learning_rate': 0.0009195771024583214, 'weight_decay': 0.00028396974224215757, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:46:53,228 - INFO - Trial 387: Train MSE=2.5135215435709273, Train R²=0.5809627366917474
2024-10-31 15:46:53,228 - INFO - Trial 387: Test MSE=2.2458380120141164, Test R²=0.6345649872507367
2024-10-31 15:46:53,228 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:46:53,230 - INFO - Trial 387 finished with value: 2.2458380120141164 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7907878707300827, 'learning_rate': 0.0009195771024583214, 'weight_decay': 0.00028396974224215757, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:47:26,284 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7762599179777494, 'learning_rate': 0.004542297668160522, 'weight_decay': 0.00032084419618490077, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 15:47:26,284 - INFO - Trial 388: Train MSE=1.9595530756882258, Train R²=0.6734256212200437
2024-10-31 15:47:26,285 - INFO - Trial 388: Test MSE=2.24019718170166, Test R²=0.6353408013071332
2024-10-31 15:47:26,285 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:47:26,287 - INFO - Trial 388 finished with value: 2.24019718170166 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7762599179777494, 'learning_rate': 0.004542297668160522, 'weight_decay': 0.00032084419618490077, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:47:59,072 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7907609512667094, 'learning_rate': 0.0016229570498884642, 'weight_decay': 0.00035257431571876003, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:47:59,072 - INFO - Trial 389: Train MSE=2.2357138437884196, Train R²=0.6273802646568843
2024-10-31 15:47:59,072 - INFO - Trial 389: Test MSE=2.2306369032178606, Test R²=0.6369119712284633
2024-10-31 15:47:59,072 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:47:59,074 - INFO - Trial 389 finished with value: 2.2306369032178606 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7907609512667094, 'learning_rate': 0.0016229570498884642, 'weight_decay': 0.00035257431571876003, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:48:33,741 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.782139077718517, 'learning_rate': 0.0011502963936899718, 'weight_decay': 0.0002964328432104189, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:48:33,741 - INFO - Trial 390: Train MSE=2.268351137638092, Train R²=0.6224387245518821
2024-10-31 15:48:33,741 - INFO - Trial 390: Test MSE=2.2172705105372836, Test R²=0.6391389880861554
2024-10-31 15:48:33,741 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:48:33,743 - INFO - Trial 390 finished with value: 2.2172705105372836 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.782139077718517, 'learning_rate': 0.0011502963936899718, 'weight_decay': 0.0002964328432104189, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:49:11,206 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7920683977933327, 'learning_rate': 0.001141871213712855, 'weight_decay': 0.00029265142535496387, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:49:11,206 - INFO - Trial 391: Train MSE=1.931144735642842, Train R²=0.6777148587363107
2024-10-31 15:49:11,206 - INFO - Trial 391: Test MSE=2.245164053780692, Test R²=0.6346031597682408
2024-10-31 15:49:11,206 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:49:11,207 - INFO - Trial 391 finished with value: 2.245164053780692 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7920683977933327, 'learning_rate': 0.001141871213712855, 'weight_decay': 0.00029265142535496387, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:49:43,729 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995257614066098, 'learning_rate': 0.0012177330413077724, 'weight_decay': 0.0003030854441951733, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 15:49:43,729 - INFO - Trial 392: Train MSE=2.4346990755626132, Train R²=0.5942392264093671
2024-10-31 15:49:43,730 - INFO - Trial 392: Test MSE=2.234511171068464, Test R²=0.63633793592453
2024-10-31 15:49:43,730 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:49:43,731 - INFO - Trial 392 finished with value: 2.234511171068464 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995257614066098, 'learning_rate': 0.0012177330413077724, 'weight_decay': 0.0003030854441951733, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:51:00,959 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7680125031296109, 'learning_rate': 0.0013243769535955247, 'weight_decay': 0.0003162812761526058, 'batch_size': 128, 'tree_depth': 8}
2024-10-31 15:51:00,959 - INFO - Trial 393: Train MSE=2.155036992260388, Train R²=0.6360686240451676
2024-10-31 15:51:00,959 - INFO - Trial 393: Test MSE=2.318042056901114, Test R²=0.6160787216254643
2024-10-31 15:51:00,959 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:51:00,961 - INFO - Trial 393 finished with value: 2.318042056901114 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7680125031296109, 'learning_rate': 0.0013243769535955247, 'weight_decay': 0.0003162812761526058, 'batch_size': 128, 'tree_depth': 8}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:51:36,256 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.3037183348037461, 'learning_rate': 0.0009923212336012909, 'weight_decay': 0.0002635623038031377, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:51:36,256 - INFO - Trial 394: Train MSE=0.5350109253610883, Train R²=0.9106954251016889
2024-10-31 15:51:36,256 - INFO - Trial 394: Test MSE=2.4969750813075473, Test R²=0.5932620338031224
2024-10-31 15:51:36,256 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:51:36,257 - INFO - Trial 394 finished with value: 2.4969750813075473 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.3037183348037461, 'learning_rate': 0.0009923212336012909, 'weight_decay': 0.0002635623038031377, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:52:10,580 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7837915852561675, 'learning_rate': 0.0011100714051849798, 'weight_decay': 0.00029380612385647317, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:52:10,580 - INFO - Trial 395: Train MSE=2.3533975226538524, Train R²=0.6087703640971865
2024-10-31 15:52:10,581 - INFO - Trial 395: Test MSE=2.237662434577942, Test R²=0.6359575305666242
2024-10-31 15:52:10,581 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:52:10,582 - INFO - Trial 395 finished with value: 2.237662434577942 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7837915852561675, 'learning_rate': 0.0011100714051849798, 'weight_decay': 0.00029380612385647317, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:52:45,713 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7505112463071711, 'learning_rate': 0.0011943458869256868, 'weight_decay': 0.00028055483703810465, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 15:52:45,713 - INFO - Trial 396: Train MSE=2.0495669160570418, Train R²=0.6588337549141475
2024-10-31 15:52:45,713 - INFO - Trial 396: Test MSE=2.244000196456909, Test R²=0.6346179757799421
2024-10-31 15:52:45,713 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:52:45,714 - INFO - Trial 396 finished with value: 2.244000196456909 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7505112463071711, 'learning_rate': 0.0011943458869256868, 'weight_decay': 0.00028055483703810465, 'batch_size': 512, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:53:19,230 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999606173868247, 'learning_rate': 0.0008981825583461335, 'weight_decay': 0.00033353143598992545, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 15:53:19,230 - INFO - Trial 397: Train MSE=2.5637955324990407, Train R²=0.5737703549010413
2024-10-31 15:53:19,231 - INFO - Trial 397: Test MSE=2.2294902290616716, Test R²=0.6370744194303241
2024-10-31 15:53:19,231 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:53:19,233 - INFO - Trial 397 finished with value: 2.2294902290616716 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999606173868247, 'learning_rate': 0.0008981825583461335, 'weight_decay': 0.00033353143598992545, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:53:54,592 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7741127632720655, 'learning_rate': 0.00968963378969916, 'weight_decay': 0.0003057777075126973, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:53:54,592 - INFO - Trial 398: Train MSE=1.9888792421136583, Train R²=0.6689596538032804
2024-10-31 15:53:54,593 - INFO - Trial 398: Test MSE=2.3074051993233815, Test R²=0.6244968686785016
2024-10-31 15:53:54,593 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:53:54,593 - INFO - Trial 398 finished with value: 2.3074051993233815 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7741127632720655, 'learning_rate': 0.00968963378969916, 'weight_decay': 0.0003057777075126973, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:54:29,257 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7839182119701738, 'learning_rate': 0.0007061867730148172, 'weight_decay': 0.0003254628641184873, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:54:29,257 - INFO - Trial 399: Train MSE=2.6710805807794844, Train R²=0.555711607847895
2024-10-31 15:54:29,257 - INFO - Trial 399: Test MSE=2.244665333202907, Test R²=0.6345555697168622
2024-10-31 15:54:29,257 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:54:29,259 - INFO - Trial 399 finished with value: 2.244665333202907 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7839182119701738, 'learning_rate': 0.0007061867730148172, 'weight_decay': 0.0003254628641184873, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:55:02,465 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.790294851914358, 'learning_rate': 0.0010690319096755103, 'weight_decay': 0.0002768916772961896, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 15:55:02,465 - INFO - Trial 400: Train MSE=2.395139855997903, Train R²=0.6019261798688343
2024-10-31 15:55:02,465 - INFO - Trial 400: Test MSE=2.2404882396970476, Test R²=0.6352752361978803
2024-10-31 15:55:02,465 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:55:02,467 - INFO - Trial 400 finished with value: 2.2404882396970476 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.790294851914358, 'learning_rate': 0.0010690319096755103, 'weight_decay': 0.0002768916772961896, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:55:35,887 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.772673777745391, 'learning_rate': 0.0035390198233952908, 'weight_decay': 0.00036668238741275895, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:55:35,888 - INFO - Trial 401: Train MSE=1.992226438862937, Train R²=0.6676880036081586
2024-10-31 15:55:35,888 - INFO - Trial 401: Test MSE=2.299804585320609, Test R²=0.625723830291203
2024-10-31 15:55:35,888 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:55:35,889 - INFO - Trial 401 finished with value: 2.299804585320609 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.772673777745391, 'learning_rate': 0.0035390198233952908, 'weight_decay': 0.00036668238741275895, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:56:08,420 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7630041576555834, 'learning_rate': 0.0008148932408736966, 'weight_decay': 0.00031006596810527, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 15:56:08,420 - INFO - Trial 402: Train MSE=2.3260870575904846, Train R²=0.6128315883023399
2024-10-31 15:56:08,420 - INFO - Trial 402: Test MSE=2.2487399748393466, Test R²=0.6340210352625165
2024-10-31 15:56:08,420 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:56:08,422 - INFO - Trial 402 finished with value: 2.2487399748393466 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7630041576555834, 'learning_rate': 0.0008148932408736966, 'weight_decay': 0.00031006596810527, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:56:47,414 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7824371656340224, 'learning_rate': 0.008441473536598033, 'weight_decay': 0.00033961200459665947, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:56:47,414 - INFO - Trial 403: Train MSE=2.0862844799246107, Train R²=0.6526747984545571
2024-10-31 15:56:47,415 - INFO - Trial 403: Test MSE=2.239609956741333, Test R²=0.6354143619537354
2024-10-31 15:56:47,415 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:56:47,416 - INFO - Trial 403 finished with value: 2.239609956741333 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7824371656340224, 'learning_rate': 0.008441473536598033, 'weight_decay': 0.00033961200459665947, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:57:25,936 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7907959497258465, 'learning_rate': 0.0009970417092558044, 'weight_decay': 0.00029163376542363026, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:57:25,937 - INFO - Trial 404: Train MSE=2.4487878339631215, Train R²=0.5927143267222813
2024-10-31 15:57:25,937 - INFO - Trial 404: Test MSE=2.23007333278656, Test R²=0.6371532848903111
2024-10-31 15:57:25,937 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:57:25,938 - INFO - Trial 404 finished with value: 2.23007333278656 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7907959497258465, 'learning_rate': 0.0009970417092558044, 'weight_decay': 0.00029163376542363026, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:58:02,294 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6372402964012323, 'learning_rate': 0.001359444761339376, 'weight_decay': 0.0003145633046586407, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 15:58:02,294 - INFO - Trial 405: Train MSE=1.2879771760531835, Train R²=0.785767280629703
2024-10-31 15:58:02,294 - INFO - Trial 405: Test MSE=2.3528874261038646, Test R²=0.6167459828513009
2024-10-31 15:58:02,294 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:58:02,295 - INFO - Trial 405 finished with value: 2.3528874261038646 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6372402964012323, 'learning_rate': 0.001359444761339376, 'weight_decay': 0.0003145633046586407, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:58:37,459 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7771815659810173, 'learning_rate': 0.0015306709987590503, 'weight_decay': 0.0002980458962072268, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 15:58:37,459 - INFO - Trial 406: Train MSE=2.102941926036562, Train R²=0.6507674711091178
2024-10-31 15:58:37,459 - INFO - Trial 406: Test MSE=2.2137936864580428, Test R²=0.6395678690501622
2024-10-31 15:58:37,459 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:58:37,460 - INFO - Trial 406 finished with value: 2.2137936864580428 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7771815659810173, 'learning_rate': 0.0015306709987590503, 'weight_decay': 0.0002980458962072268, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:59:05,960 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7066998447128536, 'learning_rate': 0.0014850450660702833, 'weight_decay': 0.00029989665146121653, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 15:59:05,960 - INFO - Trial 407: Train MSE=1.9572661774499076, Train R²=0.6750352552958897
2024-10-31 15:59:05,960 - INFO - Trial 407: Test MSE=2.319454252719879, Test R²=0.6196349114179611
2024-10-31 15:59:05,960 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:59:05,962 - INFO - Trial 407 finished with value: 2.319454252719879 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7066998447128536, 'learning_rate': 0.0014850450660702833, 'weight_decay': 0.00029989665146121653, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 15:59:40,136 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999984879079314, 'learning_rate': 0.0013353158775523731, 'weight_decay': 0.0003260815071879572, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 15:59:40,136 - INFO - Trial 408: Train MSE=2.3840499435152327, Train R²=0.6030094687427793
2024-10-31 15:59:40,136 - INFO - Trial 408: Test MSE=2.2394037587302074, Test R²=0.6354885952813285
2024-10-31 15:59:40,136 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 15:59:40,138 - INFO - Trial 408 finished with value: 2.2394037587302074 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999984879079314, 'learning_rate': 0.0013353158775523731, 'weight_decay': 0.0003260815071879572, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:00:30,465 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7840920162100581, 'learning_rate': 0.0014947607723448538, 'weight_decay': 0.00034989997437231214, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 16:00:30,465 - INFO - Trial 409: Train MSE=1.8895729907921381, Train R²=0.6843480723244804
2024-10-31 16:00:30,465 - INFO - Trial 409: Test MSE=2.260467222758702, Test R²=0.6299539293561663
2024-10-31 16:00:30,465 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:00:30,467 - INFO - Trial 409 finished with value: 2.260467222758702 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7840920162100581, 'learning_rate': 0.0014947607723448538, 'weight_decay': 0.00034989997437231214, 'batch_size': 256, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:01:04,053 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6171418676451871, 'learning_rate': 0.0012420813032798063, 'weight_decay': 0.0003126019643184737, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:01:04,053 - INFO - Trial 410: Train MSE=1.2254676818847656, Train R²=0.7958889326878956
2024-10-31 16:01:04,053 - INFO - Trial 410: Test MSE=2.339755501065935, Test R²=0.6189390335764203
2024-10-31 16:01:04,053 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:01:04,054 - INFO - Trial 410 finished with value: 2.339755501065935 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6171418676451871, 'learning_rate': 0.0012420813032798063, 'weight_decay': 0.0003126019643184737, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:01:38,146 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7908764282742783, 'learning_rate': 0.0011437768551945927, 'weight_decay': 0.0002966287790796833, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 16:01:38,146 - INFO - Trial 411: Train MSE=2.4010606919016158, Train R²=0.6014156746012824
2024-10-31 16:01:38,146 - INFO - Trial 411: Test MSE=2.2111131634031023, Test R²=0.64011378799166
2024-10-31 16:01:38,146 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:01:38,147 - INFO - Trial 411 finished with value: 2.2111131634031023 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7908764282742783, 'learning_rate': 0.0011437768551945927, 'weight_decay': 0.0002966287790796833, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:02:11,152 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7609931593815922, 'learning_rate': 0.0011045237228594978, 'weight_decay': 0.0008789856516931124, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 16:02:11,152 - INFO - Trial 412: Train MSE=2.109603979757854, Train R²=0.6490402328116553
2024-10-31 16:02:11,152 - INFO - Trial 412: Test MSE=2.2422310284205844, Test R²=0.6349557042121887
2024-10-31 16:02:11,152 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:02:11,154 - INFO - Trial 412 finished with value: 2.2422310284205844 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7609931593815922, 'learning_rate': 0.0011045237228594978, 'weight_decay': 0.0008789856516931124, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:02:47,446 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7723675608845879, 'learning_rate': 0.001163215711535947, 'weight_decay': 0.0002901029448875011, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:02:47,446 - INFO - Trial 413: Train MSE=1.81325130377497, Train R²=0.6980543434619904
2024-10-31 16:02:47,446 - INFO - Trial 413: Test MSE=2.294693946838379, Test R²=0.6264772670609611
2024-10-31 16:02:47,446 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:02:47,446 - INFO - Trial 413 finished with value: 2.294693946838379 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7723675608845879, 'learning_rate': 0.001163215711535947, 'weight_decay': 0.0002901029448875011, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:03:20,713 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7826298427648803, 'learning_rate': 0.0009468511628436595, 'weight_decay': 0.00029882487838290623, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:03:20,713 - INFO - Trial 414: Train MSE=2.3782469715390886, Train R²=0.6031449628727776
2024-10-31 16:03:20,713 - INFO - Trial 414: Test MSE=2.2299117871693204, Test R²=0.637204647064209
2024-10-31 16:03:20,713 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:03:20,715 - INFO - Trial 414 finished with value: 2.2299117871693204 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7826298427648803, 'learning_rate': 0.0009468511628436595, 'weight_decay': 0.00029882487838290623, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:03:55,614 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7887944998950988, 'learning_rate': 0.0010595480673083152, 'weight_decay': 0.0004546907949480143, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:03:55,614 - INFO - Trial 415: Train MSE=2.383821734360286, Train R²=0.6032695578677314
2024-10-31 16:03:55,614 - INFO - Trial 415: Test MSE=2.2090349197387695, Test R²=0.6403888634272984
2024-10-31 16:03:55,614 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:03:55,616 - INFO - Trial 415 finished with value: 2.2090349197387695 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7887944998950988, 'learning_rate': 0.0010595480673083152, 'weight_decay': 0.0004546907949480143, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:04:29,386 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7905036152477228, 'learning_rate': 0.0010507025649405856, 'weight_decay': 0.00044210764657637736, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 16:04:29,386 - INFO - Trial 416: Train MSE=2.398902177810669, Train R²=0.6010896776403699
2024-10-31 16:04:29,387 - INFO - Trial 416: Test MSE=2.2427925041743686, Test R²=0.6350871579987662
2024-10-31 16:04:29,387 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:04:29,388 - INFO - Trial 416 finished with value: 2.2427925041743686 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7905036152477228, 'learning_rate': 0.0010507025649405856, 'weight_decay': 0.00044210764657637736, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:05:06,577 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7914686490273559, 'learning_rate': 0.0007543962978895408, 'weight_decay': 0.0005422922486764202, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:05:06,577 - INFO - Trial 417: Train MSE=2.6271373203822543, Train R²=0.5624284190790994
2024-10-31 16:05:06,577 - INFO - Trial 417: Test MSE=2.2407268966947282, Test R²=0.6352493166923523
2024-10-31 16:05:06,577 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:05:06,579 - INFO - Trial 417 finished with value: 2.2407268966947282 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7914686490273559, 'learning_rate': 0.0007543962978895408, 'weight_decay': 0.0005422922486764202, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:05:51,346 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7813781803867191, 'learning_rate': 0.0009124748812399829, 'weight_decay': 0.00039048445225026694, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:05:51,346 - INFO - Trial 418: Train MSE=2.414233454636165, Train R²=0.5985541407551084
2024-10-31 16:05:51,346 - INFO - Trial 418: Test MSE=2.2159931319100514, Test R²=0.6394276108060565
2024-10-31 16:05:51,347 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:05:51,348 - INFO - Trial 418 finished with value: 2.2159931319100514 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7813781803867191, 'learning_rate': 0.0009124748812399829, 'weight_decay': 0.00039048445225026694, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:07:22,721 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7787058357153008, 'learning_rate': 0.0008562104303707986, 'weight_decay': 0.000512618359692301, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 16:07:22,721 - INFO - Trial 419: Train MSE=1.8590509848935264, Train R²=0.6865867919155529
2024-10-31 16:07:22,722 - INFO - Trial 419: Test MSE=2.2504185991627828, Test R²=0.6275776241506849
2024-10-31 16:07:22,722 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:07:22,722 - INFO - Trial 419 finished with value: 2.2504185991627828 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7787058357153008, 'learning_rate': 0.0008562104303707986, 'weight_decay': 0.000512618359692301, 'batch_size': 128, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:08:01,695 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7829183554208655, 'learning_rate': 0.0009054221619623214, 'weight_decay': 0.00041399469986549834, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:08:01,695 - INFO - Trial 420: Train MSE=2.3708058340208873, Train R²=0.6049369829041618
2024-10-31 16:08:01,696 - INFO - Trial 420: Test MSE=2.2312473910195485, Test R²=0.6368698733193534
2024-10-31 16:08:01,696 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:08:01,697 - INFO - Trial 420 finished with value: 2.2312473910195485 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7829183554208655, 'learning_rate': 0.0009054221619623214, 'weight_decay': 0.00041399469986549834, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:08:42,825 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7636099137592273, 'learning_rate': 0.0009665261790603342, 'weight_decay': 0.00042150368050812646, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:08:42,825 - INFO - Trial 421: Train MSE=2.500161635024207, Train R²=0.5847812167235783
2024-10-31 16:08:42,825 - INFO - Trial 421: Test MSE=2.2207013879503523, Test R²=0.6385361892836434
2024-10-31 16:08:42,825 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:08:42,827 - INFO - Trial 421 finished with value: 2.2207013879503523 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7636099137592273, 'learning_rate': 0.0009665261790603342, 'weight_decay': 0.00042150368050812646, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:09:19,447 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7733862947384366, 'learning_rate': 0.000834184710973396, 'weight_decay': 0.00046422963658270157, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:09:19,447 - INFO - Trial 422: Train MSE=2.342495424406869, Train R²=0.6102682266916547
2024-10-31 16:09:19,447 - INFO - Trial 422: Test MSE=2.225307055882045, Test R²=0.6377393688474383
2024-10-31 16:09:19,447 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:09:19,449 - INFO - Trial 422 finished with value: 2.225307055882045 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7733862947384366, 'learning_rate': 0.000834184710973396, 'weight_decay': 0.00046422963658270157, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:09:57,909 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7897013020181803, 'learning_rate': 0.0010338339090215077, 'weight_decay': 0.00039451796852145145, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:09:57,910 - INFO - Trial 423: Train MSE=2.134970392499651, Train R²=0.6449062206915447
2024-10-31 16:09:57,910 - INFO - Trial 423: Test MSE=2.244400075503758, Test R²=0.6347637091364179
2024-10-31 16:09:57,910 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:09:57,910 - INFO - Trial 423 finished with value: 2.244400075503758 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7897013020181803, 'learning_rate': 0.0010338339090215077, 'weight_decay': 0.00039451796852145145, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:10:32,115 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.780621120284073, 'learning_rate': 0.0009526380104398827, 'weight_decay': 0.0004543845055499085, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 16:10:32,115 - INFO - Trial 424: Train MSE=2.4626445940562656, Train R²=0.5889539441892079
2024-10-31 16:10:32,115 - INFO - Trial 424: Test MSE=2.2537300246102467, Test R²=0.6332639285496303
2024-10-31 16:10:32,115 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:10:32,116 - INFO - Trial 424 finished with value: 2.2537300246102467 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.780621120284073, 'learning_rate': 0.0009526380104398827, 'weight_decay': 0.0004543845055499085, 'batch_size': 512, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:11:14,614 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999948286036153, 'learning_rate': 0.0007831350358450263, 'weight_decay': 0.00048644323241220724, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:11:14,614 - INFO - Trial 425: Train MSE=2.736766585281917, Train R²=0.5441972592047283
2024-10-31 16:11:14,614 - INFO - Trial 425: Test MSE=2.235358016831534, Test R²=0.6362822226115635
2024-10-31 16:11:14,614 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:11:14,616 - INFO - Trial 425 finished with value: 2.235358016831534 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999948286036153, 'learning_rate': 0.0007831350358450263, 'weight_decay': 0.00048644323241220724, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:11:58,961 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7538825396278223, 'learning_rate': 0.0011530451995918004, 'weight_decay': 0.0003943939433692899, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:11:58,961 - INFO - Trial 426: Train MSE=1.988826939037868, Train R²=0.6686706479106631
2024-10-31 16:11:58,961 - INFO - Trial 426: Test MSE=2.257013968058995, Test R²=0.6327668258122036
2024-10-31 16:11:58,961 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:11:58,962 - INFO - Trial 426 finished with value: 2.257013968058995 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7538825396278223, 'learning_rate': 0.0011530451995918004, 'weight_decay': 0.0003943939433692899, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:12:44,280 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902997764704741, 'learning_rate': 0.001229120449999474, 'weight_decay': 0.00042635870581814276, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:12:44,280 - INFO - Trial 427: Train MSE=2.3282378145626614, Train R²=0.6130110727889198
2024-10-31 16:12:44,281 - INFO - Trial 427: Test MSE=2.259839483669826, Test R²=0.6320933359009879
2024-10-31 16:12:44,281 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:12:44,282 - INFO - Trial 427 finished with value: 2.259839483669826 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902997764704741, 'learning_rate': 0.001229120449999474, 'weight_decay': 0.00042635870581814276, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:13:29,359 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7689144496238501, 'learning_rate': 0.001065383966818353, 'weight_decay': 0.0004751139003130455, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:13:29,360 - INFO - Trial 428: Train MSE=2.16314520580428, Train R²=0.6401466046060834
2024-10-31 16:13:29,360 - INFO - Trial 428: Test MSE=2.243255921772548, Test R²=0.6348647730691093
2024-10-31 16:13:29,360 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:13:29,361 - INFO - Trial 428 finished with value: 2.243255921772548 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7689144496238501, 'learning_rate': 0.001065383966818353, 'weight_decay': 0.0004751139003130455, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:14:14,549 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7813160674403544, 'learning_rate': 0.0009060546919362159, 'weight_decay': 0.0003673586682781758, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:14:14,549 - INFO - Trial 429: Train MSE=2.4274339420454845, Train R²=0.5963073372840881
2024-10-31 16:14:14,549 - INFO - Trial 429: Test MSE=2.276941708156041, Test R²=0.6292886052812848
2024-10-31 16:14:14,549 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:14:14,550 - INFO - Trial 429 finished with value: 2.276941708156041 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7813160674403544, 'learning_rate': 0.0009060546919362159, 'weight_decay': 0.0003673586682781758, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:14:59,748 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7907727741093245, 'learning_rate': 0.0010034965958564644, 'weight_decay': 0.0005058715380366456, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:14:59,748 - INFO - Trial 430: Train MSE=2.4262326700346812, Train R²=0.5962941476276943
2024-10-31 16:14:59,748 - INFO - Trial 430: Test MSE=2.213839190346854, Test R²=0.6395901356424604
2024-10-31 16:14:59,748 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:14:59,749 - INFO - Trial 430 finished with value: 2.213839190346854 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7907727741093245, 'learning_rate': 0.0010034965958564644, 'weight_decay': 0.0005058715380366456, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:15:32,415 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7896198857776138, 'learning_rate': 0.0008346560954971334, 'weight_decay': 0.0005323519542628844, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 16:15:32,416 - INFO - Trial 431: Train MSE=3.1763748271124705, Train R²=0.47245595284870695
2024-10-31 16:15:32,416 - INFO - Trial 431: Test MSE=2.251676619052887, Test R²=0.6309066414833069
2024-10-31 16:15:32,416 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:15:32,417 - INFO - Trial 431 finished with value: 2.251676619052887 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7896198857776138, 'learning_rate': 0.0008346560954971334, 'weight_decay': 0.0005323519542628844, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:16:10,400 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995610263150907, 'learning_rate': 0.000985575450078934, 'weight_decay': 0.0005363623139581146, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:16:10,400 - INFO - Trial 432: Train MSE=2.481548982007163, Train R²=0.586076061640467
2024-10-31 16:16:10,400 - INFO - Trial 432: Test MSE=2.238970007215227, Test R²=0.6355936697551182
2024-10-31 16:16:10,400 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:16:10,402 - INFO - Trial 432 finished with value: 2.238970007215227 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995610263150907, 'learning_rate': 0.000985575450078934, 'weight_decay': 0.0005363623139581146, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:16:55,552 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7750687371192528, 'learning_rate': 0.009215176808700128, 'weight_decay': 0.0005048023356963024, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:16:55,552 - INFO - Trial 433: Train MSE=2.1993693709373474, Train R²=0.6340351083448955
2024-10-31 16:16:55,553 - INFO - Trial 433: Test MSE=2.2457103048052107, Test R²=0.6345455135617938
2024-10-31 16:16:55,553 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:16:55,554 - INFO - Trial 433 finished with value: 2.2457103048052107 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7750687371192528, 'learning_rate': 0.009215176808700128, 'weight_decay': 0.0005048023356963024, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:17:40,762 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7921249018033076, 'learning_rate': 0.000722701350214018, 'weight_decay': 0.00048117340618891973, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:17:40,762 - INFO - Trial 434: Train MSE=2.672335854598454, Train R²=0.5552618162972587
2024-10-31 16:17:40,762 - INFO - Trial 434: Test MSE=2.2407198633466447, Test R²=0.6353802766118731
2024-10-31 16:17:40,762 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:17:40,763 - INFO - Trial 434 finished with value: 2.2407198633466447 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7921249018033076, 'learning_rate': 0.000722701350214018, 'weight_decay': 0.00048117340618891973, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:18:42,787 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7901208201657813, 'learning_rate': 0.0009681959545482708, 'weight_decay': 0.000567184447207124, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 16:18:42,787 - INFO - Trial 435: Train MSE=2.0461935443537578, Train R²=0.6576182767748833
2024-10-31 16:18:42,787 - INFO - Trial 435: Test MSE=2.243264760289873, Test R²=0.6331300905772618
2024-10-31 16:18:42,787 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:18:42,788 - INFO - Trial 435 finished with value: 2.243264760289873 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7901208201657813, 'learning_rate': 0.0009681959545482708, 'weight_decay': 0.000567184447207124, 'batch_size': 256, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:19:28,256 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7658065546799427, 'learning_rate': 0.0008511074552861538, 'weight_decay': 0.0005091055981569257, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:19:28,256 - INFO - Trial 436: Train MSE=2.2950913310050964, Train R²=0.617532804608345
2024-10-31 16:19:28,256 - INFO - Trial 436: Test MSE=2.261785728590829, Test R²=0.6318809049470084
2024-10-31 16:19:28,256 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:19:28,257 - INFO - Trial 436 finished with value: 2.261785728590829 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7658065546799427, 'learning_rate': 0.0008511074552861538, 'weight_decay': 0.0005091055981569257, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:20:13,617 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.79999331583303, 'learning_rate': 0.008411029331015072, 'weight_decay': 0.000493943668072451, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:20:13,617 - INFO - Trial 437: Train MSE=2.2837852154459273, Train R²=0.6201460148606982
2024-10-31 16:20:13,617 - INFO - Trial 437: Test MSE=2.2205147402627126, Test R²=0.6385374324662345
2024-10-31 16:20:13,618 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:20:13,620 - INFO - Trial 437 finished with value: 2.2205147402627126 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.79999331583303, 'learning_rate': 0.008411029331015072, 'weight_decay': 0.000493943668072451, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:20:58,885 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7793435000238781, 'learning_rate': 0.0010309419520645746, 'weight_decay': 0.0005196550884832288, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:20:58,885 - INFO - Trial 438: Train MSE=2.2968459810529436, Train R²=0.6168609857559204
2024-10-31 16:20:58,885 - INFO - Trial 438: Test MSE=2.25562926701137, Test R²=0.6327604055404663
2024-10-31 16:20:58,886 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:20:58,887 - INFO - Trial 438 finished with value: 2.25562926701137 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7793435000238781, 'learning_rate': 0.0010309419520645746, 'weight_decay': 0.0005196550884832288, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:21:43,744 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7851912353463448, 'learning_rate': 0.0009228656970263519, 'weight_decay': 0.00047916582210805203, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:21:43,744 - INFO - Trial 439: Train MSE=2.4193898183958873, Train R²=0.5963349086897713
2024-10-31 16:21:43,744 - INFO - Trial 439: Test MSE=2.275632517678397, Test R²=0.6296177932194301
2024-10-31 16:21:43,744 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:21:43,745 - INFO - Trial 439 finished with value: 2.275632517678397 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7851912353463448, 'learning_rate': 0.0009228656970263519, 'weight_decay': 0.00047916582210805203, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:22:29,940 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.4642438558769773, 'learning_rate': 0.0010593847396022694, 'weight_decay': 0.00045584777183771294, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:22:29,940 - INFO - Trial 440: Train MSE=0.6541088776929038, Train R²=0.8909630796739033
2024-10-31 16:22:29,940 - INFO - Trial 440: Test MSE=2.494830472128732, Test R²=0.5936682905469622
2024-10-31 16:22:29,940 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:22:29,941 - INFO - Trial 440 finished with value: 2.494830472128732 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.4642438558769773, 'learning_rate': 0.0010593847396022694, 'weight_decay': 0.00045584777183771294, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:23:06,893 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7740567937552957, 'learning_rate': 0.009934439115267825, 'weight_decay': 0.0005765824340169536, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:23:06,893 - INFO - Trial 441: Train MSE=2.299782416650227, Train R²=0.6172633873564857
2024-10-31 16:23:06,894 - INFO - Trial 441: Test MSE=2.2407935006277904, Test R²=0.6352759855134147
2024-10-31 16:23:06,894 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:23:06,895 - INFO - Trial 441 finished with value: 2.2407935006277904 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7740567937552957, 'learning_rate': 0.009934439115267825, 'weight_decay': 0.0005765824340169536, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:23:45,067 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7895123436982893, 'learning_rate': 0.0012884023355495154, 'weight_decay': 0.00043582469914444673, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:23:45,067 - INFO - Trial 442: Train MSE=2.2759936366762434, Train R²=0.621064196739878
2024-10-31 16:23:45,067 - INFO - Trial 442: Test MSE=2.2206969261169434, Test R²=0.6384394764900208
2024-10-31 16:23:45,067 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:23:45,068 - INFO - Trial 442 finished with value: 2.2206969261169434 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7895123436982893, 'learning_rate': 0.0012884023355495154, 'weight_decay': 0.00043582469914444673, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:24:23,407 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7652531375422535, 'learning_rate': 0.0078016089684129816, 'weight_decay': 0.0005548286441098257, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:24:23,407 - INFO - Trial 443: Train MSE=2.14795030440603, Train R²=0.6427506059408188
2024-10-31 16:24:23,408 - INFO - Trial 443: Test MSE=2.2424711670194353, Test R²=0.6351783275604248
2024-10-31 16:24:23,408 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:24:23,409 - INFO - Trial 443 finished with value: 2.2424711670194353 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7652531375422535, 'learning_rate': 0.0078016089684129816, 'weight_decay': 0.0005548286441098257, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:26:03,831 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7422033159495791, 'learning_rate': 0.0008936509408497386, 'weight_decay': 0.00034844225114235325, 'batch_size': 128, 'tree_depth': 12}
2024-10-31 16:26:03,831 - INFO - Trial 444: Train MSE=1.6493309975734778, Train R²=0.7190258018672466
2024-10-31 16:26:03,831 - INFO - Trial 444: Test MSE=2.2754548277173723, Test R²=0.6233018572841372
2024-10-31 16:26:03,831 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:26:03,833 - INFO - Trial 444 finished with value: 2.2754548277173723 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7422033159495791, 'learning_rate': 0.0008936509408497386, 'weight_decay': 0.00034844225114235325, 'batch_size': 128, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:26:43,489 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7827195518695861, 'learning_rate': 0.0007867510621076619, 'weight_decay': 0.0003358766103787277, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:26:43,490 - INFO - Trial 445: Train MSE=3.315159874303, Train R²=0.44668527798993246
2024-10-31 16:26:43,490 - INFO - Trial 445: Test MSE=2.865007128034319, Test R²=0.5338826605251857
2024-10-31 16:26:43,490 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:26:43,491 - INFO - Trial 445 finished with value: 2.865007128034319 and parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7827195518695861, 'learning_rate': 0.0007867510621076619, 'weight_decay': 0.0003358766103787277, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:27:28,231 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999169087915011, 'learning_rate': 0.0011758849666770237, 'weight_decay': 0.0003753441784434377, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:27:28,231 - INFO - Trial 446: Train MSE=2.411227379526411, Train R²=0.597189969250134
2024-10-31 16:27:28,232 - INFO - Trial 446: Test MSE=2.2314601796013966, Test R²=0.636803754738399
2024-10-31 16:27:28,232 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:27:28,233 - INFO - Trial 446 finished with value: 2.2314601796013966 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999169087915011, 'learning_rate': 0.0011758849666770237, 'weight_decay': 0.0003753441784434377, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:28:12,569 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.774793397111702, 'learning_rate': 0.0013810707905843051, 'weight_decay': 0.0002816273324642422, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 16:28:12,569 - INFO - Trial 447: Train MSE=2.1888923943042755, Train R²=0.6362993163721902
2024-10-31 16:28:12,569 - INFO - Trial 447: Test MSE=2.248374104499817, Test R²=0.6340936422348022
2024-10-31 16:28:12,569 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:28:12,570 - INFO - Trial 447 finished with value: 2.248374104499817 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.774793397111702, 'learning_rate': 0.0013810707905843051, 'weight_decay': 0.0002816273324642422, 'batch_size': 512, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:28:50,341 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.6961104420620552, 'learning_rate': 0.005050350083264228, 'weight_decay': 0.000459879200914863, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:28:50,341 - INFO - Trial 448: Train MSE=1.5012963201318468, Train R²=0.7498418986797333
2024-10-31 16:28:50,341 - INFO - Trial 448: Test MSE=2.367969512939453, Test R²=0.6144299762589591
2024-10-31 16:28:50,341 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:28:50,342 - INFO - Trial 448 finished with value: 2.367969512939453 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.6961104420620552, 'learning_rate': 0.005050350083264228, 'weight_decay': 0.000459879200914863, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:29:31,154 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7233776695550735, 'learning_rate': 0.001015176049042861, 'weight_decay': 0.0005070931060219579, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 16:29:31,155 - INFO - Trial 449: Train MSE=1.8833888684000288, Train R²=0.686783424445561
2024-10-31 16:29:31,155 - INFO - Trial 449: Test MSE=2.279626863343375, Test R²=0.628853304045541
2024-10-31 16:29:31,155 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:29:31,156 - INFO - Trial 449 finished with value: 2.279626863343375 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7233776695550735, 'learning_rate': 0.001015176049042861, 'weight_decay': 0.0005070931060219579, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:30:16,394 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6691088624685699, 'learning_rate': 0.0010901283125940467, 'weight_decay': 0.0003126077726982704, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:30:16,395 - INFO - Trial 450: Train MSE=1.539751457316535, Train R²=0.7436196165425437
2024-10-31 16:30:16,395 - INFO - Trial 450: Test MSE=2.303332499095372, Test R²=0.6249856523105076
2024-10-31 16:30:16,395 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:30:16,396 - INFO - Trial 450 finished with value: 2.303332499095372 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6691088624685699, 'learning_rate': 0.0010901283125940467, 'weight_decay': 0.0003126077726982704, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:31:01,382 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7911231176036773, 'learning_rate': 0.0016392286626135972, 'weight_decay': 0.00026580568380393744, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:31:01,383 - INFO - Trial 451: Train MSE=2.2618281500680104, Train R²=0.6234594987971442
2024-10-31 16:31:01,383 - INFO - Trial 451: Test MSE=2.2422646284103394, Test R²=0.6349529198237828
2024-10-31 16:31:01,383 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:31:01,384 - INFO - Trial 451 finished with value: 2.2422646284103394 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7911231176036773, 'learning_rate': 0.0016392286626135972, 'weight_decay': 0.00026580568380393744, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:31:36,836 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7580297047104159, 'learning_rate': 0.0009540297436221317, 'weight_decay': 0.00038512370613847047, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 16:31:36,836 - INFO - Trial 452: Train MSE=2.20734241604805, Train R²=0.6330668649503163
2024-10-31 16:31:36,836 - INFO - Trial 452: Test MSE=2.225273847579956, Test R²=0.6380304438727242
2024-10-31 16:31:36,836 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:31:36,837 - INFO - Trial 452 finished with value: 2.225273847579956 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7580297047104159, 'learning_rate': 0.0009540297436221317, 'weight_decay': 0.00038512370613847047, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:32:18,008 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7821518795948885, 'learning_rate': 0.008846632772441056, 'weight_decay': 0.0003267199489153752, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:32:18,008 - INFO - Trial 453: Train MSE=2.1018740321908678, Train R²=0.6501967779227665
2024-10-31 16:32:18,008 - INFO - Trial 453: Test MSE=2.24599061693464, Test R²=0.6344291312353951
2024-10-31 16:32:18,008 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:32:18,009 - INFO - Trial 453 finished with value: 2.24599061693464 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7821518795948885, 'learning_rate': 0.008846632772441056, 'weight_decay': 0.0003267199489153752, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:33:03,254 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999008088939645, 'learning_rate': 0.0012786187713614186, 'weight_decay': 0.00035338339085979893, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:33:03,254 - INFO - Trial 454: Train MSE=2.357137850352696, Train R²=0.6076499649456569
2024-10-31 16:33:03,254 - INFO - Trial 454: Test MSE=2.222060510090419, Test R²=0.6384627563612801
2024-10-31 16:33:03,254 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:33:03,256 - INFO - Trial 454 finished with value: 2.222060510090419 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999008088939645, 'learning_rate': 0.0012786187713614186, 'weight_decay': 0.00035338339085979893, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:33:48,291 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7721417706841698, 'learning_rate': 0.0008970426383168506, 'weight_decay': 0.0003073123419036758, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 16:33:48,291 - INFO - Trial 455: Train MSE=2.356489794594901, Train R²=0.6077994193349566
2024-10-31 16:33:48,291 - INFO - Trial 455: Test MSE=2.2233072008405412, Test R²=0.638034428868975
2024-10-31 16:33:48,291 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:33:48,291 - INFO - Trial 455 finished with value: 2.2233072008405412 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7721417706841698, 'learning_rate': 0.0008970426383168506, 'weight_decay': 0.0003073123419036758, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:34:26,049 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7894591708545126, 'learning_rate': 0.0017164825303458532, 'weight_decay': 0.00028296894565115274, 'batch_size': 1024, 'tree_depth': 10}
2024-10-31 16:34:26,049 - INFO - Trial 456: Train MSE=2.5700871092932567, Train R²=0.5729348233767918
2024-10-31 16:34:26,049 - INFO - Trial 456: Test MSE=2.2709686160087585, Test R²=0.6277651637792587
2024-10-31 16:34:26,049 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:34:26,051 - INFO - Trial 456 finished with value: 2.2709686160087585 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7894591708545126, 'learning_rate': 0.0017164825303458532, 'weight_decay': 0.00028296894565115274, 'batch_size': 1024, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:35:11,188 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.783543351290044, 'learning_rate': 0.007230897371403508, 'weight_decay': 0.00034113419267054975, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:35:11,189 - INFO - Trial 457: Train MSE=2.054828886474882, Train R²=0.6585493577378136
2024-10-31 16:35:11,189 - INFO - Trial 457: Test MSE=2.245330776487078, Test R²=0.6344484516552517
2024-10-31 16:35:11,189 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:35:11,191 - INFO - Trial 457 finished with value: 2.245330776487078 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.783543351290044, 'learning_rate': 0.007230897371403508, 'weight_decay': 0.00034113419267054975, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:35:55,324 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7912063004788781, 'learning_rate': 0.0011678852574491267, 'weight_decay': 0.0002491522547309529, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:35:55,324 - INFO - Trial 458: Train MSE=2.3598357353891646, Train R²=0.6059993122305188
2024-10-31 16:35:55,325 - INFO - Trial 458: Test MSE=2.240159409386771, Test R²=0.6353215660367694
2024-10-31 16:35:55,325 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:35:55,326 - INFO - Trial 458 finished with value: 2.240159409386771 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7912063004788781, 'learning_rate': 0.0011678852574491267, 'weight_decay': 0.0002491522547309529, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:36:49,862 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7691053163420731, 'learning_rate': 0.001520373591775711, 'weight_decay': 0.0003194902000013366, 'batch_size': 256, 'tree_depth': 12}
2024-10-31 16:36:49,863 - INFO - Trial 459: Train MSE=2.172159744160516, Train R²=0.6364681114043508
2024-10-31 16:36:49,863 - INFO - Trial 459: Test MSE=2.2750101940972463, Test R²=0.6274620124271938
2024-10-31 16:36:49,863 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:36:49,864 - INFO - Trial 459 finished with value: 2.2750101940972463 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7691053163420731, 'learning_rate': 0.001520373591775711, 'weight_decay': 0.0003194902000013366, 'batch_size': 256, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:37:27,535 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7999593700135789, 'learning_rate': 0.0010833197221315587, 'weight_decay': 0.00030271413961795927, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:37:27,536 - INFO - Trial 460: Train MSE=2.777740248611995, Train R²=0.5382796611104693
2024-10-31 16:37:27,536 - INFO - Trial 460: Test MSE=2.268550327845982, Test R²=0.6308542660304478
2024-10-31 16:37:27,536 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:37:27,537 - INFO - Trial 460 finished with value: 2.268550327845982 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7999593700135789, 'learning_rate': 0.0010833197221315587, 'weight_decay': 0.00030271413961795927, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:38:03,710 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.4329687784072741, 'learning_rate': 0.0014070175967156927, 'weight_decay': 0.0002875338621806684, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:38:03,710 - INFO - Trial 461: Train MSE=0.7010175223861422, Train R²=0.8828401480402265
2024-10-31 16:38:03,711 - INFO - Trial 461: Test MSE=2.418574741908482, Test R²=0.6061461397579738
2024-10-31 16:38:03,711 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:38:03,712 - INFO - Trial 461 finished with value: 2.418574741908482 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.4329687784072741, 'learning_rate': 0.0014070175967156927, 'weight_decay': 0.0002875338621806684, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:38:49,112 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7792321638948168, 'learning_rate': 0.0007484507794566196, 'weight_decay': 0.00033035562089786167, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 16:38:49,112 - INFO - Trial 462: Train MSE=2.164682639496667, Train R²=0.6388612261840275
2024-10-31 16:38:49,112 - INFO - Trial 462: Test MSE=2.307249205453055, Test R²=0.6244336196354457
2024-10-31 16:38:49,112 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:38:49,113 - INFO - Trial 462 finished with value: 2.307249205453055 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7792321638948168, 'learning_rate': 0.0007484507794566196, 'weight_decay': 0.00033035562089786167, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:39:34,207 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7559964506437205, 'learning_rate': 0.0009891031360512736, 'weight_decay': 0.00040574966982487185, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:39:34,207 - INFO - Trial 463: Train MSE=2.1041849553585052, Train R²=0.6503570228815079
2024-10-31 16:39:34,207 - INFO - Trial 463: Test MSE=2.2482741389955794, Test R²=0.6340822236878532
2024-10-31 16:39:34,207 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:39:34,208 - INFO - Trial 463 finished with value: 2.2482741389955794 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7559964506437205, 'learning_rate': 0.0009891031360512736, 'weight_decay': 0.00040574966982487185, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:40:19,349 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7894991808989392, 'learning_rate': 0.0008363079846631432, 'weight_decay': 0.0005913769802781549, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:40:19,350 - INFO - Trial 464: Train MSE=2.535955880369459, Train R²=0.5779150277376175
2024-10-31 16:40:19,350 - INFO - Trial 464: Test MSE=2.2420584644590105, Test R²=0.6351952297346932
2024-10-31 16:40:19,350 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:40:19,351 - INFO - Trial 464 finished with value: 2.2420584644590105 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7894991808989392, 'learning_rate': 0.0008363079846631432, 'weight_decay': 0.0005913769802781549, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:41:04,869 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.778117622740604, 'learning_rate': 0.0006630849513835206, 'weight_decay': 0.0003067068104765066, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 16:41:04,869 - INFO - Trial 465: Train MSE=2.7506766489573886, Train R²=0.5421512084347861
2024-10-31 16:41:04,870 - INFO - Trial 465: Test MSE=2.242756349699838, Test R²=0.6349308746201652
2024-10-31 16:41:04,870 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:41:04,871 - INFO - Trial 465 finished with value: 2.242756349699838 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.778117622740604, 'learning_rate': 0.0006630849513835206, 'weight_decay': 0.0003067068104765066, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:41:49,978 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7905140956215517, 'learning_rate': 0.0012738157577543874, 'weight_decay': 0.00036213280267000526, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:41:49,978 - INFO - Trial 466: Train MSE=2.2810607041631425, Train R²=0.6204465010336467
2024-10-31 16:41:49,978 - INFO - Trial 466: Test MSE=2.2325181450162614, Test R²=0.6365861126354763
2024-10-31 16:41:49,978 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:41:49,979 - INFO - Trial 466 finished with value: 2.2325181450162614 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7905140956215517, 'learning_rate': 0.0012738157577543874, 'weight_decay': 0.00036213280267000526, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:43:30,664 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.769562557308019, 'learning_rate': 0.0010619677708509107, 'weight_decay': 0.0003180579900763947, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 16:43:30,664 - INFO - Trial 467: Train MSE=1.7664886808821134, Train R²=0.701086451964719
2024-10-31 16:43:30,664 - INFO - Trial 467: Test MSE=2.2776810824871063, Test R²=0.622828768832343
2024-10-31 16:43:30,664 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:43:30,665 - INFO - Trial 467 finished with value: 2.2776810824871063 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.769562557308019, 'learning_rate': 0.0010619677708509107, 'weight_decay': 0.0003180579900763947, 'batch_size': 128, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:44:06,264 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7827245482071866, 'learning_rate': 0.0015939540144736294, 'weight_decay': 0.00026386937775872064, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 16:44:06,264 - INFO - Trial 468: Train MSE=2.100930311850139, Train R²=0.650671763079507
2024-10-31 16:44:06,264 - INFO - Trial 468: Test MSE=2.252826145717076, Test R²=0.6332359824861798
2024-10-31 16:44:06,264 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:44:06,265 - INFO - Trial 468 finished with value: 2.252826145717076 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7827245482071866, 'learning_rate': 0.0015939540144736294, 'weight_decay': 0.00026386937775872064, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:44:49,011 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7917889100512066, 'learning_rate': 0.00826810429375644, 'weight_decay': 0.00029699078757326297, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:44:49,011 - INFO - Trial 469: Train MSE=2.0806101816041127, Train R²=0.6540148066622871
2024-10-31 16:44:49,011 - INFO - Trial 469: Test MSE=2.2223496437072754, Test R²=0.6382711614881244
2024-10-31 16:44:49,011 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:44:49,012 - INFO - Trial 469 finished with value: 2.2223496437072754 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7917889100512066, 'learning_rate': 0.00826810429375644, 'weight_decay': 0.00029699078757326297, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:45:26,609 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7633980198747565, 'learning_rate': 0.0008837731169115154, 'weight_decay': 0.000274243851694502, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:45:26,609 - INFO - Trial 470: Train MSE=2.025430445160185, Train R²=0.6634559822934014
2024-10-31 16:45:26,609 - INFO - Trial 470: Test MSE=2.237715312412807, Test R²=0.6357851283890861
2024-10-31 16:45:26,609 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:45:26,610 - INFO - Trial 470 finished with value: 2.237715312412807 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7633980198747565, 'learning_rate': 0.0008837731169115154, 'weight_decay': 0.000274243851694502, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:46:05,670 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5881646789388866, 'learning_rate': 0.001192990319294881, 'weight_decay': 0.00049347445475761, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 16:46:05,670 - INFO - Trial 471: Train MSE=1.1309175193309784, Train R²=0.8114391373736518
2024-10-31 16:46:05,670 - INFO - Trial 471: Test MSE=2.4097084317888533, Test R²=0.6078955275671822
2024-10-31 16:46:05,671 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:46:05,672 - INFO - Trial 471 finished with value: 2.4097084317888533 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5881646789388866, 'learning_rate': 0.001192990319294881, 'weight_decay': 0.00049347445475761, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:46:50,808 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7765034625744462, 'learning_rate': 0.001742279441135839, 'weight_decay': 0.00034057966987857544, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:46:50,808 - INFO - Trial 472: Train MSE=2.0486819573811124, Train R²=0.6581785018954959
2024-10-31 16:46:50,808 - INFO - Trial 472: Test MSE=2.2387508153915405, Test R²=0.6355229531015668
2024-10-31 16:46:50,809 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:46:50,810 - INFO - Trial 472 finished with value: 2.2387508153915405 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7765034625744462, 'learning_rate': 0.001742279441135839, 'weight_decay': 0.00034057966987857544, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:47:36,157 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7919381235811219, 'learning_rate': 0.0009753604204959504, 'weight_decay': 0.00029087691275267533, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:47:36,157 - INFO - Trial 473: Train MSE=2.406566483633859, Train R²=0.5999467607055392
2024-10-31 16:47:36,157 - INFO - Trial 473: Test MSE=2.2326403004782542, Test R²=0.6365575620106289
2024-10-31 16:47:36,157 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:47:36,159 - INFO - Trial 473 finished with value: 2.2326403004782542 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7919381235811219, 'learning_rate': 0.0009753604204959504, 'weight_decay': 0.00029087691275267533, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:48:20,893 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7830176880756335, 'learning_rate': 0.001428318145016142, 'weight_decay': 0.0003245207789681772, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 16:48:20,893 - INFO - Trial 474: Train MSE=2.2207491057259694, Train R²=0.6294122551168714
2024-10-31 16:48:20,894 - INFO - Trial 474: Test MSE=2.251095771789551, Test R²=0.6334325415747506
2024-10-31 16:48:20,894 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:48:20,895 - INFO - Trial 474 finished with value: 2.251095771789551 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7830176880756335, 'learning_rate': 0.001428318145016142, 'weight_decay': 0.0003245207789681772, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:49:04,998 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7997728413526374, 'learning_rate': 0.0010936127069224135, 'weight_decay': 0.0005243365535827773, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:49:04,999 - INFO - Trial 475: Train MSE=2.453381257397788, Train R²=0.5922893541199821
2024-10-31 16:49:04,999 - INFO - Trial 475: Test MSE=2.237402285848345, Test R²=0.6359315429415021
2024-10-31 16:49:04,999 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:49:05,001 - INFO - Trial 475 finished with value: 2.237402285848345 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7997728413526374, 'learning_rate': 0.0010936127069224135, 'weight_decay': 0.0005243365535827773, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:49:50,410 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7746916049592849, 'learning_rate': 0.006499710200120644, 'weight_decay': 0.00030767759195191795, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:49:50,410 - INFO - Trial 476: Train MSE=1.9685841713632857, Train R²=0.6719280396189008
2024-10-31 16:49:50,410 - INFO - Trial 476: Test MSE=2.246307066508702, Test R²=0.6342116679464068
2024-10-31 16:49:50,410 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:49:50,411 - INFO - Trial 476 finished with value: 2.246307066508702 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7746916049592849, 'learning_rate': 0.006499710200120644, 'weight_decay': 0.00030767759195191795, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:50:35,367 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.561536221448853, 'learning_rate': 0.0008072107868490999, 'weight_decay': 0.0003723914545227512, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:50:35,367 - INFO - Trial 477: Train MSE=1.2068383267947607, Train R²=0.7990442642143795
2024-10-31 16:50:35,367 - INFO - Trial 477: Test MSE=2.3766814299992154, Test R²=0.6130349040031433
2024-10-31 16:50:35,367 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:50:35,369 - INFO - Trial 477 finished with value: 2.3766814299992154 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.561536221448853, 'learning_rate': 0.0008072107868490999, 'weight_decay': 0.0003723914545227512, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:51:20,597 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7658791915158597, 'learning_rate': 0.0013421006832586113, 'weight_decay': 0.0004282359885940613, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 16:51:20,597 - INFO - Trial 478: Train MSE=2.083389265196664, Train R²=0.6521698768649783
2024-10-31 16:51:20,597 - INFO - Trial 478: Test MSE=2.2882790906088695, Test R²=0.6274772371564593
2024-10-31 16:51:20,597 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:51:20,597 - INFO - Trial 478 finished with value: 2.2882790906088695 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7658791915158597, 'learning_rate': 0.0013421006832586113, 'weight_decay': 0.0004282359885940613, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:52:05,311 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7497399037788265, 'learning_rate': 0.009379759538778265, 'weight_decay': 0.00034112150463256344, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:52:05,311 - INFO - Trial 479: Train MSE=1.991895752293723, Train R²=0.668191196663039
2024-10-31 16:52:05,311 - INFO - Trial 479: Test MSE=2.2288352761949812, Test R²=0.6372904777526855
2024-10-31 16:52:05,311 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:52:05,312 - INFO - Trial 479 finished with value: 2.2288352761949812 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7497399037788265, 'learning_rate': 0.009379759538778265, 'weight_decay': 0.00034112150463256344, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:52:50,901 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7859471072818363, 'learning_rate': 0.000978422089414978, 'weight_decay': 0.00045295471461247693, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:52:50,901 - INFO - Trial 480: Train MSE=2.3993934903826033, Train R²=0.6003485258136477
2024-10-31 16:52:50,902 - INFO - Trial 480: Test MSE=2.252889462879726, Test R²=0.6332268970353263
2024-10-31 16:52:50,902 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:52:50,903 - INFO - Trial 480 finished with value: 2.252889462879726 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7859471072818363, 'learning_rate': 0.000978422089414978, 'weight_decay': 0.00045295471461247693, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:53:28,828 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7927328187973118, 'learning_rate': 0.0012216009943181642, 'weight_decay': 0.00027744250568895076, 'batch_size': 1024, 'tree_depth': 10}
2024-10-31 16:53:28,829 - INFO - Trial 481: Train MSE=2.898148741040911, Train R²=0.5190610246998923
2024-10-31 16:53:28,829 - INFO - Trial 481: Test MSE=2.273642122745514, Test R²=0.6274463683366776
2024-10-31 16:53:28,829 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:53:28,830 - INFO - Trial 481 finished with value: 2.273642122745514 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7927328187973118, 'learning_rate': 0.0012216009943181642, 'weight_decay': 0.00027744250568895076, 'batch_size': 1024, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:54:13,379 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7769806615756489, 'learning_rate': 0.003971223774117568, 'weight_decay': 0.0003141613277964958, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 16:54:13,379 - INFO - Trial 482: Train MSE=1.9150168257100242, Train R²=0.6817861859287534
2024-10-31 16:54:13,380 - INFO - Trial 482: Test MSE=2.235680103302002, Test R²=0.6362185137612479
2024-10-31 16:54:13,380 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:54:13,381 - INFO - Trial 482 finished with value: 2.235680103302002 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7769806615756489, 'learning_rate': 0.003971223774117568, 'weight_decay': 0.0003141613277964958, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:54:58,526 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7841544923373919, 'learning_rate': 0.0008945432827457111, 'weight_decay': 0.00029393122909094206, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:54:58,526 - INFO - Trial 483: Train MSE=2.4582891379083907, Train R²=0.5912138159785952
2024-10-31 16:54:58,527 - INFO - Trial 483: Test MSE=2.2646147864205495, Test R²=0.6313862460000175
2024-10-31 16:54:58,527 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:54:58,528 - INFO - Trial 483 finished with value: 2.2646147864205495 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7841544923373919, 'learning_rate': 0.0008945432827457111, 'weight_decay': 0.00029393122909094206, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:55:44,231 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7915010303184452, 'learning_rate': 0.001779626311491501, 'weight_decay': 0.0003536763525435374, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:55:44,231 - INFO - Trial 484: Train MSE=1.743710356099265, Train R²=0.7099517668996539
2024-10-31 16:55:44,231 - INFO - Trial 484: Test MSE=2.2674847670963834, Test R²=0.6309506808008466
2024-10-31 16:55:44,231 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:55:44,232 - INFO - Trial 484 finished with value: 2.2674847670963834 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7915010303184452, 'learning_rate': 0.001779626311491501, 'weight_decay': 0.0003536763525435374, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:56:46,631 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7696516757849134, 'learning_rate': 0.005397082247941126, 'weight_decay': 0.00032889950282614195, 'batch_size': 256, 'tree_depth': 12}
2024-10-31 16:56:46,631 - INFO - Trial 485: Train MSE=2.064339369535446, Train R²=0.6548561528325081
2024-10-31 16:56:46,631 - INFO - Trial 485: Test MSE=2.2805395296641757, Test R²=0.6272070961339133
2024-10-31 16:56:46,631 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:56:46,632 - INFO - Trial 485 finished with value: 2.2805395296641757 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7696516757849134, 'learning_rate': 0.005397082247941126, 'weight_decay': 0.00032889950282614195, 'batch_size': 256, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:57:31,166 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7996315172735932, 'learning_rate': 0.0015590003277743678, 'weight_decay': 0.0002541238193145046, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:57:31,166 - INFO - Trial 486: Train MSE=2.3375339720930373, Train R²=0.6101211096559253
2024-10-31 16:57:31,166 - INFO - Trial 486: Test MSE=2.21842292376927, Test R²=0.6388223341533116
2024-10-31 16:57:31,166 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:57:31,167 - INFO - Trial 486 finished with value: 2.21842292376927 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7996315172735932, 'learning_rate': 0.0015590003277743678, 'weight_decay': 0.0002541238193145046, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:58:16,275 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7802623048194313, 'learning_rate': 0.007514795494541059, 'weight_decay': 0.00023724633697160425, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:58:16,276 - INFO - Trial 487: Train MSE=1.9745353673185622, Train R²=0.6719227518354144
2024-10-31 16:58:16,276 - INFO - Trial 487: Test MSE=2.239671996661595, Test R²=0.6355699300765991
2024-10-31 16:58:16,276 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:58:16,276 - INFO - Trial 487 finished with value: 2.239671996661595 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7802623048194313, 'learning_rate': 0.007514795494541059, 'weight_decay': 0.00023724633697160425, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:59:00,620 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7601839704723725, 'learning_rate': 0.001125238376999421, 'weight_decay': 0.00030854167557792424, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 16:59:00,620 - INFO - Trial 488: Train MSE=2.1058351567813327, Train R²=0.649561590382031
2024-10-31 16:59:00,620 - INFO - Trial 488: Test MSE=2.2715183666774204, Test R²=0.6303667681557792
2024-10-31 16:59:00,620 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:59:00,621 - INFO - Trial 488 finished with value: 2.2715183666774204 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7601839704723725, 'learning_rate': 0.001125238376999421, 'weight_decay': 0.00030854167557792424, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 16:59:41,671 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7996715477399567, 'learning_rate': 0.00892791812648736, 'weight_decay': 0.00028618200442349874, 'batch_size': 512, 'tree_depth': 8}
2024-10-31 16:59:41,671 - INFO - Trial 489: Train MSE=2.4139975139072964, Train R²=0.5986823780196053
2024-10-31 16:59:41,672 - INFO - Trial 489: Test MSE=2.278694544519697, Test R²=0.6291874476841518
2024-10-31 16:59:41,672 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 16:59:41,673 - INFO - Trial 489 finished with value: 2.278694544519697 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7996715477399567, 'learning_rate': 0.00892791812648736, 'weight_decay': 0.00028618200442349874, 'batch_size': 512, 'tree_depth': 8}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:00:26,602 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7853386394459019, 'learning_rate': 0.009993473974597902, 'weight_decay': 0.0003283540396429717, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:00:26,602 - INFO - Trial 490: Train MSE=2.173119217157364, Train R²=0.6383214294910431
2024-10-31 17:00:26,603 - INFO - Trial 490: Test MSE=2.2478879519871304, Test R²=0.6342036468642098
2024-10-31 17:00:26,603 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:00:26,604 - INFO - Trial 490 finished with value: 2.2478879519871304 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7853386394459019, 'learning_rate': 0.009993473974597902, 'weight_decay': 0.0003283540396429717, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:01:11,693 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7688069461684722, 'learning_rate': 0.00014366698225595765, 'weight_decay': 0.00038608359581532114, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:01:11,693 - INFO - Trial 491: Train MSE=6.253787074770246, Train R²=-0.042132090244974406
2024-10-31 17:01:11,693 - INFO - Trial 491: Test MSE=2.6819885798863004, Test R²=0.5636406796319144
2024-10-31 17:01:11,693 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:01:11,695 - INFO - Trial 491 finished with value: 2.6819885798863004 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7688069461684722, 'learning_rate': 0.00014366698225595765, 'weight_decay': 0.00038608359581532114, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:02:53,524 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7770649282442401, 'learning_rate': 0.0009992273323961307, 'weight_decay': 0.0005395945011160977, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 17:02:53,524 - INFO - Trial 492: Train MSE=1.8443628666656358, Train R²=0.6888920749936785
2024-10-31 17:02:53,524 - INFO - Trial 492: Test MSE=2.256411020244871, Test R²=0.6262075730732509
2024-10-31 17:02:53,524 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:02:53,526 - INFO - Trial 492 finished with value: 2.256411020244871 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7770649282442401, 'learning_rate': 0.0009992273323961307, 'weight_decay': 0.0005395945011160977, 'batch_size': 128, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:03:31,812 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.5358790776085849, 'learning_rate': 0.0008579300530271616, 'weight_decay': 0.0002980762013495708, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:03:31,813 - INFO - Trial 493: Train MSE=0.9778415603297097, Train R²=0.8368412064654487
2024-10-31 17:03:31,813 - INFO - Trial 493: Test MSE=2.4662251131875172, Test R²=0.5984436018126351
2024-10-31 17:03:31,813 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:03:31,813 - INFO - Trial 493 finished with value: 2.4662251131875172 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.5358790776085849, 'learning_rate': 0.0008579300530271616, 'weight_decay': 0.0002980762013495708, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:04:13,070 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7912217512139237, 'learning_rate': 0.0003055507144405965, 'weight_decay': 0.0003151354277021305, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:04:13,071 - INFO - Trial 494: Train MSE=4.030266514846256, Train R²=0.32780560851097107
2024-10-31 17:04:13,071 - INFO - Trial 494: Test MSE=2.418046372277396, Test R²=0.6064804026058742
2024-10-31 17:04:13,071 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:04:13,072 - INFO - Trial 494 finished with value: 2.418046372277396 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7912217512139237, 'learning_rate': 0.0003055507144405965, 'weight_decay': 0.0003151354277021305, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:04:57,833 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7843108996197259, 'learning_rate': 0.0030348782922618644, 'weight_decay': 0.0002705178343076512, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:04:57,833 - INFO - Trial 495: Train MSE=1.9683067032269068, Train R²=0.6724464190857751
2024-10-31 17:04:57,833 - INFO - Trial 495: Test MSE=2.2680459022521973, Test R²=0.6308948312486921
2024-10-31 17:04:57,833 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:04:57,834 - INFO - Trial 495 finished with value: 2.2680459022521973 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7843108996197259, 'learning_rate': 0.0030348782922618644, 'weight_decay': 0.0002705178343076512, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:05:43,334 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7743831406360813, 'learning_rate': 0.0012770535940110292, 'weight_decay': 0.0003398885286246526, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:05:43,335 - INFO - Trial 496: Train MSE=2.155153159584318, Train R²=0.6414832792111805
2024-10-31 17:05:43,335 - INFO - Trial 496: Test MSE=2.2112128053392683, Test R²=0.6399062275886536
2024-10-31 17:05:43,335 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:05:43,336 - INFO - Trial 496 finished with value: 2.2112128053392683 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7743831406360813, 'learning_rate': 0.0012770535940110292, 'weight_decay': 0.0003398885286246526, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:06:27,757 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7541601315843193, 'learning_rate': 0.0013513347733320282, 'weight_decay': 0.00036043902335153457, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:06:27,757 - INFO - Trial 497: Train MSE=1.9745346435478754, Train R²=0.6719025799206325
2024-10-31 17:06:27,757 - INFO - Trial 497: Test MSE=2.2901760169437955, Test R²=0.6272521359579903
2024-10-31 17:06:27,757 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:06:27,758 - INFO - Trial 497 finished with value: 2.2901760169437955 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7541601315843193, 'learning_rate': 0.0013513347733320282, 'weight_decay': 0.00036043902335153457, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:07:13,147 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7628983736236147, 'learning_rate': 0.0012431546546975395, 'weight_decay': 0.00034258360328795305, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:07:13,147 - INFO - Trial 498: Train MSE=2.0216529880251204, Train R²=0.6631321736744472
2024-10-31 17:07:13,148 - INFO - Trial 498: Test MSE=2.248806953430176, Test R²=0.6339383465903146
2024-10-31 17:07:13,148 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:07:13,149 - INFO - Trial 498 finished with value: 2.248806953430176 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7628983736236147, 'learning_rate': 0.0012431546546975395, 'weight_decay': 0.00034258360328795305, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:07:57,733 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7373585862306596, 'learning_rate': 0.0014877628078548953, 'weight_decay': 0.00035131079403636213, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:07:57,733 - INFO - Trial 499: Train MSE=1.7800321877002716, Train R²=0.7026551940611431
2024-10-31 17:07:57,733 - INFO - Trial 499: Test MSE=2.226520453180586, Test R²=0.6375507456915719
2024-10-31 17:07:57,733 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:07:57,734 - INFO - Trial 499 finished with value: 2.226520453180586 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7373585862306596, 'learning_rate': 0.0014877628078548953, 'weight_decay': 0.00035131079403636213, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:08:41,832 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7719330319144629, 'learning_rate': 0.0013906211637441236, 'weight_decay': 0.00033862446498332847, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:08:41,832 - INFO - Trial 500: Train MSE=2.1042282368455614, Train R²=0.6495152179683957
2024-10-31 17:08:41,832 - INFO - Trial 500: Test MSE=2.2691878931862965, Test R²=0.6306834476334708
2024-10-31 17:08:41,832 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:08:41,833 - INFO - Trial 500 finished with value: 2.2691878931862965 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7719330319144629, 'learning_rate': 0.0013906211637441236, 'weight_decay': 0.00033862446498332847, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:09:17,014 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999378243035113, 'learning_rate': 0.0016465496275496682, 'weight_decay': 0.00032332295573525067, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:09:17,015 - INFO - Trial 501: Train MSE=2.2053724101611545, Train R²=0.6323771008423397
2024-10-31 17:09:17,015 - INFO - Trial 501: Test MSE=2.225545201982771, Test R²=0.63787898847035
2024-10-31 17:09:17,015 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:09:17,016 - INFO - Trial 501 finished with value: 2.225545201982771 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999378243035113, 'learning_rate': 0.0016465496275496682, 'weight_decay': 0.00032332295573525067, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:09:56,004 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7466123485010671, 'learning_rate': 0.0013009962469383816, 'weight_decay': 0.00037734899707273764, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:09:56,004 - INFO - Trial 502: Train MSE=2.1305553317070007, Train R²=0.6444537022284099
2024-10-31 17:09:56,004 - INFO - Trial 502: Test MSE=2.203608819416591, Test R²=0.6413065876279559
2024-10-31 17:09:56,004 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:09:56,005 - INFO - Trial 502 finished with value: 2.203608819416591 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7466123485010671, 'learning_rate': 0.0013009962469383816, 'weight_decay': 0.00037734899707273764, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:10:34,565 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7827405447762902, 'learning_rate': 0.000214417393157066, 'weight_decay': 0.0003797577908024498, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:10:34,565 - INFO - Trial 503: Train MSE=5.410974723952157, Train R²=0.0982400221484048
2024-10-31 17:10:34,565 - INFO - Trial 503: Test MSE=2.4936178752354214, Test R²=0.5942542467798505
2024-10-31 17:10:34,566 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:10:34,567 - INFO - Trial 503 finished with value: 2.4936178752354214 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7827405447762902, 'learning_rate': 0.000214417393157066, 'weight_decay': 0.0003797577908024498, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:11:12,677 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7462252450258003, 'learning_rate': 0.0013136109125330107, 'weight_decay': 0.00038826886662981825, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:11:12,677 - INFO - Trial 504: Train MSE=2.071634982313429, Train R²=0.6548635470015662
2024-10-31 17:11:12,678 - INFO - Trial 504: Test MSE=2.2526724679129466, Test R²=0.6332977073533195
2024-10-31 17:11:12,678 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:11:12,679 - INFO - Trial 504 finished with value: 2.2526724679129466 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7462252450258003, 'learning_rate': 0.0013136109125330107, 'weight_decay': 0.00038826886662981825, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:11:50,638 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7919927538450295, 'learning_rate': 0.0014612315997854957, 'weight_decay': 0.0003683538108528389, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:11:50,638 - INFO - Trial 505: Train MSE=2.688017649309976, Train R²=0.5515897465603692
2024-10-31 17:11:50,638 - INFO - Trial 505: Test MSE=2.268849645342146, Test R²=0.6307997788701739
2024-10-31 17:11:50,638 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:11:50,640 - INFO - Trial 505 finished with value: 2.268849645342146 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7919927538450295, 'learning_rate': 0.0014612315997854957, 'weight_decay': 0.0003683538108528389, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:12:27,310 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7754369663014642, 'learning_rate': 0.001295953830047499, 'weight_decay': 0.0004055173528775596, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:12:27,310 - INFO - Trial 506: Train MSE=2.423767081328801, Train R²=0.5959163563592094
2024-10-31 17:12:27,310 - INFO - Trial 506: Test MSE=2.2412772519247874, Test R²=0.6351399336542402
2024-10-31 17:12:27,310 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:12:27,311 - INFO - Trial 506 finished with value: 2.2412772519247874 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7754369663014642, 'learning_rate': 0.001295953830047499, 'weight_decay': 0.0004055173528775596, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:13:00,734 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7604863568937344, 'learning_rate': 0.0012102683794698436, 'weight_decay': 0.000369014542924266, 'batch_size': 1024, 'tree_depth': 12}
2024-10-31 17:13:00,734 - INFO - Trial 507: Train MSE=3.056938477924892, Train R²=0.49217607719557627
2024-10-31 17:13:00,734 - INFO - Trial 507: Test MSE=2.3997435569763184, Test R²=0.6069341897964478
2024-10-31 17:13:00,734 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:13:00,735 - INFO - Trial 507 finished with value: 2.3997435569763184 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7604863568937344, 'learning_rate': 0.0012102683794698436, 'weight_decay': 0.000369014542924266, 'batch_size': 1024, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:13:43,265 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7899185762488448, 'learning_rate': 0.0014308740038025114, 'weight_decay': 0.00033936977290038265, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:13:43,266 - INFO - Trial 508: Train MSE=2.5094126037188937, Train R²=0.581759124994278
2024-10-31 17:13:43,266 - INFO - Trial 508: Test MSE=2.2602334192820956, Test R²=0.6321243388312203
2024-10-31 17:13:43,266 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:13:43,267 - INFO - Trial 508 finished with value: 2.2602334192820956 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7899185762488448, 'learning_rate': 0.0014308740038025114, 'weight_decay': 0.00033936977290038265, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:14:41,311 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7781831351182921, 'learning_rate': 0.001566322338025626, 'weight_decay': 0.0003600545893149101, 'batch_size': 256, 'tree_depth': 12}
2024-10-31 17:14:41,311 - INFO - Trial 509: Train MSE=1.926737666130066, Train R²=0.6777073453579631
2024-10-31 17:14:41,311 - INFO - Trial 509: Test MSE=2.2653794373784746, Test R²=0.6295914947986603
2024-10-31 17:14:41,311 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:14:41,312 - INFO - Trial 509 finished with value: 2.2653794373784746 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7781831351182921, 'learning_rate': 0.001566322338025626, 'weight_decay': 0.0003600545893149101, 'batch_size': 256, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:15:27,381 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7909161065571816, 'learning_rate': 0.0011658627882926063, 'weight_decay': 0.00030557860744204586, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:15:27,381 - INFO - Trial 510: Train MSE=2.581044912338257, Train R²=0.5706042860235486
2024-10-31 17:15:27,381 - INFO - Trial 510: Test MSE=2.230904987880162, Test R²=0.6369739174842834
2024-10-31 17:15:27,381 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:15:27,383 - INFO - Trial 510 finished with value: 2.230904987880162 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7909161065571816, 'learning_rate': 0.0011658627882926063, 'weight_decay': 0.00030557860744204586, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:16:12,841 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7703704127509039, 'learning_rate': 0.0017911291442283647, 'weight_decay': 0.0003530341794813422, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:16:12,841 - INFO - Trial 511: Train MSE=1.5921526508671897, Train R²=0.7351251457418714
2024-10-31 17:16:12,841 - INFO - Trial 511: Test MSE=2.2975354535239085, Test R²=0.6261678508349827
2024-10-31 17:16:12,842 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:16:12,842 - INFO - Trial 511 finished with value: 2.2975354535239085 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7703704127509039, 'learning_rate': 0.0017911291442283647, 'weight_decay': 0.0003530341794813422, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:16:56,991 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7849601269585091, 'learning_rate': 0.001126287253010024, 'weight_decay': 0.0002872683466759576, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:16:56,991 - INFO - Trial 512: Train MSE=2.310848670346396, Train R²=0.6159430806125913
2024-10-31 17:16:56,991 - INFO - Trial 512: Test MSE=2.228894693510873, Test R²=0.63722277539117
2024-10-31 17:16:56,991 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:16:56,992 - INFO - Trial 512 finished with value: 2.228894693510873 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7849601269585091, 'learning_rate': 0.001126287253010024, 'weight_decay': 0.0002872683466759576, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:17:42,427 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.754539663711987, 'learning_rate': 0.0012969862829389906, 'weight_decay': 0.0003994517741790741, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:17:42,427 - INFO - Trial 513: Train MSE=1.9924017020634242, Train R²=0.668271963085447
2024-10-31 17:17:42,427 - INFO - Trial 513: Test MSE=2.268455301012312, Test R²=0.6308819821902684
2024-10-31 17:17:42,427 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:17:42,428 - INFO - Trial 513 finished with value: 2.268455301012312 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.754539663711987, 'learning_rate': 0.0012969862829389906, 'weight_decay': 0.0003994517741790741, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:18:27,084 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5023804607469077, 'learning_rate': 0.0015367629549647673, 'weight_decay': 0.00032491239063429445, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:18:27,084 - INFO - Trial 514: Train MSE=0.8401344908135278, Train R²=0.8597829065152577
2024-10-31 17:18:27,084 - INFO - Trial 514: Test MSE=2.4310368469783237, Test R²=0.6038619705608913
2024-10-31 17:18:27,084 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:18:27,086 - INFO - Trial 514 finished with value: 2.4310368469783237 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5023804607469077, 'learning_rate': 0.0015367629549647673, 'weight_decay': 0.00032491239063429445, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:19:05,468 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7994829436412549, 'learning_rate': 0.0012096038463289876, 'weight_decay': 0.00030050520009367986, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 17:19:05,468 - INFO - Trial 515: Train MSE=2.921915207590376, Train R²=0.5144545776503426
2024-10-31 17:19:05,468 - INFO - Trial 515: Test MSE=2.3038908072880337, Test R²=0.6250978537968227
2024-10-31 17:19:05,468 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:19:05,469 - INFO - Trial 515 finished with value: 2.3038908072880337 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7994829436412549, 'learning_rate': 0.0012096038463289876, 'weight_decay': 0.00030050520009367986, 'batch_size': 512, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:19:43,015 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7778731715772618, 'learning_rate': 0.0013855376009435025, 'weight_decay': 0.00033733241747993054, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:19:43,015 - INFO - Trial 516: Train MSE=2.138789117336273, Train R²=0.6442673525639943
2024-10-31 17:19:43,015 - INFO - Trial 516: Test MSE=2.234939660344805, Test R²=0.636345454624721
2024-10-31 17:19:43,015 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:19:43,016 - INFO - Trial 516 finished with value: 2.234939660344805 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7778731715772618, 'learning_rate': 0.0013855376009435025, 'weight_decay': 0.00033733241747993054, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:21:16,839 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999791321990625, 'learning_rate': 0.00108792212128219, 'weight_decay': 0.0002794794713544983, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 17:21:16,839 - INFO - Trial 517: Train MSE=1.9495110916239875, Train R²=0.6691317100610051
2024-10-31 17:21:16,839 - INFO - Trial 517: Test MSE=2.2663407155445645, Test R²=0.6242282071283886
2024-10-31 17:21:16,839 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:21:16,840 - INFO - Trial 517 finished with value: 2.2663407155445645 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999791321990625, 'learning_rate': 0.00108792212128219, 'weight_decay': 0.0002794794713544983, 'batch_size': 128, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:22:02,352 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7288011721968123, 'learning_rate': 0.0016806668564366644, 'weight_decay': 0.0003156923685208414, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:22:02,352 - INFO - Trial 518: Train MSE=1.7190195236887251, Train R²=0.713201350399426
2024-10-31 17:22:02,352 - INFO - Trial 518: Test MSE=2.244112525667463, Test R²=0.6347220284598214
2024-10-31 17:22:02,352 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:22:02,353 - INFO - Trial 518 finished with value: 2.244112525667463 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7288011721968123, 'learning_rate': 0.0016806668564366644, 'weight_decay': 0.0003156923685208414, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:22:40,379 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7666060120438182, 'learning_rate': 0.0010308099404913497, 'weight_decay': 0.0002624077050298266, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:22:40,379 - INFO - Trial 519: Train MSE=1.9304555782249995, Train R²=0.6790314465761185
2024-10-31 17:22:40,379 - INFO - Trial 519: Test MSE=2.2790165969303677, Test R²=0.6291191748210362
2024-10-31 17:22:40,379 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:22:40,380 - INFO - Trial 519 finished with value: 2.2790165969303677 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7666060120438182, 'learning_rate': 0.0010308099404913497, 'weight_decay': 0.0002624077050298266, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:23:19,645 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7836293444685742, 'learning_rate': 0.001865190449027864, 'weight_decay': 0.00021340156032958264, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:23:19,645 - INFO - Trial 520: Train MSE=2.064866683312825, Train R²=0.6569619200059346
2024-10-31 17:23:19,645 - INFO - Trial 520: Test MSE=2.249064121927534, Test R²=0.6338872398648944
2024-10-31 17:23:19,645 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:23:19,645 - INFO - Trial 520 finished with value: 2.249064121927534 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7836293444685742, 'learning_rate': 0.001865190449027864, 'weight_decay': 0.00021340156032958264, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:24:01,460 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7890390338732158, 'learning_rate': 0.001276804886283001, 'weight_decay': 0.0002996247107775063, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:24:01,460 - INFO - Trial 521: Train MSE=2.2635612274919237, Train R²=0.623814025095531
2024-10-31 17:24:01,460 - INFO - Trial 521: Test MSE=2.235499007361276, Test R²=0.6361672026770455
2024-10-31 17:24:01,460 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:24:01,461 - INFO - Trial 521 finished with value: 2.235499007361276 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7890390338732158, 'learning_rate': 0.001276804886283001, 'weight_decay': 0.0002996247107775063, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:24:49,882 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7749219042668068, 'learning_rate': 0.0014793979410244779, 'weight_decay': 0.00037920231011119815, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:24:49,882 - INFO - Trial 522: Train MSE=2.3047464660235812, Train R²=0.6162478072302682
2024-10-31 17:24:49,882 - INFO - Trial 522: Test MSE=2.24590493951525, Test R²=0.6343514493533543
2024-10-31 17:24:49,882 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:24:49,884 - INFO - Trial 522 finished with value: 2.24590493951525 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7749219042668068, 'learning_rate': 0.0014793979410244779, 'weight_decay': 0.00037920231011119815, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:25:34,763 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7915362477723367, 'learning_rate': 0.0007527381150611882, 'weight_decay': 0.000319786443755868, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:25:34,763 - INFO - Trial 523: Train MSE=2.666458555630275, Train R²=0.5568753927946091
2024-10-31 17:25:34,763 - INFO - Trial 523: Test MSE=2.2261692115238736, Test R²=0.6376051817621503
2024-10-31 17:25:34,763 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:25:34,764 - INFO - Trial 523 finished with value: 2.2261692115238736 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7915362477723367, 'learning_rate': 0.0007527381150611882, 'weight_decay': 0.000319786443755868, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:26:19,706 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.764055565839438, 'learning_rate': 0.001151080778441469, 'weight_decay': 0.00034600686359963873, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:26:19,706 - INFO - Trial 524: Train MSE=2.144165060349873, Train R²=0.6422983131238392
2024-10-31 17:26:19,706 - INFO - Trial 524: Test MSE=2.2614941596984863, Test R²=0.6317156382969448
2024-10-31 17:26:19,706 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:26:19,707 - INFO - Trial 524 finished with value: 2.2614941596984863 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.764055565839438, 'learning_rate': 0.001151080778441469, 'weight_decay': 0.00034600686359963873, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:27:04,838 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.784348622359443, 'learning_rate': 0.0009369529509638711, 'weight_decay': 0.0002839232229112775, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:27:04,838 - INFO - Trial 525: Train MSE=2.407285681792668, Train R²=0.5984374902078083
2024-10-31 17:27:04,838 - INFO - Trial 525: Test MSE=2.2297555037907193, Test R²=0.6370452301842826
2024-10-31 17:27:04,838 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:27:04,839 - INFO - Trial 525 finished with value: 2.2297555037907193 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.784348622359443, 'learning_rate': 0.0009369529509638711, 'weight_decay': 0.0002839232229112775, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:27:50,185 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7761149210175226, 'learning_rate': 0.0016515398303767305, 'weight_decay': 0.0005669068959025961, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:27:50,185 - INFO - Trial 526: Train MSE=2.0575558713504245, Train R²=0.6565756031445095
2024-10-31 17:27:50,185 - INFO - Trial 526: Test MSE=2.28460122857775, Test R²=0.6281133379255023
2024-10-31 17:27:50,185 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:27:50,187 - INFO - Trial 526 finished with value: 2.28460122857775 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7761149210175226, 'learning_rate': 0.0016515398303767305, 'weight_decay': 0.0005669068959025961, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:28:34,993 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7932505225904573, 'learning_rate': 0.0010664486623433865, 'weight_decay': 0.0003077884167804457, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:28:34,993 - INFO - Trial 527: Train MSE=2.4588653360094344, Train R²=0.5899088361433574
2024-10-31 17:28:34,993 - INFO - Trial 527: Test MSE=2.24639207976205, Test R²=0.6344947985240391
2024-10-31 17:28:34,993 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:28:34,993 - INFO - Trial 527 finished with value: 2.24639207976205 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7932505225904573, 'learning_rate': 0.0010664486623433865, 'weight_decay': 0.0003077884167804457, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:29:18,426 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7824002855420866, 'learning_rate': 0.001351988203799544, 'weight_decay': 0.0006158620245448757, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 17:29:18,426 - INFO - Trial 528: Train MSE=2.253336591379983, Train R²=0.6248341969081334
2024-10-31 17:29:18,427 - INFO - Trial 528: Test MSE=2.2335470744541714, Test R²=0.6364419630595616
2024-10-31 17:29:18,427 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:29:18,428 - INFO - Trial 528 finished with value: 2.2335470744541714 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7824002855420866, 'learning_rate': 0.001351988203799544, 'weight_decay': 0.0006158620245448757, 'batch_size': 512, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:30:03,894 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7704480989717998, 'learning_rate': 0.0012171335883167421, 'weight_decay': 0.0003284417694587574, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:30:03,894 - INFO - Trial 529: Train MSE=2.141449532338551, Train R²=0.6426062903233937
2024-10-31 17:30:03,894 - INFO - Trial 529: Test MSE=2.249871628625052, Test R²=0.6337176050458636
2024-10-31 17:30:03,895 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:30:03,896 - INFO - Trial 529 finished with value: 2.249871628625052 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7704480989717998, 'learning_rate': 0.0012171335883167421, 'weight_decay': 0.0003284417694587574, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:30:42,958 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6769235943329726, 'learning_rate': 0.001012862811240171, 'weight_decay': 0.0003555967163973747, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 17:30:42,958 - INFO - Trial 530: Train MSE=2.0740604400634766, Train R²=0.6551648037774223
2024-10-31 17:30:42,958 - INFO - Trial 530: Test MSE=2.2825525999069214, Test R²=0.6255958378314972
2024-10-31 17:30:42,958 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:30:42,959 - INFO - Trial 530 finished with value: 2.2825525999069214 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6769235943329726, 'learning_rate': 0.001012862811240171, 'weight_decay': 0.0003555967163973747, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:31:28,084 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7997746822082525, 'learning_rate': 0.0021048971365832322, 'weight_decay': 0.00029281210737583613, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:31:28,084 - INFO - Trial 531: Train MSE=2.1694994483675276, Train R²=0.6387553257601601
2024-10-31 17:31:28,084 - INFO - Trial 531: Test MSE=2.2405814102717807, Test R²=0.6352625659533909
2024-10-31 17:31:28,084 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:31:28,085 - INFO - Trial 531 finished with value: 2.2405814102717807 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7997746822082525, 'learning_rate': 0.0021048971365832322, 'weight_decay': 0.00029281210737583613, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:32:13,672 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7491489004280071, 'learning_rate': 0.0008067924506471189, 'weight_decay': 0.00031417832397060775, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:32:13,672 - INFO - Trial 532: Train MSE=1.871648643698011, Train R²=0.6888493661369596
2024-10-31 17:32:13,672 - INFO - Trial 532: Test MSE=2.280043227331979, Test R²=0.6288968324661255
2024-10-31 17:32:13,672 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:32:13,672 - INFO - Trial 532 finished with value: 2.280043227331979 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7491489004280071, 'learning_rate': 0.0008067924506471189, 'weight_decay': 0.00031417832397060775, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:32:57,362 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7857798295732817, 'learning_rate': 0.0014740204577805254, 'weight_decay': 0.00026958114065704815, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:32:57,362 - INFO - Trial 533: Train MSE=2.195416569709778, Train R²=0.6341243130820138
2024-10-31 17:32:57,362 - INFO - Trial 533: Test MSE=2.2363381385803223, Test R²=0.6360862851142883
2024-10-31 17:32:57,362 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:32:57,364 - INFO - Trial 533 finished with value: 2.2363381385803223 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7857798295732817, 'learning_rate': 0.0014740204577805254, 'weight_decay': 0.00026958114065704815, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:33:58,956 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7913876119023631, 'learning_rate': 0.0009280116483761145, 'weight_decay': 0.0003314853449374378, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 17:33:58,957 - INFO - Trial 534: Train MSE=2.096243856208665, Train R²=0.6485081591776439
2024-10-31 17:33:58,957 - INFO - Trial 534: Test MSE=2.2354972192219327, Test R²=0.6340056317193168
2024-10-31 17:33:58,957 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:33:58,958 - INFO - Trial 534 finished with value: 2.2354972192219327 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7913876119023631, 'learning_rate': 0.0009280116483761145, 'weight_decay': 0.0003314853449374378, 'batch_size': 256, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:34:44,024 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7580218632608681, 'learning_rate': 0.0018706650866115865, 'weight_decay': 0.00023033829929930828, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:34:44,024 - INFO - Trial 535: Train MSE=1.8897088425500053, Train R²=0.6853725484439305
2024-10-31 17:34:44,024 - INFO - Trial 535: Test MSE=2.2328592027936662, Test R²=0.6365283216748919
2024-10-31 17:34:44,024 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:34:44,025 - INFO - Trial 535 finished with value: 2.2328592027936662 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7580218632608681, 'learning_rate': 0.0018706650866115865, 'weight_decay': 0.00023033829929930828, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:35:29,154 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.775280079610694, 'learning_rate': 0.0011225174758656723, 'weight_decay': 0.0002541261490882528, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:35:29,155 - INFO - Trial 536: Train MSE=2.2622871143477306, Train R²=0.6229303670780999
2024-10-31 17:35:29,155 - INFO - Trial 536: Test MSE=2.2114382471357072, Test R²=0.6399830750056675
2024-10-31 17:35:29,155 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:35:29,156 - INFO - Trial 536 finished with value: 2.2114382471357072 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.775280079610694, 'learning_rate': 0.0011225174758656723, 'weight_decay': 0.0002541261490882528, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:36:14,288 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7685599041643965, 'learning_rate': 0.001054564665984185, 'weight_decay': 0.00024524377279096183, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:36:14,288 - INFO - Trial 537: Train MSE=2.2202343940734863, Train R²=0.630160527569907
2024-10-31 17:36:14,288 - INFO - Trial 537: Test MSE=2.232121229171753, Test R²=0.6366673367364066
2024-10-31 17:36:14,288 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:36:14,289 - INFO - Trial 537 finished with value: 2.232121229171753 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7685599041643965, 'learning_rate': 0.001054564665984185, 'weight_decay': 0.00024524377279096183, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:36:59,447 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7810168408115573, 'learning_rate': 0.0011866330772402113, 'weight_decay': 0.00024933559355812447, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:36:59,448 - INFO - Trial 538: Train MSE=2.225332587957382, Train R²=0.6297640736613955
2024-10-31 17:36:59,448 - INFO - Trial 538: Test MSE=2.2311453308377946, Test R²=0.6367869036538261
2024-10-31 17:36:59,448 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:36:59,449 - INFO - Trial 538 finished with value: 2.2311453308377946 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7810168408115573, 'learning_rate': 0.0011866330772402113, 'weight_decay': 0.00024933559355812447, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:37:38,947 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7908367828660794, 'learning_rate': 0.003390730837973425, 'weight_decay': 0.0002583324260514996, 'batch_size': 512, 'tree_depth': 7}
2024-10-31 17:37:38,947 - INFO - Trial 539: Train MSE=2.6312266332762584, Train R²=0.5620752743312291
2024-10-31 17:37:38,947 - INFO - Trial 539: Test MSE=2.3547534261431013, Test R²=0.6167506064687457
2024-10-31 17:37:38,947 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:37:38,948 - INFO - Trial 539 finished with value: 2.3547534261431013 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7908367828660794, 'learning_rate': 0.003390730837973425, 'weight_decay': 0.0002583324260514996, 'batch_size': 512, 'tree_depth': 7}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:38:24,260 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7748387980385533, 'learning_rate': 0.0011456384493527512, 'weight_decay': 0.00025879813029427653, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:38:24,261 - INFO - Trial 540: Train MSE=2.21411840404783, Train R²=0.6312159725597927
2024-10-31 17:38:24,261 - INFO - Trial 540: Test MSE=2.210411718913487, Test R²=0.6402810386248997
2024-10-31 17:38:24,261 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:38:24,261 - INFO - Trial 540 finished with value: 2.210411718913487 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7748387980385533, 'learning_rate': 0.0011456384493527512, 'weight_decay': 0.00025879813029427653, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:39:08,633 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.766269911732286, 'learning_rate': 0.0010998621010916726, 'weight_decay': 0.0002565314716818778, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:39:08,633 - INFO - Trial 541: Train MSE=2.1995763778686523, Train R²=0.6338014453649521
2024-10-31 17:39:08,633 - INFO - Trial 541: Test MSE=2.2285988671439037, Test R²=0.6371824315616063
2024-10-31 17:39:08,633 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:39:08,634 - INFO - Trial 541 finished with value: 2.2285988671439037 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.766269911732286, 'learning_rate': 0.0010998621010916726, 'weight_decay': 0.0002565314716818778, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:39:53,471 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.44805490979764473, 'learning_rate': 0.001135493190326402, 'weight_decay': 0.00023584984662511425, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:39:53,471 - INFO - Trial 542: Train MSE=0.7930293487651008, Train R²=0.8679184743336269
2024-10-31 17:39:53,471 - INFO - Trial 542: Test MSE=2.4194496359143938, Test R²=0.6062414305550712
2024-10-31 17:39:53,471 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:39:53,472 - INFO - Trial 542 finished with value: 2.4194496359143938 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.44805490979764473, 'learning_rate': 0.001135493190326402, 'weight_decay': 0.00023584984662511425, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:41:18,548 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.6431933892796307, 'learning_rate': 0.0012416729285853222, 'weight_decay': 0.00023904063220563497, 'batch_size': 128, 'tree_depth': 12}
2024-10-31 17:41:18,548 - INFO - Trial 543: Train MSE=1.1608800691153323, Train R²=0.8045305162668228
2024-10-31 17:41:18,548 - INFO - Trial 543: Test MSE=2.33083604489054, Test R²=0.614287257194519
2024-10-31 17:41:18,548 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:41:18,549 - INFO - Trial 543 finished with value: 2.33083604489054 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.6431933892796307, 'learning_rate': 0.0012416729285853222, 'weight_decay': 0.00023904063220563497, 'batch_size': 128, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:41:58,557 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7573206242303512, 'learning_rate': 0.0009544358581857532, 'weight_decay': 0.00022457208356309278, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:41:58,558 - INFO - Trial 544: Train MSE=2.954462775162288, Train R²=0.5087620956557137
2024-10-31 17:41:58,558 - INFO - Trial 544: Test MSE=2.614865847996303, Test R²=0.5745874387877328
2024-10-31 17:41:58,558 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:41:58,559 - INFO - Trial 544 finished with value: 2.614865847996303 and parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7573206242303512, 'learning_rate': 0.0009544358581857532, 'weight_decay': 0.00022457208356309278, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:42:42,744 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7750460783234432, 'learning_rate': 0.0010385760717357916, 'weight_decay': 0.0002531135089309153, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:42:42,744 - INFO - Trial 545: Train MSE=2.3076620953423634, Train R²=0.6160832388060433
2024-10-31 17:42:42,744 - INFO - Trial 545: Test MSE=2.238334519522531, Test R²=0.6357140626226153
2024-10-31 17:42:42,745 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:42:42,746 - INFO - Trial 545 finished with value: 2.238334519522531 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7750460783234432, 'learning_rate': 0.0010385760717357916, 'weight_decay': 0.0002531135089309153, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:43:27,083 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7442061423490053, 'learning_rate': 0.0011507644841819245, 'weight_decay': 0.00026062687755461515, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:43:27,083 - INFO - Trial 546: Train MSE=1.9822582517351424, Train R²=0.6696304551192692
2024-10-31 17:43:27,083 - INFO - Trial 546: Test MSE=2.222651617867606, Test R²=0.6381913593837193
2024-10-31 17:43:27,083 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:43:27,084 - INFO - Trial 546 finished with value: 2.222651617867606 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7442061423490053, 'learning_rate': 0.0011507644841819245, 'weight_decay': 0.00026062687755461515, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:44:05,973 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.799690908071316, 'learning_rate': 0.001254646984833507, 'weight_decay': 0.0002689427503589699, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:44:05,974 - INFO - Trial 547: Train MSE=2.3713642188480923, Train R²=0.6058929136821202
2024-10-31 17:44:05,974 - INFO - Trial 547: Test MSE=2.2501271622521535, Test R²=0.6338555046490261
2024-10-31 17:44:05,974 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:44:05,975 - INFO - Trial 547 finished with value: 2.2501271622521535 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.799690908071316, 'learning_rate': 0.001254646984833507, 'weight_decay': 0.0002689427503589699, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:44:47,918 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.776530067411478, 'learning_rate': 0.0009294924939441491, 'weight_decay': 0.0002729612907914058, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:44:47,919 - INFO - Trial 548: Train MSE=2.8595371501786366, Train R²=0.5245519067559924
2024-10-31 17:44:47,919 - INFO - Trial 548: Test MSE=2.2434448344366893, Test R²=0.6350063341004508
2024-10-31 17:44:47,919 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:44:47,920 - INFO - Trial 548 finished with value: 2.2434448344366893 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.776530067411478, 'learning_rate': 0.0009294924939441491, 'weight_decay': 0.0002729612907914058, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:45:33,092 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7842151715616111, 'learning_rate': 0.0010917377722675986, 'weight_decay': 0.00025631029546072304, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:45:33,092 - INFO - Trial 549: Train MSE=2.3176535197666714, Train R²=0.6144608067614692
2024-10-31 17:45:33,092 - INFO - Trial 549: Test MSE=2.2575962713786533, Test R²=0.6325806209019252
2024-10-31 17:45:33,093 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:45:33,094 - INFO - Trial 549 finished with value: 2.2575962713786533 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7842151715616111, 'learning_rate': 0.0010917377722675986, 'weight_decay': 0.00025631029546072304, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:46:14,471 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.759695369106853, 'learning_rate': 0.0008810709129299848, 'weight_decay': 0.0002673701584253272, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:46:14,472 - INFO - Trial 550: Train MSE=2.5381848556654796, Train R²=0.5769432442528861
2024-10-31 17:46:14,472 - INFO - Trial 550: Test MSE=2.237486873354231, Test R²=0.6357858606747219
2024-10-31 17:46:14,472 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:46:14,473 - INFO - Trial 550 finished with value: 2.237486873354231 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.759695369106853, 'learning_rate': 0.0008810709129299848, 'weight_decay': 0.0002673701584253272, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:46:51,309 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7686323866194655, 'learning_rate': 0.0013126277268752753, 'weight_decay': 0.0002810196385488795, 'batch_size': 512, 'tree_depth': 6}
2024-10-31 17:46:51,309 - INFO - Trial 551: Train MSE=3.0237544775009155, Train R²=0.4970608651638031
2024-10-31 17:46:51,310 - INFO - Trial 551: Test MSE=2.4259598595755443, Test R²=0.6050865139280047
2024-10-31 17:46:51,310 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:46:51,310 - INFO - Trial 551 finished with value: 2.4259598595755443 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7686323866194655, 'learning_rate': 0.0013126277268752753, 'weight_decay': 0.0002810196385488795, 'batch_size': 512, 'tree_depth': 6}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:47:36,546 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7908387078704261, 'learning_rate': 0.0010116351934353132, 'weight_decay': 0.0002808401498855579, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:47:36,546 - INFO - Trial 552: Train MSE=2.3873216594968523, Train R²=0.6022855703319822
2024-10-31 17:47:36,546 - INFO - Trial 552: Test MSE=2.240452562059675, Test R²=0.6353511384555272
2024-10-31 17:47:36,546 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:47:36,547 - INFO - Trial 552 finished with value: 2.240452562059675 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7908387078704261, 'learning_rate': 0.0010116351934353132, 'weight_decay': 0.0002808401498855579, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:48:21,805 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7779382456967934, 'learning_rate': 0.0011591151480837877, 'weight_decay': 0.0002431160150034154, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:48:21,805 - INFO - Trial 553: Train MSE=2.190595124449049, Train R²=0.6358499441828046
2024-10-31 17:48:21,805 - INFO - Trial 553: Test MSE=2.2436793191092357, Test R²=0.634737457547869
2024-10-31 17:48:21,805 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:48:21,807 - INFO - Trial 553 finished with value: 2.2436793191092357 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7779382456967934, 'learning_rate': 0.0011591151480837877, 'weight_decay': 0.0002431160150034154, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:49:06,753 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7912760991607739, 'learning_rate': 0.0006979353245473511, 'weight_decay': 0.00022443884616741804, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:49:06,753 - INFO - Trial 554: Train MSE=2.740280704838889, Train R²=0.5439275588308062
2024-10-31 17:49:06,754 - INFO - Trial 554: Test MSE=2.2251816477094377, Test R²=0.6378361923354012
2024-10-31 17:49:06,754 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:49:06,755 - INFO - Trial 554 finished with value: 2.2251816477094377 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7912760991607739, 'learning_rate': 0.0006979353245473511, 'weight_decay': 0.00022443884616741804, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:49:50,355 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7996834157271736, 'learning_rate': 0.0008230278277633446, 'weight_decay': 0.00025274629202033276, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:49:50,355 - INFO - Trial 555: Train MSE=2.6725209525653293, Train R²=0.556436572756086
2024-10-31 17:49:50,355 - INFO - Trial 555: Test MSE=2.250084332057408, Test R²=0.6338804023606437
2024-10-31 17:49:50,355 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:49:50,356 - INFO - Trial 555 finished with value: 2.250084332057408 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7996834157271736, 'learning_rate': 0.0008230278277633446, 'weight_decay': 0.00025274629202033276, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:50:29,483 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7829046415611791, 'learning_rate': 0.0010052861433467286, 'weight_decay': 0.00041300012281280215, 'batch_size': 1024, 'tree_depth': 12}
2024-10-31 17:50:29,483 - INFO - Trial 556: Train MSE=2.9141108308519637, Train R²=0.5160197743347713
2024-10-31 17:50:29,483 - INFO - Trial 556: Test MSE=2.2809959650039673, Test R²=0.626141294836998
2024-10-31 17:50:29,483 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:50:29,485 - INFO - Trial 556 finished with value: 2.2809959650039673 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7829046415611791, 'learning_rate': 0.0010052861433467286, 'weight_decay': 0.00041300012281280215, 'batch_size': 1024, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:51:14,722 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7665392881955946, 'learning_rate': 0.002692114002658795, 'weight_decay': 0.00027114016207003806, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:51:14,723 - INFO - Trial 557: Train MSE=1.9048367823873247, Train R²=0.6829052035297666
2024-10-31 17:51:14,723 - INFO - Trial 557: Test MSE=2.2333747489111766, Test R²=0.636496228831155
2024-10-31 17:51:14,723 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:51:14,724 - INFO - Trial 557 finished with value: 2.2333747489111766 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7665392881955946, 'learning_rate': 0.002692114002658795, 'weight_decay': 0.00027114016207003806, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:51:54,552 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 1024, 'dropout_rate': 0.7140961260712115, 'learning_rate': 0.0013148861212304375, 'weight_decay': 0.0002885920618592007, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:51:54,552 - INFO - Trial 558: Train MSE=1.4888555748122079, Train R²=0.7522702259676797
2024-10-31 17:51:54,552 - INFO - Trial 558: Test MSE=2.327684300286429, Test R²=0.6208530238696507
2024-10-31 17:51:54,552 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:51:54,554 - INFO - Trial 558 finished with value: 2.327684300286429 and parameters: {'hidden_layers': 3, 'hidden_units': 1024, 'dropout_rate': 0.7140961260712115, 'learning_rate': 0.0013148861212304375, 'weight_decay': 0.0002885920618592007, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:52:49,712 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7763321306990351, 'learning_rate': 0.0012046431036897107, 'weight_decay': 0.000553922494480299, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 17:52:49,712 - INFO - Trial 559: Train MSE=1.893171685082572, Train R²=0.6826427280902863
2024-10-31 17:52:49,713 - INFO - Trial 559: Test MSE=2.259702571800777, Test R²=0.6298526525497437
2024-10-31 17:52:49,713 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:52:49,714 - INFO - Trial 559 finished with value: 2.259702571800777 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7763321306990351, 'learning_rate': 0.0012046431036897107, 'weight_decay': 0.000553922494480299, 'batch_size': 256, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:53:33,958 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7862914624732036, 'learning_rate': 0.0011125546411817557, 'weight_decay': 0.0003715825017527128, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 17:53:33,959 - INFO - Trial 560: Train MSE=2.4488272156034196, Train R²=0.5929661478315081
2024-10-31 17:53:33,959 - INFO - Trial 560: Test MSE=2.2281907285962785, Test R²=0.6373365180832999
2024-10-31 17:53:33,959 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:53:33,960 - INFO - Trial 560 finished with value: 2.2281907285962785 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7862914624732036, 'learning_rate': 0.0011125546411817557, 'weight_decay': 0.0003715825017527128, 'batch_size': 512, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:54:18,543 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.791043484136284, 'learning_rate': 0.0009090092459757865, 'weight_decay': 0.0002657778202943565, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:54:18,544 - INFO - Trial 561: Train MSE=2.4764838985034396, Train R²=0.5867776636566434
2024-10-31 17:54:18,544 - INFO - Trial 561: Test MSE=2.2468272106988088, Test R²=0.6343302300998143
2024-10-31 17:54:18,544 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:54:18,545 - INFO - Trial 561 finished with value: 2.2468272106988088 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.791043484136284, 'learning_rate': 0.0009090092459757865, 'weight_decay': 0.0002657778202943565, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:55:03,278 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7497793591305955, 'learning_rate': 0.0010803697185536552, 'weight_decay': 0.0002933763307548023, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:55:03,278 - INFO - Trial 562: Train MSE=2.082957399742944, Train R²=0.6536548946584974
2024-10-31 17:55:03,279 - INFO - Trial 562: Test MSE=2.245193805013384, Test R²=0.6345370837620327
2024-10-31 17:55:03,279 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:55:03,279 - INFO - Trial 562 finished with value: 2.245193805013384 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7497793591305955, 'learning_rate': 0.0010803697185536552, 'weight_decay': 0.0002933763307548023, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:55:48,498 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7709495174724899, 'learning_rate': 0.0009789650491064692, 'weight_decay': 0.0002780068044848251, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:55:48,498 - INFO - Trial 563: Train MSE=2.2902036564690724, Train R²=0.6194932503359658
2024-10-31 17:55:48,498 - INFO - Trial 563: Test MSE=2.2486990690231323, Test R²=0.6340233683586121
2024-10-31 17:55:48,498 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:55:48,499 - INFO - Trial 563 finished with value: 2.2486990690231323 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7709495174724899, 'learning_rate': 0.0009789650491064692, 'weight_decay': 0.0002780068044848251, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:56:33,652 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7832223053737228, 'learning_rate': 0.001351123225292103, 'weight_decay': 0.00020043603156801146, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 17:56:33,652 - INFO - Trial 564: Train MSE=2.180861238922392, Train R²=0.6372267241988864
2024-10-31 17:56:33,652 - INFO - Trial 564: Test MSE=2.258773054395403, Test R²=0.6322607398033142
2024-10-31 17:56:33,652 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:56:33,654 - INFO - Trial 564 finished with value: 2.258773054395403 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7832223053737228, 'learning_rate': 0.001351123225292103, 'weight_decay': 0.00020043603156801146, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:57:18,691 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.34989457519741707, 'learning_rate': 0.001232203782314719, 'weight_decay': 0.00038935964318291956, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:57:18,691 - INFO - Trial 565: Train MSE=0.5751552166683334, Train R²=0.9040470272302628
2024-10-31 17:57:18,691 - INFO - Trial 565: Test MSE=2.4650419780186246, Test R²=0.5987568242209298
2024-10-31 17:57:18,691 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:57:18,693 - INFO - Trial 565 finished with value: 2.4650419780186246 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.34989457519741707, 'learning_rate': 0.001232203782314719, 'weight_decay': 0.00038935964318291956, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:58:04,128 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7601182123395602, 'learning_rate': 0.0010092188934256185, 'weight_decay': 0.00024158997722997005, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 17:58:04,128 - INFO - Trial 566: Train MSE=2.1933724795069014, Train R²=0.6350892271314349
2024-10-31 17:58:04,128 - INFO - Trial 566: Test MSE=2.257126501628331, Test R²=0.6325356875147138
2024-10-31 17:58:04,129 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:58:04,130 - INFO - Trial 566 finished with value: 2.257126501628331 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7601182123395602, 'learning_rate': 0.0010092188934256185, 'weight_decay': 0.00024158997722997005, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 17:59:29,095 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.799848891077011, 'learning_rate': 0.0008604413639511695, 'weight_decay': 0.0004317474161768082, 'batch_size': 128, 'tree_depth': 12}
2024-10-31 17:59:29,095 - INFO - Trial 567: Train MSE=1.8447202018329076, Train R²=0.6890009822590011
2024-10-31 17:59:29,095 - INFO - Trial 567: Test MSE=2.3082221065248762, Test R²=0.6184740790299007
2024-10-31 17:59:29,095 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 17:59:29,097 - INFO - Trial 567 finished with value: 2.3082221065248762 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.799848891077011, 'learning_rate': 0.0008604413639511695, 'weight_decay': 0.0004317474161768082, 'batch_size': 128, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:00:13,959 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7757283618936832, 'learning_rate': 0.0007778348907956799, 'weight_decay': 0.0002952084249529652, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:00:13,959 - INFO - Trial 568: Train MSE=2.469280336584364, Train R²=0.5898349668298449
2024-10-31 18:00:13,959 - INFO - Trial 568: Test MSE=2.2585887568337575, Test R²=0.6323190842356
2024-10-31 18:00:13,959 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:00:13,961 - INFO - Trial 568 finished with value: 2.2585887568337575 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7757283618936832, 'learning_rate': 0.0007778348907956799, 'weight_decay': 0.0002952084249529652, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:00:59,680 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7919110288385361, 'learning_rate': 0.0011486292721977868, 'weight_decay': 0.00021540562255106466, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:00:59,680 - INFO - Trial 569: Train MSE=2.3985213892800465, Train R²=0.6008132100105286
2024-10-31 18:00:59,680 - INFO - Trial 569: Test MSE=2.2422894409724643, Test R²=0.6350770933287484
2024-10-31 18:00:59,680 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:00:59,681 - INFO - Trial 569 finished with value: 2.2422894409724643 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7919110288385361, 'learning_rate': 0.0011486292721977868, 'weight_decay': 0.00021540562255106466, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:01:44,783 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7821538363131604, 'learning_rate': 0.0013386623260381247, 'weight_decay': 0.0003441573313154133, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:01:44,783 - INFO - Trial 570: Train MSE=2.1644480526447296, Train R²=0.6393496223858425
2024-10-31 18:01:44,783 - INFO - Trial 570: Test MSE=2.243706464767456, Test R²=0.6348396709987095
2024-10-31 18:01:44,783 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:01:44,785 - INFO - Trial 570 finished with value: 2.243706464767456 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7821538363131604, 'learning_rate': 0.0013386623260381247, 'weight_decay': 0.0003441573313154133, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:02:27,222 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.79992055386632, 'learning_rate': 0.0010873682341590685, 'weight_decay': 0.00027907623490470805, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:02:27,222 - INFO - Trial 571: Train MSE=3.092619299888611, Train R²=0.4858506768941879
2024-10-31 18:02:27,222 - INFO - Trial 571: Test MSE=2.231602770941598, Test R²=0.6368281841278076
2024-10-31 18:02:27,222 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:02:27,223 - INFO - Trial 571 finished with value: 2.231602770941598 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.79992055386632, 'learning_rate': 0.0010873682341590685, 'weight_decay': 0.00027907623490470805, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:03:11,147 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7702755968005848, 'learning_rate': 0.00092556691948543, 'weight_decay': 0.0003554167977006, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:03:11,147 - INFO - Trial 572: Train MSE=2.315279041017805, Train R²=0.6138112800461906
2024-10-31 18:03:11,147 - INFO - Trial 572: Test MSE=2.237350736345564, Test R²=0.6359542012214661
2024-10-31 18:03:11,147 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:03:11,149 - INFO - Trial 572 finished with value: 2.237350736345564 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7702755968005848, 'learning_rate': 0.00092556691948543, 'weight_decay': 0.0003554167977006, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:03:53,332 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.785116546310854, 'learning_rate': 0.0012652477818858405, 'weight_decay': 0.0003063554436440973, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:03:53,332 - INFO - Trial 573: Train MSE=2.4953273875372752, Train R²=0.5847972546304975
2024-10-31 18:03:53,332 - INFO - Trial 573: Test MSE=2.255292126110622, Test R²=0.6329559598650251
2024-10-31 18:03:53,332 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:03:53,334 - INFO - Trial 573 finished with value: 2.255292126110622 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.785116546310854, 'learning_rate': 0.0012652477818858405, 'weight_decay': 0.0003063554436440973, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:04:31,266 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7919526535453282, 'learning_rate': 0.001456361825658632, 'weight_decay': 0.0002501011410545004, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:04:31,266 - INFO - Trial 574: Train MSE=2.2291019601481303, Train R²=0.6281308063438961
2024-10-31 18:04:31,266 - INFO - Trial 574: Test MSE=2.222062792096819, Test R²=0.6382853388786316
2024-10-31 18:04:31,266 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:04:31,267 - INFO - Trial 574 finished with value: 2.222062792096819 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7919526535453282, 'learning_rate': 0.001456361825658632, 'weight_decay': 0.0002501011410545004, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:05:16,565 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7657926244090766, 'learning_rate': 0.0010089106065019108, 'weight_decay': 0.0002954966403347148, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:05:16,565 - INFO - Trial 575: Train MSE=2.1754196030753, Train R²=0.6375386204038348
2024-10-31 18:05:16,565 - INFO - Trial 575: Test MSE=2.253797343799046, Test R²=0.6330704689025879
2024-10-31 18:05:16,565 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:05:16,566 - INFO - Trial 575 finished with value: 2.253797343799046 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7657926244090766, 'learning_rate': 0.0010089106065019108, 'weight_decay': 0.0002954966403347148, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:06:02,087 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7776405481155911, 'learning_rate': 0.0008634292558611786, 'weight_decay': 0.0002602169969927889, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:06:02,088 - INFO - Trial 576: Train MSE=2.4257541511740004, Train R²=0.595981736268316
2024-10-31 18:06:02,088 - INFO - Trial 576: Test MSE=2.239049162183489, Test R²=0.6354785731860569
2024-10-31 18:06:02,088 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:06:02,089 - INFO - Trial 576 finished with value: 2.239049162183489 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7776405481155911, 'learning_rate': 0.0008634292558611786, 'weight_decay': 0.0002602169969927889, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:06:46,837 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7911560161534773, 'learning_rate': 0.0011971011468474187, 'weight_decay': 0.0003279513677298441, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:06:46,837 - INFO - Trial 577: Train MSE=2.3489386779921397, Train R²=0.6083455766950335
2024-10-31 18:06:46,837 - INFO - Trial 577: Test MSE=2.241988045828683, Test R²=0.6351822699819293
2024-10-31 18:06:46,837 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:06:46,839 - INFO - Trial 577 finished with value: 2.241988045828683 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7911560161534773, 'learning_rate': 0.0011971011468474187, 'weight_decay': 0.0003279513677298441, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:07:31,249 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.73720834281614, 'learning_rate': 0.0010893347608979622, 'weight_decay': 0.00036219004153305914, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:07:31,249 - INFO - Trial 578: Train MSE=1.9457572613443648, Train R²=0.6752409913710186
2024-10-31 18:07:31,249 - INFO - Trial 578: Test MSE=2.2823966230664934, Test R²=0.628407461302621
2024-10-31 18:07:31,249 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:07:31,250 - INFO - Trial 578 finished with value: 2.2823966230664934 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.73720834281614, 'learning_rate': 0.0010893347608979622, 'weight_decay': 0.00036219004153305914, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:08:16,540 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7553975704345792, 'learning_rate': 0.0013948816534940759, 'weight_decay': 0.00028541820429916944, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:08:16,540 - INFO - Trial 579: Train MSE=1.9824070504733495, Train R²=0.6697593310049602
2024-10-31 18:08:16,540 - INFO - Trial 579: Test MSE=2.2451864991869246, Test R²=0.6346567358289447
2024-10-31 18:08:16,540 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:08:16,541 - INFO - Trial 579 finished with value: 2.2451864991869246 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7553975704345792, 'learning_rate': 0.0013948816534940759, 'weight_decay': 0.00028541820429916944, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:09:01,747 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7827785585132434, 'learning_rate': 0.0009532526766626464, 'weight_decay': 0.0003105971332391475, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:09:01,747 - INFO - Trial 580: Train MSE=2.3512212889535085, Train R²=0.6082760180745806
2024-10-31 18:09:01,747 - INFO - Trial 580: Test MSE=2.237945454461234, Test R²=0.6357919658933368
2024-10-31 18:09:01,747 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:09:01,749 - INFO - Trial 580 finished with value: 2.237945454461234 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7827785585132434, 'learning_rate': 0.0009532526766626464, 'weight_decay': 0.0003105971332391475, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:09:40,799 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.47739081591077037, 'learning_rate': 0.001151711931537553, 'weight_decay': 0.00026988466737115445, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 18:09:40,799 - INFO - Trial 581: Train MSE=1.0188540986606054, Train R²=0.8307243415287563
2024-10-31 18:09:40,799 - INFO - Trial 581: Test MSE=2.4294172525405884, Test R²=0.6014785766601562
2024-10-31 18:09:40,799 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:09:40,800 - INFO - Trial 581 finished with value: 2.4294172525405884 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.47739081591077037, 'learning_rate': 0.001151711931537553, 'weight_decay': 0.00026988466737115445, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:10:25,862 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7752915599301325, 'learning_rate': 0.0007743458810068388, 'weight_decay': 0.0003333107474830474, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 18:10:25,862 - INFO - Trial 582: Train MSE=2.169536679983139, Train R²=0.6388930188758033
2024-10-31 18:10:25,862 - INFO - Trial 582: Test MSE=2.296450104032244, Test R²=0.6262349912098476
2024-10-31 18:10:25,862 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:10:25,863 - INFO - Trial 582 finished with value: 2.296450104032244 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7752915599301325, 'learning_rate': 0.0007743458810068388, 'weight_decay': 0.0003333107474830474, 'batch_size': 512, 'tree_depth': 10}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:11:10,913 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.792213475818393, 'learning_rate': 0.0010432136027875467, 'weight_decay': 0.0003183720508923839, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:11:10,913 - INFO - Trial 583: Train MSE=2.426455080509186, Train R²=0.5954157667500632
2024-10-31 18:11:10,913 - INFO - Trial 583: Test MSE=2.283325740269252, Test R²=0.6283067975725446
2024-10-31 18:11:10,913 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:11:10,914 - INFO - Trial 583 finished with value: 2.283325740269252 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.792213475818393, 'learning_rate': 0.0010432136027875467, 'weight_decay': 0.0003183720508923839, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:12:13,467 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.3840313280071938, 'learning_rate': 0.004386175997924604, 'weight_decay': 0.00030070700795994655, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 18:12:13,467 - INFO - Trial 584: Train MSE=0.8998254037329129, Train R²=0.8490403922540801
2024-10-31 18:12:13,467 - INFO - Trial 584: Test MSE=2.440871928419386, Test R²=0.6006608349936349
2024-10-31 18:12:13,467 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:12:13,469 - INFO - Trial 584 finished with value: 2.440871928419386 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.3840313280071938, 'learning_rate': 0.004386175997924604, 'weight_decay': 0.00030070700795994655, 'batch_size': 256, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:12:58,494 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.766135337162994, 'learning_rate': 0.001317870373531451, 'weight_decay': 0.00039455419255637013, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:12:58,494 - INFO - Trial 585: Train MSE=2.0355429691927776, Train R²=0.6615297751767295
2024-10-31 18:12:58,495 - INFO - Trial 585: Test MSE=2.2436990567616055, Test R²=0.6349256719861712
2024-10-31 18:12:58,495 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:12:58,495 - INFO - Trial 585 finished with value: 2.2436990567616055 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.766135337162994, 'learning_rate': 0.001317870373531451, 'weight_decay': 0.00039455419255637013, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:13:43,230 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7817978529057045, 'learning_rate': 0.0009194759143604826, 'weight_decay': 0.0003431663455114289, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:13:43,230 - INFO - Trial 586: Train MSE=2.424310122217451, Train R²=0.5965349908385958
2024-10-31 18:13:43,230 - INFO - Trial 586: Test MSE=2.263793775013515, Test R²=0.6315084440367562
2024-10-31 18:13:43,230 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:13:43,232 - INFO - Trial 586 finished with value: 2.263793775013515 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7817978529057045, 'learning_rate': 0.0009194759143604826, 'weight_decay': 0.0003431663455114289, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:14:28,217 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7923762938654145, 'learning_rate': 0.0012195140906419248, 'weight_decay': 0.0002892135664364876, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:14:28,217 - INFO - Trial 587: Train MSE=2.3193640879222324, Train R²=0.6145936271974018
2024-10-31 18:14:28,217 - INFO - Trial 587: Test MSE=2.2375276259013583, Test R²=0.6359278048787799
2024-10-31 18:14:28,217 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:14:28,218 - INFO - Trial 587 finished with value: 2.2375276259013583 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7923762938654145, 'learning_rate': 0.0012195140906419248, 'weight_decay': 0.0002892135664364876, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:15:13,978 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7725700592573304, 'learning_rate': 0.0014605276243771414, 'weight_decay': 0.0005142239642150235, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:15:13,978 - INFO - Trial 588: Train MSE=2.0215003745896474, Train R²=0.6630526248897824
2024-10-31 18:15:13,978 - INFO - Trial 588: Test MSE=2.2222539356776645, Test R²=0.6383338570594788
2024-10-31 18:15:13,978 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:15:13,980 - INFO - Trial 588 finished with value: 2.2222539356776645 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7725700592573304, 'learning_rate': 0.0014605276243771414, 'weight_decay': 0.0005142239642150235, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:15:58,505 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.799882877846419, 'learning_rate': 0.003111000641529979, 'weight_decay': 0.0002760458099580592, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:15:58,505 - INFO - Trial 589: Train MSE=2.1763303918497905, Train R²=0.637731522321701
2024-10-31 18:15:58,505 - INFO - Trial 589: Test MSE=2.200345754623413, Test R²=0.6418396575110299
2024-10-31 18:15:58,505 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:15:58,506 - INFO - Trial 589 finished with value: 2.200345754623413 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.799882877846419, 'learning_rate': 0.003111000641529979, 'weight_decay': 0.0002760458099580592, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:16:43,237 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995019829525829, 'learning_rate': 0.0024208206947315294, 'weight_decay': 0.0005979400801085608, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:16:43,237 - INFO - Trial 590: Train MSE=2.1712056483541216, Train R²=0.638495494212423
2024-10-31 18:16:43,238 - INFO - Trial 590: Test MSE=2.2323101588657925, Test R²=0.6369176932743618
2024-10-31 18:16:43,238 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:16:43,239 - INFO - Trial 590 finished with value: 2.2323101588657925 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995019829525829, 'learning_rate': 0.0024208206947315294, 'weight_decay': 0.0005979400801085608, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:18:14,152 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.41181478840083985, 'learning_rate': 0.009925166305015101, 'weight_decay': 0.0002669543156783382, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 18:18:14,152 - INFO - Trial 591: Train MSE=1.8369106096880776, Train R²=0.692095936941249
2024-10-31 18:18:14,152 - INFO - Trial 591: Test MSE=2.479901147740228, Test R²=0.588969207235745
2024-10-31 18:18:14,152 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:18:14,153 - INFO - Trial 591 finished with value: 2.479901147740228 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.41181478840083985, 'learning_rate': 0.009925166305015101, 'weight_decay': 0.0002669543156783382, 'batch_size': 128, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:18:51,169 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7917922472824587, 'learning_rate': 0.0027728044832096514, 'weight_decay': 0.0002760262314113982, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:18:51,169 - INFO - Trial 592: Train MSE=2.0934963864939555, Train R²=0.6523228138685226
2024-10-31 18:18:51,169 - INFO - Trial 592: Test MSE=2.2187067781175887, Test R²=0.6389650361878532
2024-10-31 18:18:51,169 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:18:51,170 - INFO - Trial 592 finished with value: 2.2187067781175887 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7917922472824587, 'learning_rate': 0.0027728044832096514, 'weight_decay': 0.0002760262314113982, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:19:27,734 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7921642770799392, 'learning_rate': 0.003637064811979823, 'weight_decay': 0.000258675800438785, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:19:27,734 - INFO - Trial 593: Train MSE=2.0218162834644318, Train R²=0.6630703551428658
2024-10-31 18:19:27,734 - INFO - Trial 593: Test MSE=2.2456237248011996, Test R²=0.634320718901498
2024-10-31 18:19:27,734 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:19:27,736 - INFO - Trial 593 finished with value: 2.2456237248011996 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7921642770799392, 'learning_rate': 0.003637064811979823, 'weight_decay': 0.000258675800438785, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:20:05,280 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7985690020725857, 'learning_rate': 0.0032217078520770832, 'weight_decay': 0.00024318187007953506, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:20:05,280 - INFO - Trial 594: Train MSE=2.0841700732707977, Train R²=0.6528068440301078
2024-10-31 18:20:05,280 - INFO - Trial 594: Test MSE=2.251109208379473, Test R²=0.6338112439428057
2024-10-31 18:20:05,280 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:20:05,281 - INFO - Trial 594 finished with value: 2.251109208379473 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7985690020725857, 'learning_rate': 0.0032217078520770832, 'weight_decay': 0.00024318187007953506, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:20:40,239 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7851971702386359, 'learning_rate': 0.0027590400361823023, 'weight_decay': 0.00028021352328491504, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:20:40,239 - INFO - Trial 595: Train MSE=2.3459455541202, Train R²=0.6088684499263763
2024-10-31 18:20:40,240 - INFO - Trial 595: Test MSE=2.2409023897988454, Test R²=0.6352508068084717
2024-10-31 18:20:40,240 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:20:40,241 - INFO - Trial 595 finished with value: 2.2409023897988454 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7851971702386359, 'learning_rate': 0.0027590400361823023, 'weight_decay': 0.00028021352328491504, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:21:17,038 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.784916686536914, 'learning_rate': 0.0030326846790499832, 'weight_decay': 0.0002895287642462334, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:21:17,038 - INFO - Trial 596: Train MSE=2.019873789378575, Train R²=0.6643714095864978
2024-10-31 18:21:17,038 - INFO - Trial 596: Test MSE=2.2562453065599715, Test R²=0.6326670220920018
2024-10-31 18:21:17,038 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:21:17,039 - INFO - Trial 596 finished with value: 2.2562453065599715 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.784916686536914, 'learning_rate': 0.0030326846790499832, 'weight_decay': 0.0002895287642462334, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:21:53,383 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7919692272110127, 'learning_rate': 0.001568953012067258, 'weight_decay': 0.0002701341354791771, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:21:53,383 - INFO - Trial 597: Train MSE=2.253086839403425, Train R²=0.6240637579134533
2024-10-31 18:21:53,383 - INFO - Trial 597: Test MSE=2.2453156879970004, Test R²=0.634572718824659
2024-10-31 18:21:53,383 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:21:53,384 - INFO - Trial 597 finished with value: 2.2453156879970004 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7919692272110127, 'learning_rate': 0.001568953012067258, 'weight_decay': 0.0002701341354791771, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:22:27,587 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.77591082785897, 'learning_rate': 0.0014049347295010857, 'weight_decay': 0.00029804878024845545, 'batch_size': 512, 'tree_depth': 8}
2024-10-31 18:22:27,587 - INFO - Trial 598: Train MSE=2.5728774751935686, Train R²=0.57205382840974
2024-10-31 18:22:27,587 - INFO - Trial 598: Test MSE=2.2931064707892284, Test R²=0.6267346399171012
2024-10-31 18:22:27,587 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:22:27,588 - INFO - Trial 598 finished with value: 2.2931064707892284 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.77591082785897, 'learning_rate': 0.0014049347295010857, 'weight_decay': 0.00029804878024845545, 'batch_size': 512, 'tree_depth': 8}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:23:04,227 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7993745926742506, 'learning_rate': 0.0022534860725736375, 'weight_decay': 0.00030929001358379917, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:23:04,228 - INFO - Trial 599: Train MSE=2.1698852479457855, Train R²=0.6393645299332482
2024-10-31 18:23:04,228 - INFO - Trial 599: Test MSE=2.241528476987566, Test R²=0.6351303202765328
2024-10-31 18:23:04,228 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:23:04,229 - INFO - Trial 599 finished with value: 2.241528476987566 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7993745926742506, 'learning_rate': 0.0022534860725736375, 'weight_decay': 0.00030929001358379917, 'batch_size': 512, 'tree_depth': 12}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:23:40,780 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7989596090919565, 'learning_rate': 0.0012719132886529528, 'weight_decay': 0.00028435773391569764, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:23:40,780 - INFO - Trial 600: Train MSE=2.3858604856899808, Train R²=0.6019147293908256
2024-10-31 18:23:40,780 - INFO - Trial 600: Test MSE=2.202127354485648, Test R²=0.6415191548211234
2024-10-31 18:23:40,780 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:23:40,782 - INFO - Trial 600 finished with value: 2.202127354485648 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7989596090919565, 'learning_rate': 0.0012719132886529528, 'weight_decay': 0.00028435773391569764, 'batch_size': 512, 'tree_depth': 11}. Best is trial 104 with value: 2.1955713714872087.
2024-10-31 18:24:17,287 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995991491433455, 'learning_rate': 0.005623627734610015, 'weight_decay': 0.00024797053276969004, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:24:17,287 - INFO - Trial 601: Train MSE=2.0513070097991397, Train R²=0.6592411079577037
2024-10-31 18:24:17,287 - INFO - Trial 601: Test MSE=2.1809195450374057, Test R²=0.6449578319277082
2024-10-31 18:24:17,287 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:24:17,288 - INFO - Trial 601 finished with value: 2.1809195450374057 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995991491433455, 'learning_rate': 0.005623627734610015, 'weight_decay': 0.00024797053276969004, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:24:57,607 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7956489609323287, 'learning_rate': 0.005309076946988501, 'weight_decay': 0.00022565067903656513, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:24:57,607 - INFO - Trial 602: Train MSE=2.262346782854625, Train R²=0.6238513035433633
2024-10-31 18:24:57,607 - INFO - Trial 602: Test MSE=2.2757398741585866, Test R²=0.6296038712774005
2024-10-31 18:24:57,607 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:24:57,608 - INFO - Trial 602 finished with value: 2.2757398741585866 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7956489609323287, 'learning_rate': 0.005309076946988501, 'weight_decay': 0.00022565067903656513, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:25:34,352 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7989021696124269, 'learning_rate': 0.0043690303682198004, 'weight_decay': 0.00023655870611828957, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:25:34,353 - INFO - Trial 603: Train MSE=2.051564335823059, Train R²=0.6587244548967907
2024-10-31 18:25:34,353 - INFO - Trial 603: Test MSE=2.2474674497331892, Test R²=0.6342309032167707
2024-10-31 18:25:34,353 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:25:34,354 - INFO - Trial 603 finished with value: 2.2474674497331892 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7989021696124269, 'learning_rate': 0.0043690303682198004, 'weight_decay': 0.00023655870611828957, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:26:10,726 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7987245225343531, 'learning_rate': 0.003913042300559782, 'weight_decay': 0.00023399665624066645, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:26:10,727 - INFO - Trial 604: Train MSE=2.133919413600649, Train R²=0.6456545974527087
2024-10-31 18:26:10,727 - INFO - Trial 604: Test MSE=2.236998677253723, Test R²=0.6358139089175633
2024-10-31 18:26:10,727 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:26:10,728 - INFO - Trial 604 finished with value: 2.236998677253723 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7987245225343531, 'learning_rate': 0.003913042300559782, 'weight_decay': 0.00023399665624066645, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:26:48,751 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7992159864409386, 'learning_rate': 0.002545007914797989, 'weight_decay': 0.0002541913861229693, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:26:48,751 - INFO - Trial 605: Train MSE=2.1194189148289815, Train R²=0.6483872873442513
2024-10-31 18:26:48,751 - INFO - Trial 605: Test MSE=2.237715653010777, Test R²=0.6357804111071995
2024-10-31 18:26:48,751 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:26:48,752 - INFO - Trial 605 finished with value: 2.237715653010777 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7992159864409386, 'learning_rate': 0.002545007914797989, 'weight_decay': 0.0002541913861229693, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:27:24,899 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7854808381440399, 'learning_rate': 0.005059604498251683, 'weight_decay': 0.00024197494478182984, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:27:24,899 - INFO - Trial 606: Train MSE=1.9766766045774733, Train R²=0.6713150675807681
2024-10-31 18:27:24,899 - INFO - Trial 606: Test MSE=2.2391482080732072, Test R²=0.635507847581591
2024-10-31 18:27:24,899 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:27:24,900 - INFO - Trial 606 finished with value: 2.2391482080732072 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7854808381440399, 'learning_rate': 0.005059604498251683, 'weight_decay': 0.00024197494478182984, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:27:56,231 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7897928254575994, 'learning_rate': 0.001278207678969321, 'weight_decay': 0.00024902179536698537, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 18:27:56,231 - INFO - Trial 607: Train MSE=2.744297112737383, Train R²=0.5441949239798954
2024-10-31 18:27:56,231 - INFO - Trial 607: Test MSE=2.2627208828926086, Test R²=0.629153311252594
2024-10-31 18:27:56,231 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:27:56,233 - INFO - Trial 607 finished with value: 2.2627208828926086 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7897928254575994, 'learning_rate': 0.001278207678969321, 'weight_decay': 0.00024902179536698537, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:28:31,970 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 1024, 'dropout_rate': 0.799207504197343, 'learning_rate': 0.0011518844686470454, 'weight_decay': 0.00025452683232714897, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:28:31,970 - INFO - Trial 608: Train MSE=2.1687854060104916, Train R²=0.6386909995760236
2024-10-31 18:28:31,970 - INFO - Trial 608: Test MSE=2.3111025946480885, Test R²=0.6239030190876552
2024-10-31 18:28:31,970 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:28:31,971 - INFO - Trial 608 finished with value: 2.3111025946480885 and parameters: {'hidden_layers': 2, 'hidden_units': 1024, 'dropout_rate': 0.799207504197343, 'learning_rate': 0.0011518844686470454, 'weight_decay': 0.00025452683232714897, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:29:14,061 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.799963759838914, 'learning_rate': 0.0012069306168052, 'weight_decay': 0.0002632206752325796, 'batch_size': 256, 'tree_depth': 10}
2024-10-31 18:29:14,061 - INFO - Trial 609: Train MSE=2.1480964911835536, Train R²=0.6399943221892629
2024-10-31 18:29:14,062 - INFO - Trial 609: Test MSE=2.239381287779127, Test R²=0.6341456004551479
2024-10-31 18:29:14,062 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:29:14,063 - INFO - Trial 609 finished with value: 2.239381287779127 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.799963759838914, 'learning_rate': 0.0012069306168052, 'weight_decay': 0.0002632206752325796, 'batch_size': 256, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:29:50,567 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.785669586025379, 'learning_rate': 0.001083441079264328, 'weight_decay': 0.00026153307438710725, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:29:50,567 - INFO - Trial 610: Train MSE=2.2548883046422685, Train R²=0.6250131619828088
2024-10-31 18:29:50,567 - INFO - Trial 610: Test MSE=2.2272357600075856, Test R²=0.6374351467405047
2024-10-31 18:29:50,567 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:29:50,568 - INFO - Trial 610 finished with value: 2.2272357600075856 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.785669586025379, 'learning_rate': 0.001083441079264328, 'weight_decay': 0.00026153307438710725, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:30:27,915 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7871999540464327, 'learning_rate': 0.0012173493715020665, 'weight_decay': 0.00022730007296881157, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:30:27,915 - INFO - Trial 611: Train MSE=2.2246904713766917, Train R²=0.6293565779924393
2024-10-31 18:30:27,915 - INFO - Trial 611: Test MSE=2.2230078152247836, Test R²=0.6382244655064174
2024-10-31 18:30:27,915 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:30:27,917 - INFO - Trial 611 finished with value: 2.2230078152247836 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7871999540464327, 'learning_rate': 0.0012173493715020665, 'weight_decay': 0.00022730007296881157, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:31:05,045 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7793097293824278, 'learning_rate': 0.0056419562879955806, 'weight_decay': 0.00027384019641219393, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:31:05,045 - INFO - Trial 612: Train MSE=1.9901015971388136, Train R²=0.669138931802341
2024-10-31 18:31:05,045 - INFO - Trial 612: Test MSE=2.2557128156934465, Test R²=0.6329584717750549
2024-10-31 18:31:05,045 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:31:05,046 - INFO - Trial 612 finished with value: 2.2557128156934465 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7793097293824278, 'learning_rate': 0.0056419562879955806, 'weight_decay': 0.00027384019641219393, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:31:42,502 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7893247035942867, 'learning_rate': 0.0013378666311876003, 'weight_decay': 0.00024502371818995236, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:31:42,502 - INFO - Trial 613: Train MSE=2.273742586374283, Train R²=0.6217946708202362
2024-10-31 18:31:42,502 - INFO - Trial 613: Test MSE=2.257138524736677, Test R²=0.6325206671442304
2024-10-31 18:31:42,502 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:31:42,504 - INFO - Trial 613 finished with value: 2.257138524736677 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7893247035942867, 'learning_rate': 0.0013378666311876003, 'weight_decay': 0.00024502371818995236, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:32:14,691 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7991983586643783, 'learning_rate': 0.003041196509765481, 'weight_decay': 0.00025761107172000535, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:32:14,691 - INFO - Trial 614: Train MSE=2.145865572350366, Train R²=0.6431117100375039
2024-10-31 18:32:14,691 - INFO - Trial 614: Test MSE=2.2191705192838396, Test R²=0.6389158708708627
2024-10-31 18:32:14,691 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:32:14,691 - INFO - Trial 614 finished with value: 2.2191705192838396 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7991983586643783, 'learning_rate': 0.003041196509765481, 'weight_decay': 0.00025761107172000535, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:32:47,864 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7768082196097421, 'learning_rate': 0.0048589325114015685, 'weight_decay': 0.00027424479286998173, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:32:47,865 - INFO - Trial 615: Train MSE=2.2708067212785994, Train R²=0.622035665171487
2024-10-31 18:32:47,865 - INFO - Trial 615: Test MSE=2.3171491622924805, Test R²=0.6227419206074306
2024-10-31 18:32:47,865 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:32:47,866 - INFO - Trial 615 finished with value: 2.3171491622924805 and parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7768082196097421, 'learning_rate': 0.0048589325114015685, 'weight_decay': 0.00027424479286998173, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:33:22,385 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5145781338711937, 'learning_rate': 0.001053647778911092, 'weight_decay': 0.0005391937764857229, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:33:22,385 - INFO - Trial 616: Train MSE=0.9506736653191703, Train R²=0.8416262503181186
2024-10-31 18:33:22,385 - INFO - Trial 616: Test MSE=2.3794590064457486, Test R²=0.6125337736947196
2024-10-31 18:33:22,385 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:33:22,387 - INFO - Trial 616 finished with value: 2.3794590064457486 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5145781338711937, 'learning_rate': 0.001053647778911092, 'weight_decay': 0.0005391937764857229, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:33:54,286 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7888834012501486, 'learning_rate': 0.005913346202500983, 'weight_decay': 0.00021671073643638418, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:33:54,286 - INFO - Trial 617: Train MSE=1.8325048770223344, Train R²=0.6940523875611169
2024-10-31 18:33:54,286 - INFO - Trial 617: Test MSE=2.2487422738756453, Test R²=0.6339485389845712
2024-10-31 18:33:54,286 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:33:54,287 - INFO - Trial 617 finished with value: 2.2487422738756453 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7888834012501486, 'learning_rate': 0.005913346202500983, 'weight_decay': 0.00021671073643638418, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:35:21,053 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.769649273664298, 'learning_rate': 0.0011579016441128499, 'weight_decay': 0.0002809732487265475, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 18:35:21,054 - INFO - Trial 618: Train MSE=1.7662114703229495, Train R²=0.7015750301735741
2024-10-31 18:35:21,054 - INFO - Trial 618: Test MSE=2.258091006960188, Test R²=0.6255262451512473
2024-10-31 18:35:21,054 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:35:21,055 - INFO - Trial 618 finished with value: 2.258091006960188 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.769649273664298, 'learning_rate': 0.0011579016441128499, 'weight_decay': 0.0002809732487265475, 'batch_size': 128, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:35:56,634 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6151232363083776, 'learning_rate': 0.0026116753692444084, 'weight_decay': 0.0002641425863091307, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:35:56,635 - INFO - Trial 619: Train MSE=1.1701864387307848, Train R²=0.8050213839326587
2024-10-31 18:35:56,635 - INFO - Trial 619: Test MSE=2.3535633087158203, Test R²=0.6168192625045776
2024-10-31 18:35:56,635 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:35:56,636 - INFO - Trial 619 finished with value: 2.3535633087158203 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6151232363083776, 'learning_rate': 0.0026116753692444084, 'weight_decay': 0.0002641425863091307, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:36:34,516 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7997016126070557, 'learning_rate': 0.0013020421699065988, 'weight_decay': 0.0005774762719538302, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:36:34,516 - INFO - Trial 620: Train MSE=2.965761457170759, Train R²=0.5051095251526151
2024-10-31 18:36:34,516 - INFO - Trial 620: Test MSE=2.2388399498803273, Test R²=0.6356802242142814
2024-10-31 18:36:34,516 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:36:34,518 - INFO - Trial 620 finished with value: 2.2388399498803273 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7997016126070557, 'learning_rate': 0.0013020421699065988, 'weight_decay': 0.0005774762719538302, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:37:11,050 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7836686399526829, 'learning_rate': 0.006803637032320394, 'weight_decay': 0.0002380333212252502, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 18:37:11,050 - INFO - Trial 621: Train MSE=2.0480502801282063, Train R²=0.6591427028179169
2024-10-31 18:37:11,050 - INFO - Trial 621: Test MSE=2.2538930007389615, Test R²=0.6329398580959865
2024-10-31 18:37:11,050 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:37:11,052 - INFO - Trial 621 finished with value: 2.2538930007389615 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7836686399526829, 'learning_rate': 0.006803637032320394, 'weight_decay': 0.0002380333212252502, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:37:47,627 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902765685562033, 'learning_rate': 0.0010047431370814159, 'weight_decay': 0.00028098609632070027, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:37:47,627 - INFO - Trial 622: Train MSE=2.4566204377583096, Train R²=0.5916381308010646
2024-10-31 18:37:47,627 - INFO - Trial 622: Test MSE=2.3089084965842113, Test R²=0.6243165135383606
2024-10-31 18:37:47,627 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:37:47,629 - INFO - Trial 622 finished with value: 2.3089084965842113 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902765685562033, 'learning_rate': 0.0010047431370814159, 'weight_decay': 0.00028098609632070027, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:38:24,660 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7761160050263031, 'learning_rate': 0.0011418592626742286, 'weight_decay': 0.00029201498456642817, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:38:24,661 - INFO - Trial 623: Train MSE=2.1869603225163052, Train R²=0.6358895365680967
2024-10-31 18:38:24,661 - INFO - Trial 623: Test MSE=2.24203998701913, Test R²=0.6350831730025155
2024-10-31 18:38:24,661 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:38:24,662 - INFO - Trial 623 finished with value: 2.24203998701913 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7761160050263031, 'learning_rate': 0.0011418592626742286, 'weight_decay': 0.00029201498456642817, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:39:01,498 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7593200088154016, 'learning_rate': 0.0013784279018056813, 'weight_decay': 0.0002694675101060301, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:39:01,498 - INFO - Trial 624: Train MSE=2.047741021428789, Train R²=0.6588534925665174
2024-10-31 18:39:01,498 - INFO - Trial 624: Test MSE=2.2355285372052873, Test R²=0.6362430708748954
2024-10-31 18:39:01,498 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:39:01,499 - INFO - Trial 624 finished with value: 2.2355285372052873 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7593200088154016, 'learning_rate': 0.0013784279018056813, 'weight_decay': 0.0002694675101060301, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:39:36,113 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7891853946813483, 'learning_rate': 0.0010738955804973972, 'weight_decay': 0.0003187846044777238, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:39:36,113 - INFO - Trial 625: Train MSE=2.367561170033046, Train R²=0.605783720101629
2024-10-31 18:39:36,113 - INFO - Trial 625: Test MSE=2.2364092213766917, Test R²=0.6358950989586967
2024-10-31 18:39:36,113 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:39:36,115 - INFO - Trial 625 finished with value: 2.2364092213766917 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7891853946813483, 'learning_rate': 0.0010738955804973972, 'weight_decay': 0.0003187846044777238, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:40:13,047 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7803723981198907, 'learning_rate': 0.001267362417941127, 'weight_decay': 0.00024710920090864353, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:40:13,047 - INFO - Trial 626: Train MSE=2.2311313918658664, Train R²=0.6281234707151141
2024-10-31 18:40:13,047 - INFO - Trial 626: Test MSE=2.241182327270508, Test R²=0.6352645839963641
2024-10-31 18:40:13,047 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:40:13,049 - INFO - Trial 626 finished with value: 2.241182327270508 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7803723981198907, 'learning_rate': 0.001267362417941127, 'weight_decay': 0.00024710920090864353, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:40:52,034 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7675906085605704, 'learning_rate': 0.0034927823480057495, 'weight_decay': 0.0002037479165959463, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:40:52,034 - INFO - Trial 627: Train MSE=1.9615691602230072, Train R²=0.6737073915345329
2024-10-31 18:40:52,035 - INFO - Trial 627: Test MSE=2.2983730861118863, Test R²=0.6258050288472857
2024-10-31 18:40:52,035 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:40:52,036 - INFO - Trial 627 finished with value: 2.2983730861118863 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7675906085605704, 'learning_rate': 0.0034927823480057495, 'weight_decay': 0.0002037479165959463, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:41:29,043 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7914066170309744, 'learning_rate': 0.0014753865218601725, 'weight_decay': 0.000295175101499451, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:41:29,043 - INFO - Trial 628: Train MSE=2.2518813695226396, Train R²=0.6246767001492637
2024-10-31 18:41:29,043 - INFO - Trial 628: Test MSE=2.247838224683489, Test R²=0.6342430455344064
2024-10-31 18:41:29,043 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:41:29,044 - INFO - Trial 628 finished with value: 2.247838224683489 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7914066170309744, 'learning_rate': 0.0014753865218601725, 'weight_decay': 0.000295175101499451, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:42:09,185 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7778595942927212, 'learning_rate': 0.0010324042862036573, 'weight_decay': 0.0003287612300793818, 'batch_size': 512, 'tree_depth': 7}
2024-10-31 18:42:09,186 - INFO - Trial 629: Train MSE=2.9792434913771495, Train R²=0.503899233681815
2024-10-31 18:42:09,186 - INFO - Trial 629: Test MSE=2.344116108758109, Test R²=0.6184660622051784
2024-10-31 18:42:09,186 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:42:09,187 - INFO - Trial 629 finished with value: 2.344116108758109 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7778595942927212, 'learning_rate': 0.0010324042862036573, 'weight_decay': 0.0003287612300793818, 'batch_size': 512, 'tree_depth': 7}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:42:46,665 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7997972388190034, 'learning_rate': 0.0011890657857432168, 'weight_decay': 0.0002520614722911125, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:42:46,665 - INFO - Trial 630: Train MSE=2.4473310794149126, Train R²=0.5935619686331067
2024-10-31 18:42:46,665 - INFO - Trial 630: Test MSE=2.233237079211644, Test R²=0.6365357552255902
2024-10-31 18:42:46,665 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:42:46,666 - INFO - Trial 630 finished with value: 2.233237079211644 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7997972388190034, 'learning_rate': 0.0011890657857432168, 'weight_decay': 0.0002520614722911125, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:43:23,377 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.783911294383375, 'learning_rate': 0.0038991885181904255, 'weight_decay': 0.0002840752715320913, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:43:23,377 - INFO - Trial 631: Train MSE=1.9966280971254622, Train R²=0.6673060187271663
2024-10-31 18:43:23,377 - INFO - Trial 631: Test MSE=2.330379213605608, Test R²=0.6204996875354222
2024-10-31 18:43:23,377 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:43:23,378 - INFO - Trial 631 finished with value: 2.330379213605608 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.783911294383375, 'learning_rate': 0.0038991885181904255, 'weight_decay': 0.0002840752715320913, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:43:55,352 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7694933044644735, 'learning_rate': 0.0012639484834422213, 'weight_decay': 0.0006625206279663993, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 18:43:55,352 - INFO - Trial 632: Train MSE=2.510219250406538, Train R²=0.5826600406851087
2024-10-31 18:43:55,352 - INFO - Trial 632: Test MSE=2.260888934135437, Test R²=0.6294669359922409
2024-10-31 18:43:55,352 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:43:55,353 - INFO - Trial 632 finished with value: 2.260888934135437 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7694933044644735, 'learning_rate': 0.0012639484834422213, 'weight_decay': 0.0006625206279663993, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:44:32,407 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5736625498939826, 'learning_rate': 0.001109560859352026, 'weight_decay': 0.0003046583514947731, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:44:32,407 - INFO - Trial 633: Train MSE=1.0927044876984187, Train R²=0.8182366213628224
2024-10-31 18:44:32,407 - INFO - Trial 633: Test MSE=2.365936756134033, Test R²=0.6151316080774579
2024-10-31 18:44:32,407 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:44:32,408 - INFO - Trial 633 finished with value: 2.365936756134033 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5736625498939826, 'learning_rate': 0.001109560859352026, 'weight_decay': 0.0003046583514947731, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:45:17,133 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7882478380699686, 'learning_rate': 0.0009841029953808148, 'weight_decay': 0.00026479384503711237, 'batch_size': 256, 'tree_depth': 9}
2024-10-31 18:45:17,133 - INFO - Trial 634: Train MSE=1.9692014796393258, Train R²=0.6703647949865886
2024-10-31 18:45:17,133 - INFO - Trial 634: Test MSE=2.278516181877681, Test R²=0.6269409911973136
2024-10-31 18:45:17,133 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:45:17,134 - INFO - Trial 634 finished with value: 2.278516181877681 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7882478380699686, 'learning_rate': 0.0009841029953808148, 'weight_decay': 0.00026479384503711237, 'batch_size': 256, 'tree_depth': 9}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:45:48,701 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.791351002662967, 'learning_rate': 0.0013812735981201952, 'weight_decay': 0.0003198735558301703, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:45:48,701 - INFO - Trial 635: Train MSE=2.250746475798743, Train R²=0.6255606029714856
2024-10-31 18:45:48,701 - INFO - Trial 635: Test MSE=2.2065981456211636, Test R²=0.6407465594155448
2024-10-31 18:45:48,701 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:45:48,703 - INFO - Trial 635 finished with value: 2.2065981456211636 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.791351002662967, 'learning_rate': 0.0013812735981201952, 'weight_decay': 0.0003198735558301703, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:46:17,750 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7625657613133153, 'learning_rate': 0.0013294142554323572, 'weight_decay': 0.0003028988945441355, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:46:17,750 - INFO - Trial 636: Train MSE=2.0239933729171753, Train R²=0.6635979988745281
2024-10-31 18:46:17,750 - INFO - Trial 636: Test MSE=2.2223824092320035, Test R²=0.6382030674389431
2024-10-31 18:46:17,750 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:46:17,752 - INFO - Trial 636 finished with value: 2.2223824092320035 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7625657613133153, 'learning_rate': 0.0013294142554323572, 'weight_decay': 0.0003028988945441355, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:46:54,535 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7746484321089423, 'learning_rate': 0.0011521400450661852, 'weight_decay': 0.00028428944829533566, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:46:54,536 - INFO - Trial 637: Train MSE=2.2080576632704054, Train R²=0.6324918461697442
2024-10-31 18:46:54,536 - INFO - Trial 637: Test MSE=2.232726982661656, Test R²=0.6365791303770882
2024-10-31 18:46:54,536 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:46:54,538 - INFO - Trial 637 finished with value: 2.232726982661656 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7746484321089423, 'learning_rate': 0.0011521400450661852, 'weight_decay': 0.00028428944829533566, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:47:29,601 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7819925050597143, 'learning_rate': 0.0014232003328528509, 'weight_decay': 0.00031067105405676324, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:47:29,602 - INFO - Trial 638: Train MSE=2.1416374359812056, Train R²=0.6439817803246635
2024-10-31 18:47:29,602 - INFO - Trial 638: Test MSE=2.27838557107108, Test R²=0.6290502377918789
2024-10-31 18:47:29,602 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:47:29,604 - INFO - Trial 638 finished with value: 2.27838557107108 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7819925050597143, 'learning_rate': 0.0014232003328528509, 'weight_decay': 0.00031067105405676324, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:48:07,085 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7534320917471178, 'learning_rate': 0.0009646378713394305, 'weight_decay': 0.00032535141816242605, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 18:48:07,085 - INFO - Trial 639: Train MSE=2.130681267806462, Train R²=0.6456516683101654
2024-10-31 18:48:07,086 - INFO - Trial 639: Test MSE=2.2680380003792897, Test R²=0.630609563418797
2024-10-31 18:48:07,086 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:48:07,087 - INFO - Trial 639 finished with value: 2.2680380003792897 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7534320917471178, 'learning_rate': 0.0009646378713394305, 'weight_decay': 0.00032535141816242605, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:48:43,732 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7726608569711038, 'learning_rate': 0.0012277862006794178, 'weight_decay': 0.000296796497726145, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:48:43,732 - INFO - Trial 640: Train MSE=2.120985563312258, Train R²=0.6471179170267922
2024-10-31 18:48:43,732 - INFO - Trial 640: Test MSE=2.264209372656686, Test R²=0.6316996897969928
2024-10-31 18:48:43,732 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:48:43,733 - INFO - Trial 640 finished with value: 2.264209372656686 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7726608569711038, 'learning_rate': 0.0012277862006794178, 'weight_decay': 0.000296796497726145, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:49:23,416 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902229615119742, 'learning_rate': 0.0008627629530568579, 'weight_decay': 0.00023262046856758177, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:49:23,416 - INFO - Trial 641: Train MSE=2.558380424976349, Train R²=0.5742727645805904
2024-10-31 18:49:23,416 - INFO - Trial 641: Test MSE=2.2097947938101634, Test R²=0.640300955091204
2024-10-31 18:49:23,416 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:49:23,418 - INFO - Trial 641 finished with value: 2.2097947938101634 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902229615119742, 'learning_rate': 0.0008627629530568579, 'weight_decay': 0.00023262046856758177, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:50:00,844 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902559657113589, 'learning_rate': 0.0008641932583902463, 'weight_decay': 0.00021466189011021847, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:50:00,844 - INFO - Trial 642: Train MSE=2.554308193070548, Train R²=0.5745384757007871
2024-10-31 18:50:00,844 - INFO - Trial 642: Test MSE=2.2671216215406145, Test R²=0.6310215251786369
2024-10-31 18:50:00,844 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:50:00,846 - INFO - Trial 642 finished with value: 2.2671216215406145 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902559657113589, 'learning_rate': 0.0008641932583902463, 'weight_decay': 0.00021466189011021847, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:50:30,926 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7998603858899884, 'learning_rate': 0.0007112064543655085, 'weight_decay': 0.00022871743236929363, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:50:30,926 - INFO - Trial 643: Train MSE=2.5536940779004778, Train R²=0.5740024873188564
2024-10-31 18:50:30,926 - INFO - Trial 643: Test MSE=2.2543671301433017, Test R²=0.6329691750662667
2024-10-31 18:50:30,926 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:50:30,927 - INFO - Trial 643 finished with value: 2.2543671301433017 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7998603858899884, 'learning_rate': 0.0007112064543655085, 'weight_decay': 0.00022871743236929363, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:51:09,658 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7445237848880392, 'learning_rate': 0.000902101063302052, 'weight_decay': 0.00022830311735900572, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:51:09,658 - INFO - Trial 644: Train MSE=2.1314461529254913, Train R²=0.6451605792556491
2024-10-31 18:51:09,658 - INFO - Trial 644: Test MSE=2.269799198423113, Test R²=0.6303734523909432
2024-10-31 18:51:09,658 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:51:09,659 - INFO - Trial 644 finished with value: 2.269799198423113 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7445237848880392, 'learning_rate': 0.000902101063302052, 'weight_decay': 0.00022830311735900572, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:51:50,821 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7791135086649279, 'learning_rate': 0.0007784636802125643, 'weight_decay': 0.0002468009382069506, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:51:50,822 - INFO - Trial 645: Train MSE=2.5283696396010265, Train R²=0.580040693283081
2024-10-31 18:51:50,822 - INFO - Trial 645: Test MSE=2.240492650440761, Test R²=0.6355340565953936
2024-10-31 18:51:50,822 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:51:50,825 - INFO - Trial 645 finished with value: 2.240492650440761 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7791135086649279, 'learning_rate': 0.0007784636802125643, 'weight_decay': 0.0002468009382069506, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:53:14,256 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7677726694739494, 'learning_rate': 0.0008400521235741025, 'weight_decay': 0.0002227032305717451, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 18:53:14,256 - INFO - Trial 646: Train MSE=1.9047263030494963, Train R²=0.6774310373834201
2024-10-31 18:53:14,256 - INFO - Trial 646: Test MSE=2.2684498514447893, Test R²=0.6227837949991226
2024-10-31 18:53:14,256 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:53:14,258 - INFO - Trial 646 finished with value: 2.2684498514447893 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7677726694739494, 'learning_rate': 0.0008400521235741025, 'weight_decay': 0.0002227032305717451, 'batch_size': 128, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:53:51,271 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999530027691708, 'learning_rate': 0.0006514749382427903, 'weight_decay': 0.0002270538657665022, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:53:51,271 - INFO - Trial 647: Train MSE=2.8937740325927734, Train R²=0.5186996289661953
2024-10-31 18:53:51,272 - INFO - Trial 647: Test MSE=2.2444585732051303, Test R²=0.6346929499081203
2024-10-31 18:53:51,272 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:53:51,273 - INFO - Trial 647 finished with value: 2.2444585732051303 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999530027691708, 'learning_rate': 0.0006514749382427903, 'weight_decay': 0.0002270538657665022, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:54:22,178 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7863763832536851, 'learning_rate': 0.0008310313189583332, 'weight_decay': 0.0002194246290005683, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:54:22,178 - INFO - Trial 648: Train MSE=3.054211471761976, Train R²=0.49293211102485657
2024-10-31 18:54:22,178 - INFO - Trial 648: Test MSE=2.4055954047611783, Test R²=0.6085635253361293
2024-10-31 18:54:22,178 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:54:22,179 - INFO - Trial 648 finished with value: 2.4055954047611783 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7863763832536851, 'learning_rate': 0.0008310313189583332, 'weight_decay': 0.0002194246290005683, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:54:58,023 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6586287871792009, 'learning_rate': 0.0009612797095877006, 'weight_decay': 0.00021011252749279837, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:54:58,023 - INFO - Trial 649: Train MSE=1.540536378111158, Train R²=0.7436799449580056
2024-10-31 18:54:58,023 - INFO - Trial 649: Test MSE=2.3030310698917935, Test R²=0.6251189879008702
2024-10-31 18:54:58,024 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:54:58,025 - INFO - Trial 649 finished with value: 2.3030310698917935 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6586287871792009, 'learning_rate': 0.0009612797095877006, 'weight_decay': 0.00021011252749279837, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:55:34,094 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7608823456720523, 'learning_rate': 0.0010579484763339744, 'weight_decay': 0.00024024275576328195, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:55:34,094 - INFO - Trial 650: Train MSE=2.423974709851401, Train R²=0.5967323524611337
2024-10-31 18:55:34,095 - INFO - Trial 650: Test MSE=2.260483741760254, Test R²=0.6321192383766174
2024-10-31 18:55:34,095 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:55:34,096 - INFO - Trial 650 finished with value: 2.260483741760254 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7608823456720523, 'learning_rate': 0.0010579484763339744, 'weight_decay': 0.00024024275576328195, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:56:06,578 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7823135625953049, 'learning_rate': 0.0007479279882288793, 'weight_decay': 0.0002344500590611868, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:56:06,578 - INFO - Trial 651: Train MSE=2.6575549840927124, Train R²=0.5565483484949384
2024-10-31 18:56:06,578 - INFO - Trial 651: Test MSE=2.2313402720860074, Test R²=0.636852468763079
2024-10-31 18:56:06,578 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:56:06,580 - INFO - Trial 651 finished with value: 2.2313402720860074 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7823135625953049, 'learning_rate': 0.0007479279882288793, 'weight_decay': 0.0002344500590611868, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:56:42,251 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.790977498536434, 'learning_rate': 0.0009589196724829616, 'weight_decay': 0.00025365176996927635, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:56:42,251 - INFO - Trial 652: Train MSE=2.4326799852507457, Train R²=0.5955147679362979
2024-10-31 18:56:42,252 - INFO - Trial 652: Test MSE=2.2438765253339494, Test R²=0.6347569908414569
2024-10-31 18:56:42,252 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:56:42,253 - INFO - Trial 652 finished with value: 2.2438765253339494 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.790977498536434, 'learning_rate': 0.0009589196724829616, 'weight_decay': 0.00025365176996927635, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:57:15,339 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7743886180561326, 'learning_rate': 0.0010893386914852016, 'weight_decay': 0.00023742284281784697, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:57:15,339 - INFO - Trial 653: Train MSE=2.2704522950308665, Train R²=0.6220989014421191
2024-10-31 18:57:15,340 - INFO - Trial 653: Test MSE=2.2491017409733365, Test R²=0.63396874495915
2024-10-31 18:57:15,340 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:57:15,341 - INFO - Trial 653 finished with value: 2.2491017409733365 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7743886180561326, 'learning_rate': 0.0010893386914852016, 'weight_decay': 0.00023742284281784697, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:57:49,421 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.789381935736957, 'learning_rate': 0.0028784063772285843, 'weight_decay': 0.0002550831760568612, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:57:49,421 - INFO - Trial 654: Train MSE=2.021225929260254, Train R²=0.6635148099490574
2024-10-31 18:57:49,421 - INFO - Trial 654: Test MSE=2.213066714150565, Test R²=0.6396708403314862
2024-10-31 18:57:49,421 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:57:49,423 - INFO - Trial 654 finished with value: 2.213066714150565 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.789381935736957, 'learning_rate': 0.0028784063772285843, 'weight_decay': 0.0002550831760568612, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:58:21,248 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7831508002009135, 'learning_rate': 0.0013669364136416283, 'weight_decay': 0.00025873845711274365, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:58:21,248 - INFO - Trial 655: Train MSE=2.1623338886669705, Train R²=0.6390913469450814
2024-10-31 18:58:21,248 - INFO - Trial 655: Test MSE=2.233297722680228, Test R²=0.636380672454834
2024-10-31 18:58:21,248 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:58:21,249 - INFO - Trial 655 finished with value: 2.233297722680228 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7831508002009135, 'learning_rate': 0.0013669364136416283, 'weight_decay': 0.00025873845711274365, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:58:47,791 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7710267180662628, 'learning_rate': 0.0029543766759613454, 'weight_decay': 0.0002491155597825958, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 18:58:47,791 - INFO - Trial 656: Train MSE=2.0688301580292836, Train R²=0.656253205878394
2024-10-31 18:58:47,792 - INFO - Trial 656: Test MSE=2.2675049901008606, Test R²=0.6281715482473373
2024-10-31 18:58:47,792 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:58:47,793 - INFO - Trial 656 finished with value: 2.2675049901008606 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7710267180662628, 'learning_rate': 0.0029543766759613454, 'weight_decay': 0.0002491155597825958, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:59:19,747 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7909723027797103, 'learning_rate': 0.0030692880214099588, 'weight_decay': 0.0002464702230324702, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 18:59:19,747 - INFO - Trial 657: Train MSE=2.1523702698094502, Train R²=0.6421811474221093
2024-10-31 18:59:19,747 - INFO - Trial 657: Test MSE=2.2583172832216536, Test R²=0.6323531270027161
2024-10-31 18:59:19,747 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:59:19,749 - INFO - Trial 657 finished with value: 2.2583172832216536 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7909723027797103, 'learning_rate': 0.0030692880214099588, 'weight_decay': 0.0002464702230324702, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 18:59:55,391 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7625420286219718, 'learning_rate': 0.002690481667346376, 'weight_decay': 0.00023422332817683123, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 18:59:55,391 - INFO - Trial 658: Train MSE=1.504901030233928, Train R²=0.7489508560725621
2024-10-31 18:59:55,391 - INFO - Trial 658: Test MSE=2.295192463057382, Test R²=0.6262704730033875
2024-10-31 18:59:55,391 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 18:59:55,392 - INFO - Trial 658 finished with value: 2.295192463057382 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7625420286219718, 'learning_rate': 0.002690481667346376, 'weight_decay': 0.00023422332817683123, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:00:27,412 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.776663136804694, 'learning_rate': 0.0025143675027088737, 'weight_decay': 0.0002614726844808285, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:00:27,412 - INFO - Trial 659: Train MSE=1.9644945178713118, Train R²=0.673505282827786
2024-10-31 19:00:27,412 - INFO - Trial 659: Test MSE=2.2435383115495955, Test R²=0.6347945587975639
2024-10-31 19:00:27,412 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:00:27,414 - INFO - Trial 659 finished with value: 2.2435383115495955 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.776663136804694, 'learning_rate': 0.0025143675027088737, 'weight_decay': 0.0002614726844808285, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:01:19,193 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7907708417997632, 'learning_rate': 0.0034093552964550855, 'weight_decay': 0.00027397022947249397, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 19:01:19,193 - INFO - Trial 660: Train MSE=1.9126598579542977, Train R²=0.6800204004560199
2024-10-31 19:01:19,193 - INFO - Trial 660: Test MSE=2.2527588180133273, Test R²=0.6313061032976423
2024-10-31 19:01:19,193 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:01:19,195 - INFO - Trial 660 finished with value: 2.2527588180133273 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7907708417997632, 'learning_rate': 0.0034093552964550855, 'weight_decay': 0.00027397022947249397, 'batch_size': 256, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:01:53,319 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7801400620522355, 'learning_rate': 0.0028838782891005385, 'weight_decay': 0.0002515936028867198, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:01:53,319 - INFO - Trial 661: Train MSE=2.01039981842041, Train R²=0.6646548722471509
2024-10-31 19:01:53,320 - INFO - Trial 661: Test MSE=2.2900387900216237, Test R²=0.6271377376147679
2024-10-31 19:01:53,320 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:01:53,321 - INFO - Trial 661 finished with value: 2.2900387900216237 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7801400620522355, 'learning_rate': 0.0028838782891005385, 'weight_decay': 0.0002515936028867198, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:02:27,141 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7529834832824477, 'learning_rate': 0.002451759248889578, 'weight_decay': 0.00023309474989083407, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:02:27,141 - INFO - Trial 662: Train MSE=1.761796589408602, Train R²=0.7057895851986749
2024-10-31 19:02:27,142 - INFO - Trial 662: Test MSE=2.2943196637289867, Test R²=0.6265853473118373
2024-10-31 19:02:27,142 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:02:27,143 - INFO - Trial 662 finished with value: 2.2943196637289867 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7529834832824477, 'learning_rate': 0.002451759248889578, 'weight_decay': 0.00023309474989083407, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:02:58,983 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.791359507564157, 'learning_rate': 0.0032616473885887353, 'weight_decay': 0.00020975725042951274, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:02:58,983 - INFO - Trial 663: Train MSE=2.0177939108439853, Train R²=0.6641517600842884
2024-10-31 19:02:58,984 - INFO - Trial 663: Test MSE=2.26126035622188, Test R²=0.631880351475307
2024-10-31 19:02:58,984 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:02:58,985 - INFO - Trial 663 finished with value: 2.26126035622188 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.791359507564157, 'learning_rate': 0.0032616473885887353, 'weight_decay': 0.00020975725042951274, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:03:31,199 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998109757473852, 'learning_rate': 0.0012366326963822176, 'weight_decay': 0.00026113958693086575, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:03:31,199 - INFO - Trial 664: Train MSE=2.375282449381692, Train R²=0.604234686919621
2024-10-31 19:03:31,199 - INFO - Trial 664: Test MSE=2.224401201520647, Test R²=0.6381385581833976
2024-10-31 19:03:31,199 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:03:31,201 - INFO - Trial 664 finished with value: 2.224401201520647 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998109757473852, 'learning_rate': 0.0012366326963822176, 'weight_decay': 0.00026113958693086575, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:04:03,830 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7835255677979633, 'learning_rate': 0.002606288357251585, 'weight_decay': 0.00027158542941505367, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:04:03,830 - INFO - Trial 665: Train MSE=2.014711639710835, Train R²=0.6650129365069526
2024-10-31 19:04:03,830 - INFO - Trial 665: Test MSE=2.238526667867388, Test R²=0.6355844736099243
2024-10-31 19:04:03,830 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:04:03,832 - INFO - Trial 665 finished with value: 2.238526667867388 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7835255677979633, 'learning_rate': 0.002606288357251585, 'weight_decay': 0.00027158542941505367, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:04:36,726 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7688631558253278, 'learning_rate': 0.0023821068963910965, 'weight_decay': 0.00024322893390982665, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:04:36,727 - INFO - Trial 666: Train MSE=1.9319231978484563, Train R²=0.679181409733636
2024-10-31 19:04:36,727 - INFO - Trial 666: Test MSE=2.2764591489519392, Test R²=0.6294509427888053
2024-10-31 19:04:36,727 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:04:36,728 - INFO - Trial 666 finished with value: 2.2764591489519392 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7688631558253278, 'learning_rate': 0.0023821068963910965, 'weight_decay': 0.00024322893390982665, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:05:52,543 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7997075794177004, 'learning_rate': 0.0024236720469576543, 'weight_decay': 0.00022187032030256552, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 19:05:52,543 - INFO - Trial 667: Train MSE=1.9502843884485108, Train R²=0.6718888570155416
2024-10-31 19:05:52,543 - INFO - Trial 667: Test MSE=2.2254483018602644, Test R²=0.6310949964182717
2024-10-31 19:05:52,543 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:05:52,544 - INFO - Trial 667 finished with value: 2.2254483018602644 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7997075794177004, 'learning_rate': 0.0024236720469576543, 'weight_decay': 0.00022187032030256552, 'batch_size': 128, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:06:24,303 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5916339586616799, 'learning_rate': 0.0032009032464214715, 'weight_decay': 0.0002650344382792034, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:06:24,303 - INFO - Trial 668: Train MSE=1.0857431782143456, Train R²=0.8191136206899371
2024-10-31 19:06:24,303 - INFO - Trial 668: Test MSE=2.364147220339094, Test R²=0.6151640840939113
2024-10-31 19:06:24,303 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:06:24,305 - INFO - Trial 668 finished with value: 2.364147220339094 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5916339586616799, 'learning_rate': 0.0032009032464214715, 'weight_decay': 0.0002650344382792034, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:06:56,126 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.78221099683701, 'learning_rate': 0.0027886684734420553, 'weight_decay': 0.00028008712731678634, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:06:56,126 - INFO - Trial 669: Train MSE=2.4286024400166104, Train R²=0.5959653024162564
2024-10-31 19:06:56,127 - INFO - Trial 669: Test MSE=2.2653931038720265, Test R²=0.6313655206135341
2024-10-31 19:06:56,127 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:06:56,128 - INFO - Trial 669 finished with value: 2.2653931038720265 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.78221099683701, 'learning_rate': 0.0027886684734420553, 'weight_decay': 0.00028008712731678634, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:07:28,408 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7731887495662219, 'learning_rate': 0.002907429840620128, 'weight_decay': 0.0002461925626147621, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:07:28,408 - INFO - Trial 670: Train MSE=1.6919531311307634, Train R²=0.7180681611810412
2024-10-31 19:07:28,409 - INFO - Trial 670: Test MSE=2.277060100010463, Test R²=0.629332891532353
2024-10-31 19:07:28,409 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:07:28,409 - INFO - Trial 670 finished with value: 2.277060100010463 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7731887495662219, 'learning_rate': 0.002907429840620128, 'weight_decay': 0.0002461925626147621, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:08:01,074 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.791082178972868, 'learning_rate': 0.0014502613852059654, 'weight_decay': 0.00025958555920392866, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:08:01,074 - INFO - Trial 671: Train MSE=2.2402224370411465, Train R²=0.6271997626338687
2024-10-31 19:08:01,074 - INFO - Trial 671: Test MSE=2.250044448035104, Test R²=0.633778418813433
2024-10-31 19:08:01,074 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:08:01,076 - INFO - Trial 671 finished with value: 2.250044448035104 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.791082178972868, 'learning_rate': 0.0014502613852059654, 'weight_decay': 0.00025958555920392866, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:08:32,264 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7604901237824445, 'learning_rate': 0.0013109954473871466, 'weight_decay': 0.00027376497315449955, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 19:08:32,264 - INFO - Trial 672: Train MSE=2.076398206608636, Train R²=0.6537793555430004
2024-10-31 19:08:32,264 - INFO - Trial 672: Test MSE=2.2858582735061646, Test R²=0.6279638750212533
2024-10-31 19:08:32,264 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:08:32,266 - INFO - Trial 672 finished with value: 2.2858582735061646 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7604901237824445, 'learning_rate': 0.0013109954473871466, 'weight_decay': 0.00027376497315449955, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:09:03,943 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7834530412569009, 'learning_rate': 0.0022697944265010765, 'weight_decay': 0.00028922725419524827, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:09:03,943 - INFO - Trial 673: Train MSE=2.0666369199752808, Train R²=0.6563577950000763
2024-10-31 19:09:03,943 - INFO - Trial 673: Test MSE=2.2389428274972096, Test R²=0.6354547994477409
2024-10-31 19:09:03,943 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:09:03,944 - INFO - Trial 673 finished with value: 2.2389428274972096 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7834530412569009, 'learning_rate': 0.0022697944265010765, 'weight_decay': 0.00028922725419524827, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:09:35,540 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7733492102453402, 'learning_rate': 0.004654243887243277, 'weight_decay': 0.000232288454540227, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:09:35,540 - INFO - Trial 674: Train MSE=1.8875193681035722, Train R²=0.6858198919466564
2024-10-31 19:09:35,540 - INFO - Trial 674: Test MSE=2.2402644838605608, Test R²=0.635143348148891
2024-10-31 19:09:35,540 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:09:35,542 - INFO - Trial 674 finished with value: 2.2402644838605608 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7733492102453402, 'learning_rate': 0.004654243887243277, 'weight_decay': 0.000232288454540227, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:10:07,774 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7895650263922953, 'learning_rate': 0.0011719823197796756, 'weight_decay': 0.00026949664473228577, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:10:07,774 - INFO - Trial 675: Train MSE=2.3283914072172984, Train R²=0.6114167613642556
2024-10-31 19:10:07,774 - INFO - Trial 675: Test MSE=2.2218272345406667, Test R²=0.6383852022034782
2024-10-31 19:10:07,774 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:10:07,776 - INFO - Trial 675 finished with value: 2.2218272345406667 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7895650263922953, 'learning_rate': 0.0011719823197796756, 'weight_decay': 0.00026949664473228577, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:10:39,515 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7301319888867857, 'learning_rate': 0.0011258641693359477, 'weight_decay': 0.0002513574607831516, 'batch_size': 512, 'tree_depth': 6}
2024-10-31 19:10:39,516 - INFO - Trial 676: Train MSE=2.990658734525953, Train R²=0.502509953720229
2024-10-31 19:10:39,516 - INFO - Trial 676: Test MSE=2.4398460728781566, Test R²=0.6028435059956142
2024-10-31 19:10:39,516 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:10:39,517 - INFO - Trial 676 finished with value: 2.4398460728781566 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7301319888867857, 'learning_rate': 0.0011258641693359477, 'weight_decay': 0.0002513574607831516, 'batch_size': 512, 'tree_depth': 6}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:11:11,564 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7994522110430425, 'learning_rate': 0.006067674527505996, 'weight_decay': 0.0002885872319504593, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:11:11,564 - INFO - Trial 677: Train MSE=2.1036496460437775, Train R²=0.6502141973802021
2024-10-31 19:11:11,564 - INFO - Trial 677: Test MSE=2.2456520284925188, Test R²=0.6345344356128148
2024-10-31 19:11:11,564 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:11:11,566 - INFO - Trial 677 finished with value: 2.2456520284925188 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7994522110430425, 'learning_rate': 0.006067674527505996, 'weight_decay': 0.0002885872319504593, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:11:43,117 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7796218784337878, 'learning_rate': 0.0038523246458330943, 'weight_decay': 0.00031595181867486545, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:11:43,117 - INFO - Trial 678: Train MSE=1.972419125693185, Train R²=0.6710185664040702
2024-10-31 19:11:43,117 - INFO - Trial 678: Test MSE=2.244092736925398, Test R²=0.6347062161990574
2024-10-31 19:11:43,118 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:11:43,119 - INFO - Trial 678 finished with value: 2.244092736925398 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7796218784337878, 'learning_rate': 0.0038523246458330943, 'weight_decay': 0.00031595181867486545, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:12:14,402 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7658084995458119, 'learning_rate': 0.0015126138634175093, 'weight_decay': 0.0002378470611606739, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:12:14,402 - INFO - Trial 679: Train MSE=1.9293472979749953, Train R²=0.6786935584885734
2024-10-31 19:12:14,402 - INFO - Trial 679: Test MSE=2.2661080360412598, Test R²=0.6312054480825152
2024-10-31 19:12:14,402 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:12:14,404 - INFO - Trial 679 finished with value: 2.2661080360412598 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7658084995458119, 'learning_rate': 0.0015126138634175093, 'weight_decay': 0.0002378470611606739, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:12:46,400 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7920097850236145, 'learning_rate': 0.002222925802280843, 'weight_decay': 0.0003008575326915694, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:12:46,401 - INFO - Trial 680: Train MSE=2.0886354403836385, Train R²=0.652752697467804
2024-10-31 19:12:46,401 - INFO - Trial 680: Test MSE=2.253768035343715, Test R²=0.6331236107008797
2024-10-31 19:12:46,401 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:12:46,402 - INFO - Trial 680 finished with value: 2.253768035343715 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7920097850236145, 'learning_rate': 0.002222925802280843, 'weight_decay': 0.0003008575326915694, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:13:17,089 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5442275073491325, 'learning_rate': 0.0012780236597104608, 'weight_decay': 0.0002791991075918326, 'batch_size': 512, 'tree_depth': 8}
2024-10-31 19:13:17,089 - INFO - Trial 681: Train MSE=1.4113365709781647, Train R²=0.7643542864492961
2024-10-31 19:13:17,089 - INFO - Trial 681: Test MSE=2.4636612960270474, Test R²=0.5990070360047477
2024-10-31 19:13:17,089 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:13:17,090 - INFO - Trial 681 finished with value: 2.4636612960270474 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5442275073491325, 'learning_rate': 0.0012780236597104608, 'weight_decay': 0.0002791991075918326, 'batch_size': 512, 'tree_depth': 8}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:13:47,171 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7997097293179076, 'learning_rate': 0.0008451384775796486, 'weight_decay': 0.0002159249140800115, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 19:13:47,172 - INFO - Trial 682: Train MSE=2.7267308064869473, Train R²=0.5471871324947902
2024-10-31 19:13:47,172 - INFO - Trial 682: Test MSE=2.403102695941925, Test R²=0.6062916666269302
2024-10-31 19:13:47,172 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:13:47,173 - INFO - Trial 682 finished with value: 2.403102695941925 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7997097293179076, 'learning_rate': 0.0008451384775796486, 'weight_decay': 0.0002159249140800115, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:14:19,819 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7823220704446734, 'learning_rate': 0.0010498569526876168, 'weight_decay': 0.0007088599682019253, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:14:19,819 - INFO - Trial 683: Train MSE=2.345960336072104, Train R²=0.6099253680024829
2024-10-31 19:14:19,820 - INFO - Trial 683: Test MSE=2.257605927331107, Test R²=0.6323582104274205
2024-10-31 19:14:19,820 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:14:19,821 - INFO - Trial 683 finished with value: 2.257605927331107 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7823220704446734, 'learning_rate': 0.0010498569526876168, 'weight_decay': 0.0007088599682019253, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:15:05,923 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7466497424575855, 'learning_rate': 0.001401455723073265, 'weight_decay': 0.00033473695796423146, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 19:15:05,923 - INFO - Trial 684: Train MSE=1.704371037227767, Train R²=0.7151580325194767
2024-10-31 19:15:05,923 - INFO - Trial 684: Test MSE=2.2904373662812367, Test R²=0.6255353518894741
2024-10-31 19:15:05,923 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:15:05,924 - INFO - Trial 684 finished with value: 2.2904373662812367 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7466497424575855, 'learning_rate': 0.001401455723073265, 'weight_decay': 0.00033473695796423146, 'batch_size': 256, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:15:37,342 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.799988790042062, 'learning_rate': 0.0009031984156121595, 'weight_decay': 0.0002594772674928253, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:15:37,342 - INFO - Trial 685: Train MSE=2.58789039509637, Train R²=0.5693161849464689
2024-10-31 19:15:37,342 - INFO - Trial 685: Test MSE=2.250669479370117, Test R²=0.6337290150778634
2024-10-31 19:15:37,342 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:15:37,344 - INFO - Trial 685 finished with value: 2.250669479370117 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.799988790042062, 'learning_rate': 0.0009031984156121595, 'weight_decay': 0.0002594772674928253, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:16:09,076 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7761492925731114, 'learning_rate': 0.0026469812677520172, 'weight_decay': 0.0003179157380903244, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:16:09,076 - INFO - Trial 686: Train MSE=1.9470712670258112, Train R²=0.6762418895959854
2024-10-31 19:16:09,076 - INFO - Trial 686: Test MSE=2.2743512221745084, Test R²=0.6297486424446106
2024-10-31 19:16:09,076 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:16:09,077 - INFO - Trial 686 finished with value: 2.2743512221745084 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7761492925731114, 'learning_rate': 0.0026469812677520172, 'weight_decay': 0.0003179157380903244, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:16:41,058 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7886377540778932, 'learning_rate': 0.001213404507575518, 'weight_decay': 0.0007819418379118813, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:16:41,058 - INFO - Trial 687: Train MSE=2.326186554772513, Train R²=0.6134994817631585
2024-10-31 19:16:41,059 - INFO - Trial 687: Test MSE=2.227030328341893, Test R²=0.6375402467591422
2024-10-31 19:16:41,059 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:16:41,060 - INFO - Trial 687 finished with value: 2.227030328341893 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7886377540778932, 'learning_rate': 0.001213404507575518, 'weight_decay': 0.0007819418379118813, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:17:12,870 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7695617999356316, 'learning_rate': 0.0011104627836874459, 'weight_decay': 0.0006408282484739249, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:17:12,870 - INFO - Trial 688: Train MSE=2.208448269537517, Train R²=0.6324631337608609
2024-10-31 19:17:12,870 - INFO - Trial 688: Test MSE=2.219627857208252, Test R²=0.6387387428964887
2024-10-31 19:17:12,870 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:17:12,872 - INFO - Trial 688 finished with value: 2.219627857208252 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7695617999356316, 'learning_rate': 0.0011104627836874459, 'weight_decay': 0.0006408282484739249, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:17:47,337 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7849722772642056, 'learning_rate': 0.0009983722411849869, 'weight_decay': 0.00028994503596674234, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:17:47,337 - INFO - Trial 689: Train MSE=2.8507236327443803, Train R²=0.5260420484202248
2024-10-31 19:17:47,338 - INFO - Trial 689: Test MSE=2.294818810054234, Test R²=0.6267018062727792
2024-10-31 19:17:47,338 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:17:47,339 - INFO - Trial 689 finished with value: 2.294818810054234 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7849722772642056, 'learning_rate': 0.0009983722411849869, 'weight_decay': 0.00028994503596674234, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:18:18,743 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7571899385988363, 'learning_rate': 0.001274422848024766, 'weight_decay': 0.00027266948104299495, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:18:18,743 - INFO - Trial 690: Train MSE=1.9604765347072057, Train R²=0.6745564000947135
2024-10-31 19:18:18,743 - INFO - Trial 690: Test MSE=2.246843303952898, Test R²=0.6341327854565212
2024-10-31 19:18:18,743 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:18:18,745 - INFO - Trial 690 finished with value: 2.246843303952898 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7571899385988363, 'learning_rate': 0.001274422848024766, 'weight_decay': 0.00027266948104299495, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:19:35,093 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7894759914899341, 'learning_rate': 0.0015624060328426105, 'weight_decay': 0.00035369310349245075, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 19:19:35,093 - INFO - Trial 691: Train MSE=1.8325719577925546, Train R²=0.6923117456691605
2024-10-31 19:19:35,094 - INFO - Trial 691: Test MSE=2.238205168928419, Test R²=0.6296004078217915
2024-10-31 19:19:35,094 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:19:35,094 - INFO - Trial 691 finished with value: 2.238205168928419 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7894759914899341, 'learning_rate': 0.0015624060328426105, 'weight_decay': 0.00035369310349245075, 'batch_size': 128, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:20:06,870 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7777574307481462, 'learning_rate': 0.0008017361575710754, 'weight_decay': 0.0007412125812192406, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:20:06,871 - INFO - Trial 692: Train MSE=2.471236961228507, Train R²=0.5885355706725802
2024-10-31 19:20:06,871 - INFO - Trial 692: Test MSE=2.255598647253854, Test R²=0.6329015323093959
2024-10-31 19:20:06,871 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:20:06,873 - INFO - Trial 692 finished with value: 2.255598647253854 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7777574307481462, 'learning_rate': 0.0008017361575710754, 'weight_decay': 0.0007412125812192406, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:20:39,016 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7860311447342193, 'learning_rate': 0.0011644988955073652, 'weight_decay': 0.00030195880569442097, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:20:39,016 - INFO - Trial 693: Train MSE=2.33259163584028, Train R²=0.6117316165140697
2024-10-31 19:20:39,016 - INFO - Trial 693: Test MSE=2.226055928639003, Test R²=0.6376215219497681
2024-10-31 19:20:39,016 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:20:39,018 - INFO - Trial 693 finished with value: 2.226055928639003 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7860311447342193, 'learning_rate': 0.0011644988955073652, 'weight_decay': 0.00030195880569442097, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:21:10,771 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7656771776368001, 'learning_rate': 0.000711493735947369, 'weight_decay': 0.0002496961530348896, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:21:10,771 - INFO - Trial 694: Train MSE=3.0015539612088884, Train R²=0.4988159941775458
2024-10-31 19:21:10,771 - INFO - Trial 694: Test MSE=2.2509466920580183, Test R²=0.6335984127862113
2024-10-31 19:21:10,771 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:21:10,773 - INFO - Trial 694 finished with value: 2.2509466920580183 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7656771776368001, 'learning_rate': 0.000711493735947369, 'weight_decay': 0.0002496961530348896, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:21:41,773 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7920849793103676, 'learning_rate': 0.0013881628324569919, 'weight_decay': 0.00032416542716975206, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 19:21:41,774 - INFO - Trial 695: Train MSE=2.356095233133861, Train R²=0.6080005126340049
2024-10-31 19:21:41,774 - INFO - Trial 695: Test MSE=2.239938293184553, Test R²=0.6354073796953473
2024-10-31 19:21:41,774 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:21:41,776 - INFO - Trial 695 finished with value: 2.239938293184553 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7920849793103676, 'learning_rate': 0.0013881628324569919, 'weight_decay': 0.00032416542716975206, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:22:14,248 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.77505909954964, 'learning_rate': 0.0009210287929261543, 'weight_decay': 0.00026413488484506686, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:22:14,248 - INFO - Trial 696: Train MSE=2.6001671637807573, Train R²=0.5671177910906928
2024-10-31 19:22:14,248 - INFO - Trial 696: Test MSE=2.2431309393474033, Test R²=0.6349138532366071
2024-10-31 19:22:14,248 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:22:14,249 - INFO - Trial 696 finished with value: 2.2431309393474033 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.77505909954964, 'learning_rate': 0.0009210287929261543, 'weight_decay': 0.00026413488484506686, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:22:45,952 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7909718541999661, 'learning_rate': 0.0010549259936739025, 'weight_decay': 0.000281500965753088, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:22:45,952 - INFO - Trial 697: Train MSE=2.4348068492753163, Train R²=0.5944788157939911
2024-10-31 19:22:45,952 - INFO - Trial 697: Test MSE=2.2297628947666714, Test R²=0.6370746919087001
2024-10-31 19:22:45,952 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:22:45,954 - INFO - Trial 697 finished with value: 2.2297628947666714 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7909718541999661, 'learning_rate': 0.0010549259936739025, 'weight_decay': 0.000281500965753088, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:23:17,455 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7780377492724968, 'learning_rate': 0.0012458992876413016, 'weight_decay': 0.00020177686323470632, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:23:17,456 - INFO - Trial 698: Train MSE=2.190309537308557, Train R²=0.6348954971347537
2024-10-31 19:23:17,456 - INFO - Trial 698: Test MSE=2.2405104637145996, Test R²=0.6352911506380353
2024-10-31 19:23:17,456 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:23:17,457 - INFO - Trial 698 finished with value: 2.2405104637145996 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7780377492724968, 'learning_rate': 0.0012458992876413016, 'weight_decay': 0.00020177686323470632, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:23:49,407 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6828037694450264, 'learning_rate': 0.0010088221880804808, 'weight_decay': 0.00031110052672979566, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:23:49,407 - INFO - Trial 699: Train MSE=1.6222566834517889, Train R²=0.7291812513555799
2024-10-31 19:23:49,408 - INFO - Trial 699: Test MSE=2.333339214324951, Test R²=0.6200729267937797
2024-10-31 19:23:49,408 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:23:49,409 - INFO - Trial 699 finished with value: 2.333339214324951 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6828037694450264, 'learning_rate': 0.0010088221880804808, 'weight_decay': 0.00031110052672979566, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:24:21,470 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998091236056886, 'learning_rate': 0.0011492728717985745, 'weight_decay': 0.000335911544815158, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:24:21,470 - INFO - Trial 700: Train MSE=2.4229772048337117, Train R²=0.5964216377053942
2024-10-31 19:24:21,470 - INFO - Trial 700: Test MSE=2.215037294796535, Test R²=0.6394209946904864
2024-10-31 19:24:21,470 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:24:21,472 - INFO - Trial 700 finished with value: 2.215037294796535 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998091236056886, 'learning_rate': 0.0011492728717985745, 'weight_decay': 0.000335911544815158, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:24:52,174 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7644362260556499, 'learning_rate': 0.0041459434758316285, 'weight_decay': 0.00022930175358278028, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:24:52,175 - INFO - Trial 701: Train MSE=1.8808500639029913, Train R²=0.6871887935059411
2024-10-31 19:24:52,175 - INFO - Trial 701: Test MSE=2.2302039010184154, Test R²=0.6369067941393171
2024-10-31 19:24:52,175 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:24:52,175 - INFO - Trial 701 finished with value: 2.2302039010184154 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7644362260556499, 'learning_rate': 0.0041459434758316285, 'weight_decay': 0.00022930175358278028, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:25:23,593 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7849376118333776, 'learning_rate': 0.0021195074424125247, 'weight_decay': 0.00029739074625210554, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:25:23,593 - INFO - Trial 702: Train MSE=2.0880882143974304, Train R²=0.6522785318749291
2024-10-31 19:25:23,593 - INFO - Trial 702: Test MSE=2.237816180501665, Test R²=0.6356544239180428
2024-10-31 19:25:23,593 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:25:23,595 - INFO - Trial 702 finished with value: 2.237816180501665 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7849376118333776, 'learning_rate': 0.0021195074424125247, 'weight_decay': 0.00029739074625210554, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:25:54,411 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7901718913832019, 'learning_rate': 0.0008955193252869176, 'weight_decay': 0.0002466268128977477, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:25:54,411 - INFO - Trial 703: Train MSE=2.4265696236065457, Train R²=0.5956816928727287
2024-10-31 19:25:54,411 - INFO - Trial 703: Test MSE=2.233187368937901, Test R²=0.6365622707775661
2024-10-31 19:25:54,412 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:25:54,413 - INFO - Trial 703 finished with value: 2.233187368937901 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7901718913832019, 'learning_rate': 0.0008955193252869176, 'weight_decay': 0.0002466268128977477, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:26:20,828 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.772579442065333, 'learning_rate': 0.0013696112256980297, 'weight_decay': 0.0002746176983803467, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 19:26:20,828 - INFO - Trial 704: Train MSE=2.481619324002947, Train R²=0.5882377454212734
2024-10-31 19:26:20,828 - INFO - Trial 704: Test MSE=2.253878951072693, Test R²=0.630604088306427
2024-10-31 19:26:20,828 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:26:20,829 - INFO - Trial 704 finished with value: 2.253878951072693 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.772579442065333, 'learning_rate': 0.0013696112256980297, 'weight_decay': 0.0002746176983803467, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:26:53,371 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6945318477546103, 'learning_rate': 0.0010769388926425182, 'weight_decay': 0.00028716855284017216, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:26:53,371 - INFO - Trial 705: Train MSE=1.6379935613700323, Train R²=0.7277117903743472
2024-10-31 19:26:53,371 - INFO - Trial 705: Test MSE=2.2969509533473422, Test R²=0.6259892582893372
2024-10-31 19:26:53,372 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:26:53,373 - INFO - Trial 705 finished with value: 2.2969509533473422 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6945318477546103, 'learning_rate': 0.0010769388926425182, 'weight_decay': 0.00028716855284017216, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:27:27,872 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.782860338720179, 'learning_rate': 0.0008124259774773403, 'weight_decay': 0.0002576680751293896, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:27:27,872 - INFO - Trial 706: Train MSE=2.103722563811711, Train R²=0.6500156628234046
2024-10-31 19:27:27,872 - INFO - Trial 706: Test MSE=2.323707342147827, Test R²=0.6218780108860561
2024-10-31 19:27:27,872 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:27:27,873 - INFO - Trial 706 finished with value: 2.323707342147827 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.782860338720179, 'learning_rate': 0.0008124259774773403, 'weight_decay': 0.0002576680751293896, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:28:00,082 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7548782057825767, 'learning_rate': 0.003004517469462824, 'weight_decay': 0.0003427422493830737, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:28:00,082 - INFO - Trial 707: Train MSE=1.8057114354201727, Train R²=0.6999078456844602
2024-10-31 19:28:00,083 - INFO - Trial 707: Test MSE=2.2616796493530273, Test R²=0.6316833240645272
2024-10-31 19:28:00,083 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:28:00,084 - INFO - Trial 707 finished with value: 2.2616796493530273 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7548782057825767, 'learning_rate': 0.003004517469462824, 'weight_decay': 0.0003427422493830737, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:28:46,958 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7918991486357073, 'learning_rate': 0.003535665318307694, 'weight_decay': 0.0003174911552078095, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 19:28:46,958 - INFO - Trial 708: Train MSE=1.9089620219809669, Train R²=0.6800648463623864
2024-10-31 19:28:46,958 - INFO - Trial 708: Test MSE=2.2361786535808017, Test R²=0.6337158552237919
2024-10-31 19:28:46,958 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:28:46,959 - INFO - Trial 708 finished with value: 2.2361786535808017 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7918991486357073, 'learning_rate': 0.003535665318307694, 'weight_decay': 0.0003174911552078095, 'batch_size': 256, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:29:18,651 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.780624193652275, 'learning_rate': 0.0009516772865057193, 'weight_decay': 0.00029678449300479847, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:29:18,651 - INFO - Trial 709: Train MSE=2.3967391507966176, Train R²=0.6006083978073937
2024-10-31 19:29:18,651 - INFO - Trial 709: Test MSE=2.238612106868199, Test R²=0.6356758305004665
2024-10-31 19:29:18,651 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:29:18,652 - INFO - Trial 709 finished with value: 2.238612106868199 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.780624193652275, 'learning_rate': 0.0009516772865057193, 'weight_decay': 0.00029678449300479847, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:29:50,351 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.799722905036425, 'learning_rate': 0.0015530122741771236, 'weight_decay': 0.0003066341448940099, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:29:50,352 - INFO - Trial 710: Train MSE=2.312935995204108, Train R²=0.6151756133352008
2024-10-31 19:29:50,352 - INFO - Trial 710: Test MSE=2.243167076792036, Test R²=0.6350047758647374
2024-10-31 19:29:50,352 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:29:50,353 - INFO - Trial 710 finished with value: 2.243167076792036 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.799722905036425, 'learning_rate': 0.0015530122741771236, 'weight_decay': 0.0003066341448940099, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:30:23,730 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7711319915556331, 'learning_rate': 0.0012447844437269632, 'weight_decay': 0.00024322118331776183, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:30:23,730 - INFO - Trial 711: Train MSE=2.106417898620878, Train R²=0.6496554676975522
2024-10-31 19:30:23,731 - INFO - Trial 711: Test MSE=2.2097319194248746, Test R²=0.6402124762535095
2024-10-31 19:30:23,731 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:30:23,732 - INFO - Trial 711 finished with value: 2.2097319194248746 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7711319915556331, 'learning_rate': 0.0012447844437269632, 'weight_decay': 0.00024322118331776183, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:30:59,659 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7648218219638137, 'learning_rate': 0.0011748962926616902, 'weight_decay': 0.0002217403498107211, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 19:30:59,659 - INFO - Trial 712: Train MSE=2.892700186797551, Train R²=0.5193164199590683
2024-10-31 19:30:59,659 - INFO - Trial 712: Test MSE=2.3533835411071777, Test R²=0.6170765246663775
2024-10-31 19:30:59,659 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:30:59,661 - INFO - Trial 712 finished with value: 2.3533835411071777 and parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7648218219638137, 'learning_rate': 0.0011748962926616902, 'weight_decay': 0.0002217403498107211, 'batch_size': 512, 'tree_depth': 9}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:31:31,272 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7711598989245286, 'learning_rate': 0.0010407978623947483, 'weight_decay': 0.00022380982136999778, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:31:31,272 - INFO - Trial 713: Train MSE=2.2896948882511685, Train R²=0.6194075409855161
2024-10-31 19:31:31,273 - INFO - Trial 713: Test MSE=2.230070539883205, Test R²=0.6369686467306954
2024-10-31 19:31:31,273 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:31:31,274 - INFO - Trial 713 finished with value: 2.230070539883205 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7711598989245286, 'learning_rate': 0.0010407978623947483, 'weight_decay': 0.00022380982136999778, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:32:02,403 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7454802848902107, 'learning_rate': 0.0012838642570145355, 'weight_decay': 0.00023799879918849742, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:32:02,403 - INFO - Trial 714: Train MSE=1.9436318363462175, Train R²=0.6769385486841202
2024-10-31 19:32:02,403 - INFO - Trial 714: Test MSE=2.2257435832704817, Test R²=0.6376886027199882
2024-10-31 19:32:02,403 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:32:02,405 - INFO - Trial 714 finished with value: 2.2257435832704817 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7454802848902107, 'learning_rate': 0.0012838642570145355, 'weight_decay': 0.00023799879918849742, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:32:33,856 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7920614074450874, 'learning_rate': 0.001127983733192217, 'weight_decay': 0.0002461734844850576, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 19:32:33,856 - INFO - Trial 715: Train MSE=2.5150988016809737, Train R²=0.5807691812515259
2024-10-31 19:32:33,856 - INFO - Trial 715: Test MSE=2.2375741686139787, Test R²=0.6359199455806187
2024-10-31 19:32:33,856 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:32:33,858 - INFO - Trial 715 finished with value: 2.2375741686139787 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7920614074450874, 'learning_rate': 0.001127983733192217, 'weight_decay': 0.0002461734844850576, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:33:05,541 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.780303372497014, 'learning_rate': 0.0012369217131887819, 'weight_decay': 0.00025342486605345067, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:33:05,541 - INFO - Trial 716: Train MSE=2.2026125405515944, Train R²=0.6339892042534692
2024-10-31 19:33:05,542 - INFO - Trial 716: Test MSE=2.2227874313082014, Test R²=0.6381079128810337
2024-10-31 19:33:05,542 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:33:05,543 - INFO - Trial 716 finished with value: 2.2227874313082014 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.780303372497014, 'learning_rate': 0.0012369217131887819, 'weight_decay': 0.00025342486605345067, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:33:37,818 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.758999794412499, 'learning_rate': 0.001052651122471866, 'weight_decay': 0.0002367567090264196, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:33:37,818 - INFO - Trial 717: Train MSE=1.8905108869075775, Train R²=0.6854940567697797
2024-10-31 19:33:37,818 - INFO - Trial 717: Test MSE=2.2430340221949985, Test R²=0.6348410078457424
2024-10-31 19:33:37,818 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:33:37,819 - INFO - Trial 717 finished with value: 2.2430340221949985 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.758999794412499, 'learning_rate': 0.001052651122471866, 'weight_decay': 0.0002367567090264196, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:34:19,654 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7910643243973732, 'learning_rate': 0.0009809447401997469, 'weight_decay': 0.00023206363849352378, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:34:19,654 - INFO - Trial 718: Train MSE=3.0151128939219882, Train R²=0.4965393862554005
2024-10-31 19:34:19,654 - INFO - Trial 718: Test MSE=2.264760596411569, Test R²=0.6313665764672416
2024-10-31 19:34:19,655 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:34:19,656 - INFO - Trial 718 finished with value: 2.264760596411569 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7910643243973732, 'learning_rate': 0.0009809447401997469, 'weight_decay': 0.00023206363849352378, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:34:51,332 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7741168329602375, 'learning_rate': 0.0026182488704835334, 'weight_decay': 0.0002132616223264793, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:34:51,332 - INFO - Trial 719: Train MSE=1.9607634501797813, Train R²=0.6731056123971939
2024-10-31 19:34:51,333 - INFO - Trial 719: Test MSE=2.2555633783340454, Test R²=0.6327930092811584
2024-10-31 19:34:51,333 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:34:51,334 - INFO - Trial 719 finished with value: 2.2555633783340454 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7741168329602375, 'learning_rate': 0.0026182488704835334, 'weight_decay': 0.0002132616223264793, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:36:04,774 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7848785772229446, 'learning_rate': 0.0011971462466291787, 'weight_decay': 0.00023962593244174983, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 19:36:04,774 - INFO - Trial 720: Train MSE=1.806597916143281, Train R²=0.6945802377802985
2024-10-31 19:36:04,774 - INFO - Trial 720: Test MSE=2.2542448937892914, Test R²=0.6255302833659309
2024-10-31 19:36:04,774 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:36:04,775 - INFO - Trial 720 finished with value: 2.2542448937892914 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7848785772229446, 'learning_rate': 0.0011971462466291787, 'weight_decay': 0.00023962593244174983, 'batch_size': 128, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:36:35,665 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995299105633112, 'learning_rate': 0.000868607294216955, 'weight_decay': 0.00026127274241434685, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:36:35,665 - INFO - Trial 721: Train MSE=2.7024832538196017, Train R²=0.5500440469809941
2024-10-31 19:36:35,665 - INFO - Trial 721: Test MSE=2.2732904297964915, Test R²=0.6299543295587812
2024-10-31 19:36:35,665 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:36:35,667 - INFO - Trial 721 finished with value: 2.2732904297964915 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995299105633112, 'learning_rate': 0.000868607294216955, 'weight_decay': 0.00026127274241434685, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:37:07,879 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6281154396773898, 'learning_rate': 0.0011141562494261397, 'weight_decay': 0.00025373108012807387, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:37:07,879 - INFO - Trial 722: Train MSE=1.3178507047040122, Train R²=0.7810213203941073
2024-10-31 19:37:07,879 - INFO - Trial 722: Test MSE=2.34673844064985, Test R²=0.6178524323872158
2024-10-31 19:37:07,879 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:37:07,881 - INFO - Trial 722 finished with value: 2.34673844064985 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6281154396773898, 'learning_rate': 0.0011141562494261397, 'weight_decay': 0.00025373108012807387, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:37:41,447 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998065395297848, 'learning_rate': 0.0013055020642771685, 'weight_decay': 0.00024486442449616377, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:37:41,448 - INFO - Trial 723: Train MSE=2.431442712034498, Train R²=0.5949405005999974
2024-10-31 19:37:41,448 - INFO - Trial 723: Test MSE=2.2328611442020962, Test R²=0.6364837118557521
2024-10-31 19:37:41,448 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:37:41,449 - INFO - Trial 723 finished with value: 2.2328611442020962 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998065395297848, 'learning_rate': 0.0013055020642771685, 'weight_decay': 0.00024486442449616377, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:38:13,862 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7673485547808195, 'learning_rate': 0.000959081532822993, 'weight_decay': 0.0002675162727099548, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:38:13,862 - INFO - Trial 724: Train MSE=2.256578964846475, Train R²=0.6236960291862488
2024-10-31 19:38:13,862 - INFO - Trial 724: Test MSE=2.2160320622580394, Test R²=0.6392137152808053
2024-10-31 19:38:13,862 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:38:13,865 - INFO - Trial 724 finished with value: 2.2160320622580394 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7673485547808195, 'learning_rate': 0.000959081532822993, 'weight_decay': 0.0002675162727099548, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:38:45,761 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7832297670086988, 'learning_rate': 0.0011307205980916964, 'weight_decay': 0.00023058862607007935, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:38:45,761 - INFO - Trial 725: Train MSE=2.217331745794841, Train R²=0.6310100236109325
2024-10-31 19:38:45,761 - INFO - Trial 725: Test MSE=2.2418717997414723, Test R²=0.635068586894444
2024-10-31 19:38:45,761 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:38:45,762 - INFO - Trial 725 finished with value: 2.2418717997414723 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7832297670086988, 'learning_rate': 0.0011307205980916964, 'weight_decay': 0.00023058862607007935, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:39:21,259 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7744359047516268, 'learning_rate': 0.005511921896496343, 'weight_decay': 0.00036490705215642385, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:39:21,259 - INFO - Trial 726: Train MSE=1.9367847655500685, Train R²=0.6781120087419238
2024-10-31 19:39:21,259 - INFO - Trial 726: Test MSE=2.2389412948063443, Test R²=0.6354712588446481
2024-10-31 19:39:21,259 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:39:21,261 - INFO - Trial 726 finished with value: 2.2389412948063443 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7744359047516268, 'learning_rate': 0.005511921896496343, 'weight_decay': 0.00036490705215642385, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:39:55,106 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7917339594971976, 'learning_rate': 0.0023443376018925, 'weight_decay': 0.0002626865755225368, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:39:55,106 - INFO - Trial 727: Train MSE=2.1027140574795857, Train R²=0.6500903580869947
2024-10-31 19:39:55,106 - INFO - Trial 727: Test MSE=2.216061455862863, Test R²=0.639417290687561
2024-10-31 19:39:55,106 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:39:55,108 - INFO - Trial 727 finished with value: 2.216061455862863 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7917339594971976, 'learning_rate': 0.0023443376018925, 'weight_decay': 0.0002626865755225368, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:40:26,486 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7829383828641294, 'learning_rate': 0.0013633882333414598, 'weight_decay': 0.00022176711126203506, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:40:26,486 - INFO - Trial 728: Train MSE=2.2178352815764293, Train R²=0.6303354437862124
2024-10-31 19:40:26,486 - INFO - Trial 728: Test MSE=2.2364812067576816, Test R²=0.6358984793935504
2024-10-31 19:40:26,486 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:40:26,488 - INFO - Trial 728 finished with value: 2.2364812067576816 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7829383828641294, 'learning_rate': 0.0013633882333414598, 'weight_decay': 0.00022176711126203506, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:40:53,824 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7880473281666873, 'learning_rate': 0.000730586207079003, 'weight_decay': 0.00024346033809438832, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 19:40:53,824 - INFO - Trial 729: Train MSE=3.4252916233880177, Train R²=0.43076713170324055
2024-10-31 19:40:53,824 - INFO - Trial 729: Test MSE=2.2634111642837524, Test R²=0.6291132867336273
2024-10-31 19:40:53,824 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:40:53,826 - INFO - Trial 729 finished with value: 2.2634111642837524 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7880473281666873, 'learning_rate': 0.000730586207079003, 'weight_decay': 0.00024346033809438832, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:41:28,196 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7999963379595354, 'learning_rate': 0.0010114888554271088, 'weight_decay': 0.00034764899016735456, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:41:28,196 - INFO - Trial 730: Train MSE=2.976811945438385, Train R²=0.5047390162944794
2024-10-31 19:41:28,196 - INFO - Trial 730: Test MSE=2.2667915480477467, Test R²=0.6311864342008319
2024-10-31 19:41:28,196 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:41:28,198 - INFO - Trial 730 finished with value: 2.2667915480477467 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7999963379595354, 'learning_rate': 0.0010114888554271088, 'weight_decay': 0.00034764899016735456, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:42:00,683 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7585670540517541, 'learning_rate': 0.0008756163852621919, 'weight_decay': 0.00027512196728333397, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 19:42:00,683 - INFO - Trial 731: Train MSE=2.657551739897047, Train R²=0.5579873919487
2024-10-31 19:42:00,683 - INFO - Trial 731: Test MSE=2.246374385697501, Test R²=0.6344570176942008
2024-10-31 19:42:00,684 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:42:00,685 - INFO - Trial 731 finished with value: 2.246374385697501 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7585670540517541, 'learning_rate': 0.0008756163852621919, 'weight_decay': 0.00027512196728333397, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:42:35,972 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7717761722064056, 'learning_rate': 0.0012318374310002324, 'weight_decay': 0.00033064778080926153, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:42:35,972 - INFO - Trial 732: Train MSE=1.758602419069835, Train R²=0.7075823077133724
2024-10-31 19:42:35,972 - INFO - Trial 732: Test MSE=2.265690411840166, Test R²=0.6312024593353271
2024-10-31 19:42:35,972 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:42:35,973 - INFO - Trial 732 finished with value: 2.265690411840166 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7717761722064056, 'learning_rate': 0.0012318374310002324, 'weight_decay': 0.00033064778080926153, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:43:21,402 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7905301745873322, 'learning_rate': 0.0011122840622236633, 'weight_decay': 0.0002595854195778666, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 19:43:21,402 - INFO - Trial 733: Train MSE=1.9985220283269882, Train R²=0.6663700821144241
2024-10-31 19:43:21,402 - INFO - Trial 733: Test MSE=2.2643079331942966, Test R²=0.6296248606273106
2024-10-31 19:43:21,402 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:43:21,403 - INFO - Trial 733 finished with value: 2.2643079331942966 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7905301745873322, 'learning_rate': 0.0011122840622236633, 'weight_decay': 0.0002595854195778666, 'batch_size': 256, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:43:56,445 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7796385068513207, 'learning_rate': 0.0009657662038301309, 'weight_decay': 0.00027350502701404677, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:43:56,446 - INFO - Trial 734: Train MSE=2.32411561693464, Train R²=0.6134248269455773
2024-10-31 19:43:56,446 - INFO - Trial 734: Test MSE=2.2325559854507446, Test R²=0.6368040783064706
2024-10-31 19:43:56,446 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:43:56,448 - INFO - Trial 734 finished with value: 2.2325559854507446 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7796385068513207, 'learning_rate': 0.0009657662038301309, 'weight_decay': 0.00027350502701404677, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:44:29,135 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5630923956554188, 'learning_rate': 0.001396900936766638, 'weight_decay': 0.00024875734578262763, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:44:29,135 - INFO - Trial 735: Train MSE=0.9949638949973243, Train R²=0.8341102791684014
2024-10-31 19:44:29,135 - INFO - Trial 735: Test MSE=2.406373977661133, Test R²=0.6083442057882037
2024-10-31 19:44:29,135 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:44:29,137 - INFO - Trial 735 finished with value: 2.406373977661133 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5630923956554188, 'learning_rate': 0.001396900936766638, 'weight_decay': 0.00024875734578262763, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:45:00,336 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7673710959726024, 'learning_rate': 0.0012322449605564102, 'weight_decay': 0.0003259823946989993, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:45:00,336 - INFO - Trial 736: Train MSE=2.072663737194879, Train R²=0.6543483350958142
2024-10-31 19:45:00,336 - INFO - Trial 736: Test MSE=2.2520552022116527, Test R²=0.6335318769727435
2024-10-31 19:45:00,336 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:45:00,337 - INFO - Trial 736 finished with value: 2.2520552022116527 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7673710959726024, 'learning_rate': 0.0012322449605564102, 'weight_decay': 0.0003259823946989993, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:45:34,028 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7501035003322978, 'learning_rate': 0.0027323634455392056, 'weight_decay': 0.00020666768255119187, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:45:34,028 - INFO - Trial 737: Train MSE=1.7789707311562128, Train R²=0.7040854138987405
2024-10-31 19:45:34,028 - INFO - Trial 737: Test MSE=2.2670468602861678, Test R²=0.6309768387249538
2024-10-31 19:45:34,028 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:45:34,030 - INFO - Trial 737 finished with value: 2.2670468602861678 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7501035003322978, 'learning_rate': 0.0027323634455392056, 'weight_decay': 0.00020666768255119187, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:46:06,463 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.790954173613764, 'learning_rate': 0.0010402126475110819, 'weight_decay': 0.0002826272058512833, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:46:06,463 - INFO - Trial 738: Train MSE=2.4382978081703186, Train R²=0.5947633172784533
2024-10-31 19:46:06,463 - INFO - Trial 738: Test MSE=2.2314378193446567, Test R²=0.6369402153151376
2024-10-31 19:46:06,463 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:46:06,465 - INFO - Trial 738 finished with value: 2.2314378193446567 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.790954173613764, 'learning_rate': 0.0010402126475110819, 'weight_decay': 0.0002826272058512833, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:46:37,580 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999124784778509, 'learning_rate': 0.0011666720701634017, 'weight_decay': 0.00023419213804095425, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:46:37,581 - INFO - Trial 739: Train MSE=2.456751448767526, Train R²=0.5907138522182193
2024-10-31 19:46:37,581 - INFO - Trial 739: Test MSE=2.22405583517892, Test R²=0.6380473290170942
2024-10-31 19:46:37,581 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:46:37,582 - INFO - Trial 739 finished with value: 2.22405583517892 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999124784778509, 'learning_rate': 0.0011666720701634017, 'weight_decay': 0.00023419213804095425, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:47:51,629 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7796018944143172, 'learning_rate': 0.0008169787435773817, 'weight_decay': 0.0003561812100383073, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 19:47:51,629 - INFO - Trial 740: Train MSE=1.7344844511577062, Train R²=0.7054331334573882
2024-10-31 19:47:51,629 - INFO - Trial 740: Test MSE=2.2545927677835738, Test R²=0.6263525422130313
2024-10-31 19:47:51,630 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:47:51,630 - INFO - Trial 740 finished with value: 2.2545927677835738 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7796018944143172, 'learning_rate': 0.0008169787435773817, 'weight_decay': 0.0003561812100383073, 'batch_size': 128, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:48:26,433 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7833625060463683, 'learning_rate': 0.0009175073939431889, 'weight_decay': 0.0002536783245239229, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:48:26,433 - INFO - Trial 741: Train MSE=2.4275634459086826, Train R²=0.5959091803857258
2024-10-31 19:48:26,433 - INFO - Trial 741: Test MSE=2.2262844358171736, Test R²=0.6375776188714164
2024-10-31 19:48:26,433 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:48:26,434 - INFO - Trial 741 finished with value: 2.2262844358171736 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7833625060463683, 'learning_rate': 0.0009175073939431889, 'weight_decay': 0.0002536783245239229, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:48:59,790 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7723432249765488, 'learning_rate': 0.0012704290929068886, 'weight_decay': 0.000314691166069012, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:48:59,791 - INFO - Trial 742: Train MSE=2.1147580913134982, Train R²=0.6473681649991444
2024-10-31 19:48:59,791 - INFO - Trial 742: Test MSE=2.2545069626399448, Test R²=0.6330529451370239
2024-10-31 19:48:59,791 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:48:59,793 - INFO - Trial 742 finished with value: 2.2545069626399448 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7723432249765488, 'learning_rate': 0.0012704290929068886, 'weight_decay': 0.000314691166069012, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:49:33,165 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7999929652572043, 'learning_rate': 0.0010564232914914067, 'weight_decay': 0.00033636878660326416, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:49:33,165 - INFO - Trial 743: Train MSE=2.99922205720629, Train R²=0.49992609875542776
2024-10-31 19:49:33,165 - INFO - Trial 743: Test MSE=2.2702823536736623, Test R²=0.6304950884410313
2024-10-31 19:49:33,165 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:49:33,166 - INFO - Trial 743 finished with value: 2.2702823536736623 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7999929652572043, 'learning_rate': 0.0010564232914914067, 'weight_decay': 0.00033636878660326416, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:50:05,373 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7904996025856565, 'learning_rate': 0.0031302698320924516, 'weight_decay': 0.0002669550264933901, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:50:05,373 - INFO - Trial 744: Train MSE=1.995158578668322, Train R²=0.6679369785955974
2024-10-31 19:50:05,373 - INFO - Trial 744: Test MSE=2.22337463923863, Test R²=0.6380687611443656
2024-10-31 19:50:05,373 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:50:05,375 - INFO - Trial 744 finished with value: 2.22337463923863 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7904996025856565, 'learning_rate': 0.0031302698320924516, 'weight_decay': 0.0002669550264933901, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:50:40,073 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7379253288268945, 'learning_rate': 0.0064437130703381825, 'weight_decay': 0.00037821533735570804, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:50:40,074 - INFO - Trial 745: Train MSE=1.8343892012323653, Train R²=0.6945552889789853
2024-10-31 19:50:40,074 - INFO - Trial 745: Test MSE=2.262442180088588, Test R²=0.631678581237793
2024-10-31 19:50:40,074 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:50:40,076 - INFO - Trial 745 finished with value: 2.262442180088588 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7379253288268945, 'learning_rate': 0.0064437130703381825, 'weight_decay': 0.00037821533735570804, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:51:10,992 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7606410986939587, 'learning_rate': 0.0007863326124085371, 'weight_decay': 0.0002866652436706986, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 19:51:10,992 - INFO - Trial 746: Train MSE=2.634527087211609, Train R²=0.5611344277858734
2024-10-31 19:51:10,992 - INFO - Trial 746: Test MSE=2.251528058733259, Test R²=0.6335777810641697
2024-10-31 19:51:10,993 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:51:10,994 - INFO - Trial 746 finished with value: 2.251528058733259 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7606410986939587, 'learning_rate': 0.0007863326124085371, 'weight_decay': 0.0002866652436706986, 'batch_size': 512, 'tree_depth': 9}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:51:42,935 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7834903149109378, 'learning_rate': 0.001203453595782902, 'weight_decay': 0.00024084491803389628, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:51:42,935 - INFO - Trial 747: Train MSE=2.2857644643102373, Train R²=0.6193563725267138
2024-10-31 19:51:42,935 - INFO - Trial 747: Test MSE=2.2393994671957835, Test R²=0.6354996732303074
2024-10-31 19:51:42,935 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:51:42,937 - INFO - Trial 747 finished with value: 2.2393994671957835 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7834903149109378, 'learning_rate': 0.001203453595782902, 'weight_decay': 0.00024084491803389628, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:52:19,861 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7747597353256654, 'learning_rate': 0.0014193963176712858, 'weight_decay': 0.00030486930233270605, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:52:19,862 - INFO - Trial 748: Train MSE=2.0863854118755887, Train R²=0.6525223148720605
2024-10-31 19:52:19,862 - INFO - Trial 748: Test MSE=2.2503689527511597, Test R²=0.6336373005594526
2024-10-31 19:52:19,862 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:52:19,864 - INFO - Trial 748 finished with value: 2.2503689527511597 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7747597353256654, 'learning_rate': 0.0014193963176712858, 'weight_decay': 0.00030486930233270605, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:52:52,517 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7896649152235499, 'learning_rate': 0.0011187846805296624, 'weight_decay': 0.00031733334060047333, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:52:52,517 - INFO - Trial 749: Train MSE=2.3406136206218173, Train R²=0.6107945293188095
2024-10-31 19:52:52,517 - INFO - Trial 749: Test MSE=2.218749761581421, Test R²=0.6389529534748623
2024-10-31 19:52:52,517 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:52:52,518 - INFO - Trial 749 finished with value: 2.218749761581421 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7896649152235499, 'learning_rate': 0.0011187846805296624, 'weight_decay': 0.00031733334060047333, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:53:25,774 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.790470757923067, 'learning_rate': 0.0009500618883599068, 'weight_decay': 0.00019331286957512294, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:53:25,774 - INFO - Trial 750: Train MSE=2.5070492880684987, Train R²=0.5824634730815887
2024-10-31 19:53:25,774 - INFO - Trial 750: Test MSE=2.242667998586382, Test R²=0.6350334797586713
2024-10-31 19:53:25,774 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:53:25,776 - INFO - Trial 750 finished with value: 2.242667998586382 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.790470757923067, 'learning_rate': 0.0009500618883599068, 'weight_decay': 0.00019331286957512294, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:53:59,597 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7640285144668822, 'learning_rate': 0.0021371568591208763, 'weight_decay': 0.0003482813038806992, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:53:59,597 - INFO - Trial 751: Train MSE=1.9122230666024345, Train R²=0.6819544839007514
2024-10-31 19:53:59,597 - INFO - Trial 751: Test MSE=2.2184391362326488, Test R²=0.6387657863753182
2024-10-31 19:53:59,597 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:53:59,599 - INFO - Trial 751 finished with value: 2.2184391362326488 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7640285144668822, 'learning_rate': 0.0021371568591208763, 'weight_decay': 0.0003482813038806992, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:54:32,799 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7773634888898698, 'learning_rate': 0.0013447725428197756, 'weight_decay': 0.00025566597345938084, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:54:32,800 - INFO - Trial 752: Train MSE=2.1292678075177327, Train R²=0.6461812193904605
2024-10-31 19:54:32,800 - INFO - Trial 752: Test MSE=2.25643447467259, Test R²=0.6325990898268563
2024-10-31 19:54:32,800 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:54:32,802 - INFO - Trial 752 finished with value: 2.25643447467259 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7773634888898698, 'learning_rate': 0.0013447725428197756, 'weight_decay': 0.00025566597345938084, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:55:00,787 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.33399806319210384, 'learning_rate': 0.0008671617779553493, 'weight_decay': 0.0006826651101171968, 'batch_size': 1024, 'tree_depth': 12}
2024-10-31 19:55:00,787 - INFO - Trial 753: Train MSE=0.8650271339075906, Train R²=0.8563513287476131
2024-10-31 19:55:00,787 - INFO - Trial 753: Test MSE=2.517831027507782, Test R²=0.5872595310211182
2024-10-31 19:55:00,787 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:55:00,789 - INFO - Trial 753 finished with value: 2.517831027507782 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.33399806319210384, 'learning_rate': 0.0008671617779553493, 'weight_decay': 0.0006826651101171968, 'batch_size': 1024, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:55:34,410 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7847360583253308, 'learning_rate': 0.00010343414117437345, 'weight_decay': 0.00021595610910736342, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:55:34,410 - INFO - Trial 754: Train MSE=8.825277021953038, Train R²=-0.47385913133621216
2024-10-31 19:55:34,410 - INFO - Trial 754: Test MSE=3.570843355996268, Test R²=0.4187922648021153
2024-10-31 19:55:34,410 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:55:34,412 - INFO - Trial 754 finished with value: 3.570843355996268 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7847360583253308, 'learning_rate': 0.00010343414117437345, 'weight_decay': 0.00021595610910736342, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:56:07,221 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7914551354276961, 'learning_rate': 0.0010332476262996141, 'weight_decay': 0.0002707816948172649, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:56:07,221 - INFO - Trial 755: Train MSE=2.401352448122842, Train R²=0.6011678853205272
2024-10-31 19:56:07,222 - INFO - Trial 755: Test MSE=2.216592993055071, Test R²=0.6392937047140939
2024-10-31 19:56:07,222 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:56:07,223 - INFO - Trial 755 finished with value: 2.216592993055071 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7914551354276961, 'learning_rate': 0.0010332476262996141, 'weight_decay': 0.0002707816948172649, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:56:40,537 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.799993371906865, 'learning_rate': 0.001148497903884426, 'weight_decay': 0.00029065445960475757, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:56:40,537 - INFO - Trial 756: Train MSE=2.6566917215074812, Train R²=0.5585727883236749
2024-10-31 19:56:40,537 - INFO - Trial 756: Test MSE=2.2609809807368686, Test R²=0.6319407820701599
2024-10-31 19:56:40,537 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:56:40,538 - INFO - Trial 756 finished with value: 2.2609809807368686 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.799993371906865, 'learning_rate': 0.001148497903884426, 'weight_decay': 0.00029065445960475757, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:57:33,012 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.770224399989672, 'learning_rate': 0.002394153434518679, 'weight_decay': 0.00032065120340539905, 'batch_size': 256, 'tree_depth': 10}
2024-10-31 19:57:33,012 - INFO - Trial 757: Train MSE=1.682922431400844, Train R²=0.7197254928095
2024-10-31 19:57:33,012 - INFO - Trial 757: Test MSE=2.3046784571238925, Test R²=0.623220465012959
2024-10-31 19:57:33,012 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:57:33,013 - INFO - Trial 757 finished with value: 2.3046784571238925 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.770224399989672, 'learning_rate': 0.002394153434518679, 'weight_decay': 0.00032065120340539905, 'batch_size': 256, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:58:05,673 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7799271221817178, 'learning_rate': 0.002875673332168165, 'weight_decay': 0.00023012881438844038, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:58:05,673 - INFO - Trial 758: Train MSE=1.9043743184634618, Train R²=0.6820177542311805
2024-10-31 19:58:05,673 - INFO - Trial 758: Test MSE=2.2321554252079556, Test R²=0.6367352945463998
2024-10-31 19:58:05,673 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:58:05,674 - INFO - Trial 758 finished with value: 2.2321554252079556 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7799271221817178, 'learning_rate': 0.002875673332168165, 'weight_decay': 0.00023012881438844038, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:58:38,478 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7551580176008813, 'learning_rate': 0.0001421140932817492, 'weight_decay': 0.00030384675358737726, 'batch_size': 512, 'tree_depth': 7}
2024-10-31 19:58:38,478 - INFO - Trial 759: Train MSE=6.524080225399563, Train R²=-0.0850444563797542
2024-10-31 19:58:38,478 - INFO - Trial 759: Test MSE=2.5528981345040456, Test R²=0.5846489838191441
2024-10-31 19:58:38,478 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:58:38,479 - INFO - Trial 759 finished with value: 2.5528981345040456 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7551580176008813, 'learning_rate': 0.0001421140932817492, 'weight_decay': 0.00030384675358737726, 'batch_size': 512, 'tree_depth': 7}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:59:13,793 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7901705842970229, 'learning_rate': 0.0012624061360353702, 'weight_decay': 0.0004226028740354189, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 19:59:13,793 - INFO - Trial 760: Train MSE=2.229612801756178, Train R²=0.6284843449081693
2024-10-31 19:59:13,793 - INFO - Trial 760: Test MSE=2.2274244172232494, Test R²=0.6374562552997044
2024-10-31 19:59:13,793 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:59:13,794 - INFO - Trial 760 finished with value: 2.2274244172232494 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7901705842970229, 'learning_rate': 0.0012624061360353702, 'weight_decay': 0.0004226028740354189, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 19:59:47,700 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.775486346382051, 'learning_rate': 0.0009766946117553846, 'weight_decay': 0.0002828527597060415, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 19:59:47,700 - INFO - Trial 761: Train MSE=2.29423634495054, Train R²=0.6182124295404979
2024-10-31 19:59:47,700 - INFO - Trial 761: Test MSE=2.208996994154794, Test R²=0.6404264909880502
2024-10-31 19:59:47,700 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 19:59:47,702 - INFO - Trial 761 finished with value: 2.208996994154794 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.775486346382051, 'learning_rate': 0.0009766946117553846, 'weight_decay': 0.0002828527597060415, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:00:21,710 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7534727938370218, 'learning_rate': 0.001059241151391238, 'weight_decay': 0.00028004670058843394, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:00:21,710 - INFO - Trial 762: Train MSE=2.071003402982439, Train R²=0.6553768558161599
2024-10-31 20:00:21,710 - INFO - Trial 762: Test MSE=2.2544839722769603, Test R²=0.6329990540231977
2024-10-31 20:00:21,710 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:00:21,712 - INFO - Trial 762 finished with value: 2.2544839722769603 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7534727938370218, 'learning_rate': 0.001059241151391238, 'weight_decay': 0.00028004670058843394, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:00:56,434 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7656306850894969, 'learning_rate': 0.0011550445328472755, 'weight_decay': 0.0002657213878406045, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:00:56,434 - INFO - Trial 763: Train MSE=2.151523389986583, Train R²=0.6416425577231816
2024-10-31 20:00:56,435 - INFO - Trial 763: Test MSE=2.243398513112749, Test R²=0.6348458358219692
2024-10-31 20:00:56,435 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:00:56,436 - INFO - Trial 763 finished with value: 2.243398513112749 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7656306850894969, 'learning_rate': 0.0011550445328472755, 'weight_decay': 0.0002657213878406045, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:01:31,009 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7668136941273718, 'learning_rate': 0.0014106934455544334, 'weight_decay': 0.0002763709962105549, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:01:31,010 - INFO - Trial 764: Train MSE=2.0565211389745985, Train R²=0.6572519413062504
2024-10-31 20:01:31,010 - INFO - Trial 764: Test MSE=2.218422600201198, Test R²=0.6387126956667218
2024-10-31 20:01:31,010 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:01:31,011 - INFO - Trial 764 finished with value: 2.218422600201198 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7668136941273718, 'learning_rate': 0.0014106934455544334, 'weight_decay': 0.0002763709962105549, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:02:51,935 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7749722021892606, 'learning_rate': 0.003343107975422524, 'weight_decay': 0.0002588240079588205, 'batch_size': 128, 'tree_depth': 12}
2024-10-31 20:02:51,935 - INFO - Trial 765: Train MSE=1.9696707416857993, Train R²=0.6669173379029546
2024-10-31 20:02:51,935 - INFO - Trial 765: Test MSE=2.2693412687097276, Test R²=0.6243252243314471
2024-10-31 20:02:51,935 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:02:51,938 - INFO - Trial 765 finished with value: 2.2693412687097276 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7749722021892606, 'learning_rate': 0.003343107975422524, 'weight_decay': 0.0002588240079588205, 'batch_size': 128, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:03:26,415 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7760890676258229, 'learning_rate': 0.0009916906087595748, 'weight_decay': 0.00024439608147623914, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:03:26,415 - INFO - Trial 766: Train MSE=2.299917161464691, Train R²=0.6174531025545937
2024-10-31 20:03:26,415 - INFO - Trial 766: Test MSE=2.252983467919486, Test R²=0.6333552598953247
2024-10-31 20:03:26,415 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:03:26,417 - INFO - Trial 766 finished with value: 2.252983467919486 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7760890676258229, 'learning_rate': 0.0009916906087595748, 'weight_decay': 0.00024439608147623914, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:04:02,027 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7633723894006025, 'learning_rate': 0.0012858124882367337, 'weight_decay': 0.000284973759556075, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:04:02,027 - INFO - Trial 767: Train MSE=2.0947492761271342, Train R²=0.651374625308173
2024-10-31 20:04:02,027 - INFO - Trial 767: Test MSE=2.2352531296866283, Test R²=0.6360285537583488
2024-10-31 20:04:02,027 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:04:02,029 - INFO - Trial 767 finished with value: 2.2352531296866283 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7633723894006025, 'learning_rate': 0.0012858124882367337, 'weight_decay': 0.000284973759556075, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:04:34,840 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7452477821107685, 'learning_rate': 0.0011264903987036065, 'weight_decay': 0.0002520673297127638, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:04:34,840 - INFO - Trial 768: Train MSE=2.4078201396124705, Train R²=0.597993444119181
2024-10-31 20:04:34,840 - INFO - Trial 768: Test MSE=2.260827507291521, Test R²=0.6320066622325352
2024-10-31 20:04:34,840 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:04:34,841 - INFO - Trial 768 finished with value: 2.260827507291521 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7452477821107685, 'learning_rate': 0.0011264903987036065, 'weight_decay': 0.0002520673297127638, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:05:09,393 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7792812494195253, 'learning_rate': 0.0014901734585334467, 'weight_decay': 0.0002670533198822101, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:05:09,393 - INFO - Trial 769: Train MSE=2.1552640923431943, Train R²=0.641081514103072
2024-10-31 20:05:09,393 - INFO - Trial 769: Test MSE=2.2567737783704485, Test R²=0.6326396891048977
2024-10-31 20:05:09,393 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:05:09,395 - INFO - Trial 769 finished with value: 2.2567737783704485 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7792812494195253, 'learning_rate': 0.0014901734585334467, 'weight_decay': 0.0002670533198822101, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:05:44,065 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7834235474926687, 'learning_rate': 0.0009562384710958334, 'weight_decay': 0.000274449456233618, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:05:44,065 - INFO - Trial 770: Train MSE=2.4205862283706665, Train R²=0.5969472186905997
2024-10-31 20:05:44,065 - INFO - Trial 770: Test MSE=2.244771787098476, Test R²=0.6346074172428676
2024-10-31 20:05:44,065 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:05:44,066 - INFO - Trial 770 finished with value: 2.244771787098476 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7834235474926687, 'learning_rate': 0.0009562384710958334, 'weight_decay': 0.000274449456233618, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:06:18,828 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.30742263607601295, 'learning_rate': 0.0012214509461919282, 'weight_decay': 0.00028999113470824155, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:06:18,829 - INFO - Trial 771: Train MSE=0.5326571475182261, Train R²=0.9114196811403547
2024-10-31 20:06:18,829 - INFO - Trial 771: Test MSE=2.411764281136649, Test R²=0.6075251953942435
2024-10-31 20:06:18,829 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:06:18,830 - INFO - Trial 771 finished with value: 2.411764281136649 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.30742263607601295, 'learning_rate': 0.0012214509461919282, 'weight_decay': 0.00028999113470824155, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:06:53,733 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7534901208429786, 'learning_rate': 0.0010906951036481175, 'weight_decay': 0.00022721498497275627, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:06:53,734 - INFO - Trial 772: Train MSE=2.0370433713708604, Train R²=0.6615960087094989
2024-10-31 20:06:53,734 - INFO - Trial 772: Test MSE=2.274986301149641, Test R²=0.6297564251082284
2024-10-31 20:06:53,734 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:06:53,735 - INFO - Trial 772 finished with value: 2.274986301149641 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7534901208429786, 'learning_rate': 0.0010906951036481175, 'weight_decay': 0.00022721498497275627, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:07:27,819 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.771812274320564, 'learning_rate': 0.0025068097015865046, 'weight_decay': 0.00025315606868016685, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:07:27,819 - INFO - Trial 773: Train MSE=1.9558081541742598, Train R²=0.6745345784085137
2024-10-31 20:07:27,819 - INFO - Trial 773: Test MSE=2.258002962384905, Test R²=0.6323209149496896
2024-10-31 20:07:27,819 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:07:27,821 - INFO - Trial 773 finished with value: 2.258002962384905 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.771812274320564, 'learning_rate': 0.0025068097015865046, 'weight_decay': 0.00025315606868016685, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:08:02,476 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7907302743944729, 'learning_rate': 0.0013102770879382915, 'weight_decay': 0.00023822194215134196, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:08:02,476 - INFO - Trial 774: Train MSE=2.2905376851558685, Train R²=0.6178368074553353
2024-10-31 20:08:02,476 - INFO - Trial 774: Test MSE=2.2409806081226895, Test R²=0.6352183222770691
2024-10-31 20:08:02,477 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:08:02,478 - INFO - Trial 774 finished with value: 2.2409806081226895 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7907302743944729, 'learning_rate': 0.0013102770879382915, 'weight_decay': 0.00023822194215134196, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:08:33,896 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7629375253505644, 'learning_rate': 0.0046809625026460345, 'weight_decay': 0.0002661387844142236, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:08:33,896 - INFO - Trial 775: Train MSE=1.816826777798789, Train R²=0.6975212629352298
2024-10-31 20:08:33,896 - INFO - Trial 775: Test MSE=2.2632319246019637, Test R²=0.6312721967697144
2024-10-31 20:08:33,896 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:08:33,897 - INFO - Trial 775 finished with value: 2.2632319246019637 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7629375253505644, 'learning_rate': 0.0046809625026460345, 'weight_decay': 0.0002661387844142236, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:09:10,850 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7848035036336877, 'learning_rate': 0.0010402540174451308, 'weight_decay': 0.00029211867341454067, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:09:10,850 - INFO - Trial 776: Train MSE=2.3633686814989363, Train R²=0.6067962944507599
2024-10-31 20:09:10,850 - INFO - Trial 776: Test MSE=2.231865950993129, Test R²=0.6367922425270081
2024-10-31 20:09:10,850 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:09:10,852 - INFO - Trial 776 finished with value: 2.231865950993129 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7848035036336877, 'learning_rate': 0.0010402540174451308, 'weight_decay': 0.00029211867341454067, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:09:47,834 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.773350860456104, 'learning_rate': 0.0036175915189326007, 'weight_decay': 0.0004653995291777493, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:09:47,834 - INFO - Trial 777: Train MSE=2.1035965851375034, Train R²=0.6492653169802257
2024-10-31 20:09:47,834 - INFO - Trial 777: Test MSE=2.2491847446986606, Test R²=0.6338342939104352
2024-10-31 20:09:47,835 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:09:47,835 - INFO - Trial 777 finished with value: 2.2491847446986606 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.773350860456104, 'learning_rate': 0.0036175915189326007, 'weight_decay': 0.0004653995291777493, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:10:18,766 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7927175219887282, 'learning_rate': 0.0009446198659380324, 'weight_decay': 0.0002754975262375854, 'batch_size': 1024, 'tree_depth': 12}
2024-10-31 20:10:18,766 - INFO - Trial 778: Train MSE=3.0667733464922224, Train R²=0.4907349390642984
2024-10-31 20:10:18,766 - INFO - Trial 778: Test MSE=2.2516344785690308, Test R²=0.6309647411108017
2024-10-31 20:10:18,766 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:10:18,767 - INFO - Trial 778 finished with value: 2.2516344785690308 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7927175219887282, 'learning_rate': 0.0009446198659380324, 'weight_decay': 0.0002754975262375854, 'batch_size': 1024, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:10:53,778 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7836722295079203, 'learning_rate': 0.0016864335169000195, 'weight_decay': 0.00030178047662216375, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:10:53,778 - INFO - Trial 779: Train MSE=2.7133465238979886, Train R²=0.5484104646103722
2024-10-31 20:10:53,778 - INFO - Trial 779: Test MSE=2.35097404888698, Test R²=0.6174447025571551
2024-10-31 20:10:53,778 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:10:53,780 - INFO - Trial 779 finished with value: 2.35097404888698 and parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7836722295079203, 'learning_rate': 0.0016864335169000195, 'weight_decay': 0.00030178047662216375, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:11:27,396 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7248203237998216, 'learning_rate': 0.0012035053908127347, 'weight_decay': 0.00036686842186372506, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:11:27,396 - INFO - Trial 780: Train MSE=1.4298288098403387, Train R²=0.7622509471007756
2024-10-31 20:11:27,397 - INFO - Trial 780: Test MSE=2.3138341903686523, Test R²=0.6232017874717712
2024-10-31 20:11:27,397 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:11:27,397 - INFO - Trial 780 finished with value: 2.3138341903686523 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7248203237998216, 'learning_rate': 0.0012035053908127347, 'weight_decay': 0.00036686842186372506, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:12:18,877 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6100949947160326, 'learning_rate': 0.0008792426293312486, 'weight_decay': 0.0002596869096202698, 'batch_size': 256, 'tree_depth': 10}
2024-10-31 20:12:18,877 - INFO - Trial 781: Train MSE=1.2308277764490672, Train R²=0.7928254189235824
2024-10-31 20:12:18,877 - INFO - Trial 781: Test MSE=2.3144757407052174, Test R²=0.6216869822570256
2024-10-31 20:12:18,877 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:12:18,878 - INFO - Trial 781 finished with value: 2.3144757407052174 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6100949947160326, 'learning_rate': 0.0008792426293312486, 'weight_decay': 0.0002596869096202698, 'batch_size': 256, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:13:02,115 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7759040623495719, 'learning_rate': 0.0019947884455632893, 'weight_decay': 0.00021870015703224238, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:13:02,116 - INFO - Trial 782: Train MSE=2.022921566452299, Train R²=0.6631048279149192
2024-10-31 20:13:02,116 - INFO - Trial 782: Test MSE=2.2527060508728027, Test R²=0.6334227238382611
2024-10-31 20:13:02,116 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:13:02,117 - INFO - Trial 782 finished with value: 2.2527060508728027 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7759040623495719, 'learning_rate': 0.0019947884455632893, 'weight_decay': 0.00021870015703224238, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:13:36,078 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.6491574951021912, 'learning_rate': 0.0013835142466140252, 'weight_decay': 0.00024593605117927684, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:13:36,078 - INFO - Trial 783: Train MSE=1.5634565012795585, Train R²=0.739795161145074
2024-10-31 20:13:36,078 - INFO - Trial 783: Test MSE=2.324875593185425, Test R²=0.6213604637554714
2024-10-31 20:13:36,078 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:13:36,080 - INFO - Trial 783 finished with value: 2.324875593185425 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.6491574951021912, 'learning_rate': 0.0013835142466140252, 'weight_decay': 0.00024593605117927684, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:14:13,557 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7922100089253771, 'learning_rate': 0.001049398593791145, 'weight_decay': 0.0008927809334124462, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:14:13,558 - INFO - Trial 784: Train MSE=2.384695734296526, Train R²=0.6038081965276173
2024-10-31 20:14:13,558 - INFO - Trial 784: Test MSE=2.2083802052906583, Test R²=0.6406589320727757
2024-10-31 20:14:13,558 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:14:13,559 - INFO - Trial 784 finished with value: 2.2083802052906583 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7922100089253771, 'learning_rate': 0.001049398593791145, 'weight_decay': 0.0008927809334124462, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:14:58,067 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7994125489473705, 'learning_rate': 0.0011527259579959747, 'weight_decay': 0.0009550424826260842, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:14:58,067 - INFO - Trial 785: Train MSE=2.4577363984925404, Train R²=0.5902847519942692
2024-10-31 20:14:58,067 - INFO - Trial 785: Test MSE=2.2491069521222795, Test R²=0.6340254374912807
2024-10-31 20:14:58,067 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:14:58,068 - INFO - Trial 785 finished with value: 2.2491069521222795 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7994125489473705, 'learning_rate': 0.0011527259579959747, 'weight_decay': 0.0009550424826260842, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:15:42,455 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7911437471067767, 'learning_rate': 0.0010796280629078831, 'weight_decay': 0.00034117084123582483, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:15:42,455 - INFO - Trial 786: Train MSE=2.4009922487395152, Train R²=0.5998903257506234
2024-10-31 20:15:42,456 - INFO - Trial 786: Test MSE=2.2374651772635326, Test R²=0.6357110738754272
2024-10-31 20:15:42,456 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:15:42,457 - INFO - Trial 786 finished with value: 2.2374651772635326 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7911437471067767, 'learning_rate': 0.0010796280629078831, 'weight_decay': 0.00034117084123582483, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:16:26,776 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7640186017685331, 'learning_rate': 0.0012939836722522708, 'weight_decay': 0.00028444971802815466, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:16:26,777 - INFO - Trial 787: Train MSE=2.0643977395125797, Train R²=0.6561879515647888
2024-10-31 20:16:26,777 - INFO - Trial 787: Test MSE=2.257557613509042, Test R²=0.6327319826398577
2024-10-31 20:16:26,777 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:16:26,778 - INFO - Trial 787 finished with value: 2.257557613509042 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7640186017685331, 'learning_rate': 0.0012939836722522708, 'weight_decay': 0.00028444971802815466, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:17:11,276 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7815960323686642, 'learning_rate': 0.001471809392526785, 'weight_decay': 0.0009679390794049367, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:17:11,276 - INFO - Trial 788: Train MSE=2.139282579932894, Train R²=0.6437623287950244
2024-10-31 20:17:11,276 - INFO - Trial 788: Test MSE=2.2357844965798512, Test R²=0.6360723887171064
2024-10-31 20:17:11,276 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:17:11,277 - INFO - Trial 788 finished with value: 2.2357844965798512 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7815960323686642, 'learning_rate': 0.001471809392526785, 'weight_decay': 0.0009679390794049367, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:17:55,407 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7833577837094782, 'learning_rate': 0.0010328527445931067, 'weight_decay': 0.00032731713387160953, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:17:55,408 - INFO - Trial 789: Train MSE=2.3231164131845747, Train R²=0.6128442457744053
2024-10-31 20:17:55,408 - INFO - Trial 789: Test MSE=2.2538848434175764, Test R²=0.633314950125558
2024-10-31 20:17:55,408 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:17:55,409 - INFO - Trial 789 finished with value: 2.2538848434175764 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7833577837094782, 'learning_rate': 0.0010328527445931067, 'weight_decay': 0.00032731713387160953, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:19:40,140 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7919992494480752, 'learning_rate': 0.0011487557255149769, 'weight_decay': 0.0008575966338378847, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 20:19:40,140 - INFO - Trial 790: Train MSE=1.9899540820292063, Train R²=0.6645369923540524
2024-10-31 20:19:40,140 - INFO - Trial 790: Test MSE=2.2613733453410014, Test R²=0.625341751745769
2024-10-31 20:19:40,140 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:19:40,142 - INFO - Trial 790 finished with value: 2.2613733453410014 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7919992494480752, 'learning_rate': 0.0011487557255149769, 'weight_decay': 0.0008575966338378847, 'batch_size': 128, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:20:12,784 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7995759441944824, 'learning_rate': 0.001247726267950581, 'weight_decay': 0.00037752655615928127, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:20:12,785 - INFO - Trial 791: Train MSE=2.0578343059335436, Train R²=0.657105103135109
2024-10-31 20:20:12,785 - INFO - Trial 791: Test MSE=2.2209565469196866, Test R²=0.6386099202292306
2024-10-31 20:20:12,785 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:20:12,786 - INFO - Trial 791 finished with value: 2.2209565469196866 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7995759441944824, 'learning_rate': 0.001247726267950581, 'weight_decay': 0.00037752655615928127, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:20:49,351 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.771600032796178, 'learning_rate': 0.0010821762289683246, 'weight_decay': 0.00029846597086831796, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:20:49,351 - INFO - Trial 792: Train MSE=2.715956279209682, Train R²=0.5483038829905647
2024-10-31 20:20:49,351 - INFO - Trial 792: Test MSE=2.2416177477155412, Test R²=0.6351837175233024
2024-10-31 20:20:49,351 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:20:49,352 - INFO - Trial 792 finished with value: 2.2416177477155412 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.771600032796178, 'learning_rate': 0.0010821762289683246, 'weight_decay': 0.00029846597086831796, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:21:34,180 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.4021214227255171, 'learning_rate': 0.001315299456476437, 'weight_decay': 0.00040851024461311633, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:21:34,180 - INFO - Trial 793: Train MSE=0.6683438643813133, Train R²=0.888575228197234
2024-10-31 20:21:34,181 - INFO - Trial 793: Test MSE=2.3649069581712996, Test R²=0.6151216966765267
2024-10-31 20:21:34,181 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:21:34,182 - INFO - Trial 793 finished with value: 2.3649069581712996 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.4021214227255171, 'learning_rate': 0.001315299456476437, 'weight_decay': 0.00040851024461311633, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:22:18,535 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7844977717473527, 'learning_rate': 0.0011923525495955028, 'weight_decay': 0.0009485599934137097, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:22:18,535 - INFO - Trial 794: Train MSE=2.2205178482191905, Train R²=0.6299130746296474
2024-10-31 20:22:18,535 - INFO - Trial 794: Test MSE=2.211092097418649, Test R²=0.6401331765311105
2024-10-31 20:22:18,535 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:22:18,536 - INFO - Trial 794 finished with value: 2.211092097418649 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7844977717473527, 'learning_rate': 0.0011923525495955028, 'weight_decay': 0.0009485599934137097, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:23:02,707 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7535314225411005, 'learning_rate': 0.001521397398286931, 'weight_decay': 0.0007734189077621162, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:23:02,707 - INFO - Trial 795: Train MSE=1.9209056454045432, Train R²=0.679854976279395
2024-10-31 20:23:02,707 - INFO - Trial 795: Test MSE=2.21568078654153, Test R²=0.6392979451588222
2024-10-31 20:23:02,708 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:23:02,709 - INFO - Trial 795 finished with value: 2.21568078654153 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7535314225411005, 'learning_rate': 0.001521397398286931, 'weight_decay': 0.0007734189077621162, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:23:46,697 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.768261937560402, 'learning_rate': 0.001205761257756665, 'weight_decay': 0.0009884081107224536, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:23:46,697 - INFO - Trial 796: Train MSE=2.0966890241418565, Train R²=0.6500576904841832
2024-10-31 20:23:46,697 - INFO - Trial 796: Test MSE=2.240426710673741, Test R²=0.6352522713797433
2024-10-31 20:23:46,697 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:23:46,698 - INFO - Trial 796 finished with value: 2.240426710673741 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.768261937560402, 'learning_rate': 0.001205761257756665, 'weight_decay': 0.0009884081107224536, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:24:30,308 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998419302593843, 'learning_rate': 0.001377920592114006, 'weight_decay': 0.0004476622433327275, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:24:30,309 - INFO - Trial 797: Train MSE=2.389634817838669, Train R²=0.6022341677120754
2024-10-31 20:24:30,309 - INFO - Trial 797: Test MSE=2.2129348005567278, Test R²=0.6397433110645839
2024-10-31 20:24:30,309 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:24:30,310 - INFO - Trial 797 finished with value: 2.2129348005567278 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998419302593843, 'learning_rate': 0.001377920592114006, 'weight_decay': 0.0004476622433327275, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:25:14,091 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7917326936715825, 'learning_rate': 0.001740291686942902, 'weight_decay': 0.000926765356083948, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:25:14,092 - INFO - Trial 798: Train MSE=2.1969217317444936, Train R²=0.6330118732792991
2024-10-31 20:25:14,092 - INFO - Trial 798: Test MSE=2.2485803025109425, Test R²=0.6339091488293239
2024-10-31 20:25:14,092 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:25:14,093 - INFO - Trial 798 finished with value: 2.2485803025109425 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7917326936715825, 'learning_rate': 0.001740291686942902, 'weight_decay': 0.000926765356083948, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:25:57,728 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.782379250388287, 'learning_rate': 0.001452771636211421, 'weight_decay': 0.0008847100803420234, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:25:57,729 - INFO - Trial 799: Train MSE=2.1122390925884247, Train R²=0.6485717445611954
2024-10-31 20:25:57,729 - INFO - Trial 799: Test MSE=2.2237818241119385, Test R²=0.6379392232213702
2024-10-31 20:25:57,729 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:25:57,730 - INFO - Trial 799 finished with value: 2.2237818241119385 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.782379250388287, 'learning_rate': 0.001452771636211421, 'weight_decay': 0.0008847100803420234, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:26:41,155 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995001349249302, 'learning_rate': 0.001616019580840733, 'weight_decay': 0.0009546992990897849, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:26:41,155 - INFO - Trial 800: Train MSE=2.2937115260532925, Train R²=0.6174491771629879
2024-10-31 20:26:41,155 - INFO - Trial 800: Test MSE=2.226815564291818, Test R²=0.6375311613082886
2024-10-31 20:26:41,155 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:26:41,157 - INFO - Trial 800 finished with value: 2.226815564291818 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995001349249302, 'learning_rate': 0.001616019580840733, 'weight_decay': 0.0009546992990897849, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:27:24,995 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995848949268703, 'learning_rate': 0.0013784611426983328, 'weight_decay': 0.00042888995421033646, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:27:24,996 - INFO - Trial 801: Train MSE=2.2883772935186113, Train R²=0.618332211460386
2024-10-31 20:27:24,996 - INFO - Trial 801: Test MSE=2.235088586807251, Test R²=0.6362932920455933
2024-10-31 20:27:24,996 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:27:24,997 - INFO - Trial 801 finished with value: 2.235088586807251 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995848949268703, 'learning_rate': 0.0013784611426983328, 'weight_decay': 0.00042888995421033646, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:28:08,907 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.735133268086706, 'learning_rate': 0.0015021810029948305, 'weight_decay': 0.00044260964035208907, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:28:08,907 - INFO - Trial 802: Train MSE=1.790761181286403, Train R²=0.7019844800233841
2024-10-31 20:28:08,907 - INFO - Trial 802: Test MSE=2.2500027247837613, Test R²=0.6337697846548898
2024-10-31 20:28:08,907 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:28:08,909 - INFO - Trial 802 finished with value: 2.2500027247837613 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.735133268086706, 'learning_rate': 0.0015021810029948305, 'weight_decay': 0.00044260964035208907, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:28:50,852 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7767514707348008, 'learning_rate': 0.0013337469667309293, 'weight_decay': 0.00045920633025429156, 'batch_size': 512, 'tree_depth': 8}
2024-10-31 20:28:50,852 - INFO - Trial 803: Train MSE=2.5316376430647716, Train R²=0.5764571279287338
2024-10-31 20:28:50,852 - INFO - Trial 803: Test MSE=2.28937714440482, Test R²=0.6271861621311733
2024-10-31 20:28:50,852 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:28:50,853 - INFO - Trial 803 finished with value: 2.28937714440482 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7767514707348008, 'learning_rate': 0.0013337469667309293, 'weight_decay': 0.00045920633025429156, 'batch_size': 512, 'tree_depth': 8}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:29:35,494 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7838254058828635, 'learning_rate': 0.0012149494740971985, 'weight_decay': 0.0009319072197346049, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:29:35,495 - INFO - Trial 804: Train MSE=2.235200456210545, Train R²=0.6276003548077175
2024-10-31 20:29:35,495 - INFO - Trial 804: Test MSE=2.2357384817940846, Test R²=0.6361474735396249
2024-10-31 20:29:35,495 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:29:35,496 - INFO - Trial 804 finished with value: 2.2357384817940846 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7838254058828635, 'learning_rate': 0.0012149494740971985, 'weight_decay': 0.0009319072197346049, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:30:13,362 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7606479559956297, 'learning_rate': 0.0016206380561387995, 'weight_decay': 0.0008963411185306167, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 20:30:13,362 - INFO - Trial 805: Train MSE=2.2759987115859985, Train R²=0.6218729146889278
2024-10-31 20:30:13,363 - INFO - Trial 805: Test MSE=2.24133962392807, Test R²=0.6325771659612656
2024-10-31 20:30:13,363 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:30:13,363 - INFO - Trial 805 finished with value: 2.24133962392807 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7606479559956297, 'learning_rate': 0.0016206380561387995, 'weight_decay': 0.0008963411185306167, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:30:48,062 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7906334650184597, 'learning_rate': 0.0013233935913740586, 'weight_decay': 0.0009262062912819987, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:30:48,062 - INFO - Trial 806: Train MSE=1.7653228342533112, Train R²=0.7062168398073742
2024-10-31 20:30:48,062 - INFO - Trial 806: Test MSE=2.29670136315482, Test R²=0.6263493044035775
2024-10-31 20:30:48,063 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:30:48,063 - INFO - Trial 806 finished with value: 2.29670136315482 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7906334650184597, 'learning_rate': 0.0013233935913740586, 'weight_decay': 0.0009262062912819987, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:31:18,787 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.799615645400659, 'learning_rate': 0.0014242347847814563, 'weight_decay': 0.0009887418566793674, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:31:18,787 - INFO - Trial 807: Train MSE=2.366895088127681, Train R²=0.6070281841925212
2024-10-31 20:31:18,787 - INFO - Trial 807: Test MSE=2.223362752369472, Test R²=0.6382583720343453
2024-10-31 20:31:18,787 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:31:18,789 - INFO - Trial 807 finished with value: 2.223362752369472 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.799615645400659, 'learning_rate': 0.0014242347847814563, 'weight_decay': 0.0009887418566793674, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:32:20,919 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7746383425804545, 'learning_rate': 0.001004602888432517, 'weight_decay': 0.0009528115685187048, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 20:32:20,920 - INFO - Trial 808: Train MSE=1.988619280712945, Train R²=0.6675807897533689
2024-10-31 20:32:20,920 - INFO - Trial 808: Test MSE=2.2479604993547713, Test R²=0.6321262972695487
2024-10-31 20:32:20,920 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:32:20,921 - INFO - Trial 808 finished with value: 2.2479604993547713 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7746383425804545, 'learning_rate': 0.001004602888432517, 'weight_decay': 0.0009528115685187048, 'batch_size': 256, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:33:04,334 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.781623912989449, 'learning_rate': 0.0011213620182797639, 'weight_decay': 0.000762748788675932, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:33:04,334 - INFO - Trial 809: Train MSE=2.303186970097678, Train R²=0.6172672935894558
2024-10-31 20:33:04,334 - INFO - Trial 809: Test MSE=2.2695511068616594, Test R²=0.6305573838097709
2024-10-31 20:33:04,334 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:33:04,335 - INFO - Trial 809 finished with value: 2.2695511068616594 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.781623912989449, 'learning_rate': 0.0011213620182797639, 'weight_decay': 0.000762748788675932, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:33:47,555 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999167224175815, 'learning_rate': 0.0012309928532362965, 'weight_decay': 0.0009031011125542216, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:33:47,555 - INFO - Trial 810: Train MSE=2.3878156627927507, Train R²=0.6019211624349866
2024-10-31 20:33:47,555 - INFO - Trial 810: Test MSE=2.2316338334764754, Test R²=0.636766791343689
2024-10-31 20:33:47,555 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:33:47,557 - INFO - Trial 810 finished with value: 2.2316338334764754 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999167224175815, 'learning_rate': 0.0012309928532362965, 'weight_decay': 0.0009031011125542216, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:34:22,980 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7684496309919092, 'learning_rate': 0.001510503888276031, 'weight_decay': 0.0009971507915247048, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:34:22,980 - INFO - Trial 811: Train MSE=2.244704621178763, Train R²=0.6266802889960152
2024-10-31 20:34:22,980 - INFO - Trial 811: Test MSE=2.278127295630319, Test R²=0.628997232232775
2024-10-31 20:34:22,980 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:34:22,982 - INFO - Trial 811 finished with value: 2.278127295630319 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7684496309919092, 'learning_rate': 0.001510503888276031, 'weight_decay': 0.0009971507915247048, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:34:56,973 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7877928213519847, 'learning_rate': 0.001127382261752844, 'weight_decay': 0.0006449625450594739, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:34:56,974 - INFO - Trial 812: Train MSE=2.3073267936706543, Train R²=0.6161764072520393
2024-10-31 20:34:56,974 - INFO - Trial 812: Test MSE=2.227531671524048, Test R²=0.6375445468085152
2024-10-31 20:34:56,974 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:34:56,975 - INFO - Trial 812 finished with value: 2.227531671524048 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7877928213519847, 'learning_rate': 0.001127382261752844, 'weight_decay': 0.0006449625450594739, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:35:41,114 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998208096350995, 'learning_rate': 0.0018312809277980316, 'weight_decay': 0.0008631091581550964, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 20:35:41,114 - INFO - Trial 813: Train MSE=2.3069926542895183, Train R²=0.6165469948734555
2024-10-31 20:35:41,114 - INFO - Trial 813: Test MSE=2.2420318126678467, Test R²=0.6350115367344448
2024-10-31 20:35:41,114 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:35:41,115 - INFO - Trial 813 finished with value: 2.2420318126678467 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998208096350995, 'learning_rate': 0.0018312809277980316, 'weight_decay': 0.0008631091581550964, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:36:24,650 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7453853949119513, 'learning_rate': 0.0013248783573115914, 'weight_decay': 0.0008486287605998806, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:36:24,650 - INFO - Trial 814: Train MSE=1.9004461467266083, Train R²=0.6834536726985659
2024-10-31 20:36:24,650 - INFO - Trial 814: Test MSE=2.2550338166100636, Test R²=0.633067752633776
2024-10-31 20:36:24,650 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:36:24,651 - INFO - Trial 814 finished with value: 2.2550338166100636 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7453853949119513, 'learning_rate': 0.0013248783573115914, 'weight_decay': 0.0008486287605998806, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:37:36,288 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7817650276353201, 'learning_rate': 0.0010130927088951827, 'weight_decay': 0.0008063244768089433, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 20:37:36,288 - INFO - Trial 815: Train MSE=1.8200019534145082, Train R²=0.6922055589301246
2024-10-31 20:37:36,289 - INFO - Trial 815: Test MSE=2.2750910903726305, Test R²=0.6236113799469811
2024-10-31 20:37:36,289 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:37:36,290 - INFO - Trial 815 finished with value: 2.2750910903726305 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7817650276353201, 'learning_rate': 0.0010130927088951827, 'weight_decay': 0.0008063244768089433, 'batch_size': 128, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:38:09,201 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902841279199739, 'learning_rate': 0.0016500739189105674, 'weight_decay': 0.0008239032550822103, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:38:09,201 - INFO - Trial 816: Train MSE=2.2044883114951, Train R²=0.63340896155153
2024-10-31 20:38:09,201 - INFO - Trial 816: Test MSE=2.2658671821866716, Test R²=0.6311655555452619
2024-10-31 20:38:09,202 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:38:09,203 - INFO - Trial 816 finished with value: 2.2658671821866716 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902841279199739, 'learning_rate': 0.0016500739189105674, 'weight_decay': 0.0008239032550822103, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:38:54,740 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7582214724652298, 'learning_rate': 0.0011879581317841604, 'weight_decay': 0.0008956841853835508, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:38:54,741 - INFO - Trial 817: Train MSE=2.093750544956752, Train R²=0.6512369981833867
2024-10-31 20:38:54,741 - INFO - Trial 817: Test MSE=2.2171894311904907, Test R²=0.6392125572477069
2024-10-31 20:38:54,741 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:38:54,742 - INFO - Trial 817 finished with value: 2.2171894311904907 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7582214724652298, 'learning_rate': 0.0011879581317841604, 'weight_decay': 0.0008956841853835508, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:39:39,229 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7730795659584979, 'learning_rate': 0.0010631200690576408, 'weight_decay': 0.0004029297468224199, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:39:39,229 - INFO - Trial 818: Train MSE=2.211470808301653, Train R²=0.6315827135528836
2024-10-31 20:39:39,230 - INFO - Trial 818: Test MSE=2.2473874943596974, Test R²=0.634152352809906
2024-10-31 20:39:39,230 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:39:39,231 - INFO - Trial 818 finished with value: 2.2473874943596974 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7730795659584979, 'learning_rate': 0.0010631200690576408, 'weight_decay': 0.0004029297468224199, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:40:22,875 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.444809185305413, 'learning_rate': 0.005694599328163522, 'weight_decay': 0.0009076072525670615, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:40:22,875 - INFO - Trial 819: Train MSE=1.321773886680603, Train R²=0.7796643546649388
2024-10-31 20:40:22,875 - INFO - Trial 819: Test MSE=2.4591562747955322, Test R²=0.5995465176446098
2024-10-31 20:40:22,875 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:40:22,877 - INFO - Trial 819 finished with value: 2.4591562747955322 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.444809185305413, 'learning_rate': 0.005694599328163522, 'weight_decay': 0.0009076072525670615, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:41:07,453 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.48102012871905064, 'learning_rate': 0.0009464248360770022, 'weight_decay': 0.0004481048273410606, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 20:41:07,453 - INFO - Trial 820: Train MSE=0.9601738452911377, Train R²=0.8401044458150864
2024-10-31 20:41:07,454 - INFO - Trial 820: Test MSE=2.3947462694985524, Test R²=0.610059414591108
2024-10-31 20:41:07,454 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:41:07,455 - INFO - Trial 820 finished with value: 2.3947462694985524 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.48102012871905064, 'learning_rate': 0.0009464248360770022, 'weight_decay': 0.0004481048273410606, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:41:51,510 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7907189005585423, 'learning_rate': 0.004222207461210054, 'weight_decay': 0.0008273719801261736, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:41:51,510 - INFO - Trial 821: Train MSE=2.110664631639208, Train R²=0.6492719288383212
2024-10-31 20:41:51,510 - INFO - Trial 821: Test MSE=2.215219395501273, Test R²=0.6394057273864746
2024-10-31 20:41:51,510 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:41:51,512 - INFO - Trial 821 finished with value: 2.215219395501273 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7907189005585423, 'learning_rate': 0.004222207461210054, 'weight_decay': 0.0008273719801261736, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:42:34,850 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7783429808618184, 'learning_rate': 0.0012791018315434605, 'weight_decay': 0.0004882902669260476, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:42:34,850 - INFO - Trial 822: Train MSE=2.1800598246710643, Train R²=0.6365586625678199
2024-10-31 20:42:34,850 - INFO - Trial 822: Test MSE=2.2681915760040283, Test R²=0.6307705215045384
2024-10-31 20:42:34,850 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:42:34,852 - INFO - Trial 822 finished with value: 2.2681915760040283 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7783429808618184, 'learning_rate': 0.0012791018315434605, 'weight_decay': 0.0004882902669260476, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:43:19,051 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7680600809597995, 'learning_rate': 0.001395848258722905, 'weight_decay': 0.00012446605388902836, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:43:19,051 - INFO - Trial 823: Train MSE=2.0495417586394717, Train R²=0.6586001536675862
2024-10-31 20:43:19,051 - INFO - Trial 823: Test MSE=2.2097722121647427, Test R²=0.6403105684689113
2024-10-31 20:43:19,051 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:43:19,052 - INFO - Trial 823 finished with value: 2.2097722121647427 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7680600809597995, 'learning_rate': 0.001395848258722905, 'weight_decay': 0.00012446605388902836, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:44:02,498 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7541355325810455, 'learning_rate': 0.0011832488749264885, 'weight_decay': 0.000701501963889321, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:44:02,498 - INFO - Trial 824: Train MSE=1.991433552333287, Train R²=0.6686070774282727
2024-10-31 20:44:02,498 - INFO - Trial 824: Test MSE=2.2439049993242537, Test R²=0.6347564288548061
2024-10-31 20:44:02,498 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:44:02,499 - INFO - Trial 824 finished with value: 2.2439049993242537 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7541355325810455, 'learning_rate': 0.0011832488749264885, 'weight_decay': 0.000701501963889321, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:44:46,355 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7610970087156966, 'learning_rate': 0.005030532985618391, 'weight_decay': 0.00036045672874033077, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:44:46,356 - INFO - Trial 825: Train MSE=1.913568607398442, Train R²=0.6811189076730183
2024-10-31 20:44:46,356 - INFO - Trial 825: Test MSE=2.231686234474182, Test R²=0.636765113898686
2024-10-31 20:44:46,356 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:44:46,357 - INFO - Trial 825 finished with value: 2.231686234474182 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7610970087156966, 'learning_rate': 0.005030532985618391, 'weight_decay': 0.00036045672874033077, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:45:30,484 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7457051881641779, 'learning_rate': 0.0015234833725601019, 'weight_decay': 0.00011086325990319175, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:45:30,484 - INFO - Trial 826: Train MSE=1.8238776241030012, Train R²=0.6963240333965847
2024-10-31 20:45:30,484 - INFO - Trial 826: Test MSE=2.2671514408929005, Test R²=0.6309439199311393
2024-10-31 20:45:30,484 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:45:30,486 - INFO - Trial 826 finished with value: 2.2671514408929005 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7457051881641779, 'learning_rate': 0.0015234833725601019, 'weight_decay': 0.00011086325990319175, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:46:14,139 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.762918617244661, 'learning_rate': 0.0010947100824398209, 'weight_decay': 0.00034972136592663236, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:46:14,139 - INFO - Trial 827: Train MSE=2.1222632144178664, Train R²=0.6471041845423835
2024-10-31 20:46:14,139 - INFO - Trial 827: Test MSE=2.284093448093959, Test R²=0.6282387971878052
2024-10-31 20:46:14,139 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:46:14,141 - INFO - Trial 827 finished with value: 2.284093448093959 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.762918617244661, 'learning_rate': 0.0010947100824398209, 'weight_decay': 0.00034972136592663236, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:46:50,392 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7668594842951779, 'learning_rate': 0.0009800440425552666, 'weight_decay': 0.0009270881365476854, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 20:46:50,392 - INFO - Trial 828: Train MSE=2.856444699423654, Train R²=0.5254192011696952
2024-10-31 20:46:50,392 - INFO - Trial 828: Test MSE=2.235950529575348, Test R²=0.6335131078958511
2024-10-31 20:46:50,392 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:46:50,394 - INFO - Trial 828 finished with value: 2.235950529575348 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7668594842951779, 'learning_rate': 0.0009800440425552666, 'weight_decay': 0.0009270881365476854, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:47:33,085 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7685376045803828, 'learning_rate': 0.0013823428968267092, 'weight_decay': 0.00012392646210757324, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:47:33,085 - INFO - Trial 829: Train MSE=2.038366049528122, Train R²=0.66105517745018
2024-10-31 20:47:33,085 - INFO - Trial 829: Test MSE=2.249816349574498, Test R²=0.6338439328329903
2024-10-31 20:47:33,085 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:47:33,087 - INFO - Trial 829 finished with value: 2.249816349574498 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7685376045803828, 'learning_rate': 0.0013823428968267092, 'weight_decay': 0.00012392646210757324, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:48:07,017 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7524820676385832, 'learning_rate': 0.0012311314697611654, 'weight_decay': 0.00016831246770746745, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:48:07,017 - INFO - Trial 830: Train MSE=2.3679833582469394, Train R²=0.606446236371994
2024-10-31 20:48:07,017 - INFO - Trial 830: Test MSE=2.281987258366176, Test R²=0.6286197134426662
2024-10-31 20:48:07,017 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:48:07,019 - INFO - Trial 830 finished with value: 2.281987258366176 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7524820676385832, 'learning_rate': 0.0012311314697611654, 'weight_decay': 0.00016831246770746745, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:48:55,188 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7732069958924266, 'learning_rate': 0.000895531140745241, 'weight_decay': 0.0007328834663029508, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 20:48:55,188 - INFO - Trial 831: Train MSE=1.5178571598870414, Train R²=0.7459701917001179
2024-10-31 20:48:55,188 - INFO - Trial 831: Test MSE=2.2627513578959872, Test R²=0.6293439226491111
2024-10-31 20:48:55,188 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:48:55,189 - INFO - Trial 831 finished with value: 2.2627513578959872 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7732069958924266, 'learning_rate': 0.000895531140745241, 'weight_decay': 0.0007328834663029508, 'batch_size': 256, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:49:32,474 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7710320338225778, 'learning_rate': 0.006798402109639612, 'weight_decay': 0.00028027309004139116, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:49:32,474 - INFO - Trial 832: Train MSE=1.9559787256377084, Train R²=0.6750227468354362
2024-10-31 20:49:32,474 - INFO - Trial 832: Test MSE=2.2673187937055315, Test R²=0.6309263961655753
2024-10-31 20:49:32,474 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:49:32,476 - INFO - Trial 832 finished with value: 2.2673187937055315 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7710320338225778, 'learning_rate': 0.006798402109639612, 'weight_decay': 0.00028027309004139116, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:50:12,434 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7596072659720373, 'learning_rate': 0.0010762569493666353, 'weight_decay': 0.00029214082218465963, 'batch_size': 512, 'tree_depth': 6}
2024-10-31 20:50:12,434 - INFO - Trial 833: Train MSE=3.0610782333782742, Train R²=0.49027799708502634
2024-10-31 20:50:12,434 - INFO - Trial 833: Test MSE=2.4262210641588484, Test R²=0.60505553654262
2024-10-31 20:50:12,434 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:50:12,435 - INFO - Trial 833 finished with value: 2.4262210641588484 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7596072659720373, 'learning_rate': 0.0010762569493666353, 'weight_decay': 0.00029214082218465963, 'batch_size': 512, 'tree_depth': 6}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:50:46,836 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7797404353057971, 'learning_rate': 0.0012967799895742015, 'weight_decay': 0.0001093691926867579, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:50:46,836 - INFO - Trial 834: Train MSE=2.385638100760324, Train R²=0.6020488334553582
2024-10-31 20:50:46,836 - INFO - Trial 834: Test MSE=2.2296643938337053, Test R²=0.6371127196720668
2024-10-31 20:50:46,836 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:50:46,838 - INFO - Trial 834 finished with value: 2.2296643938337053 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7797404353057971, 'learning_rate': 0.0012967799895742015, 'weight_decay': 0.0001093691926867579, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:51:26,057 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7768302635197575, 'learning_rate': 0.0016016254017024586, 'weight_decay': 0.00010122812552103221, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 20:51:26,058 - INFO - Trial 835: Train MSE=2.3341131848948344, Train R²=0.6121455090386527
2024-10-31 20:51:26,058 - INFO - Trial 835: Test MSE=2.243772029876709, Test R²=0.6346030575888497
2024-10-31 20:51:26,058 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:51:26,059 - INFO - Trial 835 finished with value: 2.243772029876709 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7768302635197575, 'learning_rate': 0.0016016254017024586, 'weight_decay': 0.00010122812552103221, 'batch_size': 512, 'tree_depth': 9}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:52:10,666 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.768135944132692, 'learning_rate': 0.0018049373708964678, 'weight_decay': 0.00013236901973726813, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:52:10,667 - INFO - Trial 836: Train MSE=2.0089433193206787, Train R²=0.6648366536412921
2024-10-31 20:52:10,667 - INFO - Trial 836: Test MSE=2.2733393737248013, Test R²=0.6299297213554382
2024-10-31 20:52:10,667 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:52:10,668 - INFO - Trial 836 finished with value: 2.2733393737248013 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.768135944132692, 'learning_rate': 0.0018049373708964678, 'weight_decay': 0.00013236901973726813, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:52:55,376 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7390146498755159, 'learning_rate': 0.0009923267150839423, 'weight_decay': 0.0008495360287262411, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:52:55,376 - INFO - Trial 837: Train MSE=1.9808774122170039, Train R²=0.6691780345780509
2024-10-31 20:52:55,376 - INFO - Trial 837: Test MSE=2.274510553904942, Test R²=0.6297849757330758
2024-10-31 20:52:55,376 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:52:55,378 - INFO - Trial 837 finished with value: 2.274510553904942 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7390146498755159, 'learning_rate': 0.0009923267150839423, 'weight_decay': 0.0008495360287262411, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:53:39,956 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7814529058788695, 'learning_rate': 0.001199176316111718, 'weight_decay': 0.0003349474551011089, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:53:39,956 - INFO - Trial 838: Train MSE=2.274837442806789, Train R²=0.6209410620587212
2024-10-31 20:53:39,956 - INFO - Trial 838: Test MSE=2.257290210042681, Test R²=0.6326402085168021
2024-10-31 20:53:39,956 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:53:39,958 - INFO - Trial 838 finished with value: 2.257290210042681 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7814529058788695, 'learning_rate': 0.001199176316111718, 'weight_decay': 0.0003349474551011089, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:54:12,822 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7845661987831778, 'learning_rate': 0.0014293761789910256, 'weight_decay': 0.0001488236911099174, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:54:12,823 - INFO - Trial 839: Train MSE=1.895431011915207, Train R²=0.6851675638130733
2024-10-31 20:54:12,823 - INFO - Trial 839: Test MSE=2.2623913628714427, Test R²=0.6315673845154899
2024-10-31 20:54:12,823 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:54:12,824 - INFO - Trial 839 finished with value: 2.2623913628714427 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7845661987831778, 'learning_rate': 0.0014293761789910256, 'weight_decay': 0.0001488236911099174, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:55:49,997 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7598909804730122, 'learning_rate': 0.0011020851125483216, 'weight_decay': 0.0003022790669925922, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 20:55:49,998 - INFO - Trial 840: Train MSE=1.671265643622194, Train R²=0.7174137883952686
2024-10-31 20:55:49,998 - INFO - Trial 840: Test MSE=2.2853824198246, Test R²=0.6217793162379947
2024-10-31 20:55:49,998 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:55:50,000 - INFO - Trial 840 finished with value: 2.2853824198246 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7598909804730122, 'learning_rate': 0.0011020851125483216, 'weight_decay': 0.0003022790669925922, 'batch_size': 128, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:56:33,258 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7738720712385772, 'learning_rate': 0.0009215666171486694, 'weight_decay': 0.000159979688190308, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:56:33,258 - INFO - Trial 841: Train MSE=2.295748846871512, Train R²=0.618653233562197
2024-10-31 20:56:33,258 - INFO - Trial 841: Test MSE=2.244982957839966, Test R²=0.6346838474273682
2024-10-31 20:56:33,258 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:56:33,260 - INFO - Trial 841 finished with value: 2.244982957839966 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7738720712385772, 'learning_rate': 0.0009215666171486694, 'weight_decay': 0.000159979688190308, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:57:16,441 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7836765962550652, 'learning_rate': 0.0008454205972010983, 'weight_decay': 0.0006086650670880674, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:57:16,441 - INFO - Trial 842: Train MSE=2.9860439470836093, Train R²=0.5015778158392225
2024-10-31 20:57:16,441 - INFO - Trial 842: Test MSE=2.2315781457083568, Test R²=0.6368541717529297
2024-10-31 20:57:16,442 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:57:16,442 - INFO - Trial 842 finished with value: 2.2315781457083568 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7836765962550652, 'learning_rate': 0.0008454205972010983, 'weight_decay': 0.0006086650670880674, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:57:59,988 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.750441226147553, 'learning_rate': 0.001985228526544114, 'weight_decay': 0.0001185044377648376, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:57:59,988 - INFO - Trial 843: Train MSE=1.8157477251120977, Train R²=0.6987286869968686
2024-10-31 20:57:59,988 - INFO - Trial 843: Test MSE=2.2613760914121355, Test R²=0.6319554022380284
2024-10-31 20:57:59,988 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:57:59,989 - INFO - Trial 843 finished with value: 2.2613760914121355 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.750441226147553, 'learning_rate': 0.001985228526544114, 'weight_decay': 0.0001185044377648376, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:58:42,903 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7899443717138148, 'learning_rate': 0.00022858738706917786, 'weight_decay': 0.00012751140028309524, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 20:58:42,903 - INFO - Trial 844: Train MSE=4.9233841725758145, Train R²=0.18131079631192343
2024-10-31 20:58:42,904 - INFO - Trial 844: Test MSE=2.2875172070094516, Test R²=0.6278223821095058
2024-10-31 20:58:42,904 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:58:42,905 - INFO - Trial 844 finished with value: 2.2875172070094516 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7899443717138148, 'learning_rate': 0.00022858738706917786, 'weight_decay': 0.00012751140028309524, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 20:59:26,457 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7635847299161856, 'learning_rate': 0.0011637831797737261, 'weight_decay': 0.00018429842586986054, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 20:59:26,457 - INFO - Trial 845: Train MSE=2.115030829395567, Train R²=0.6472871473857335
2024-10-31 20:59:26,458 - INFO - Trial 845: Test MSE=2.2538966791970387, Test R²=0.6330480660711016
2024-10-31 20:59:26,458 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 20:59:26,459 - INFO - Trial 845 finished with value: 2.2538966791970387 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7635847299161856, 'learning_rate': 0.0011637831797737261, 'weight_decay': 0.00018429842586986054, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:00:11,103 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7757887797472894, 'learning_rate': 0.0013109110259679388, 'weight_decay': 0.00028161643447608114, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:00:11,103 - INFO - Trial 846: Train MSE=2.1804298630782535, Train R²=0.6374028878552573
2024-10-31 21:00:11,104 - INFO - Trial 846: Test MSE=2.297410777636937, Test R²=0.6259886281830924
2024-10-31 21:00:11,104 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:00:11,105 - INFO - Trial 846 finished with value: 2.297410777636937 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7757887797472894, 'learning_rate': 0.0013109110259679388, 'weight_decay': 0.00028161643447608114, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:00:55,234 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902035596783861, 'learning_rate': 0.0010082719326026531, 'weight_decay': 0.00017719426396986087, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:00:55,234 - INFO - Trial 847: Train MSE=2.3993203214236667, Train R²=0.6013964946780886
2024-10-31 21:00:55,234 - INFO - Trial 847: Test MSE=2.227750710078648, Test R²=0.6376020652907235
2024-10-31 21:00:55,234 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:00:55,236 - INFO - Trial 847 finished with value: 2.227750710078648 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902035596783861, 'learning_rate': 0.0010082719326026531, 'weight_decay': 0.00017719426396986087, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:01:39,306 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7846069729542755, 'learning_rate': 0.0013929469098973915, 'weight_decay': 0.0003618335110894736, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:01:39,306 - INFO - Trial 848: Train MSE=2.1882455902440205, Train R²=0.6354714035987854
2024-10-31 21:01:39,307 - INFO - Trial 848: Test MSE=2.2452635765075684, Test R²=0.6343994566372463
2024-10-31 21:01:39,307 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:01:39,308 - INFO - Trial 848 finished with value: 2.2452635765075684 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7846069729542755, 'learning_rate': 0.0013929469098973915, 'weight_decay': 0.0003618335110894736, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:02:23,317 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7730371789649503, 'learning_rate': 0.0010855806603932506, 'weight_decay': 0.0001381913161573807, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:02:23,317 - INFO - Trial 849: Train MSE=2.2464745215007236, Train R²=0.6256903069359916
2024-10-31 21:02:23,317 - INFO - Trial 849: Test MSE=2.217865824699402, Test R²=0.6390650272369385
2024-10-31 21:02:23,317 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:02:23,318 - INFO - Trial 849 finished with value: 2.217865824699402 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7730371789649503, 'learning_rate': 0.0010855806603932506, 'weight_decay': 0.0001381913161573807, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:03:06,875 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902645260829316, 'learning_rate': 0.0012470469870722786, 'weight_decay': 0.0003863037870468841, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 21:03:06,875 - INFO - Trial 850: Train MSE=2.398797162941524, Train R²=0.6003672012260982
2024-10-31 21:03:06,876 - INFO - Trial 850: Test MSE=2.2420478207724437, Test R²=0.6351625578744071
2024-10-31 21:03:06,876 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:03:06,876 - INFO - Trial 850 finished with value: 2.2420478207724437 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7902645260829316, 'learning_rate': 0.0012470469870722786, 'weight_decay': 0.0003863037870468841, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:03:49,990 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7108605221585347, 'learning_rate': 0.0014917140554383233, 'weight_decay': 0.0001062426402259186, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:03:49,990 - INFO - Trial 851: Train MSE=1.6474595069885254, Train R²=0.7257128315312522
2024-10-31 21:03:49,990 - INFO - Trial 851: Test MSE=2.301147324698312, Test R²=0.6254359228270394
2024-10-31 21:03:49,990 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:03:49,991 - INFO - Trial 851 finished with value: 2.301147324698312 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7108605221585347, 'learning_rate': 0.0014917140554383233, 'weight_decay': 0.0001062426402259186, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:04:26,166 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7676639958148926, 'learning_rate': 0.0007831068181590143, 'weight_decay': 0.000991321698474251, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 21:04:26,167 - INFO - Trial 852: Train MSE=3.1110169206346785, Train R²=0.4835060068539211
2024-10-31 21:04:26,167 - INFO - Trial 852: Test MSE=2.2569549083709717, Test R²=0.63022480905056
2024-10-31 21:04:26,167 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:04:26,168 - INFO - Trial 852 finished with value: 2.2569549083709717 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7676639958148926, 'learning_rate': 0.0007831068181590143, 'weight_decay': 0.000991321698474251, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:05:10,491 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7787180588461291, 'learning_rate': 0.0011685548684492383, 'weight_decay': 0.0003160952444273252, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:05:10,491 - INFO - Trial 853: Train MSE=2.2252881739820753, Train R²=0.6305112689733505
2024-10-31 21:05:10,491 - INFO - Trial 853: Test MSE=2.2305215086255754, Test R²=0.6369379588535854
2024-10-31 21:05:10,491 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:05:10,492 - INFO - Trial 853 finished with value: 2.2305215086255754 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7787180588461291, 'learning_rate': 0.0011685548684492383, 'weight_decay': 0.0003160952444273252, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:05:54,756 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.3726227384430097, 'learning_rate': 0.000957836534237754, 'weight_decay': 0.00014796374635766125, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:05:54,757 - INFO - Trial 854: Train MSE=0.6379777640104294, Train R²=0.8936200929539544
2024-10-31 21:05:54,757 - INFO - Trial 854: Test MSE=2.4466285024370467, Test R²=0.6017932721546718
2024-10-31 21:05:54,757 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:05:54,758 - INFO - Trial 854 finished with value: 2.4466285024370467 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.3726227384430097, 'learning_rate': 0.000957836534237754, 'weight_decay': 0.00014796374635766125, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:06:28,774 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7846207000783697, 'learning_rate': 0.0003039963874807637, 'weight_decay': 0.00027065419592011536, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:06:28,774 - INFO - Trial 855: Train MSE=3.235176886831011, Train R²=0.46161635645798277
2024-10-31 21:06:28,774 - INFO - Trial 855: Test MSE=2.3283704348972867, Test R²=0.621069610118866
2024-10-31 21:06:28,774 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:06:28,775 - INFO - Trial 855 finished with value: 2.3283704348972867 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7846207000783697, 'learning_rate': 0.0003039963874807637, 'weight_decay': 0.00027065419592011536, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:07:19,535 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7924319939653232, 'learning_rate': 0.001069370986110573, 'weight_decay': 0.0006611295105109812, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 21:07:19,535 - INFO - Trial 856: Train MSE=2.297892166035516, Train R²=0.615694774048669
2024-10-31 21:07:19,535 - INFO - Trial 856: Test MSE=2.241341769695282, Test R²=0.633537986448833
2024-10-31 21:07:19,536 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:07:19,537 - INFO - Trial 856 finished with value: 2.241341769695282 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7924319939653232, 'learning_rate': 0.001069370986110573, 'weight_decay': 0.0006611295105109812, 'batch_size': 256, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:07:59,797 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.76093452326502, 'learning_rate': 0.0016468884813366095, 'weight_decay': 0.0003330727965848228, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:07:59,797 - INFO - Trial 857: Train MSE=1.9405388576643807, Train R²=0.6770300482000623
2024-10-31 21:07:59,797 - INFO - Trial 857: Test MSE=2.234368392399379, Test R²=0.63643536397389
2024-10-31 21:07:59,798 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:07:59,799 - INFO - Trial 857 finished with value: 2.234368392399379 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.76093452326502, 'learning_rate': 0.0016468884813366095, 'weight_decay': 0.0003330727965848228, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:08:44,650 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7750009703461755, 'learning_rate': 0.001288253546637992, 'weight_decay': 0.0002911230215994839, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:08:44,650 - INFO - Trial 858: Train MSE=2.1313189012663707, Train R²=0.6451805830001831
2024-10-31 21:08:44,650 - INFO - Trial 858: Test MSE=2.2519868101392473, Test R²=0.6335258824484689
2024-10-31 21:08:44,651 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:08:44,652 - INFO - Trial 858 finished with value: 2.2519868101392473 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7750009703461755, 'learning_rate': 0.001288253546637992, 'weight_decay': 0.0002911230215994839, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:09:28,775 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7909017385158016, 'learning_rate': 0.0010066715972702075, 'weight_decay': 0.0003076396879033527, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:09:28,776 - INFO - Trial 859: Train MSE=2.384009267602648, Train R²=0.601978001849992
2024-10-31 21:09:28,776 - INFO - Trial 859: Test MSE=2.226146391459874, Test R²=0.6376747829573495
2024-10-31 21:09:28,776 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:09:28,777 - INFO - Trial 859 finished with value: 2.226146391459874 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7909017385158016, 'learning_rate': 0.0010066715972702075, 'weight_decay': 0.0003076396879033527, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:10:12,616 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7826566241333742, 'learning_rate': 0.0008619729134828457, 'weight_decay': 0.00027447037364574343, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:10:12,616 - INFO - Trial 860: Train MSE=2.4563372816358293, Train R²=0.59080799136843
2024-10-31 21:10:12,616 - INFO - Trial 860: Test MSE=2.241877692086356, Test R²=0.634960012776511
2024-10-31 21:10:12,616 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:10:12,617 - INFO - Trial 860 finished with value: 2.241877692086356 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7826566241333742, 'learning_rate': 0.0008619729134828457, 'weight_decay': 0.00027447037364574343, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:10:56,867 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7680483581929789, 'learning_rate': 0.0011463658271094563, 'weight_decay': 0.0003761569071993823, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:10:56,867 - INFO - Trial 861: Train MSE=2.1338983859334673, Train R²=0.6448292178767068
2024-10-31 21:10:56,867 - INFO - Trial 861: Test MSE=2.292200888906206, Test R²=0.6268942696707589
2024-10-31 21:10:56,867 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:10:56,868 - INFO - Trial 861 finished with value: 2.292200888906206 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7680483581929789, 'learning_rate': 0.0011463658271094563, 'weight_decay': 0.0003761569071993823, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:11:32,512 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7998467741925364, 'learning_rate': 0.0014444109938909623, 'weight_decay': 0.00035191981122350066, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:11:32,512 - INFO - Trial 862: Train MSE=3.028166106769017, Train R²=0.4957109753574644
2024-10-31 21:11:32,513 - INFO - Trial 862: Test MSE=2.494189500808716, Test R²=0.5941969326564244
2024-10-31 21:11:32,513 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:11:32,513 - INFO - Trial 862 finished with value: 2.494189500808716 and parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7998467741925364, 'learning_rate': 0.0014444109938909623, 'weight_decay': 0.00035191981122350066, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:12:47,711 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7557945103958227, 'learning_rate': 0.0012549931982443578, 'weight_decay': 0.0001221180403189851, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 21:12:47,711 - INFO - Trial 863: Train MSE=1.5446357684476035, Train R²=0.7373867764004639
2024-10-31 21:12:47,711 - INFO - Trial 863: Test MSE=2.324772839035307, Test R²=0.615901204092162
2024-10-31 21:12:47,711 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:12:47,712 - INFO - Trial 863 finished with value: 2.324772839035307 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7557945103958227, 'learning_rate': 0.0012549931982443578, 'weight_decay': 0.0001221180403189851, 'batch_size': 128, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:13:21,874 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.4926111407372375, 'learning_rate': 0.0009226905361782868, 'weight_decay': 0.00011635346874384637, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:13:21,875 - INFO - Trial 864: Train MSE=0.9149081196103778, Train R²=0.8472823777369091
2024-10-31 21:13:21,875 - INFO - Trial 864: Test MSE=2.3701251574925015, Test R²=0.6140596781458173
2024-10-31 21:13:21,875 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:13:21,876 - INFO - Trial 864 finished with value: 2.3701251574925015 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.4926111407372375, 'learning_rate': 0.0009226905361782868, 'weight_decay': 0.00011635346874384637, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:13:53,217 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998600632158938, 'learning_rate': 0.0010622084328366155, 'weight_decay': 0.000323646545132553, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:13:53,217 - INFO - Trial 865: Train MSE=2.4274855852127075, Train R²=0.5956596455403737
2024-10-31 21:13:53,217 - INFO - Trial 865: Test MSE=2.241122007369995, Test R²=0.6352451699120658
2024-10-31 21:13:53,217 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:13:53,218 - INFO - Trial 865 finished with value: 2.241122007369995 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998600632158938, 'learning_rate': 0.0010622084328366155, 'weight_decay': 0.000323646545132553, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:14:27,648 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7820156983035113, 'learning_rate': 0.0006597474186840297, 'weight_decay': 0.00026928152896247756, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:14:27,648 - INFO - Trial 866: Train MSE=2.7131778257233754, Train R²=0.5478658867733819
2024-10-31 21:14:27,648 - INFO - Trial 866: Test MSE=2.2364914076668874, Test R²=0.6360787068094526
2024-10-31 21:14:27,648 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:14:27,650 - INFO - Trial 866 finished with value: 2.2364914076668874 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7820156983035113, 'learning_rate': 0.0006597474186840297, 'weight_decay': 0.00026928152896247756, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:15:02,625 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7734452755526914, 'learning_rate': 0.0013617905501069126, 'weight_decay': 0.0002957625567120453, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:15:02,625 - INFO - Trial 867: Train MSE=2.5145040495055064, Train R²=0.5809079536369869
2024-10-31 21:15:02,625 - INFO - Trial 867: Test MSE=2.259735550199236, Test R²=0.6322337474141803
2024-10-31 21:15:02,625 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:15:02,627 - INFO - Trial 867 finished with value: 2.259735550199236 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7734452755526914, 'learning_rate': 0.0013617905501069126, 'weight_decay': 0.0002957625567120453, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:15:35,325 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7909669042892277, 'learning_rate': 0.001158546598480242, 'weight_decay': 0.0003103101887911179, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:15:35,325 - INFO - Trial 868: Train MSE=2.330050153391702, Train R²=0.6119773196322578
2024-10-31 21:15:35,325 - INFO - Trial 868: Test MSE=2.198304687227522, Test R²=0.6421103988374982
2024-10-31 21:15:35,326 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:15:35,327 - INFO - Trial 868 finished with value: 2.198304687227522 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7909669042892277, 'learning_rate': 0.001158546598480242, 'weight_decay': 0.0003103101887911179, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:16:06,927 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7910566033662548, 'learning_rate': 0.0011786158135167644, 'weight_decay': 0.00028281152938602075, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:16:06,928 - INFO - Trial 869: Train MSE=2.9437797410147533, Train R²=0.5103793506111417
2024-10-31 21:16:06,928 - INFO - Trial 869: Test MSE=2.2341013976505826, Test R²=0.6362361567361015
2024-10-31 21:16:06,928 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:16:06,929 - INFO - Trial 869 finished with value: 2.2341013976505826 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7910566033662548, 'learning_rate': 0.0011786158135167644, 'weight_decay': 0.00028281152938602075, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:16:39,403 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7832097802736298, 'learning_rate': 0.0012547002345635408, 'weight_decay': 0.0003042674590778728, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:16:39,403 - INFO - Trial 870: Train MSE=2.2908032834529877, Train R²=0.6179789645331246
2024-10-31 21:16:39,403 - INFO - Trial 870: Test MSE=2.2345334461757114, Test R²=0.6363962973867144
2024-10-31 21:16:39,403 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:16:39,405 - INFO - Trial 870 finished with value: 2.2345334461757114 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7832097802736298, 'learning_rate': 0.0012547002345635408, 'weight_decay': 0.0003042674590778728, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:17:12,478 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999102268070611, 'learning_rate': 0.0011710882118542247, 'weight_decay': 0.00015355923938580827, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:17:12,478 - INFO - Trial 871: Train MSE=2.41825418812888, Train R²=0.5975576766899654
2024-10-31 21:17:12,478 - INFO - Trial 871: Test MSE=2.2241924490247453, Test R²=0.6380980014801025
2024-10-31 21:17:12,478 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:17:12,479 - INFO - Trial 871 finished with value: 2.2241924490247453 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999102268070611, 'learning_rate': 0.0011710882118542247, 'weight_decay': 0.00015355923938580827, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:17:44,839 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7679135116299062, 'learning_rate': 0.0015653032137156553, 'weight_decay': 0.0002859664654106153, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:17:44,839 - INFO - Trial 872: Train MSE=2.00447170649256, Train R²=0.6668948318277087
2024-10-31 21:17:44,839 - INFO - Trial 872: Test MSE=2.267402717045375, Test R²=0.6307301436151777
2024-10-31 21:17:44,840 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:17:44,842 - INFO - Trial 872 finished with value: 2.267402717045375 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7679135116299062, 'learning_rate': 0.0015653032137156553, 'weight_decay': 0.0002859664654106153, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:18:16,595 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7912504898344892, 'learning_rate': 0.0013812813885135345, 'weight_decay': 0.0009452326088122204, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:18:16,596 - INFO - Trial 873: Train MSE=2.2983129705701555, Train R²=0.6176726434912
2024-10-31 21:18:16,596 - INFO - Trial 873: Test MSE=2.2310635021754672, Test R²=0.6369631631033761
2024-10-31 21:18:16,596 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:18:16,597 - INFO - Trial 873 finished with value: 2.2310635021754672 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7912504898344892, 'learning_rate': 0.0013812813885135345, 'weight_decay': 0.0009452326088122204, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:18:49,373 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7787534089459809, 'learning_rate': 0.001132166523598699, 'weight_decay': 0.00026576578035063773, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:18:49,373 - INFO - Trial 874: Train MSE=2.2507336182253703, Train R²=0.6261268343244281
2024-10-31 21:18:49,374 - INFO - Trial 874: Test MSE=2.2366283110209872, Test R²=0.6360028300966535
2024-10-31 21:18:49,374 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:18:49,376 - INFO - Trial 874 finished with value: 2.2366283110209872 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7787534089459809, 'learning_rate': 0.001132166523598699, 'weight_decay': 0.00026576578035063773, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:19:23,756 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7501276399051546, 'learning_rate': 0.0013285172048779917, 'weight_decay': 0.00030946834065952975, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:19:23,756 - INFO - Trial 875: Train MSE=1.9599696908678328, Train R²=0.674438306263515
2024-10-31 21:19:23,756 - INFO - Trial 875: Test MSE=2.2215013674327304, Test R²=0.6384786878313337
2024-10-31 21:19:23,757 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:19:23,760 - INFO - Trial 875 finished with value: 2.2215013674327304 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7501276399051546, 'learning_rate': 0.0013285172048779917, 'weight_decay': 0.00030946834065952975, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:19:56,345 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7896122084510431, 'learning_rate': 0.0012340342859662777, 'weight_decay': 0.00013894746375926447, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:19:56,345 - INFO - Trial 876: Train MSE=2.2821607845170155, Train R²=0.6198054062468665
2024-10-31 21:19:56,345 - INFO - Trial 876: Test MSE=2.2372208663395474, Test R²=0.6359723806381226
2024-10-31 21:19:56,345 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:19:56,347 - INFO - Trial 876 finished with value: 2.2372208663395474 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7896122084510431, 'learning_rate': 0.0012340342859662777, 'weight_decay': 0.00013894746375926447, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:20:23,383 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7763442679322851, 'learning_rate': 0.0010752922826987475, 'weight_decay': 0.00029869941582730806, 'batch_size': 1024, 'tree_depth': 12}
2024-10-31 21:20:23,383 - INFO - Trial 877: Train MSE=2.747427531651088, Train R²=0.5437540539673397
2024-10-31 21:20:23,383 - INFO - Trial 877: Test MSE=2.310775876045227, Test R²=0.6212431043386459
2024-10-31 21:20:23,383 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:20:23,384 - INFO - Trial 877 finished with value: 2.310775876045227 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7763442679322851, 'learning_rate': 0.0010752922826987475, 'weight_decay': 0.00029869941582730806, 'batch_size': 1024, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:20:56,467 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7896943263129671, 'learning_rate': 0.0015015109314935242, 'weight_decay': 0.00028260044396885683, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:20:56,467 - INFO - Trial 878: Train MSE=2.251908472606114, Train R²=0.6247572749853134
2024-10-31 21:20:56,467 - INFO - Trial 878: Test MSE=2.2313467264175415, Test R²=0.6367817521095276
2024-10-31 21:20:56,467 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:20:56,468 - INFO - Trial 878 finished with value: 2.2313467264175415 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7896943263129671, 'learning_rate': 0.0015015109314935242, 'weight_decay': 0.00028260044396885683, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:21:31,310 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7660905692789829, 'learning_rate': 0.0016780524199626185, 'weight_decay': 0.0008809760434697689, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:21:31,310 - INFO - Trial 879: Train MSE=1.5698260750089372, Train R²=0.7388556067432676
2024-10-31 21:21:31,310 - INFO - Trial 879: Test MSE=2.291210855756487, Test R²=0.6269846984318325
2024-10-31 21:21:31,310 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:21:31,311 - INFO - Trial 879 finished with value: 2.291210855756487 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7660905692789829, 'learning_rate': 0.0016780524199626185, 'weight_decay': 0.0008809760434697689, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:22:04,424 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5220665825299562, 'learning_rate': 0.0018726380853878422, 'weight_decay': 0.00026332532983530443, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:22:04,424 - INFO - Trial 880: Train MSE=0.8501029972519193, Train R²=0.8583274015358516
2024-10-31 21:22:04,424 - INFO - Trial 880: Test MSE=2.327352728162493, Test R²=0.6210262179374695
2024-10-31 21:22:04,424 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:22:04,426 - INFO - Trial 880 finished with value: 2.327352728162493 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5220665825299562, 'learning_rate': 0.0018726380853878422, 'weight_decay': 0.00026332532983530443, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:22:51,384 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.782260160304695, 'learning_rate': 0.0012972913680962357, 'weight_decay': 0.0003131972501260113, 'batch_size': 256, 'tree_depth': 12}
2024-10-31 21:22:51,384 - INFO - Trial 881: Train MSE=1.932023544396673, Train R²=0.6751215468559947
2024-10-31 21:22:51,385 - INFO - Trial 881: Test MSE=2.251637978213174, Test R²=0.6316146041665759
2024-10-31 21:22:51,385 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:22:51,386 - INFO - Trial 881 finished with value: 2.251637978213174 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.782260160304695, 'learning_rate': 0.0012972913680962357, 'weight_decay': 0.0003131972501260113, 'batch_size': 256, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:23:24,173 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.791959002988403, 'learning_rate': 0.0011262087158505543, 'weight_decay': 0.000295554900348934, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:23:24,173 - INFO - Trial 882: Train MSE=2.3803505982671465, Train R²=0.6041483325617654
2024-10-31 21:23:24,173 - INFO - Trial 882: Test MSE=2.240194865635463, Test R²=0.6355192576135907
2024-10-31 21:23:24,173 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:23:24,174 - INFO - Trial 882 finished with value: 2.240194865635463 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.791959002988403, 'learning_rate': 0.0011262087158505543, 'weight_decay': 0.000295554900348934, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:23:58,587 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7753509673836086, 'learning_rate': 0.0001865480439028316, 'weight_decay': 0.00027374020147664946, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:23:58,587 - INFO - Trial 883: Train MSE=5.723814232008798, Train R²=0.045240474598748345
2024-10-31 21:23:58,587 - INFO - Trial 883: Test MSE=2.8899081775120328, Test R²=0.5298522881099156
2024-10-31 21:23:58,587 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:23:58,589 - INFO - Trial 883 finished with value: 2.8899081775120328 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7753509673836086, 'learning_rate': 0.0001865480439028316, 'weight_decay': 0.00027374020147664946, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:24:30,279 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7830367144223623, 'learning_rate': 0.0010284167794834596, 'weight_decay': 0.00032119568358613906, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:24:30,279 - INFO - Trial 884: Train MSE=2.291964794908251, Train R²=0.6184971183538437
2024-10-31 21:24:30,279 - INFO - Trial 884: Test MSE=2.254414643560137, Test R²=0.6330521787915911
2024-10-31 21:24:30,279 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:24:30,280 - INFO - Trial 884 finished with value: 2.254414643560137 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7830367144223623, 'learning_rate': 0.0010284167794834596, 'weight_decay': 0.00032119568358613906, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:25:05,839 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.759131675514912, 'learning_rate': 0.0060465468306823335, 'weight_decay': 0.0002891861244488416, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:25:05,839 - INFO - Trial 885: Train MSE=1.8637324827057975, Train R²=0.6898753749472755
2024-10-31 21:25:05,839 - INFO - Trial 885: Test MSE=2.421107428414481, Test R²=0.6057796222823006
2024-10-31 21:25:05,839 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:25:05,840 - INFO - Trial 885 finished with value: 2.421107428414481 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.759131675514912, 'learning_rate': 0.0060465468306823335, 'weight_decay': 0.0002891861244488416, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:25:39,857 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7996860688597753, 'learning_rate': 0.0014138647606054527, 'weight_decay': 0.0007858078457742275, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:25:39,858 - INFO - Trial 886: Train MSE=2.314721473625728, Train R²=0.6142111420631409
2024-10-31 21:25:39,858 - INFO - Trial 886: Test MSE=2.2449244431086948, Test R²=0.6345630628722054
2024-10-31 21:25:39,858 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:25:39,859 - INFO - Trial 886 finished with value: 2.2449244431086948 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7996860688597753, 'learning_rate': 0.0014138647606054527, 'weight_decay': 0.0007858078457742275, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:26:12,100 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7692776423739288, 'learning_rate': 0.0012186500792318905, 'weight_decay': 0.00025908853055360445, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:26:12,100 - INFO - Trial 887: Train MSE=2.1119653838021413, Train R²=0.6484767092125756
2024-10-31 21:26:12,101 - INFO - Trial 887: Test MSE=2.2448374373572215, Test R²=0.6344667673110962
2024-10-31 21:26:12,101 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:26:12,102 - INFO - Trial 887 finished with value: 2.2448374373572215 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7692776423739288, 'learning_rate': 0.0012186500792318905, 'weight_decay': 0.00025908853055360445, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:27:29,596 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998905163989309, 'learning_rate': 0.002136766544222902, 'weight_decay': 0.00028036816847380454, 'batch_size': 128, 'tree_depth': 12}
2024-10-31 21:27:29,596 - INFO - Trial 888: Train MSE=1.9537016823887825, Train R²=0.6692258385675294
2024-10-31 21:27:29,597 - INFO - Trial 888: Test MSE=2.254182360001973, Test R²=0.627500404204641
2024-10-31 21:27:29,597 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:27:29,598 - INFO - Trial 888 finished with value: 2.254182360001973 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7998905163989309, 'learning_rate': 0.002136766544222902, 'weight_decay': 0.00028036816847380454, 'batch_size': 128, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:28:03,300 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7853005706211458, 'learning_rate': 0.0011384746472208945, 'weight_decay': 0.0003122070476330755, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:28:03,300 - INFO - Trial 889: Train MSE=2.0061267486640384, Train R²=0.6663310825824738
2024-10-31 21:28:03,300 - INFO - Trial 889: Test MSE=2.234780260494777, Test R²=0.636377922126225
2024-10-31 21:28:03,300 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:28:03,301 - INFO - Trial 889 finished with value: 2.234780260494777 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7853005706211458, 'learning_rate': 0.0011384746472208945, 'weight_decay': 0.0003122070476330755, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:28:35,283 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.743019371185605, 'learning_rate': 0.0013152125589298061, 'weight_decay': 0.00033483562287924494, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:28:35,283 - INFO - Trial 890: Train MSE=1.9500111724649156, Train R²=0.6747297197580338
2024-10-31 21:28:35,283 - INFO - Trial 890: Test MSE=2.2457659414836337, Test R²=0.6344517469406128
2024-10-31 21:28:35,283 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:28:35,284 - INFO - Trial 890 finished with value: 2.2457659414836337 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.743019371185605, 'learning_rate': 0.0013152125589298061, 'weight_decay': 0.00033483562287924494, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:29:08,371 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7766426531103303, 'learning_rate': 0.001057782934121705, 'weight_decay': 0.0002942171011782941, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 21:29:08,371 - INFO - Trial 891: Train MSE=2.903466062886374, Train R²=0.5162004019532885
2024-10-31 21:29:08,371 - INFO - Trial 891: Test MSE=2.2497380461011613, Test R²=0.6338002000536237
2024-10-31 21:29:08,372 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:29:08,372 - INFO - Trial 891 finished with value: 2.2497380461011613 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7766426531103303, 'learning_rate': 0.001057782934121705, 'weight_decay': 0.0002942171011782941, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:29:41,052 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7903283906159378, 'learning_rate': 0.0014459275423810026, 'weight_decay': 0.00026667051042412803, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:29:41,052 - INFO - Trial 892: Train MSE=2.2634324175970897, Train R²=0.623437626021249
2024-10-31 21:29:41,052 - INFO - Trial 892: Test MSE=2.2340629952294484, Test R²=0.6364236899784633
2024-10-31 21:29:41,052 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:29:41,054 - INFO - Trial 892 finished with value: 2.2340629952294484 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7903283906159378, 'learning_rate': 0.0014459275423810026, 'weight_decay': 0.00026667051042412803, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:30:14,383 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7572538881549398, 'learning_rate': 0.0011893233035814238, 'weight_decay': 0.00042275236222540796, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:30:14,383 - INFO - Trial 893: Train MSE=2.0337790080479214, Train R²=0.6619292071887425
2024-10-31 21:30:14,383 - INFO - Trial 893: Test MSE=2.2103838409696306, Test R²=0.6402409587587629
2024-10-31 21:30:14,384 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:30:14,385 - INFO - Trial 893 finished with value: 2.2103838409696306 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7572538881549398, 'learning_rate': 0.0011893233035814238, 'weight_decay': 0.00042275236222540796, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:30:45,958 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7465177371528854, 'learning_rate': 0.000992304247724882, 'weight_decay': 0.00039290526439219404, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:30:45,958 - INFO - Trial 894: Train MSE=2.059909680059978, Train R²=0.6574588801179614
2024-10-31 21:30:45,958 - INFO - Trial 894: Test MSE=2.2542361531938826, Test R²=0.6330363750457764
2024-10-31 21:30:45,958 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:30:45,959 - INFO - Trial 894 finished with value: 2.2542361531938826 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7465177371528854, 'learning_rate': 0.000992304247724882, 'weight_decay': 0.00039290526439219404, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:31:19,075 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7538462160587128, 'learning_rate': 0.0011829911734669706, 'weight_decay': 0.0004140804524142163, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:31:19,075 - INFO - Trial 895: Train MSE=1.984163271529334, Train R²=0.6703678688832692
2024-10-31 21:31:19,076 - INFO - Trial 895: Test MSE=2.2377958638327464, Test R²=0.6357505236353193
2024-10-31 21:31:19,076 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:31:19,077 - INFO - Trial 895 finished with value: 2.2377958638327464 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7538462160587128, 'learning_rate': 0.0011829911734669706, 'weight_decay': 0.0004140804524142163, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:31:58,683 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7279487972066555, 'learning_rate': 0.0010889900040918297, 'weight_decay': 0.0004161739927233845, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:31:58,683 - INFO - Trial 896: Train MSE=1.9066635029656547, Train R²=0.68239754651274
2024-10-31 21:31:58,683 - INFO - Trial 896: Test MSE=2.26931665624891, Test R²=0.6306602954864502
2024-10-31 21:31:58,683 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:31:58,684 - INFO - Trial 896 finished with value: 2.26931665624891 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7279487972066555, 'learning_rate': 0.0010889900040918297, 'weight_decay': 0.0004161739927233845, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:32:33,686 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7537259720724976, 'learning_rate': 0.0009925789557024202, 'weight_decay': 0.0004291924787307685, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:32:33,686 - INFO - Trial 897: Train MSE=2.5623870491981506, Train R²=0.5737162381410599
2024-10-31 21:32:33,686 - INFO - Trial 897: Test MSE=2.2471296957560947, Test R²=0.6342830317361015
2024-10-31 21:32:33,686 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:32:33,688 - INFO - Trial 897 finished with value: 2.2471296957560947 and parameters: {'hidden_layers': 3, 'hidden_units': 256, 'dropout_rate': 0.7537259720724976, 'learning_rate': 0.0009925789557024202, 'weight_decay': 0.0004291924787307685, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:33:05,672 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7611387128040534, 'learning_rate': 0.004417049242132898, 'weight_decay': 0.00043256894895333245, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:33:05,673 - INFO - Trial 898: Train MSE=1.9102819136210851, Train R²=0.6819190340382713
2024-10-31 21:33:05,673 - INFO - Trial 898: Test MSE=2.247886896133423, Test R²=0.6342851519584656
2024-10-31 21:33:05,673 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:33:05,674 - INFO - Trial 898 finished with value: 2.247886896133423 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7611387128040534, 'learning_rate': 0.004417049242132898, 'weight_decay': 0.00043256894895333245, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:33:42,324 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7590386654731603, 'learning_rate': 0.0012433462071309905, 'weight_decay': 0.0004787251193301084, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:33:42,324 - INFO - Trial 899: Train MSE=1.9652370725359236, Train R²=0.6733100414276123
2024-10-31 21:33:42,324 - INFO - Trial 899: Test MSE=2.2445007732936313, Test R²=0.6347044450896127
2024-10-31 21:33:42,325 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:33:42,326 - INFO - Trial 899 finished with value: 2.2445007732936313 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7590386654731603, 'learning_rate': 0.0012433462071309905, 'weight_decay': 0.0004787251193301084, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:34:14,176 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7354132937929584, 'learning_rate': 0.0011491991927788298, 'weight_decay': 0.00045062052771658277, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:34:14,177 - INFO - Trial 900: Train MSE=1.8923189342021942, Train R²=0.6843969055584499
2024-10-31 21:34:14,177 - INFO - Trial 900: Test MSE=2.2878425972802297, Test R²=0.6276658007076809
2024-10-31 21:34:14,177 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:34:14,179 - INFO - Trial 900 finished with value: 2.2878425972802297 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7354132937929584, 'learning_rate': 0.0011491991927788298, 'weight_decay': 0.00045062052771658277, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:34:47,259 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7422945694270333, 'learning_rate': 0.0017715314384835704, 'weight_decay': 0.0002559712159867014, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:34:47,259 - INFO - Trial 901: Train MSE=1.7902092507907323, Train R²=0.7022605751241956
2024-10-31 21:34:47,260 - INFO - Trial 901: Test MSE=2.285567113331386, Test R²=0.6279941626957485
2024-10-31 21:34:47,260 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:34:47,261 - INFO - Trial 901 finished with value: 2.285567113331386 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7422945694270333, 'learning_rate': 0.0017715314384835704, 'weight_decay': 0.0002559712159867014, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:35:12,562 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7635145347869134, 'learning_rate': 0.0015737584271216288, 'weight_decay': 0.000401121597103573, 'batch_size': 1024, 'tree_depth': 12}
2024-10-31 21:35:12,562 - INFO - Trial 902: Train MSE=2.3327591078622, Train R²=0.6119788459369114
2024-10-31 21:35:12,563 - INFO - Trial 902: Test MSE=2.243110239505768, Test R²=0.63235042989254
2024-10-31 21:35:12,563 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:35:12,564 - INFO - Trial 902 finished with value: 2.243110239505768 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7635145347869134, 'learning_rate': 0.0015737584271216288, 'weight_decay': 0.000401121597103573, 'batch_size': 1024, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:35:46,978 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6027732883939538, 'learning_rate': 0.0013225083345594464, 'weight_decay': 0.0003792226267928296, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:35:46,979 - INFO - Trial 903: Train MSE=1.1154987003122057, Train R²=0.8143272038017001
2024-10-31 21:35:46,979 - INFO - Trial 903: Test MSE=2.3259738513401578, Test R²=0.6212892021451678
2024-10-31 21:35:46,979 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:35:46,980 - INFO - Trial 903 finished with value: 2.3259738513401578 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6027732883939538, 'learning_rate': 0.0013225083345594464, 'weight_decay': 0.0003792226267928296, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:36:25,165 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7678736598126091, 'learning_rate': 0.0010147287854037482, 'weight_decay': 0.000461908248518602, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:36:25,165 - INFO - Trial 904: Train MSE=2.215364992618561, Train R²=0.6313385346106121
2024-10-31 21:36:25,165 - INFO - Trial 904: Test MSE=2.272224119731358, Test R²=0.6302183440753392
2024-10-31 21:36:25,166 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:36:25,167 - INFO - Trial 904 finished with value: 2.272224119731358 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7678736598126091, 'learning_rate': 0.0010147287854037482, 'weight_decay': 0.000461908248518602, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:37:03,747 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 1024, 'dropout_rate': 0.7555489465141332, 'learning_rate': 0.001096705174438556, 'weight_decay': 0.00042033085891534554, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:37:03,747 - INFO - Trial 905: Train MSE=1.848608523607254, Train R²=0.6927164601428168
2024-10-31 21:37:03,747 - INFO - Trial 905: Test MSE=2.3189447266714915, Test R²=0.6225772840636117
2024-10-31 21:37:03,747 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:37:03,749 - INFO - Trial 905 finished with value: 2.3189447266714915 and parameters: {'hidden_layers': 2, 'hidden_units': 1024, 'dropout_rate': 0.7555489465141332, 'learning_rate': 0.001096705174438556, 'weight_decay': 0.00042033085891534554, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:37:31,899 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7464330331286033, 'learning_rate': 0.007322275354172463, 'weight_decay': 0.00038646362328036404, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:37:31,899 - INFO - Trial 906: Train MSE=1.9493762339864458, Train R²=0.6757346178804126
2024-10-31 21:37:31,899 - INFO - Trial 906: Test MSE=2.21737916128976, Test R²=0.6389100551605225
2024-10-31 21:37:31,899 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:37:31,901 - INFO - Trial 906 finished with value: 2.21737916128976 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7464330331286033, 'learning_rate': 0.007322275354172463, 'weight_decay': 0.00038646362328036404, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:38:05,768 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7691591184648473, 'learning_rate': 0.0012308422743274898, 'weight_decay': 0.0004010968687999766, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:38:05,768 - INFO - Trial 907: Train MSE=2.124133071729115, Train R²=0.6471348362309592
2024-10-31 21:38:05,768 - INFO - Trial 907: Test MSE=2.2337537152426585, Test R²=0.6363711357116699
2024-10-31 21:38:05,768 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:38:05,770 - INFO - Trial 907 finished with value: 2.2337537152426585 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7691591184648473, 'learning_rate': 0.0012308422743274898, 'weight_decay': 0.0004010968687999766, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:38:45,462 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7720432848349073, 'learning_rate': 0.0014484317634809462, 'weight_decay': 0.00041334105607236264, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:38:45,462 - INFO - Trial 908: Train MSE=2.0779342353343964, Train R²=0.6534584952252251
2024-10-31 21:38:45,462 - INFO - Trial 908: Test MSE=2.247593198503767, Test R²=0.6341141377176557
2024-10-31 21:38:45,462 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:38:45,463 - INFO - Trial 908 finished with value: 2.247593198503767 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7720432848349073, 'learning_rate': 0.0014484317634809462, 'weight_decay': 0.00041334105607236264, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:39:40,882 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7776210381095967, 'learning_rate': 0.0013329471065870058, 'weight_decay': 0.0002745069244136111, 'batch_size': 256, 'tree_depth': 12}
2024-10-31 21:39:40,882 - INFO - Trial 909: Train MSE=1.890236279794148, Train R²=0.6837327065212386
2024-10-31 21:39:40,882 - INFO - Trial 909: Test MSE=2.245342697416033, Test R²=0.6330623584134238
2024-10-31 21:39:40,882 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:39:40,884 - INFO - Trial 909 finished with value: 2.245342697416033 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7776210381095967, 'learning_rate': 0.0013329471065870058, 'weight_decay': 0.0002745069244136111, 'batch_size': 256, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:40:18,885 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.425254697161045, 'learning_rate': 0.0009446463959622681, 'weight_decay': 0.0003688912265858921, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:40:18,885 - INFO - Trial 910: Train MSE=0.7511406370571682, Train R²=0.8747575687510627
2024-10-31 21:40:18,885 - INFO - Trial 910: Test MSE=2.4105982099260603, Test R²=0.6072458284241813
2024-10-31 21:40:18,885 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:40:18,887 - INFO - Trial 910 finished with value: 2.4105982099260603 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.425254697161045, 'learning_rate': 0.0009446463959622681, 'weight_decay': 0.0003688912265858921, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:40:56,422 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7611603612847407, 'learning_rate': 0.0011278112214695554, 'weight_decay': 0.0009224532054629991, 'batch_size': 512, 'tree_depth': 8}
2024-10-31 21:40:56,422 - INFO - Trial 911: Train MSE=2.5276681865964616, Train R²=0.5794864531074252
2024-10-31 21:40:56,422 - INFO - Trial 911: Test MSE=2.291987555367606, Test R²=0.6268932819366455
2024-10-31 21:40:56,422 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:40:56,423 - INFO - Trial 911 finished with value: 2.291987555367606 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7611603612847407, 'learning_rate': 0.0011278112214695554, 'weight_decay': 0.0009224532054629991, 'batch_size': 512, 'tree_depth': 8}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:41:34,925 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7798706906835347, 'learning_rate': 0.0038036447834644276, 'weight_decay': 0.00024974660022227777, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:41:34,925 - INFO - Trial 912: Train MSE=1.952190718480519, Train R²=0.6748421745640891
2024-10-31 21:41:34,925 - INFO - Trial 912: Test MSE=2.289183020591736, Test R²=0.6272735680852618
2024-10-31 21:41:34,926 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:41:34,926 - INFO - Trial 912 finished with value: 2.289183020591736 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7798706906835347, 'learning_rate': 0.0038036447834644276, 'weight_decay': 0.00024974660022227777, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:42:18,056 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7691115160089724, 'learning_rate': 0.0010340160077484091, 'weight_decay': 0.0002624211065271652, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:42:18,057 - INFO - Trial 913: Train MSE=2.0046090270791734, Train R²=0.6661006403820855
2024-10-31 21:42:18,057 - INFO - Trial 913: Test MSE=2.246411681175232, Test R²=0.6343096664973668
2024-10-31 21:42:18,057 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:42:18,057 - INFO - Trial 913 finished with value: 2.246411681175232 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7691115160089724, 'learning_rate': 0.0010340160077484091, 'weight_decay': 0.0002624211065271652, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:43:50,458 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.508815640894981, 'learning_rate': 0.0020821068845678086, 'weight_decay': 0.000992873742098226, 'batch_size': 128, 'tree_depth': 12}
2024-10-31 21:43:50,458 - INFO - Trial 914: Train MSE=1.3521566529359137, Train R²=0.7711132349712508
2024-10-31 21:43:50,458 - INFO - Trial 914: Test MSE=2.414038347346442, Test R²=0.5996367718492236
2024-10-31 21:43:50,458 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:43:50,460 - INFO - Trial 914 finished with value: 2.414038347346442 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.508815640894981, 'learning_rate': 0.0020821068845678086, 'weight_decay': 0.000992873742098226, 'batch_size': 128, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:44:28,904 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.749608851311991, 'learning_rate': 0.0012429459238741845, 'weight_decay': 0.0002783511202045474, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:44:28,904 - INFO - Trial 915: Train MSE=1.9559940184865678, Train R²=0.6736275724002293
2024-10-31 21:44:28,904 - INFO - Trial 915: Test MSE=2.2570297036852156, Test R²=0.6325039182390485
2024-10-31 21:44:28,904 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:44:28,905 - INFO - Trial 915 finished with value: 2.2570297036852156 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.749608851311991, 'learning_rate': 0.0012429459238741845, 'weight_decay': 0.0002783511202045474, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:45:08,512 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999582559115407, 'learning_rate': 0.005128215570538928, 'weight_decay': 0.0002896489046023407, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:45:08,512 - INFO - Trial 916: Train MSE=2.0968518214566365, Train R²=0.6519035995006561
2024-10-31 21:45:08,512 - INFO - Trial 916: Test MSE=2.2340275389807567, Test R²=0.6364415884017944
2024-10-31 21:45:08,512 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:45:08,513 - INFO - Trial 916 finished with value: 2.2340275389807567 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999582559115407, 'learning_rate': 0.005128215570538928, 'weight_decay': 0.0002896489046023407, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:45:47,579 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7850257598192987, 'learning_rate': 0.0014239377182426354, 'weight_decay': 0.0002679114779538449, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:45:47,579 - INFO - Trial 917: Train MSE=2.1460240951606204, Train R²=0.642623211656298
2024-10-31 21:45:47,579 - INFO - Trial 917: Test MSE=2.241972599710737, Test R²=0.6350141848836627
2024-10-31 21:45:47,579 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:45:47,581 - INFO - Trial 917 finished with value: 2.241972599710737 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7850257598192987, 'learning_rate': 0.0014239377182426354, 'weight_decay': 0.0002679114779538449, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:46:24,993 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7740776411564889, 'learning_rate': 0.0015873824106232665, 'weight_decay': 0.00025547916252239715, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:46:24,994 - INFO - Trial 918: Train MSE=2.525472513266972, Train R²=0.5792499078171593
2024-10-31 21:46:24,994 - INFO - Trial 918: Test MSE=2.249915225165231, Test R²=0.6338340810367039
2024-10-31 21:46:24,994 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:46:24,996 - INFO - Trial 918 finished with value: 2.249915225165231 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7740776411564889, 'learning_rate': 0.0015873824106232665, 'weight_decay': 0.00025547916252239715, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:46:58,624 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7841822325980797, 'learning_rate': 0.0011502944228736754, 'weight_decay': 0.0003716397764178745, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 21:46:58,624 - INFO - Trial 919: Train MSE=2.4882509538105557, Train R²=0.5864726603031158
2024-10-31 21:46:58,624 - INFO - Trial 919: Test MSE=2.2310825756617954, Test R²=0.636995792388916
2024-10-31 21:46:58,625 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:46:58,626 - INFO - Trial 919 finished with value: 2.2310825756617954 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7841822325980797, 'learning_rate': 0.0011502944228736754, 'weight_decay': 0.0003716397764178745, 'batch_size': 512, 'tree_depth': 9}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:47:28,105 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7909055169028394, 'learning_rate': 0.0009435314395480394, 'weight_decay': 0.0004740843338362376, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:47:28,106 - INFO - Trial 920: Train MSE=2.507939398288727, Train R²=0.5822530495268958
2024-10-31 21:47:28,106 - INFO - Trial 920: Test MSE=2.2194965396608626, Test R²=0.6387102007865906
2024-10-31 21:47:28,106 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:47:28,107 - INFO - Trial 920 finished with value: 2.2194965396608626 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7909055169028394, 'learning_rate': 0.0009435314395480394, 'weight_decay': 0.0004740843338362376, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:47:58,045 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.763883777219769, 'learning_rate': 0.0010772176812237839, 'weight_decay': 0.00043210397548722255, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:47:58,045 - INFO - Trial 921: Train MSE=2.1674553964819228, Train R²=0.6390320956707001
2024-10-31 21:47:58,045 - INFO - Trial 921: Test MSE=2.2563183307647705, Test R²=0.6327192187309265
2024-10-31 21:47:58,046 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:47:58,047 - INFO - Trial 921 finished with value: 2.2563183307647705 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.763883777219769, 'learning_rate': 0.0010772176812237839, 'weight_decay': 0.00043210397548722255, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:48:33,553 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.777218997492951, 'learning_rate': 0.006494525855640676, 'weight_decay': 0.0003931634850527801, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:48:33,553 - INFO - Trial 922: Train MSE=1.9974179821355003, Train R²=0.6679047367402485
2024-10-31 21:48:33,553 - INFO - Trial 922: Test MSE=2.2432261875697543, Test R²=0.6347904205322266
2024-10-31 21:48:33,553 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:48:33,554 - INFO - Trial 922 finished with value: 2.2432261875697543 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.777218997492951, 'learning_rate': 0.006494525855640676, 'weight_decay': 0.0003931634850527801, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:49:15,170 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7911854005163411, 'learning_rate': 0.001327430590067634, 'weight_decay': 0.00024403871069170454, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 21:49:15,170 - INFO - Trial 923: Train MSE=2.2848805274282182, Train R²=0.6195215923445565
2024-10-31 21:49:15,170 - INFO - Trial 923: Test MSE=2.211993064199175, Test R²=0.6399859019688198
2024-10-31 21:49:15,170 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:49:15,172 - INFO - Trial 923 finished with value: 2.211993064199175 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7911854005163411, 'learning_rate': 0.001327430590067634, 'weight_decay': 0.00024403871069170454, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:49:57,143 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7556894325307905, 'learning_rate': 0.0012345865082223745, 'weight_decay': 0.0002779807377325375, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:49:57,143 - INFO - Trial 924: Train MSE=2.026008984872273, Train R²=0.662218668631145
2024-10-31 21:49:57,143 - INFO - Trial 924: Test MSE=2.2098147698811124, Test R²=0.6403660603931972
2024-10-31 21:49:57,143 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:49:57,145 - INFO - Trial 924 finished with value: 2.2098147698811124 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7556894325307905, 'learning_rate': 0.0012345865082223745, 'weight_decay': 0.0002779807377325375, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:50:36,091 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7336139024797655, 'learning_rate': 0.0015382506903218276, 'weight_decay': 0.0002996930410660517, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:50:36,091 - INFO - Trial 925: Train MSE=1.715486194406237, Train R²=0.7147942589862006
2024-10-31 21:50:36,091 - INFO - Trial 925: Test MSE=2.255706889288766, Test R²=0.6326407449586051
2024-10-31 21:50:36,091 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:50:36,092 - INFO - Trial 925 finished with value: 2.255706889288766 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7336139024797655, 'learning_rate': 0.0015382506903218276, 'weight_decay': 0.0002996930410660517, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:51:13,986 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.743270996196352, 'learning_rate': 0.0017701533837300052, 'weight_decay': 0.0002814481752113379, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:51:13,986 - INFO - Trial 926: Train MSE=1.798772122178759, Train R²=0.7005456302847181
2024-10-31 21:51:13,986 - INFO - Trial 926: Test MSE=2.261030844279698, Test R²=0.6319121973855155
2024-10-31 21:51:13,986 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:51:13,987 - INFO - Trial 926 finished with value: 2.261030844279698 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.743270996196352, 'learning_rate': 0.0017701533837300052, 'weight_decay': 0.0002814481752113379, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:51:44,058 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7216579824984232, 'learning_rate': 0.0013356259124515015, 'weight_decay': 0.00029064541355249495, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 21:51:44,058 - INFO - Trial 927: Train MSE=2.0605731180735996, Train R²=0.6577772370406559
2024-10-31 21:51:44,058 - INFO - Trial 927: Test MSE=2.2443453073501587, Test R²=0.6321086585521698
2024-10-31 21:51:44,058 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:51:44,059 - INFO - Trial 927 finished with value: 2.2443453073501587 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7216579824984232, 'learning_rate': 0.0013356259124515015, 'weight_decay': 0.00029064541355249495, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:52:19,495 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 1024, 'dropout_rate': 0.7414151384520954, 'learning_rate': 0.001242678769618816, 'weight_decay': 0.00027875523575073566, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:52:19,495 - INFO - Trial 928: Train MSE=1.6801381707191467, Train R²=0.7194700922284808
2024-10-31 21:52:19,495 - INFO - Trial 928: Test MSE=2.3329812458583286, Test R²=0.6203064833368573
2024-10-31 21:52:19,495 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:52:19,496 - INFO - Trial 928 finished with value: 2.3329812458583286 and parameters: {'hidden_layers': 2, 'hidden_units': 1024, 'dropout_rate': 0.7414151384520954, 'learning_rate': 0.001242678769618816, 'weight_decay': 0.00027875523575073566, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:52:58,899 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5367150292005118, 'learning_rate': 0.0012099490461457655, 'weight_decay': 0.0006289959130252503, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:52:58,899 - INFO - Trial 929: Train MSE=0.9651146807840892, Train R²=0.8393321335315704
2024-10-31 21:52:58,899 - INFO - Trial 929: Test MSE=2.3984429836273193, Test R²=0.6094130192484174
2024-10-31 21:52:58,899 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:52:58,900 - INFO - Trial 929 finished with value: 2.3984429836273193 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.5367150292005118, 'learning_rate': 0.0012099490461457655, 'weight_decay': 0.0006289959130252503, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:53:52,855 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7510638464050399, 'learning_rate': 0.0014489169830297298, 'weight_decay': 0.00029539963662208497, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 21:53:52,855 - INFO - Trial 930: Train MSE=1.7465785252196449, Train R²=0.7071209784064975
2024-10-31 21:53:52,855 - INFO - Trial 930: Test MSE=2.2613971744264876, Test R²=0.630496369940894
2024-10-31 21:53:52,855 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:53:52,857 - INFO - Trial 930 finished with value: 2.2613971744264876 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7510638464050399, 'learning_rate': 0.0014489169830297298, 'weight_decay': 0.00029539963662208497, 'batch_size': 256, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:54:26,247 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7392384773496402, 'learning_rate': 0.002305844357036088, 'weight_decay': 0.00030064687812018947, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 21:54:26,247 - INFO - Trial 931: Train MSE=1.8268172570637293, Train R²=0.6962507537433079
2024-10-31 21:54:26,247 - INFO - Trial 931: Test MSE=2.209703411374773, Test R²=0.6403602276529584
2024-10-31 21:54:26,247 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:54:26,248 - INFO - Trial 931 finished with value: 2.209703411374773 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7392384773496402, 'learning_rate': 0.002305844357036088, 'weight_decay': 0.00030064687812018947, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:55:04,030 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7264692411301238, 'learning_rate': 0.002159948271000371, 'weight_decay': 0.0002726094663058622, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 21:55:04,030 - INFO - Trial 932: Train MSE=1.7542914875916071, Train R²=0.7073508990662438
2024-10-31 21:55:04,030 - INFO - Trial 932: Test MSE=2.2809801442282542, Test R²=0.62857357944761
2024-10-31 21:55:04,030 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:55:04,031 - INFO - Trial 932 finished with value: 2.2809801442282542 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7264692411301238, 'learning_rate': 0.002159948271000371, 'weight_decay': 0.0002726094663058622, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:55:40,579 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7508478153999343, 'learning_rate': 0.002322582895367742, 'weight_decay': 0.00030255117764603837, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 21:55:40,579 - INFO - Trial 933: Train MSE=2.0905675164290836, Train R²=0.6511379608086177
2024-10-31 21:55:40,579 - INFO - Trial 933: Test MSE=2.278776134763445, Test R²=0.6291806527546474
2024-10-31 21:55:40,579 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:55:40,580 - INFO - Trial 933 finished with value: 2.278776134763445 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7508478153999343, 'learning_rate': 0.002322582895367742, 'weight_decay': 0.00030255117764603837, 'batch_size': 512, 'tree_depth': 9}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:56:17,522 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7494989685096711, 'learning_rate': 0.0023120908024902563, 'weight_decay': 0.00028542504573570885, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 21:56:17,522 - INFO - Trial 934: Train MSE=1.8632941246032715, Train R²=0.6891333929130009
2024-10-31 21:56:17,522 - INFO - Trial 934: Test MSE=2.2624553612300327, Test R²=0.6317577872957502
2024-10-31 21:56:17,522 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:56:17,523 - INFO - Trial 934 finished with value: 2.2624553612300327 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7494989685096711, 'learning_rate': 0.0023120908024902563, 'weight_decay': 0.00028542504573570885, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:56:54,338 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7386198802266709, 'learning_rate': 0.002263245432456421, 'weight_decay': 0.000307212067469264, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 21:56:54,338 - INFO - Trial 935: Train MSE=1.8508883629526411, Train R²=0.6918118127754757
2024-10-31 21:56:54,339 - INFO - Trial 935: Test MSE=2.2729121957506453, Test R²=0.6299979771886554
2024-10-31 21:56:54,339 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:56:54,340 - INFO - Trial 935 finished with value: 2.2729121957506453 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7386198802266709, 'learning_rate': 0.002263245432456421, 'weight_decay': 0.000307212067469264, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:57:26,357 - INFO - Parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7437213403813357, 'learning_rate': 0.0019756116199858686, 'weight_decay': 0.00028280444085744175, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 21:57:26,357 - INFO - Trial 936: Train MSE=2.393068185874394, Train R²=0.6018222208533969
2024-10-31 21:57:26,357 - INFO - Trial 936: Test MSE=2.307276657649449, Test R²=0.6242518424987793
2024-10-31 21:57:26,357 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:57:26,359 - INFO - Trial 936 finished with value: 2.307276657649449 and parameters: {'hidden_layers': 4, 'hidden_units': 256, 'dropout_rate': 0.7437213403813357, 'learning_rate': 0.0019756116199858686, 'weight_decay': 0.00028280444085744175, 'batch_size': 512, 'tree_depth': 9}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:57:57,957 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7302601106818994, 'learning_rate': 0.0026701906820950686, 'weight_decay': 0.0007222077893664573, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 21:57:57,957 - INFO - Trial 937: Train MSE=1.72253440959113, Train R²=0.7136647360665458
2024-10-31 21:57:57,957 - INFO - Trial 937: Test MSE=2.278915677751814, Test R²=0.6290520599910191
2024-10-31 21:57:57,957 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:57:57,958 - INFO - Trial 937 finished with value: 2.278915677751814 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7302601106818994, 'learning_rate': 0.0026701906820950686, 'weight_decay': 0.0007222077893664573, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 21:58:28,109 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.743443527175118, 'learning_rate': 0.0025040075994304358, 'weight_decay': 0.0001617895472195971, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 21:58:28,109 - INFO - Trial 938: Train MSE=1.8386785345418113, Train R²=0.6939796400921685
2024-10-31 21:58:28,109 - INFO - Trial 938: Test MSE=2.30912070614951, Test R²=0.624167834009443
2024-10-31 21:58:28,109 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 21:58:28,110 - INFO - Trial 938 finished with value: 2.30912070614951 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.743443527175118, 'learning_rate': 0.0025040075994304358, 'weight_decay': 0.0001617895472195971, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:00:05,613 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7520273242887571, 'learning_rate': 0.001994622433054498, 'weight_decay': 0.0002959714345860152, 'batch_size': 128, 'tree_depth': 10}
2024-10-31 22:00:05,613 - INFO - Trial 939: Train MSE=1.7605594002774783, Train R²=0.7029044495097229
2024-10-31 22:00:05,613 - INFO - Trial 939: Test MSE=2.3279285558632443, Test R²=0.6155598035880497
2024-10-31 22:00:05,613 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:00:05,614 - INFO - Trial 939 finished with value: 2.3279285558632443 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7520273242887571, 'learning_rate': 0.001994622433054498, 'weight_decay': 0.0002959714345860152, 'batch_size': 128, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:00:45,852 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.726380115519185, 'learning_rate': 0.002168045465262931, 'weight_decay': 0.00027277102977626267, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:00:45,852 - INFO - Trial 940: Train MSE=1.630174687930516, Train R²=0.7282419289861407
2024-10-31 22:00:45,852 - INFO - Trial 940: Test MSE=2.2510413101741245, Test R²=0.6335432188851493
2024-10-31 22:00:45,852 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:00:45,854 - INFO - Trial 940 finished with value: 2.2510413101741245 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.726380115519185, 'learning_rate': 0.002168045465262931, 'weight_decay': 0.00027277102977626267, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:01:17,257 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7328003112166918, 'learning_rate': 0.0017390208819366832, 'weight_decay': 0.0008693997355637456, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 22:01:17,258 - INFO - Trial 941: Train MSE=1.8559653631278448, Train R²=0.6908711812325886
2024-10-31 22:01:17,258 - INFO - Trial 941: Test MSE=2.2855285576411655, Test R²=0.6278442995888847
2024-10-31 22:01:17,258 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:01:17,259 - INFO - Trial 941 finished with value: 2.2855285576411655 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7328003112166918, 'learning_rate': 0.0017390208819366832, 'weight_decay': 0.0008693997355637456, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:01:52,404 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.735635502544693, 'learning_rate': 0.002086901116822448, 'weight_decay': 0.00035134671784964783, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:01:52,404 - INFO - Trial 942: Train MSE=2.172583963189806, Train R²=0.6377771326473781
2024-10-31 22:01:52,404 - INFO - Trial 942: Test MSE=2.2679607357297624, Test R²=0.6309758424758911
2024-10-31 22:01:52,404 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:01:52,406 - INFO - Trial 942 finished with value: 2.2679607357297624 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.735635502544693, 'learning_rate': 0.002086901116822448, 'weight_decay': 0.00035134671784964783, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:02:26,607 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.754855562336523, 'learning_rate': 0.002559377336254925, 'weight_decay': 0.0003080762311836935, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 22:02:26,607 - INFO - Trial 943: Train MSE=1.9353921583720617, Train R²=0.6774359451872962
2024-10-31 22:02:26,608 - INFO - Trial 943: Test MSE=2.250600610460554, Test R²=0.6336239491190229
2024-10-31 22:02:26,608 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:02:26,609 - INFO - Trial 943 finished with value: 2.250600610460554 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.754855562336523, 'learning_rate': 0.002559377336254925, 'weight_decay': 0.0003080762311836935, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:03:06,586 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.758083653184665, 'learning_rate': 0.002241571398336257, 'weight_decay': 0.00028793055254868805, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:03:06,586 - INFO - Trial 944: Train MSE=1.8477082337651933, Train R²=0.6922519249575478
2024-10-31 22:03:06,587 - INFO - Trial 944: Test MSE=2.2817853348595754, Test R²=0.6287679331643241
2024-10-31 22:03:06,587 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:03:06,588 - INFO - Trial 944 finished with value: 2.2817853348595754 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.758083653184665, 'learning_rate': 0.002241571398336257, 'weight_decay': 0.00028793055254868805, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:03:47,149 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7591946919429664, 'learning_rate': 0.002517244684418391, 'weight_decay': 0.0002667794999788109, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 22:03:47,149 - INFO - Trial 945: Train MSE=1.913091003894806, Train R²=0.6815853267908096
2024-10-31 22:03:47,149 - INFO - Trial 945: Test MSE=2.242871710232326, Test R²=0.6350460733686175
2024-10-31 22:03:47,149 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:03:47,151 - INFO - Trial 945 finished with value: 2.242871710232326 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7591946919429664, 'learning_rate': 0.002517244684418391, 'weight_decay': 0.0002667794999788109, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:04:27,708 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7200582685781691, 'learning_rate': 0.00040955573728662404, 'weight_decay': 0.00031695987885221806, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:04:27,708 - INFO - Trial 946: Train MSE=2.841999888420105, Train R²=0.5267975628376007
2024-10-31 22:04:27,708 - INFO - Trial 946: Test MSE=2.2679147720336914, Test R²=0.6308942096573966
2024-10-31 22:04:27,708 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:04:27,709 - INFO - Trial 946 finished with value: 2.2679147720336914 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7200582685781691, 'learning_rate': 0.00040955573728662404, 'weight_decay': 0.00031695987885221806, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:05:04,028 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.46616672776907064, 'learning_rate': 0.0018481558628601433, 'weight_decay': 0.0002698791093994065, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:05:04,029 - INFO - Trial 947: Train MSE=0.7842959101711001, Train R²=0.8691403248480388
2024-10-31 22:05:04,029 - INFO - Trial 947: Test MSE=2.4289399215153287, Test R²=0.6044882025037494
2024-10-31 22:05:04,029 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:05:04,031 - INFO - Trial 947 finished with value: 2.4289399215153287 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.46616672776907064, 'learning_rate': 0.0018481558628601433, 'weight_decay': 0.0002698791093994065, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:05:39,453 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7438824341410426, 'learning_rate': 0.0019198298130354426, 'weight_decay': 0.0002817963458042197, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 22:05:39,454 - INFO - Trial 948: Train MSE=1.8698826943125044, Train R²=0.6886012298720223
2024-10-31 22:05:39,454 - INFO - Trial 948: Test MSE=2.268188544682094, Test R²=0.6308961425508771
2024-10-31 22:05:39,454 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:05:39,457 - INFO - Trial 948 finished with value: 2.268188544682094 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7438824341410426, 'learning_rate': 0.0019198298130354426, 'weight_decay': 0.0002817963458042197, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:06:20,398 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7580200618653675, 'learning_rate': 0.001563555514929734, 'weight_decay': 0.00039422782564741484, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:06:20,398 - INFO - Trial 949: Train MSE=1.9536492654255457, Train R²=0.6742883729083198
2024-10-31 22:06:20,398 - INFO - Trial 949: Test MSE=2.271214859826224, Test R²=0.630361659186227
2024-10-31 22:06:20,398 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:06:20,399 - INFO - Trial 949 finished with value: 2.271214859826224 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7580200618653675, 'learning_rate': 0.001563555514929734, 'weight_decay': 0.00039422782564741484, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:06:54,857 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7382430869025017, 'learning_rate': 0.001659825112091316, 'weight_decay': 0.0006881869881981146, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:06:54,857 - INFO - Trial 950: Train MSE=1.8081784674099513, Train R²=0.6990767398050853
2024-10-31 22:06:54,857 - INFO - Trial 950: Test MSE=2.275463972772871, Test R²=0.6295011384146554
2024-10-31 22:06:54,857 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:06:54,858 - INFO - Trial 950 finished with value: 2.275463972772871 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7382430869025017, 'learning_rate': 0.001659825112091316, 'weight_decay': 0.0006881869881981146, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:07:20,217 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7641754163243492, 'learning_rate': 0.001411070145494527, 'weight_decay': 0.00029903024460537056, 'batch_size': 1024, 'tree_depth': 11}
2024-10-31 22:07:20,217 - INFO - Trial 951: Train MSE=2.389441660472325, Train R²=0.6024082856518882
2024-10-31 22:07:20,217 - INFO - Trial 951: Test MSE=2.2406347393989563, Test R²=0.6326712220907211
2024-10-31 22:07:20,217 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:07:20,218 - INFO - Trial 951 finished with value: 2.2406347393989563 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7641754163243492, 'learning_rate': 0.001411070145494527, 'weight_decay': 0.00029903024460537056, 'batch_size': 1024, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:07:49,431 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7646651226109789, 'learning_rate': 0.0012945549687026817, 'weight_decay': 0.000820830211981855, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:07:49,431 - INFO - Trial 952: Train MSE=2.071933993271419, Train R²=0.6541739233902523
2024-10-31 22:07:49,431 - INFO - Trial 952: Test MSE=2.240729366030012, Test R²=0.6352214983531407
2024-10-31 22:07:49,431 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:07:49,433 - INFO - Trial 952 finished with value: 2.240729366030012 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7646651226109789, 'learning_rate': 0.0012945549687026817, 'weight_decay': 0.000820830211981855, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:08:26,351 - INFO - Parameters: {'hidden_layers': 3, 'hidden_units': 1024, 'dropout_rate': 0.5819794747449224, 'learning_rate': 0.0014637198521669, 'weight_decay': 0.0006006793792223565, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:08:26,351 - INFO - Trial 953: Train MSE=0.9517697457756314, Train R²=0.841652193239757
2024-10-31 22:08:26,351 - INFO - Trial 953: Test MSE=2.3575983388083324, Test R²=0.6162534441266742
2024-10-31 22:08:26,351 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:08:26,355 - INFO - Trial 953 finished with value: 2.3575983388083324 and parameters: {'hidden_layers': 3, 'hidden_units': 1024, 'dropout_rate': 0.5819794747449224, 'learning_rate': 0.0014637198521669, 'weight_decay': 0.0006006793792223565, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:08:55,752 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7518581029685837, 'learning_rate': 0.002378266630370401, 'weight_decay': 0.00035962057664272375, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 22:08:55,752 - INFO - Trial 954: Train MSE=1.8433111224855696, Train R²=0.6935500460011619
2024-10-31 22:08:55,753 - INFO - Trial 954: Test MSE=2.257190431867327, Test R²=0.6326540878840855
2024-10-31 22:08:55,753 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:08:55,754 - INFO - Trial 954 finished with value: 2.257190431867327 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7518581029685837, 'learning_rate': 0.002378266630370401, 'weight_decay': 0.00035962057664272375, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:09:36,527 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7059602266719354, 'learning_rate': 0.00134299731276264, 'weight_decay': 0.0009521116890473291, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 22:09:36,527 - INFO - Trial 955: Train MSE=1.6015034254108156, Train R²=0.7320728525519371
2024-10-31 22:09:36,527 - INFO - Trial 955: Test MSE=2.315081630434309, Test R²=0.6213165181023734
2024-10-31 22:09:36,527 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:09:36,528 - INFO - Trial 955 finished with value: 2.315081630434309 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7059602266719354, 'learning_rate': 0.00134299731276264, 'weight_decay': 0.0009521116890473291, 'batch_size': 256, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:10:04,898 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7600485787101919, 'learning_rate': 0.001218340129077458, 'weight_decay': 0.00032501238803831156, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:10:04,898 - INFO - Trial 956: Train MSE=2.037590746368681, Train R²=0.6606818586587906
2024-10-31 22:10:04,898 - INFO - Trial 956: Test MSE=2.2376455579485213, Test R²=0.6359190004212516
2024-10-31 22:10:04,898 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:10:04,900 - INFO - Trial 956 finished with value: 2.2376455579485213 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7600485787101919, 'learning_rate': 0.001218340129077458, 'weight_decay': 0.00032501238803831156, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:10:34,756 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7166609919765755, 'learning_rate': 0.003239160216210038, 'weight_decay': 0.0003410378101130224, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:10:34,756 - INFO - Trial 957: Train MSE=1.585518547466823, Train R²=0.7361997451101031
2024-10-31 22:10:34,756 - INFO - Trial 957: Test MSE=2.2651523181370328, Test R²=0.6312524931771415
2024-10-31 22:10:34,756 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:10:34,757 - INFO - Trial 957 finished with value: 2.2651523181370328 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7166609919765755, 'learning_rate': 0.003239160216210038, 'weight_decay': 0.0003410378101130224, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:11:04,354 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.767508459133409, 'learning_rate': 0.002022070353534799, 'weight_decay': 0.00028909696592438347, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:11:04,355 - INFO - Trial 958: Train MSE=1.9926561287471227, Train R²=0.6682613470724651
2024-10-31 22:11:04,355 - INFO - Trial 958: Test MSE=2.2699573721204485, Test R²=0.6302998406546456
2024-10-31 22:11:04,355 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:11:04,356 - INFO - Trial 958 finished with value: 2.2699573721204485 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.767508459133409, 'learning_rate': 0.002022070353534799, 'weight_decay': 0.00028909696592438347, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:11:34,264 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7707657453149679, 'learning_rate': 0.0028731460724713076, 'weight_decay': 0.0004876649457069326, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:11:34,264 - INFO - Trial 959: Train MSE=2.1046750290053233, Train R²=0.6494067971195493
2024-10-31 22:11:34,265 - INFO - Trial 959: Test MSE=2.2436529908861433, Test R²=0.6346643652234759
2024-10-31 22:11:34,265 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:11:34,266 - INFO - Trial 959 finished with value: 2.2436529908861433 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7707657453149679, 'learning_rate': 0.0028731460724713076, 'weight_decay': 0.0004876649457069326, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:12:06,264 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7819712992834343, 'learning_rate': 0.005648949455768657, 'weight_decay': 0.00011437940405136886, 'batch_size': 512, 'tree_depth': 9}
2024-10-31 22:12:06,264 - INFO - Trial 960: Train MSE=2.163293195622308, Train R²=0.6400751982416425
2024-10-31 22:12:06,264 - INFO - Trial 960: Test MSE=2.214860098702567, Test R²=0.6395658850669861
2024-10-31 22:12:06,264 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:12:06,266 - INFO - Trial 960 finished with value: 2.214860098702567 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7819712992834343, 'learning_rate': 0.005648949455768657, 'weight_decay': 0.00011437940405136886, 'batch_size': 512, 'tree_depth': 9}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:12:36,030 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.749842302458492, 'learning_rate': 0.0015868631741620058, 'weight_decay': 0.00026760025079647994, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:12:36,030 - INFO - Trial 961: Train MSE=1.8621742512498582, Train R²=0.6896608471870422
2024-10-31 22:12:36,030 - INFO - Trial 961: Test MSE=2.252388289996556, Test R²=0.6334196584565299
2024-10-31 22:12:36,030 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:12:36,031 - INFO - Trial 961 finished with value: 2.252388289996556 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.749842302458492, 'learning_rate': 0.0015868631741620058, 'weight_decay': 0.00026760025079647994, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:13:39,331 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6652148012634232, 'learning_rate': 0.0013928860638994776, 'weight_decay': 0.0005121453509034131, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 22:13:39,331 - INFO - Trial 962: Train MSE=1.471099839146648, Train R²=0.7511052452027798
2024-10-31 22:13:39,331 - INFO - Trial 962: Test MSE=2.353690045220511, Test R²=0.6096676204885755
2024-10-31 22:13:39,331 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:13:39,332 - INFO - Trial 962 finished with value: 2.353690045220511 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6652148012634232, 'learning_rate': 0.0013928860638994776, 'weight_decay': 0.0005121453509034131, 'batch_size': 128, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:14:09,543 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7920215770965885, 'learning_rate': 0.0011916965120025336, 'weight_decay': 0.00031464030895790037, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:14:09,543 - INFO - Trial 963: Train MSE=2.018622270652226, Train R²=0.6632536692278725
2024-10-31 22:14:09,543 - INFO - Trial 963: Test MSE=2.240097556795393, Test R²=0.6353696584701538
2024-10-31 22:14:09,543 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:14:09,544 - INFO - Trial 963 finished with value: 2.240097556795393 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7920215770965885, 'learning_rate': 0.0011916965120025336, 'weight_decay': 0.00031464030895790037, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:14:37,914 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999035309031955, 'learning_rate': 0.0012956499896963427, 'weight_decay': 0.000560582823629913, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:14:37,914 - INFO - Trial 964: Train MSE=2.318552723952702, Train R²=0.6149906686374119
2024-10-31 22:14:37,914 - INFO - Trial 964: Test MSE=2.2591404063361034, Test R²=0.6323293788092477
2024-10-31 22:14:37,914 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:14:37,916 - INFO - Trial 964 finished with value: 2.2591404063361034 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7999035309031955, 'learning_rate': 0.0012956499896963427, 'weight_decay': 0.000560582823629913, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:15:07,735 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7707817722565804, 'learning_rate': 0.0016965493773888618, 'weight_decay': 0.00025975605825677705, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:15:07,735 - INFO - Trial 965: Train MSE=2.004064163991383, Train R²=0.6662526918309075
2024-10-31 22:15:07,735 - INFO - Trial 965: Test MSE=2.2547879900251115, Test R²=0.6329271197319031
2024-10-31 22:15:07,735 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:15:07,737 - INFO - Trial 965 finished with value: 2.2547879900251115 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7707817722565804, 'learning_rate': 0.0016965493773888618, 'weight_decay': 0.00025975605825677705, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:15:38,015 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7814268288032868, 'learning_rate': 0.0011398734173498496, 'weight_decay': 0.00027676231139789836, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:15:38,015 - INFO - Trial 966: Train MSE=2.7448765209742954, Train R²=0.5433687418699265
2024-10-31 22:15:38,015 - INFO - Trial 966: Test MSE=2.2298885583877563, Test R²=0.6370676670755658
2024-10-31 22:15:38,016 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:15:38,017 - INFO - Trial 966 finished with value: 2.2298885583877563 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7814268288032868, 'learning_rate': 0.0011398734173498496, 'weight_decay': 0.00027676231139789836, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:16:06,727 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7667513566899354, 'learning_rate': 0.00011946921652936034, 'weight_decay': 0.0004322500882397067, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:16:06,728 - INFO - Trial 967: Train MSE=7.237776739256723, Train R²=-0.20516058802604675
2024-10-31 22:16:06,728 - INFO - Trial 967: Test MSE=3.0685880524771556, Test R²=0.5007755841527667
2024-10-31 22:16:06,728 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:16:06,729 - INFO - Trial 967 finished with value: 3.0685880524771556 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7667513566899354, 'learning_rate': 0.00011946921652936034, 'weight_decay': 0.0004322500882397067, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:16:35,018 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7570977181804656, 'learning_rate': 0.0010278695595707528, 'weight_decay': 0.00037543085161703487, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:16:35,018 - INFO - Trial 968: Train MSE=2.140433426414217, Train R²=0.6439585579293114
2024-10-31 22:16:35,018 - INFO - Trial 968: Test MSE=2.2521094254084995, Test R²=0.6334289397512164
2024-10-31 22:16:35,018 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:16:35,020 - INFO - Trial 968 finished with value: 2.2521094254084995 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7570977181804656, 'learning_rate': 0.0010278695595707528, 'weight_decay': 0.00037543085161703487, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:17:02,940 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7912236239423277, 'learning_rate': 0.004688292252484051, 'weight_decay': 0.0002898266428784212, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 22:17:02,940 - INFO - Trial 969: Train MSE=2.118408794913973, Train R²=0.647826897246497
2024-10-31 22:17:02,940 - INFO - Trial 969: Test MSE=2.2444395508084978, Test R²=0.634676456451416
2024-10-31 22:17:02,940 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:17:02,941 - INFO - Trial 969 finished with value: 2.2444395508084978 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7912236239423277, 'learning_rate': 0.004688292252484051, 'weight_decay': 0.0002898266428784212, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:17:32,236 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7767588677912232, 'learning_rate': 0.007772295094553447, 'weight_decay': 0.00030674800541618684, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:17:32,237 - INFO - Trial 970: Train MSE=2.062762681927, Train R²=0.6558719830853599
2024-10-31 22:17:32,237 - INFO - Trial 970: Test MSE=2.223459039415632, Test R²=0.6380749259676252
2024-10-31 22:17:32,237 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:17:32,239 - INFO - Trial 970 finished with value: 2.223459039415632 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7767588677912232, 'learning_rate': 0.007772295094553447, 'weight_decay': 0.00030674800541618684, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:18:01,676 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7842410292962849, 'learning_rate': 0.0014944992277557414, 'weight_decay': 0.00017591864462360474, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:18:01,676 - INFO - Trial 971: Train MSE=2.176123538187572, Train R²=0.6380781552621296
2024-10-31 22:18:01,676 - INFO - Trial 971: Test MSE=2.2462148666381836, Test R²=0.6343897836548942
2024-10-31 22:18:01,676 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:18:01,677 - INFO - Trial 971 finished with value: 2.2462148666381836 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7842410292962849, 'learning_rate': 0.0014944992277557414, 'weight_decay': 0.00017591864462360474, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:18:29,256 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7920756932022877, 'learning_rate': 0.0012362114090025771, 'weight_decay': 0.0008964628464091786, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:18:29,256 - INFO - Trial 972: Train MSE=2.2776940039225986, Train R²=0.6203905876193728
2024-10-31 22:18:29,256 - INFO - Trial 972: Test MSE=2.2307372093200684, Test R²=0.6368848936898368
2024-10-31 22:18:29,256 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:18:29,258 - INFO - Trial 972 finished with value: 2.2307372093200684 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7920756932022877, 'learning_rate': 0.0012362114090025771, 'weight_decay': 0.0008964628464091786, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:18:58,727 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7723185747880542, 'learning_rate': 0.0023065964735164922, 'weight_decay': 0.0002578424915355685, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:18:58,727 - INFO - Trial 973: Train MSE=1.9570910590035575, Train R²=0.6741986210857119
2024-10-31 22:18:58,727 - INFO - Trial 973: Test MSE=2.253227949142456, Test R²=0.6333023054259164
2024-10-31 22:18:58,727 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:18:58,728 - INFO - Trial 973 finished with value: 2.253227949142456 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7723185747880542, 'learning_rate': 0.0023065964735164922, 'weight_decay': 0.0002578424915355685, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:19:27,404 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7360107963375154, 'learning_rate': 0.001349470104608296, 'weight_decay': 0.0002993093521980022, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 22:19:27,404 - INFO - Trial 974: Train MSE=1.853694600718362, Train R²=0.6914723813533783
2024-10-31 22:19:27,404 - INFO - Trial 974: Test MSE=2.2520177023751393, Test R²=0.6332006284168789
2024-10-31 22:19:27,404 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:19:27,405 - INFO - Trial 974 finished with value: 2.2520177023751393 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7360107963375154, 'learning_rate': 0.001349470104608296, 'weight_decay': 0.0002993093521980022, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:19:50,454 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7825805174912839, 'learning_rate': 0.0011252922136345033, 'weight_decay': 0.0003278634272117124, 'batch_size': 1024, 'tree_depth': 9}
2024-10-31 22:19:50,454 - INFO - Trial 975: Train MSE=2.9708143642970493, Train R²=0.5063865823405129
2024-10-31 22:19:50,454 - INFO - Trial 975: Test MSE=2.267633080482483, Test R²=0.6282691210508347
2024-10-31 22:19:50,455 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:19:50,455 - INFO - Trial 975 finished with value: 2.267633080482483 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7825805174912839, 'learning_rate': 0.0011252922136345033, 'weight_decay': 0.0003278634272117124, 'batch_size': 1024, 'tree_depth': 9}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:20:20,154 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7653600521360104, 'learning_rate': 0.0026934584915628097, 'weight_decay': 0.00041546000173370566, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:20:20,154 - INFO - Trial 976: Train MSE=1.8889449025903429, Train R²=0.6852405795029232
2024-10-31 22:20:20,154 - INFO - Trial 976: Test MSE=2.2283405576433455, Test R²=0.6370874813624791
2024-10-31 22:20:20,154 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:20:20,155 - INFO - Trial 976 finished with value: 2.2283405576433455 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7653600521360104, 'learning_rate': 0.0026934584915628097, 'weight_decay': 0.00041546000173370566, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:20:48,333 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7915130461383717, 'learning_rate': 0.0009658828008233668, 'weight_decay': 0.0002797070298851542, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:20:48,333 - INFO - Trial 977: Train MSE=2.5244286230632236, Train R²=0.5805516072681972
2024-10-31 22:20:48,333 - INFO - Trial 977: Test MSE=2.2628914628710066, Test R²=0.6317092435700553
2024-10-31 22:20:48,334 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:20:48,335 - INFO - Trial 977 finished with value: 2.2628914628710066 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7915130461383717, 'learning_rate': 0.0009658828008233668, 'weight_decay': 0.0002797070298851542, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:21:17,671 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7532724086131726, 'learning_rate': 0.001842387841844752, 'weight_decay': 0.00034532012477240414, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 22:21:17,671 - INFO - Trial 978: Train MSE=1.8597854929310935, Train R²=0.6902436401162829
2024-10-31 22:21:17,671 - INFO - Trial 978: Test MSE=2.2748100417000905, Test R²=0.6295333504676819
2024-10-31 22:21:17,671 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:21:17,673 - INFO - Trial 978 finished with value: 2.2748100417000905 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7532724086131726, 'learning_rate': 0.001842387841844752, 'weight_decay': 0.00034532012477240414, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:21:57,722 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7759928620512017, 'learning_rate': 0.0010735666376868592, 'weight_decay': 0.00010521787923436985, 'batch_size': 256, 'tree_depth': 11}
2024-10-31 22:21:57,722 - INFO - Trial 979: Train MSE=1.9306897904191698, Train R²=0.6767039149999619
2024-10-31 22:21:57,722 - INFO - Trial 979: Test MSE=2.233704992703029, Test R²=0.634629773242133
2024-10-31 22:21:57,722 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:21:57,723 - INFO - Trial 979 finished with value: 2.233704992703029 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7759928620512017, 'learning_rate': 0.0010735666376868592, 'weight_decay': 0.00010521787923436985, 'batch_size': 256, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:22:26,569 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6392265672320889, 'learning_rate': 0.0012159533849202151, 'weight_decay': 0.00026922823531546784, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:22:26,569 - INFO - Trial 980: Train MSE=1.346327258007867, Train R²=0.7752141505479813
2024-10-31 22:22:26,569 - INFO - Trial 980: Test MSE=2.334876503263201, Test R²=0.6196872166224888
2024-10-31 22:22:26,569 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:22:26,571 - INFO - Trial 980 finished with value: 2.334876503263201 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.6392265672320889, 'learning_rate': 0.0012159533849202151, 'weight_decay': 0.00026922823531546784, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:22:56,446 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7995916511760714, 'learning_rate': 0.0014334367269013128, 'weight_decay': 0.00045236966022822815, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 22:22:56,446 - INFO - Trial 981: Train MSE=1.8533671498298645, Train R²=0.6900359434740884
2024-10-31 22:22:56,446 - INFO - Trial 981: Test MSE=2.307937043053763, Test R²=0.6243241514478411
2024-10-31 22:22:56,446 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:22:56,447 - INFO - Trial 981 finished with value: 2.307937043053763 and parameters: {'hidden_layers': 1, 'hidden_units': 1024, 'dropout_rate': 0.7995916511760714, 'learning_rate': 0.0014334367269013128, 'weight_decay': 0.00045236966022822815, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:23:27,555 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7853520126323998, 'learning_rate': 0.0008909887275902666, 'weight_decay': 0.000315885818790254, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 22:23:27,555 - INFO - Trial 982: Train MSE=2.5818016614232744, Train R²=0.5700589439698628
2024-10-31 22:23:27,555 - INFO - Trial 982: Test MSE=2.245649082320077, Test R²=0.6345332520348685
2024-10-31 22:23:27,555 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:23:27,557 - INFO - Trial 982 finished with value: 2.245649082320077 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7853520126323998, 'learning_rate': 0.0008909887275902666, 'weight_decay': 0.000315885818790254, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:23:56,660 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7999509996029371, 'learning_rate': 0.0013044246477827445, 'weight_decay': 0.00029400470078281025, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:23:56,660 - INFO - Trial 983: Train MSE=2.637211399418967, Train R²=0.5609954978738513
2024-10-31 22:23:56,660 - INFO - Trial 983: Test MSE=2.216203655515398, Test R²=0.6392025862421308
2024-10-31 22:23:56,660 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:23:56,661 - INFO - Trial 983 finished with value: 2.216203655515398 and parameters: {'hidden_layers': 2, 'hidden_units': 256, 'dropout_rate': 0.7999509996029371, 'learning_rate': 0.0013044246477827445, 'weight_decay': 0.00029400470078281025, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:24:24,131 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7603670608420866, 'learning_rate': 0.0010464027980846488, 'weight_decay': 0.00025301039847240125, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:24:24,131 - INFO - Trial 984: Train MSE=2.112106340272086, Train R²=0.647969684430531
2024-10-31 22:24:24,131 - INFO - Trial 984: Test MSE=2.2487263679504395, Test R²=0.6339348639760699
2024-10-31 22:24:24,131 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:24:24,132 - INFO - Trial 984 finished with value: 2.2487263679504395 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7603670608420866, 'learning_rate': 0.0010464027980846488, 'weight_decay': 0.00025301039847240125, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:24:53,057 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7746785620442619, 'learning_rate': 0.0015452321816011383, 'weight_decay': 0.0002802337538099016, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 22:24:53,057 - INFO - Trial 985: Train MSE=2.0777695732457295, Train R²=0.6544520131179264
2024-10-31 22:24:53,057 - INFO - Trial 985: Test MSE=2.20168673992157, Test R²=0.6417153051921299
2024-10-31 22:24:53,057 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:24:53,058 - INFO - Trial 985 finished with value: 2.20168673992157 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7746785620442619, 'learning_rate': 0.0015452321816011383, 'weight_decay': 0.0002802337538099016, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:25:20,734 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7826260324073899, 'learning_rate': 0.001764875543332977, 'weight_decay': 0.00027746777439140673, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 22:25:20,734 - INFO - Trial 986: Train MSE=2.119931344475065, Train R²=0.6452347721372332
2024-10-31 22:25:20,734 - INFO - Trial 986: Test MSE=2.2573814562388828, Test R²=0.6325250012534005
2024-10-31 22:25:20,734 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:25:20,735 - INFO - Trial 986 finished with value: 2.2573814562388828 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7826260324073899, 'learning_rate': 0.001764875543332977, 'weight_decay': 0.00027746777439140673, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:26:22,099 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7998893180254708, 'learning_rate': 0.001760396381645825, 'weight_decay': 0.0002657059533170834, 'batch_size': 128, 'tree_depth': 11}
2024-10-31 22:26:22,099 - INFO - Trial 987: Train MSE=1.9206512873726231, Train R²=0.6741614198046071
2024-10-31 22:26:22,099 - INFO - Trial 987: Test MSE=2.2533665682588304, Test R²=0.626402708036559
2024-10-31 22:26:22,099 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:26:22,100 - INFO - Trial 987 finished with value: 2.2533665682588304 and parameters: {'hidden_layers': 1, 'hidden_units': 512, 'dropout_rate': 0.7998893180254708, 'learning_rate': 0.001760396381645825, 'weight_decay': 0.0002657059533170834, 'batch_size': 128, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:26:49,480 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7734999771730364, 'learning_rate': 0.0016122591900689911, 'weight_decay': 0.00028018954308740705, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:26:49,480 - INFO - Trial 988: Train MSE=2.013479709625244, Train R²=0.6649806478193828
2024-10-31 22:26:49,480 - INFO - Trial 988: Test MSE=2.2488666602543423, Test R²=0.6339053681918553
2024-10-31 22:26:49,480 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:26:49,481 - INFO - Trial 988 finished with value: 2.2488666602543423 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7734999771730364, 'learning_rate': 0.0016122591900689911, 'weight_decay': 0.00028018954308740705, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:27:17,986 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7906978255258972, 'learning_rate': 0.001596860403177774, 'weight_decay': 0.00026856821665245233, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 22:27:17,986 - INFO - Trial 989: Train MSE=2.19711657507079, Train R²=0.6342319441693169
2024-10-31 22:27:17,986 - INFO - Trial 989: Test MSE=2.2170993770871843, Test R²=0.6391538466726031
2024-10-31 22:27:17,986 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:27:17,988 - INFO - Trial 989 finished with value: 2.2170993770871843 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7906978255258972, 'learning_rate': 0.001596860403177774, 'weight_decay': 0.00026856821665245233, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:27:46,833 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7450856611491519, 'learning_rate': 0.0020015910883815634, 'weight_decay': 0.0002858749203898508, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:27:46,833 - INFO - Trial 990: Train MSE=2.1973068714141846, Train R²=0.6321726569107601
2024-10-31 22:27:46,833 - INFO - Trial 990: Test MSE=2.3180953093937466, Test R²=0.6225569929395404
2024-10-31 22:27:46,834 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:27:46,835 - INFO - Trial 990 finished with value: 2.3180953093937466 and parameters: {'hidden_layers': 1, 'hidden_units': 128, 'dropout_rate': 0.7450856611491519, 'learning_rate': 0.0020015910883815634, 'weight_decay': 0.0002858749203898508, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:28:16,817 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.3507572058113141, 'learning_rate': 0.0019119983410369843, 'weight_decay': 0.00014739928706716633, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:28:16,817 - INFO - Trial 991: Train MSE=0.5201010193143573, Train R²=0.9134776570967266
2024-10-31 22:28:16,817 - INFO - Trial 991: Test MSE=2.4401256697518483, Test R²=0.6025229522160122
2024-10-31 22:28:16,817 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:28:16,819 - INFO - Trial 991 finished with value: 2.4401256697518483 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.3507572058113141, 'learning_rate': 0.0019119983410369843, 'weight_decay': 0.00014739928706716633, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:28:46,377 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.765872253287371, 'learning_rate': 0.001525056161922213, 'weight_decay': 0.0002505854467500221, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:28:46,377 - INFO - Trial 992: Train MSE=2.0123485582215443, Train R²=0.6650603775467191
2024-10-31 22:28:46,377 - INFO - Trial 992: Test MSE=2.2495025907244, Test R²=0.6337905355862209
2024-10-31 22:28:46,377 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:28:46,378 - INFO - Trial 992 finished with value: 2.2495025907244 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.765872253287371, 'learning_rate': 0.001525056161922213, 'weight_decay': 0.0002505854467500221, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:29:13,948 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7794007300974958, 'learning_rate': 0.003988203388459522, 'weight_decay': 0.0002949596241477805, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 22:29:13,948 - INFO - Trial 993: Train MSE=1.9497667806489127, Train R²=0.6748942711523601
2024-10-31 22:29:13,948 - INFO - Trial 993: Test MSE=2.229491284915379, Test R²=0.6370961325509208
2024-10-31 22:29:13,948 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:29:13,950 - INFO - Trial 993 finished with value: 2.229491284915379 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7794007300974958, 'learning_rate': 0.003988203388459522, 'weight_decay': 0.0002949596241477805, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:29:42,173 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7914333365917562, 'learning_rate': 0.0015048142949633417, 'weight_decay': 0.0002605247390238081, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:29:42,173 - INFO - Trial 994: Train MSE=2.2089732757636478, Train R²=0.6327094222818103
2024-10-31 22:29:42,173 - INFO - Trial 994: Test MSE=2.2792329617909024, Test R²=0.6291871326310294
2024-10-31 22:29:42,173 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:29:42,175 - INFO - Trial 994 finished with value: 2.2792329617909024 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7914333365917562, 'learning_rate': 0.0015048142949633417, 'weight_decay': 0.0002605247390238081, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:30:11,873 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7848400864571772, 'learning_rate': 0.0017118097658753348, 'weight_decay': 0.0002747855628452236, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 22:30:11,873 - INFO - Trial 995: Train MSE=2.1277159111840382, Train R²=0.6455651691981724
2024-10-31 22:30:11,873 - INFO - Trial 995: Test MSE=2.288766247885568, Test R²=0.6274631704602923
2024-10-31 22:30:11,873 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:30:11,875 - INFO - Trial 995 finished with value: 2.288766247885568 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7848400864571772, 'learning_rate': 0.0017118097658753348, 'weight_decay': 0.0002747855628452236, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:30:39,463 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7712651754130136, 'learning_rate': 0.002235002619464578, 'weight_decay': 0.0002897275799841766, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:30:39,464 - INFO - Trial 996: Train MSE=1.9557636337620872, Train R²=0.6739928105047771
2024-10-31 22:30:39,464 - INFO - Trial 996: Test MSE=2.237571086202349, Test R²=0.635857743876321
2024-10-31 22:30:39,464 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:30:39,466 - INFO - Trial 996 finished with value: 2.237571086202349 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7712651754130136, 'learning_rate': 0.002235002619464578, 'weight_decay': 0.0002897275799841766, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:31:08,029 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7570102296497794, 'learning_rate': 0.0024452288263705785, 'weight_decay': 0.0002459991553600186, 'batch_size': 512, 'tree_depth': 11}
2024-10-31 22:31:08,029 - INFO - Trial 997: Train MSE=1.8539023867675237, Train R²=0.6910758891275951
2024-10-31 22:31:08,030 - INFO - Trial 997: Test MSE=2.26791478906359, Test R²=0.6307308333260673
2024-10-31 22:31:08,030 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:31:08,031 - INFO - Trial 997 finished with value: 2.26791478906359 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7570102296497794, 'learning_rate': 0.0024452288263705785, 'weight_decay': 0.0002459991553600186, 'batch_size': 512, 'tree_depth': 11}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:31:37,061 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7910015569357947, 'learning_rate': 0.0015019341043014465, 'weight_decay': 0.00027838226316567564, 'batch_size': 512, 'tree_depth': 10}
2024-10-31 22:31:37,061 - INFO - Trial 998: Train MSE=2.3323860679353987, Train R²=0.6125780258859906
2024-10-31 22:31:37,061 - INFO - Trial 998: Test MSE=2.2652408395494734, Test R²=0.6313568949699402
2024-10-31 22:31:37,061 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:31:37,062 - INFO - Trial 998 finished with value: 2.2652408395494734 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7910015569357947, 'learning_rate': 0.0015019341043014465, 'weight_decay': 0.00027838226316567564, 'batch_size': 512, 'tree_depth': 10}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:32:05,680 - INFO - Parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7787336684896902, 'learning_rate': 0.0013880888672483964, 'weight_decay': 0.00026609628085411607, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 22:32:05,680 - INFO - Trial 999: Train MSE=2.1572770306042264, Train R²=0.640789344906807
2024-10-31 22:32:05,680 - INFO - Trial 999: Test MSE=2.24817088672093, Test R²=0.6339063729558673
2024-10-31 22:32:05,680 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-10-31 22:32:05,681 - INFO - Trial 999 finished with value: 2.24817088672093 and parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7787336684896902, 'learning_rate': 0.0013880888672483964, 'weight_decay': 0.00026609628085411607, 'batch_size': 512, 'tree_depth': 12}. Best is trial 601 with value: 2.1809195450374057.
2024-10-31 22:32:05,682 - INFO - 最佳參數: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.7995991491433455, 'learning_rate': 0.005623627734610015, 'weight_decay': 0.00024797053276969004, 'batch_size': 512, 'tree_depth': 12}
2024-10-31 22:32:05,682 - INFO - 最低 MSE: 2.1809195450374057
2024-11-01 00:30:30,736 - INFO - A new study created in memory with name: no-name-cd8f3c62-cf99-416f-816f-b6cd85a13587
2024-11-01 00:31:00,291 - INFO - Parameters: {'hidden_layers': 2, 'hidden_units': 320, 'dropout_rate': 0.7966668141660387, 'learning_rate': 0.005155903963673008, 'tree_depth': 13}
2024-11-01 00:31:00,292 - INFO - Trial 0: Train MSE=2.1258848820413863, Train R²=0.6469940160002027
2024-11-01 00:31:00,292 - INFO - Trial 0: Test MSE=2.2472220829554965, Test R²=0.6343313881329128
2024-11-01 00:31:00,292 - INFO - ============================================================================================================================================================================================================================================================================================================
2024-11-01 00:31:00,293 - INFO - Trial 0 finished with value: 2.2472220829554965 and parameters: {'hidden_layers': 2, 'hidden_units': 320, 'dropout_rate': 0.7966668141660387, 'learning_rate': 0.005155903963673008, 'tree_depth': 13}. Best is trial 0 with value: 2.2472220829554965.
2024-11-01 00:31:05,807 - WARNING - Trial 1 failed with parameters: {'hidden_layers': 1, 'hidden_units': 256, 'dropout_rate': 0.8480040207010648, 'learning_rate': 0.005446263033722706, 'tree_depth': 12} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\optuna\study\_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\3998281780.py", line 45, in objective
    metrics = trainer.fit(dl_train, dl_test, num_epochs=100)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\2713248567.py", line 80, in fit
    train_loss, train_r2 = self.train_step(dataloader_train)
  File "C:\Users\Nico\AppData\Local\Temp\ipykernel_32248\2713248567.py", line 36, in train_step
    self.optimizer.step()  # 更新權重
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\optim\optimizer.py", line 484, in wrapper
    out = func(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\optim\optimizer.py", line 89, in _use_grad
    ret = func(self, *args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\optim\adam.py", line 226, in step
    adam(
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\optim\optimizer.py", line 161, in maybe_fallback
    return func(*args, **kwargs)
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\optim\adam.py", line 766, in adam
    func(
  File "c:\Users\Nico\anaconda3\envs\dev310-mldl\lib\site-packages\torch\optim\adam.py", line 536, in _multi_tensor_adam
    torch._foreach_mul_(device_exp_avg_sqs, beta2)
KeyboardInterrupt
2024-11-01 00:31:05,808 - WARNING - Trial 1 failed with value None.
